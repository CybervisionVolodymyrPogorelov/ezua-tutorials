[
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#release-notes",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.26",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-26",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.26",
      "lvl3": "Version 0.26.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-26-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.26",
      "lvl3": "Version 0.26.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-26-0",
    "content": "Release Date: September 25, 2023 Breaking Changes Kubernetes: Remove the agent_reattach_enabled config option. Agent reattach is now always enabled. Agent: Take the default value for the --visible-gpus option from the CUDA_VISIBLE_DEVICES or ROCR_VISIBLE_DEVICES environment variables, if defined. New Features SDK: Add the ability to keep track of what experiments use a particular checkpoint or model version for inference. SDK: Add Checkpoint.get_metrics and ModelVersion.get_metrics methods. Kubernetes: Support enabling and disabling agents to prevent Determined from scheduling jobs on specific nodes. Upgrading from a version before this feature to a version after this feature only on Kubernetes will cause queued allocations to be killed on upgrade. Users can pause queued experiments to avoid this. Improvements Enable reporting and display of metrics with floating-point epoch values. API: Allow the reporting of duplicate metrics across multiple report_metrics calls with the same steps_completed, provided they have identical values. SDK: stream_trials_training_metrics() and stream_trials_validation_metrics() are now deprecated. Please use stream_trials_metrics() instead. The corresponding methods of Determined and TrialReference have also been updated similarly. Bug Fixes Checkpoints: Fix an issue where in certain situations duplicate checkpoints with the same UUID would be returned by the WebUI and the CLI. Models: Fix a bug where det model describe and other methods in the CLI and SDK that act on a single model would error if two models had similar names. Workspaces: Fix an issue where notebooks, TensorBoards, shells, and commands would not inherit agent user group and agent user information from their workspace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.25",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-25",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.25",
      "lvl3": "Version 0.25.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-25-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.25",
      "lvl3": "Version 0.25.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-25-1",
    "content": "Release Date: September 11, 2023 Breaking Changes Fluent Bit is no longer used for log shipping and configs associated with Fluent Bit are now no longer in use. Fluent Bit has been replaced with an internal log shipper (the same one that is used for Slurm). Bug Fixes Reduce the time before seeing the first metrics of a new experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.25",
      "lvl3": "Version 0.25.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-25-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.25",
      "lvl3": "Version 0.25.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-25-0",
    "content": "Release Date: August 29, 2023 Breaking Changes Remove EstimatorTrial, which has been deprecated since Determined version 0.22.0 (May 2023). Bug Fixes Trials: Fix an issue where trial logs could fail for trials created prior to Determined version 0.17.0. CLI: Fix an issue where template association with workspaces, when listed, was missing. This would prevent templates from being listed for some users and templates on RBAC-enabled clusters.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.24",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-24",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.24",
      "lvl3": "Version 0.24.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-24-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.24",
      "lvl3": "Version 0.24.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-24-0",
    "content": "Release Date: August 18, 2023 Breaking Changes API: Remove LightningAdapter, which was deprecated in 0.23.1 (June 2023). We recommend that PyTorch Lightning users migrate to the Core API. New Features Environments: Add experimental PyTorch 2.0 images containing PyTorch 2.0.1, Python 3.10.12, and (for the GPU image) CUDA 11.8. Bug Fixes Users: Fix an issue that caused the CLI command det user list to always show \u201cfalse\u201d in the \u201cremote\u201d column.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-4",
    "content": "Release Date: July 31, 2023 Breaking Changes API: The /api/v1/users/setting endpoint no longer accepts storagePath and now accepts a settings array instead of a single setting. New Features Allow non-intersecting dictionaries of metrics to be merged on the same total_batches. This update was rejected before. API: Add a new patch API endpoint /api/v1/master/config that allows the user to make changes to the master config while the cluster is running. Currently, only changing the log config is supported. CLI: Add a new CLI command det master config --log --level <log_level> --color <on/off> that allows the user to change the log level and color settings of the master config while the cluster is still running. det master config can still be used to get the master config. Cluster: Allow binding resource pools to specific workspaces. Bound resource pools can only be used by the workspaces they are bound to. Each workspace can also now have a default compute resource pool and a default auxiliary resource pool configured. Kubernetes: Users may now populate all securityContext fields within the pod spec of the determined-container container except for RunAsUser and RunAsGroup. For those fields, use det user link-with-agent-user instead. WebUI: The experiment list page now has the following new capabilities: Select metrics and hyperparameters as columns. Filter the list on any available column. Specify complex filters. Sort the list on any available column. Display total number of experiments matching the filter. Compare metrics, hyperparameters, and trial details across experiments. Toggle between pagination and infinite scroll. Select preferred table density. Improvements WebUI: Improve performance and stability.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-3",
    "content": "Release Date: July 18, 2023 Breaking Changes API: Remove the /config endpoint, replaced by /api/v1/master/config. Improvements Notebooks: Upgrade the connection between the master and notebook tasks to use HTTPS for enhanced security. Deprecated Features API: Remove the SummarizeTrial endpoint favor of CompareTrials; CompareTrials sends a similar request with the trial_id parameter replaced by the trial_ids array. API: Remove the scale from the CompareTrialsRequest endpoint; this was used only for LTTB downsampling, which has since been replaced.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-2",
    "content": "Release Date: July 05, 2023 New Features CLI: det deploy gcp up now uses a default Google Cloud Storage bucket $PROJECT-ID-determined-deploy to store the Terraform state unless a local Terraform state file is present or a different Cloud Storage bucket is specified. CLI: A new list function det deploy gcp list --project-id <project_id> was added that lists all clusters under the default Cloud Storage bucket in the given project. Clusters from a particular Cloud Storage bucket can also be listed using det deploy gcp list --project-id <project_id> --tf-state-gcs-bucket-name <tf_state_gcs_bucket_name>. CLI: A new delete subcommand det deploy gcp down --cluster-id <cluster_id> --project-id <project_id> was added that deletes a particular cluster from the project. det deploy gcp down can still be used to delete clusters with local Terraform state files.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-1",
    "content": "Release Date: June 21, 2023 Improvements Errors: Errors that return 404 or \u2018Not Found\u2019 codes now have standardized messaging using the format \u201c<task/trial/workspace etc.> <ID> not found\u201d. In addition, if RBAC is enabled, the error message includes a suffix to remind users to check their permissions. This is because with RBAC enabled, permission denied errors and not found errors both return a \u2018Not Found\u2019 response. Deprecated Features LightningAdapter is deprecated and will be removed in a future version. We recommend that PyTorch Lightning users migrate to the Core API. Bug Fixes Users: Resolved an issue that was causing an error when attempting to create a new user with a username that was previously used by a renamed user.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.23",
      "lvl3": "Version 0.23.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-23-0",
    "content": "Release Date: June 05, 2023 Breaking Changes Remove HDFS checkpoint storage support, which has been deprecated since 0.21.1 (April 2023). Kubernetes: When a pod spec is specified in both task_container_defaults and the experiment/job configuration, the pod spec is merged according to strategic merge patch. The previous behavior was using only the experiment/job configuration if supplied. CLI: The det notebook|tensorboard start commands no longer block for the whole life cycle of the notebook or TensorBoard process. They will also not stream related event logs. Users should use the existing det notebook|tensorboard|task logs commands to stream logs from the process. Python SDK: Remove the packages determined-cli, determined-common, and determined-deploy, which were deprecated in 0.15.0 (April 2021). The submodules determined.cli, determined.common, and determined.deploy of the determined package should be used instead. New Features Experiment: Custom hyperparameter searchers can include extra directories to pass into the client.create_experiment context. Checkpoints: Add support for deleting a subset of files from checkpoints. The SDK method determined.experimental.client.Checkpoint.remove_files() has been added to delete files matching a list of globs provided. The CLI command det checkpoint rm uuid1,uuuid2 --glob 'deleteDir1/**' --glob deleteDir2 provides access to this method. AWS and GCP: Add launch_error_timeout and launch_error_retries provider configuration options. launch_error_timeout: Duration for which a provisioning error is valid. Tasks that are unschedulable in the existing cluster may be canceled. After the timeout period, the error state is reset. Defaults to 0s. launch_error_retries: Number of retries to allow before registering a provider provisioning error. Defaults to 0. DeepSpeed experiments can now be wrapped with the determined.pytorch.dsat module to automatically tune their distributed training hyperparameters. API: GetExperiments(archived=False) no longer lists experiments from archived projects or workspaces. This change affects both the WebUI and the CLI. Unarchived projects and workspaces are not affected. Improvements CLI: det user list will not display the Admin column when RBAC is enabled. Checkpoints: In checkpoint-related views and APIs, the previously hidden file metadata.json is now visible.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-2",
    "content": "Release Date: May 24, 2023 Improvements Cluster: Slurm/PBS requires HPC Launcher 3.2.9. The HPC Launcher includes new support to enable improved scalablity. When used with Slurm or PBS, the launcher must be version 3.2.9 or greater. Bind mounts for notebooks (and other commands) can be configured with --config. For example usage, see the section for --config in det command run --help. Trials: Reporting a training or validation metric with the epoch set to a non-numeric value will now return an error. Deprecated Features CLI: det template set <name> <config> has been deprecated. Removed Features API: Legacy APIs for trial details and trial metrics, which were deprecated in 0.19.2, have now been removed. API: Legacy APIs for experiment creation and updates, which were deprecated in 0.19.10, have now been removed. Bug Fixes CLI: det e list and det e list -a behaviors were erroneously switched. Earlier, det e list was showing both archived and unarchived experiments, and det e list -a was showing only unarchived experiments. This has now been fixed \u2014 det e list will show only unarchived experiments and det e list -a will show both archived and unarchived experiments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-1",
    "content": "Release Date: May 17, 2023 Bug Fixes Fix a critical regression in 0.22.0 that could lead to database deadlocks and incorrect experiment progress info when restarting trials after failure. Specifically, this problem may occur when the max_restarts experiment configuration option is set to a value greater than zero (default: 5). We advise all users running 0.22.0 to upgrade as soon as possible.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.22",
      "lvl3": "Version 0.22.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-22-0",
    "content": "Release Date: May 05, 2023 Breaking Change The previous template CRUD endpoints have been removed from the /templates/* location. Please use the APIs found at /api/v1/templates/*. Experiment: Optimizer must be an instance of tensorflow.keras.optimizers.legacy.Optimizer starting from Keras 2.11. Experiments now use images with TensorFlow 2.11 by default. TensorFlow users who are not explicitly configuring their training images will need to adapt their model code to reflect these changes. Users will likely need to use Keras optimizers located in tensorflow.keras.optimizers.legacy. Depending on the sophistication of users\u2019 model code, there may be other breaking changes. Determined is not responsible for these breakages. See the TensorFlow release notes for more details. PyTorch users and users who specify custom images should not be affected. Deprecated Features Legacy TensorFlow 1 + PyTorch 1.7 + CUDA 10.2 support is deprecated and will be removed in a future version. The final TensorFlow 1.15.5 patch was released in January 2021, and no further security patches are planned. Consequently, we recommend users migrate to modern versions of TensorFlow 2 and PyTorch. Our default environment images currently ship with tensorflow==2.11.1 and torch==1.12.0. EstimatorTrial is deprecated and will be removed in a future version. TensorFlow has advised Estimator users to switch to Keras since TensorFlow 2.0 was released. Consequently, we recommend users of EstimatorTrial switch to the TFKerasTrial class. Master config option logging.additional_fluent_outputs is deprecated and will be removed in a future version. We do not plan to offer a replacement at this time. If you are interested in additional logging integrations, please contact us. Improvement HP Search: Trials are persisted as soon as they are requested by the searcher, instead of after they are first scheduled. Trials: Metric storage has been optimized for reading summaries of metrics reported during a trial. Extended downtime may result when upgrading from a previous version to this version or a later version. This will occur when your cluster contains a large number of trials and training steps reported. For example, a database with 10,000 trials with 125 million training metrics on a small instance may experience 6 or more hours of downtime during the upgrade. (Optional) To minimize downtime, users with large databases can choose to manually run this SQL file against their cluster\u2019s database while it is still running before upgrading to a new version. This is an optional step and is only recommended for significantly large databases.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-2",
    "content": "Release Date: April 28, 2023 New Features Add the launch_error configuration option to the master config, which specifies whether to refuse experiments or tasks if they request more slots than the cluster has. See Master Configuration Reference for more information. Improvements CLI: Add det (experiment|trial|task) logs --json option, allowing users to get JSON-formatted logs for experiments, trials, and tasks. Cluster: HPC Launcher 3.2.7 migrates the resource_manager.job_storage_root to a more efficient format. This happens automatically, but once migrated you cannot downgrade to an older version of the HPC launcher. Cluster: The manage-singularity-cache script has added the --docker-login option to enable access to private Docker images. Removed Features The \u201chyperparameter importance\u201d feature and associated API endpoints have been removed. Bug Fixes Tasks: Fix an issue where task proxies were not recovered when running on Slurm. Tasks: Fix an issue where det task list would sometimes return an incorrect 404 error.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-1",
    "content": "Release Date: April 11, 2023 Breaking Change Remove old master logs /logs endpoint. Users should use /api/v1/master/logs instead. Bug Fixes Fix an issue introduced in 0.19.9 where task_container_defaults for the default resource pools were not respected for experiments and tasks unless they specified the resource pool name explicitly. Checkpoints: Fix an issue where checkpoint insertion on a cluster with a lot of checkpoints and reported metrics could take a long time. Kubernetes: Fix a crash affecting zero-slot workloads when resources.limits and resources.requests overrides were explicitly specified in the pod spec. Deprecated Features HDFS checkpoint storage support has been deprecated and will be removed in a future version. Please contact Determined if you still need it, or else migrate to a different storage backend. Improvement Cluster: Add HPC Launcher support for JVM resource configuration. The master configuration option resource_manager.launcher_jvm_args can be used to override the default HPC Launcher JVM heap configuration. This support requires HPC Launcher version 3.2.6 or greater. New Features Python SDK: Add methods for efficient export of training and validation metrics to the Python SDK. The methods are listed below. stream_trials_training_metrics() stream_trials_validation_metrics() stream_training_metrics() stream_validation_metrics() Removed Features The separate det-deploy executable was deprecated in 0.15.0 (April 2021) and is now removed. Use the det deploy subcommand instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.21",
      "lvl3": "Version 0.21.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-21-0",
    "content": "Release Date: March 27, 2023 Breaking Changes Cluster: K80 GPUs are no longer supported. API: Remove all old PATCH endpoints under /agents*, including the APIs for enabling and disabling slots. Users should use the new APIs under /api/v1/agents. API: The on_validation_step_start and on_validation_step_end callbacks on PyTorchTrial and DeepSpeedTrial were deprecated in 0.12.12 (Jul 2020) and have been removed. Please use on_validation_start and on_validation_end instead. Trial API: records_per_epoch has been dropped from PyTorch code paths. We were previously using this value internally to estimate epoch lengths. We are now using the chief worker\u2019s epoch length as the epoch length. API: average_training_metrics is no longer configurable. This value previously defaulted to false and was dropped to simplify the training API. We always average training metrics now. API: The unused latest_training field has been removed from the GetTrial and GetExperimentTrials APIs due to slow performance. Bug Fixes CLI: Fix an issue where det user change-password would return an authentication error when trying to change the current user\u2019s password. Improvements CLI: Command-line deployments will now default to provisioning NVIDIA T4 GPU instances instead of K80 instances. This change is intended to improve the performance/cost and driver support of the default deployment. Kubernetes: Ease permission requirements in Kubernetes so master no longer requires access to all Kubernetes namespaces. This only affects custom modified Helm chart configurations. Checkpoints: Improve performance of checkpoint insertion and deletion. New Feature API: Deprecate TorchWriter and add a PyTorch SummaryWriter object to PyTorchTrialContext and DeepSpeedTrialContext that we manage on behalf of users. See get_tensorboard_writer() for details. API: Introduce Trainer, a high-level training API for PyTorchTrial that allows for Python-side training loop customizations and includes support for off-cluster local training. Removed Features The following methods of Checkpoint, Model, and ModelVersion were deprecated in 0.17.9 (Feb 2022) and are now removed: Checkpoint.load() Checkpoint.load_from_path() Checkpoint.parse_metadata() Checkpoint.get_type() Checkpoint.from_json() Model.from_json() ModelVersion.from_json()",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.20",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-20",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.20",
      "lvl3": "Version 0.20.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-20-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.20",
      "lvl3": "Version 0.20.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-20-1",
    "content": "Release Date: March 15, 2023 Breaking Changes Database: Several unused columns have been dropped from the raw_steps, raw_validations, and raw_checkpoints database tables. The database migration will involve a sequential scan for these tables, and it may take a significant amount of time, depending on the database size and performance. New Features Tasks and experiments can now expose arbitrary ports that you can tunnel to using the CLI. To learn more about how to expose custom ports or see an example, check out Exposing Custom Ports or visit examples/features/ports. Container Images: Add maintained images for PyTorch-only environments. The current environment images contain both PyTorch and TensorFlow, resulting in large image sizes. The new images are appropriate for users who do not require TensorFlow but may still require TensorBoard. Removed Features API: Remove internal ExpCompareMetricNames and ExpCompareTrialsSample endpoints, which have been unused and deprecated since 0.19.5. Known Issue For multi-trial experiments, training metrics do not start appearing unless there has been at least one validation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.20",
      "lvl3": "Version 0.20.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-20-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.20",
      "lvl3": "Version 0.20.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-20-0",
    "content": "Release Date: February 28, 2023 Breaking Changes Cluster: The resources.agent_label task option and label agent config option are no longer supported and will be ignored. If you are not explicitly using these options, or only use a single empty or non-empty label value per resource pool, no changes are necessary. Otherwise, cluster admins should create a resource pool for each existing resource_pool/agent_label combination and reconfigure agents to use these new pools. Cluster users should update their tasks to use the new resource pool names. Bug Fixes Model Registry: Fix an issue where a model with versions from multiple workspaces could have its versions modified by a user with edit access to only a single one of those workspaces. WebUI: Patch an issue where logging out would not properly redirect to the login page. WebUI: Fix a bug where the cluster\u2019s job queue page could crash in certain cases. Improvements Agents: The master configuration agent_reattach_enabled is always enabled and agents will now always reattach containers on restart. Kubernetes: The cluster information page now takes resource quotas into account if there are any on relevant namespaces. RBAC: Model registry models and commands that are inaccessible to the user will appear as uneditable. Previously, users could attempt the action and would encounter a permission denied error. CLI: When listing TensorBoards, show workspaceName instead of workspaceId for better readability and prevent N/A values from appearing. New Features RBAC: Following on the initial RBAC support added in 0.19.7, the enterprise edition of Determined (HPE Machine Learning Development Environment) has added support for role-based access control (RBAC) over new entities: Notebooks, TensorBoards, shells, and commands are now housed under workspaces. Access to these tasks can now be restricted by role. Model Registry: Models are now associated with workspaces. Models can be moved between workspaces and access to them can be restricted by role. These changes allow for more granular control over who can access what resources. See RBAC for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-11",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-11",
    "content": "Release Date: February 17, 2023 Bug Fixes Kubernetes: Fix an issue where environment variables with an equals character in the value, such as func=f(x)=x, were processed incorrectly in Kubernetes. Agent: Fix a bug where if agent reattach was enabled and the master was down while an active task\u2019s Docker container failed, the task could get stuck in an unkillable running state. det deploy aws: Update CloudFormation permissions to allow checkpoint downloads through master. Tasks: Fix a bug where in rare cases tasks could take an extra 30 seconds to complete. Improvements Container Images: Publish multi-arch master and agent container image manifests with AMD64, ARM64, and PPC64 architectures. Experiments: If an experiment with no checkpoints is deleted, a checkpoint GC task will no longer be launched. Launching a checkpoint GC task could prevent experiments with certain incorrect configuration from being deleted. Cluster: Capability added for checkpoint downloads from Google Cloud Storage via a master instance. Installation: .deb and .rpm Linux packages will now install master and agent binaries into /usr/bin/ instead of /usr/local/bin/, to be more in line with the Filesystem Hierarchy Standard. Kubernetes: Empty environment variables can now be specified in Kubernetes, while before they would throw an error. Kubernetes: Zero-slot tasks on GPU clusters will not request nvidia.com/gpu: 0 resources any more, allowing them to be scheduled on CPU-only nodes. Installation: Add experimental Homebrew (macOS) package. Scheduler: The scheduler can be configured to find fits for distributed jobs against agents of different sizes. New Features CLI: Add a --add-tag flag to AWS det deploy aws up, which specifies tags to add to the underlying CloudFormation stack. New tags will not replace automatically added tags such as deployment-type or managed-by. Any added tags that should persist across updates should be always be included when using det deploy aws up \u2013 if the argument is missing, any previously added tags would be removed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-10",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-10",
    "content": "Release Date: January 20, 2023 Breaking Changes Kubernetes: Add the kubernetes_namespace config field for resource pools, specifying a Kubernetes namespace that tasks will be launched into. The name of the resource pool in Kubernetes has changed from \"kubernetes\" to \"default\". Forked experiments will need to have their configurations manually modified to update the resource pool name. New Features Cluster: Add support for experiment tag propagation. The enterprise edition of Determined (HPE Machine Learning Development) now allows for experiment tags to be propagated as labels to the associated jobs on the HPC cluster. A number of labeling schemes are supported, controlled by the configuration item resource_manager.job_project_source. Cluster: Add support for launcher-provided resource pools. The enterprise edition of Determined (HPE Machine Learning Development) now allows for custom resource pools to be defined that submit work to an underlying Slurm/PBS partition on an HPC cluster with different submission options. Cluster: Determined Enterprise Edition now supports the NVIDIA Enroot container platform as an alternative to Apptainer/Singularity/Podman. Improvements Notebooks: The default idle notebook termination timeout can now be set via the notebook_timeout master config option. Trials: Trials can now be killed when in the STOPPING_CANCELED state. Previously, if a trial did not implement preemption correctly and was canceled, the trial did not stop and was unkillable until the preemption timeout of an hour. Bug Fixes Fix a bug where notebooks, TensorBoards, shells, and commands restored after a master restart would have a submission time of when the master restarted rather than the original job submission time. det deploy aws: Fix reliability issue in efs deployment type, fix broken fsx deployment type. Job queue: Fix an issue where the CLI command det job list would ignore the argument --resource-pool. Distributed training: Fix a bug where a distributed training trial that called context.set_stop_requested would cause the trial to error and prevent it from completing successfully. Removed Features The data layer feature, which was deprecated in 0.18.0 (May 2022), has been removed. A migration guide to use the underlying yogadl library directly may be found here. Affected users are encouraged to follow the migration guide before upgrading to avoid downtime.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-9",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-9",
    "content": "Release Date: December 20, 2022 New Features WebUI: Display total checkpoint size for experiments. WebUI: Add links from forked experiments and continued trials to their parents. API: Add structured fields to task log objects. Cluster: Add support for launcher-provided resource pools. Determined Enterprise Edition now allows for custom resource pools to be defined that submit work to an underlying Slurm/PBS partition on an HPC cluster with different submission options. Cluster: Determined Enterprise Edition now supports the NVIDIA Enroot container platform as an alternative to Apptainer/Singularity/Podman.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-8",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-8",
    "content": "Release Date: December 02, 2022 Breaking Changes API: The GetModelVersion, PatchModelVersion, and DeleteModelVersion APIs now take a sequential model version number model_version_num instead of a surrogate key model_version_id. Bug Fixes Experiment: Fix an issue where experiments created before version 0.16.0 could have issues loading. Python SDK: Fix an issue where the Model Registry call model.get_version(version) did not work when a specific version was passed. Improvements Kubernetes: If a pod exits and Determined cannot get the exit code, the code will be set to 1025 instead of 137 to avoid confusion with potential out-of-memory issues. API: Patching a user will no longer make partial updates if an error occurs. Kubernetes: Specifying tensorboardTimeout in Helm will cause the specified timeout to be applied. AWS: det deploy aws will use IMDSv2 for improved security. New Features Experiment: Determined Enterprise Edition now allows control of the GPU type within a Slurm GRES expression. If you have partitions with mixed GPU types, you may now specify the desired type using the slurm.gpu_type attribute of the experiment configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-7",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-7",
    "content": "Release Date: November 14, 2022 New Features WebUI: Adds support for creating and managing webhooks to enable receiving updates regarding experiment state changes. Checkpoint storage can now be configured at a workspace level. Experiments created in projects will now inherit checkpoint storage configuration from the project\u2019s workspace if set. Experiment configuration can override the workspace level checkpoint storage configuration. Example: Textual Inversion training and generation using Stable Diffusion with Core API and Hugging Face\u2019s Diffusers. Python SDK now supports reading logs from trials, via the new logs() method. Additionally, the Python SDK also supports a new blocking call on an experiment to get the first trial created for an experiment via the await_first_trial() method. Users who have been writing automation around the det e create --follow-first-trial CLI command may now use the Python SDK instead, by combining .await_first_trial() and .logs(). RBAC: the enterprise edition of Determined (HPE Machine Learning Development Environment) has added preliminary support for Role-Based Access Control. Administrators can now configure which users or user groups can administer users, create or configure workspaces, run or view experiments in particular workspaces, or perform other actions. See RBAC for more information. Bug Fixes Master: Correctly handle pending allocations in historical resource allocation aggregation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-6",
    "content": "Release Date: October 28, 2022 Breaking Changes API: Remove the legacy endpoint /tasks/:task_id due to it always incorrectly returning a missing parameter. Experiment: Additional Slurm options formerly specified in the experiment environment section are now part of a new slurm section of the experiment configuration. For example, what was formerly written as environment: ... slurm: - --mem-per-cpu=10 - --exclusive is now specified as environment: ... slurm: sbatch_args: - --mem-per-cpu=10 - --exclusive Improvements CLI: Add the ls abbreviation for list to all applicable CLI commands. CLI: Support a new -i/--include option in task-starting CLI commands. The context option (--context) is useful for copying a directory of files into the task container, but it may only be provided once, and it can be clunky if you only care about one or two files. The --include option also copies files into the task container, but: The directory name is preserved, so -i my_data/ would result in a directory named my_data/ appearing in the working directory of the task container. It may point to a file, so -i my_data.csv will place my_data.csv into the working directory. It may be specified multiple times to include multiple files and/or directories. Breaking Change: det deploy aws by default now configures agent instances to automatically shut down if they lose their connection to the master. The --no-shut-down-agents-on-connection-loss option can be used to turn off this behavior. New Features Custom Searcher: users can now define their own logic to coordinate across multiple trials within an experiment. Examples of use cases are custom hyperparameter searching algorithms, ensembling, active learning, neural architecture search, reinforcement learning. See Custom Search Methods for more information. Cluster: The enterprise edition of HPE Machine Learning Development Environment can now be deployed on a PBS cluster. When using PBS scheduler, HPE Machine Learning Development Environment delegates all job scheduling and prioritization to the PBS workload manager. This integration enables existing PBS workloads and HPE Machine Learning Development Environment workloads to coexist and access all of the advanced capabilities of the PBS workload manager. You can use either Singularity or Podman for the container runtime.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 56
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-5",
    "content": "Release Date: October 10, 2022 Improvements Added the ability to set what Unix user and group tasks will run as on the agent at the workspace level. The setting takes precedence over users\u2019 individual user and group settings. CLI: The det workspace edit command now accepts a new workspace name as an optional --name flag, e.g., det workspace edit OLD_WORKSPACE_NAME --name NEW_WORKSPACE_NAME. Bug Fixes Agent: Fixed a bug where in certain cases of the master restarting with active tasks, the agent resource manager could prevent other tasks from running. Kubernetes: When a TensorBoard inherits its images from an experiment configuration, it now also inherits the environment.pod_spec.spec.imagePullSecrets value.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 57
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 58
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-4",
    "content": "Release Date: September 22, 2022 Breaking Changes det deploy aws: Remove --deployment-type=vpc option. Please use efs or fsx deployment types instead. API Changes The STATE_ACTIVE state for experiments and trials is now divided into four sub-states: STATE_QUEUED, STATE_PULLING, STATE_STARTING, and STATE_RUNNING. Queries to GetExperimentsRequest that filter by state continue to use STATE_ACTIVE. The possible states of tasks have been adjusted to match those of experiments and trials. The previous STATE_PENDING and STATE_ASSIGNED are now STATE_QUEUED. Bug Fixes Checkpoints: Fixed a bug where operations that listed checkpoints could sometimes return the same checkpoint multiple times.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 59
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 60
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-3",
    "content": "Release Date: September 09, 2022 Improvements Slurm: Singularity containers may now use AMD ROCm GPUs. Slurm: Podman V4.0+ is now supported in conjunction with the Slurm job scheduler. Kubernetes: The UID and GID of Fluent Bit logging sidecars may now be configured on a cluster-wide basis. New Features Example: Allow training of models that do not fit into GPU memory using DeepSpeed ZeRO Stage 3 with CPU offloading. Kubernetes: Allow the UID and GID of Fluent Bit logging sidecars to be configured on a cluster-wide basis.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 61
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 62
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-2",
    "content": "Release Date: August 26, 2022 Breaking Changes API: Response format for metrics has been standardized to return aggregated and per-batch metrics in a uniform way. GetTrialWorkloads, GetTrials API response format has changed. ReportTrialTrainingMetrics, ReportTrialValidationMetrics API request format has changed as well. API: GetJobs request format for pagination object has changed. Instead of being contained in a nested pagination object, these are now top level options, in line with the other paginatable API requests. CLI: det trial describe --json output format has changed. Fixed a bug where det trial describe --json --metrics would fail for trials with a very large number of steps. CLI: det job list will now return all jobs by default instead of a single API results page. Use --pages=1 option for the old behavior. The /api/v1/trials/:id endpoint no longer returns the workloads attribute. Workloads should instead be retrieved from the paginated /api/v1/trials/:id/workloads endpoint. Bug Fixes Kubernetes: Fixed an issue where restoring a job in a Kubernetes set up could crash the resource manager. CLI: Fixed a bug where det e set gc-policy would fail when deserializing an api response because it wasn\u2019t adjusted for the new format. Distributed training: Previously, experiments launched with determined.launch.torch_distributed were wrongly skipping torch.distributed.run for single-slot trials and invoking training scripts directly. As a result, functions such as torch.distributed.init_process_group() would fail, but only inside single-slot trials. Now, determined.launch.torch_distributed will conform to the intended behavior as a wrapper around torch.distributed.run and will invoke torch.distributed.run on all training scripts. Experiments with a single trial are now considered canceled when their trial is canceled or killed. Improvements API: GetTrialWorkloads can now optionally include per-batch metrics when includeBatchMetrics query parameter is set. New Features Cluster: The enterprise edition of Determined (HPE Machine Learning Development), can now be deployed on a Slurm cluster. When using Slurm, Determined delegates all job scheduling and prioritization to the Slurm workload manager. This integration enables existing Slurm workloads and Determined workloads to coexist and access all of the advanced capabilities of the Slurm workload manager. The Determined Slurm integration can use either Singularity or Podman for the container runtime.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 63
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 64
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-1",
    "content": "Release Date: August 11, 2022 Fixes Fix the Python SDK with Determined 0.19.0. An important endpoint broke in the 0.19.0 release, causing several Python SDK methods to break. Additional tests have been added to prevent similar breakages in the future. Improvements API: new on_training_workload_end and on_checkpoint_upload_end PyTorchCallback methods available for use with PyTorchTrial and DeepSpeedTrial. API: PyTorchTrial and DeepSpeedTrial callback `on_checkpoint_end deprecated in favor of on_checkpoint_write_end, re-named for clarity. New Features Web: Add a button to start a hyperparameter search experiment based on an experiment or trial. The button brings up a form allowing users to change searcher settings and hyperparameter ranges.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 65
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 66
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.19",
      "lvl3": "Version 0.19.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-19-0",
    "content": "Release Date: July 29, 2022 New Features Introduce a file system cache for model definition files, configured via cache.cache_dir in the master configuration. The default path is /var/cache/determined. Note that the master will crash on startup if the directory does not exist and cannot be created. Improvements Security: Setting registry_auth.serveraddress will now only send credentials to the server configured. Not setting registry_auth.serveraddress is now deprecated when registry_auth is set. In the future, serveraddress will be required whenever registry_auth is set. Agent: Users may now run docker login on agent host machines to authenticate with Docker registries. Note that if the agent is running inside a Docker container then ~/.docker/config.json will need to be mounted to $HOME/.docker/config.json (by default /root/.docker/config.json) inside the container. CLI: The Determined CLI now supports reading a username and password from the DET_USER and DET_PASS environment variables to avoid the need to run det user login, allowing for easier use of the CLI in scripts. det user login is still the preferred mechanism for most use cases of the CLI. Breaking Changes Experiment: The default value for the average_training_metrics experiment configuration option has been changed to true. This change only affects distributed training. The previous default of false leads to only the chief worker\u2019s training metrics being reported. Setting this configuration to true instead reports the true average of all workers\u2019 training metrics at the cost of increased communication overhead. Users who do not require accurate training metrics may explicitly set the value to false as an optimization. API: The /projects/:id/experiments endpoint has been removed and replaced with a project_id parameter on the /experiments endpoint. API: The config attribute in the response of the /experiments/:id endpoint has been moved into the experiment object. The config attribute is now also available for experiments returned from the /experiments endpoint. Bug Fixes When creating a test experiment, the container storage path was not being set correctly. Notebooks: Fix a bug where notebooks would ignore the --template CLI argument. Notebooks: Fix a bug where running det notebook start --preview would launch a notebook instead of just displaying the configuration. Kubernetes: Fix an issue where zero-slot tasks would use the GPU image instead of the CPU image. Kubernetes: Fix an issue where zero-slot tasks would incorrectly be exposed to all GPUs. Kubernetes: Fix an issue where the Helm option defaultPassword caused the deployment to hang. Ensure an allocation\u2019s recorded end time is always valid, even on restoration failures. Invalid end times could cause historical reporting rollups to fail. If there were any failures, they will be fixed by database migrations this update. Security Fixes Breaking Change PyTorch Lightning is no longer a part of Determined environments. When needed, it should be installed as part of startup hooks.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 67
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 68
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 69
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-4",
    "content": "Release Date: July 14, 2022 New Features Configuration: Add support for task_container_defaults.environment_variables in the master config, which allows users to specify a list of environment variables that will be set in the default task container environment. Web: Most user settings and preferences, like filters, are now persisted to the database. Users will now be able to retain their settings across devices. Bug Fixes Since 0.17.7, det experiment download-model-def $ID has been saving the downloaded tarballs as just $ID. This release corrects that behavior and names them experiment_$ID_model_def.tgz instead. Kubernetes: Fix a bug where following the link to live TensorBoards would redirect to the Uncategorized page. Ensure an allocation\u2019s recorded end time is always valid, even on restoration failures. Invalid end times could cause historical reporting rollups to fail. Previous failures, if any, will be fixed by database migrations this update. Improvements Add the resource pool field when listing experiments or commands in Kubernetes, where it was previously left blank.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 70
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 71
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-3",
    "content": "Release Date: July 07, 2022 Breaking Changes WebUI: Remove previously unlisted cluster page. This page has been replaced by a new version available through the navigation bar. New Features Workspaces & Projects: Teams can now organize related experiments into projects and workspaces. See video for a walkthrough. Logging: Master configuration now supports logging.additional_fluent_outputs allowing advanced users to specify custom integrations for task logs. Kubernetes: Task init containers no longer require root privileges. API: Trial API now uploads profiling data to the checkpoint storage from all workers. Core API users can now pass a new optional argument, tensorboard_mode, to core.init(). The default value is AUTO. In AUTO mode, TensorBoard metrics are written on the chief, and metrics as well as profiling data are uploaded to checkpoint storage from the chief only. In MANUAL mode, the user is responsible for writing TensorBoard metrics and uploading profiling data. In order to make that possible, two new methods are introduced on TrainContext: get_tensorboard_path() returns the path to the directory where metrics can be written and upload_tensorboard_files() uploads metrics and other files, such as profiling data, to checkpoint storage. Add support for recovering live commands, notebooks, TensorBoards, and shells on master restart. This is an extension of live trial recovery, available since version 0.18.1. Bug Fixes WebUI: Fix a bug where a previous resource pool selection would not update when a new resource pool is selected for viewing associated jobs. API: Fix a bug where /api/v1/tasks/{taskId} would often return incorrect allocation states. Since 0.17.15, there was a bug where task_container_defaults.registry_auth was not correctly passed to tasks, resulting in tasks being unable to pull images. Improvements CLI: Add new flag --agent-config-path to det deploy local agent-up allowing custom agent configs to be used. CLI: Add det (notebook|shell|tensorboard) list --json option, allowing user to get JSON-formatted notebook, shell or tensorboard task list. Configuration: Experiment configuration resources.shm_size now supports passing in a unit like 4.5 G or 128MiB.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 72
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 73
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-2",
    "content": "Release Date: June 14, 2022 Bug Fixes Web: Update task cards to only truncate task UUIDs and leave experiment IDs alone. CLI: Fix an issue for det task logs where trial task IDs and checkpoint GC task IDs could not be used. Agent: Fix being unable to use control-C to cancel the agent when it is connecting to master. Trial: Fix a bug where the rendezvous timeout warning could be printed erroneously. Commands: Fix an issue for commands where setting an environment variable as FOO instead of FOO=bar in environment.environment_variables causes the agent to panic. Fixes Prevent certain hangs when using one of Determined\u2019s built-in launchers, which begin in release 0.18.0. These hangs were caused by wrapper processes seeing SIGTERM but not passing it to their child process. Supports running in containers that do not have a /bin/which path, such as python-slim. The error was caused by accidentally hardcoding /bin/which instead of letting the shell find which on the path. Automatically add a determined_version key to the metadata of checkpoints created by any of the Trial APIs. This automatic key was accidentally dropped in release 0.18.0. Note that Core API checkpoints have full control over their checkpoint metadata and so are unaffected. Improvements Scheduler: Tasks now release resources as they become free instead of holding them until all resources are free. CLI: det deploy aws up, det deploy aws down, and det deploy gcp down now take --yes to skip prompts asking for confirmation. --no-prompt is still usable. Experiments: When attempting to delete an experiment, if the delete fails it is now retryable. Agents: Improve behavior and observability when agents lose WebSocket messages due to network failures. Trials: Trial logs will report some system events such as when a trial gets canceled, paused, killed, or preempted. New Features Kubernetes: Specifying observability.enable_prometheus in Helm will now correctly enable Prometheus monitoring routes. Kubernetes: Users may now specify a checkpointStorage.prefix in the Determined Helm chart if using S3 buckets for checkpoint storage. Checkpoints will now be uploaded with the path prefix whereas before it was ignored. CLI: Add new command det experiment logs <experiment-id> to get logs of the first trial of an experiment. Flags from det trial logs are supported. Configuration: Add support for checkpointStorage.prefix in master and experiment configuration for Google Cloud Storage (gcs). Security Fixes API: Endpoints under /debug/pprof now require authentication.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 74
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 75
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-1",
    "content": "Release Date: May 24, 2022 New Features Web: Themes have been introduced and styles have been adjusted to support various themes. Theme switching is currently limited to dark/light mode and is set first through OS-level preferences, then through browser-level preference. In-app controllers will be coming soon. Add experimental support for recovering live trials on master process restart. Users can restart the master (with updated configuration options or an upgraded software version), and the current running trials will continue running using the original configuration and harness versions. This requires the agent to reconnect within a configurable agent_reconnect_wait period. This is only available for the agent resource manager, and can be enabled for resource pools using the agent_reattach_enabled flag. May only be available for patch-level releases. Web: A trial restart counter has been added to the experiment detail header for single-trial experiments. For multi-trial experiments, trial restart counts are shown in a new Restarts column in the Trials table. Improvements Security: Improved security by requiring admin privileges for the following actions. Reading master config. Enabling or disabling an agent. Enabling or disabling a slot. Logging: Ensure logs for very short tasks are not truncated in Kubernetes. Web: Centralize sidebar options Cluster, Job Queues, and Cluster Logs into Cluster page for a simplified layout. Web: In order to provide a more precise view of resource pools, new fields like accelerator and warm slots have been added. Web: Clicking on resource pool cards will lead to a detail page, which also includes a Stats tab showing average queued time by day. Breaking Changes Security: The following routes and CLI commands now need admin privileges. /config /api/v1/master/config /api/v1/agents/:agent_id/enable /api/v1/agents/:agent_id/disable /agents/:agent_id/slots/:slot_id /api/v1/agents/:agent_id/slots/:slot_id/enable /api/v1/agents/:agent_id/slots/:slot_id/disable det master config det agent enable det agent disable det slot enable det slot disable Logging: The default Fluent Bit version in all deployment modes is now 1.9.3, changed from 1.6. Bug Fixes Web: Fix the user filtering for migrating from Determined 0.17.15 to Determined 0.18.0. API: Fix an issue where the POST /users endpoint always returned an error instead of the user\u2019s information, even when the user was created successfully.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 76
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 77
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.18",
      "lvl3": "Version 0.18.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-18-0",
    "content": "Release Date: May 09, 2022 New Features Add the Core API. The Core API is the first API offered by Determined that allows users to fully integrate arbitrary models and training loops into the Determined platform. All of the features offered by the higher-level Trial APIs, such as reporting metrics, pausing and reactivating, hyperparameter search, and distributed training, are now available to arbitrary models, frameworks, and training loops, with only light code changes. Breaking Change: Checkpoints: The Python SDK\u2019s Checkpoint.download() method now writes a differently formatted metadata.json file into the checkpoint directory. Previously, the JSON content in the file contained many system-defined fields, plus a metadata field that contained the user-defined metadata for the checkpoint, which was also available as a Python object as Checkpoint.metadata. Now, metadata.json contains only the user-defined metadata, and those metadata appear as top-level keys. Some of the fields which were previously system-defined are now considered user-defined, even though they are uploaded automatically in Trial-based training. This decision is in line with the Trial APIs now being optional\u2014that is, part of userspace\u2014after the release of the Core API. Job queue: Add support for dynamic job modification on Kubernetes using the job queue. Users can now use the WebUI or CLI to change the priority and queue position of jobs in k8s. To update jobs through the WebUI, go to the Job Queue section, find the target job, and click on the Manage Job option. To update jobs in the CLI, use the det job update command. Run det job update --help for more information. Bug Fixes CLI: API requests executed through the Python bindings have been erroneously using the SSL \u201cnoverify\u201d option since version 0.17.6, making them potentially insecure. The option is now disabled. Deprecated Features The Determined Data Layer has been deprecated and will be removed in a future version. New code should not begin using it, but we will assist existing users to migrate to using YogaDL directly before removing the feature. Removed Features Python API: The old experimental namespace methods for custom reducers in both PyTorchTrial and EstimatorTrial have been removed. The experimental names were deprecated in 0.15.2 (April 2021) when custom reducers were promoted to general availability. Any users who have not already migrated to the non-experimental namespace for custom reducer methods must do so. Searcher: Remove the PBT searcher, which was deprecated in version 0.17.6 (January 2022). API: Remove the notebook logs endpoint in favor of the new task logs endpoint. Python API: Remove the remaining parts of the Native API, which was deprecated in version 0.13.5 (September 2020). The only Native API functions that still remained were det.experimental.create() and det.experimental.create_trial_instance(). Python API: Remove the det.pytorch.reset_parameters() function, which was deprecated in 0.12.13 (August 2020).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 78
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 79
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.15",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-15",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 80
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.15",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-15",
    "content": "Release Date: April 22, 2022 Breaking Changes API: Endpoints for getting or updating a user now accept a userId instead of username as the path parameter. Bug Fixes Fix an issue where deleted experiments would get stuck in a DELETING state indefinitely due to their checkpoint GC tasks not completing. API: Fix an issue where a reported job state could be stale due to a faulty caching mechanism. This could have resulted in an experiment showing in queued or scheduled state, either in CLI or WebUI, when it was in the other state. New Features Add a translation of DeepSpeed\u2019s DCGAN example using the new DeepSpeedTrial API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 81
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.14",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-14",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 82
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.14",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-14",
    "content": "Release Date: April 13, 2022 Bug Fixes Resource Pool: Fix a bug that causes the resource pool and resource manager to crash after submitting a command with a non-default priority. We recommend that all users on 0.17.12 and 0.17.13 update to 0.17.14 or later.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 83
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-13",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 84
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-13",
    "content": "Release Date: April 07, 2022 New Features Support DeepSpeed with a new DeepSpeedTrial API. DeepSpeed is a powerful library for training large scale models. With the new DeepSpeedTrial you can combine all the benefits of Determined with the features available in DeepSpeed like the Zero Redundancy Optimizer and pipeline parallel training. We also provide an example based on Eleuther AI\u2019s GPT-NeoX repo to help you get started training state-of-the-art language models. CLI: Allow the CLI to accept any unique prefix of a task UUID to refer to the task, rather than requiring the entire UUID. In some places, Determined only displays the first few characters of a UUID. Improvements Model Hub: add support for panoptic segmentation. Model Hub mmdetection now supports panoptic segmentation task in addition to object detection. Previously, the associated Docker image lacked dependencies for panoptic segmentation. Users can now use mmdetection configs under panoptic_fpn and also the coco_panoptic dataset base config. Collect data for agent/instance start time and end time in order to track unused GPUs. Two new kinds (agent and instance) added to CSV report at Cluster page. API Changes The model registry API now accepts either the ID or model name in /api/v1/models/:id or /api/v1/models/:name. This applies to all API routes for models and model versions. The ID can be used in the API and the WebUI (/det/models/:id) as a permanent link to the model. Breaking Changes Changed the message body of PatchModelRequest and PatchModelVersionRequest such that the POST-ed body is the PatchModel or PatchModelVersion object, instead of being wrapped in { \"model\": PatchModel }. Updated typing hints on other Model Registry API endpoints to make it clear which fields will be returned in API responses. Bug Fixes Fix an issue where the originally requested page to redirect to after a previously successful authentication flow was not remembered. Fix an issue where trial logs may display timestamps twice.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 85
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-12",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 86
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-12",
    "content": "Release Date: March 28, 2022 New Features Job queue: Add support for dynamic job modification using the job queue. Users can use the WebUI or CLI to change the priority, weight, resource pool, and queue position of jobs without having to cancel and resubmit them. This feature is currently available for the fair share and priority schedulers. To update jobs through the WebUI, go to the Job Queue section and find the Manage Job option for a job. To update jobs using the CLI, use the det job update command. Run det job update --help for more information. Breaking Changes API: Remove these legacy endpoints: /:experiment_id /:experiment_id/checkpoints /:experiment_id/config /:experiment_id/summary /:experiment_id/metrics/summary /:trial_id/details /:trial_id/metrics The data from those endpoints are still available through the new REST API endpoints under the /api/v1/experiments/:experiment_id and /api/v1/trials/:trial\u1d62d prefixes. Improvements Images: Update default environment images to PyTorch 1.10.2, TensorFlow 2.8, and Horovod 0.24.2. Bug Fixes Database migrations: Ensure that migrations run in transactions. The lack of transactional migrations surfaced as a bug where, if the master was restarted during a migration, it would attempt to rerun the migration when it was already partially or wholly applied (but not marked as complete), resulting in various SQL errors on non-idempotent DDL statements. Distributed training: Allow multiple ranks within a distributed training job to report invalid hyperparameter exits. Previously, if more than one report was received, the experiment would fail.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 87
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-11",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 88
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-11",
    "content": "Release Date: March 14, 2022 New Features Add on_trial_startup() and on_trial_shutdown() methods to PyTorchCallback. Whenever on_trial_startup() is called, on_trial_shutdown() is always called before the trial container shuts down. These callbacks make it possible to do reliable resource management in a training container, such as if you wish to start a background thread or process for data loading and shut it down before the process exits.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 89
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-10",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 90
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-10",
    "content": "Release Date: March 03, 2022 Breaking Change API: PyTorch Lightning has been updated from 1.3.5 to 1.5.9 to address a security vulnerability. Experiments using PyTorch Lightning Adapter with v1.3.5 are no longer supported. New Features Added PyTorch example using Bootstrap Your Own Latent (BYOL) to do self-supervised, no labels, image classification. PyTorchTrial and TFKerasTrial now automatically log the number of batches and number of records in every training and validation workload, as well as the duration of the workload and the calculated batches per second and records per second to make tracking progress easier. All (non-experiment) task logs are now persisted. Task logs can be retrieved through the new det task logs CLI command, or the WebUI or REST API. Task logs are now accessible even after a master restart, or 72 hours post completion. Support specifying root certificates for the DB via the Determined Helm chart. This allows Determined to use SSL to connect to the DB without having to replace the master config manually. To use this feature, save the certificate in a configmap or secret and set the following values: sslMode, sslRootCert, resourceType, and certResourceName. Additional details can be found in the default values.yaml file.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 91
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-9",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 92
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-9",
    "content": "Release Date: February 11, 2022 New Features Python API: Add new framework-specific methods for loading checkpoints: determined.pytorch.load_trial_from_checkpoint_path() determined.keras.load_model_from_checkpoint_path() determined.estimator.load_estimator_from_checkpoint_path() These new methods are part of a larger effort to support more frameworks. Python API: Add on_training_epoch_end() method to PyTorchCallback. Add epoch_idx argument to on_training_epoch_start(). Overriding on_training_epoch_start without the epoch_idx argument is still supported for backward compatibility, but doing so is discouraged. Web: Add a column picker to the experiment list page to allow users to choose which table columns to display. Notebooks: Add a config field notebook_idle_type that changes how the idleness of a notebook is determined for the idle timeout feature. If the value is different from the default, users do not need to manually shut down kernels to allow the idle timeout to take effect. Web: Use the Page Visiblity API to detect changes in page visibility and avoid unnecessary polling, which can be expensive. While the user is not actively focused on the page, all polling is stopped; if the page becomes visible again, any previously active polling is restarted. Improvements Breaking Change: CLI: The det master config command now takes the --json and --yaml options to configure its output format, rather than -o <output>. Breaking Change: API: The /api/v1/preview-hp-search endpoint no longer includes units (epochs/records/batches) in its response. API: The PATCH /api/v1/experiments/:id route no longer uses a field mask. When you include a field in the body (e.g., notes or labels) that field will be updated, if it is excluded then it will remain unchanged. API: When an experiment successfully completes, its progress value will be set to 100% instead of 0% or null; when an experiment fails, its progress value will stay the same instead of being reset to 0% or null. API: Calls to /api/v1/experiments and /api/v1/experiments/:id will return a progress value of null instead of 0 in cases where the progress has not been recorded or was reset to null. Deprecations Python API: Checkpoint.load is deprecated. It should be replaced by determined.experimental.client.Checkpoint.download() along with the appropriate one of the new framework-specific functions for loading checkpoints. Python API: The following methods on objects in determined.experimental.client are formally deprecated (even though they were not technically public methods previously): Model.from_json Checkpoint.from_json Checkpoint.parse_metadata Checkpoint.get_type These methods will be removed in a future version. Removed Features API: Remove /searcher/preview, /checkpoints, and /checkpoints/:checkpoint_id/* endpoints from the legacy API. These functions were already replaced by the gRPC API (/api/v1/preview-hp-search and /api/v1/checkpoints) in the web UI, CLI, and tests.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 93
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-8",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 94
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-8",
    "content": "Release Date: February 3, 2022 Bug Fixes Distributed Training: Fix a bug that shows experiments in a COMPLETED state even if they errored out. We recommend that users of distributed training update to 0.17.8 or later.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 95
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-7",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 96
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-7",
    "content": "Release Date: January 26, 2022 Breaking Changes API: Routes with /api/v1/models/:id/* are replaced by /api/v1/models/:name/*. Spaces and special characters in a name must be URI-encoded. You can get a model by ID with /api/v1/models?id=<id>. API: On the list of models (/api/v1/models) the optional name parameter is now a case-sensitive match, unless you add the parameter name_case_insensitive=true. Python API: determined.experimental.client.Determined.get_model() now takes a name rather than an ID. Use determined.experimental.client.Determined.get_model_by_id() to get a model from its ID. Model Registry: New model names must not be blank, have a slash, have multiple spaces, only numbers, or be case-insensitive matches to an existing model name. Model Registry: Model names with a forward slash will replace the slash in the name with \u2018\u2013\u2018. Bug Fixes Master: Fix a bug in the priority scheduler where jobs with equal priority would be scheduled or preempted in an order not correctly respecting job submission time. Removed Features API: remove /experiment-list, /experiment-summaries, and /:experiment_id/kill endpoints from the legacy API. These functions are now replaced by the gRPC API (/api/v1/experiments) in the web UI, CLI, and tests.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 97
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 98
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-6",
    "content": "Release Date: January 20, 2022 New Features Master: Add support for systemd socket activation to the master. Scheduling/CLI: Add support for adjusting job priority and weight through the WebUI and CLI. Add experimental ROCm support. In the environment config for images and environment variables, the rocm key configures ROCm support. The gpu key has been renamed to cuda; gpu is still supported for backward compatibility, but its use is discouraged. Improvement Docs: Improve many pages to address onboarding gaps. Bug Fixes Master: Fix an issue where an update to an experiment\u2019s name wouldn\u2019t be reflected in its job representation until a master restart. Agent: Fix displayed CPU core count for CPU slots. WebUI: Fix an issue where the JupyterLab modal didn\u2019t pass the full config. WebUI: Fix the issue of the profiler filter UI not triggering updates. Improvements Logging: Decrease the volume of Docker image pull logs that are rendered into trial logs, and make the overall image pull progress more understandable by combining all layers\u2019 progress into a single progress bar. Deprecated Features Searcher: The Population Based Training searcher (pbt in the searcher config) will be removed in the next release. Model Registry: The API and Python interface will be returning to primarily identifying models based on their names, rather than their numeric IDs, in the next release. Removed Features Remove support for Python 3.6, which has reached end-of-life.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 99
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 100
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-5",
    "content": "Release Date: December 10, 2021 New Features Add reporting of job queue state. The ordering of jobs in the queue and their status can be viewed through Determined WebUI, and CLI. WebUI: Add buttons to the WebUI to create new models in the Model Registry, as well as add checkpoints as versions to existing models. The Register Checkpoint modal can be accessed through the Checkpoint modal. The New Model modal can be accessed through the Register Checkpoint modal or on the Model Registry page. API: Add a method for listing trials within an experiment. Improvements Agent: Improve handling of master connection failures. Bug Fixes Deploy: Fix a bug where GCP clusters created with --no-filestore still had unused filestores created.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 101
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 102
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-4",
    "content": "Release Date: November 30, 2021 New Features WebUI: Add the model registry as a new top-level navigation option, allowing for viewing, editing, and deleting existing models created using the CLI. Add experimental support for Multi-Instance GPUs (MIGs) to agent-based setups, in parity with the experimental support for MIGs in Kubernetes-based setups. Static agents and Kubernetes clusters may be able to use MIG instances for some workloads. Distributed training is not supported, and all MIG instances and nodes within a resource pool must still be homogeneous. Improvements Breaking Change: Model Registry: The names of models in the model registry must now be unique. If multiple models were previously created with the same name in the registry, the names will change. Model Registry CLI: Allow models to be referred to by their now-unique names, not only by ID. Tasks: Historical usage over users now properly accounts for all task types (commands, notebooks, etc.), not just trials. Images: Add environment images for TF 2.7. Agent: The environment.force_pull_image: true option no longer deletes the environment image before re-pulling it. Now, it will only fetch updated layers, which is much less wasteful of network resources and execution time. Bug Fixes Master: Fix a bug where deleting experiments with trial restarts always failed, and then failed to be marked as failed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 103
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 104
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-3",
    "content": "Release Date: November 12, 2021 Improvements Model Registry APIs: Add PATCH and DELETE endpoints to update the attributes of models and model versions. Model Registry: Allow models to be deleted only by the user who created them. Security and Logging: When a job is run on Kubernetes as a non-root user, the corresponding Fluent Bit sidecar will also run as a non-root user. Deploy: det deploy will now confirm potentially destructive updates on AWS unless --no-prompt is specified. Bug Fixes Model Registry APIs: Change the /models/{}/versions/{} to accept model ID as an int.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 105
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 106
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-2",
    "content": "Release Date: October 29, 2021 New Features Model Registry APIs: Add new APIs to create a model with labels and to update the labels of an existing model. Improvements Breaking Change: Deploy: det deploy now uses cloud images that use the NVIDIA Container Toolkit on agent hosts instead of relying on an older NVIDIA runtime, and custom images should be updated to do the same. Determined will no longer override the default container runtime according to the workload. Breaking Change: Model Registry APIs: Require name in the body rather than the URL for the post_model endpoint. Breaking Change: Model Registry APIs: Use model ID (integer) instead of name (string) as the lookup parameter for the get_model and get_model_versions endpoints. Docs: Switch to the Furo Sphinx theme, which fixes searching in the docs. Bug Fixes Model Registry APIs: Sort models by name, description, and other attributes. Harness: Represent infinite and NaN metric values as strings in JSON. WebUI: Convert infinite and NaN value strings to numeric metrics. WebUI: Report login failures caused by the cluster being unreachable.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 107
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 108
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-1",
    "content": "Release Date: October 18, 2021 New Features WebUI: Add a \u201cNotes\u201d tab allowing for the input and viewing of free-form Markdown text on experiment pages. This works for both single-trial experiments and trials within a multi-trial experiment. Improvements Docs: reorganize documents to be more user-friendly. Merge some how-to guides, topic guides, and reference guides. Users should now need to read very few documents to understand what they need to do in Determined rather than having to jump around between documents. Merge most information on best practices into how-to guides so that users find out about best practices as soon as they learn how to use something. Decompose the top-level FAQ document and move different parts of it to relevant pages so that users can develop a better expectation of what common issues they might hit. Profiler: samples_per_second in PyTorch now reflects samples across all workers. Database migrations: Run upgrades in transactions to improve stability. Bug Fixes Deploy: Fix an issue where the default checkpoint storage directory was not created for some users.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 109
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 110
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.17",
      "lvl3": "Version 0.17.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-17-0",
    "content": "Release Date: September 28, 2021 Breaking Changes Deploy: Remove --auto-bind-mount support from det deploy local. The new --auto-work-dir feature should be a strictly better experience. Users who depended on the shared_fs directory created by --auto-bind-mount can implement the same behavior by calling det deploy local cluster_up with a --master-config-path pointing to a master.yaml file containing the following text: task_container_defaults: bind_mounts: container_path: ./shared_fs host_path: /path/to/your/HOME/dir Deploy: This version of det deploy will not be able to deploy previous versions of Determined. If you need to deploy an older version, please use a matching version of the determined package. Experiment: Include maxval in int-type hyperparameter ranges. Previously, the docs said that the endpoints of the hyperparameter were both inclusive, but in reality the upper limit maxval was never actually selected. The reproducibility of hyperparameter selection may differ between Determined v0.16.5 and v0.17.0 for hyperparameter searches containing int-type hyperparameters as a result of this fix. However, the reproducibility of model training for any given set of hyperparameters should be unaffected. API: Endpoints no longer return the start times of workloads (training, validation, and checkpoints). This is part of a longer move to model metrics and workloads separately as part of the upcoming generic API. CLI: det master config now outputs YAML instead of JSON by default. To obtain the old behavior, run det master config -o json. New Features Notebooks/TensorBoards: Support a configurable timeout field idle_timeout that will cause notebook and TensorBoard instances to automatically shut down after a period of idleness. A notebook is considered to be idle if no kernels or terminals are running and there is no network traffic going to the server. A TensorBoard is considered to be idle if there is no network traffic going to the server. Note that if you open a notebook file it might open a kernel for you, and the kernels and the terminals will not be shut down automatically. You need to manually shut down the kernels to make the idle timeout effective. Deploy: Add a new --auto-work-dir feature to det deploy local. Setting --auto-work-dir /some/path will have two effects: first, /some/path will be bind-mounted into the container (still as /some/path); second, interactive jobs (notebooks, shells, and commands) will run in the provided working directory by default. Note that containers run as the root user by default, so you may want to configure your user with det user such that interactive jobs run as your regular user. Commands/shells/notebooks: Support configuring the working directory using the work_dir configuration field for commands, shells, and notebooks. You can also optionally set it in the task_container_defaults.work_dir field of the master configuration. The value set in the master configuration will be ignored when a context directory is submitted. WebUI: Allow experiment owners to delete their own experiments, singly or in batches. WebUI: Display the latest log entry available for a trial at the bottom of the trial\u2019s page. This works for both single-trial experiments and trials within a multi-trial experiment. WebUI: Add support for displaying NaN and Infinity metric values. Model Hub: Support the MMDetection library to easily train object detection models. MMDetection provides efficient implementations of popular object detection methods like Mask R-CNN, Faster R-CNN, and DETR on par with Detectron2. In addition, cutting-edge approaches from academia are regularly added to the library. Deploy: Add the ability to use customizable master configuration templates in det deploy aws|gcp. Images: Add an environment image for CPU-only TensorFlow 2.5 and 2.6. Improvements API: The aggregated historical resource allocation APIs /api/v1/resources/allocation/aggregated and /allocation/aggregated now account for all resources, not just those allocated to experiments. Images: Add CPU-only images for TF 2.5 and 2.6. Images: Upgrade JupyterLab to version 3.1. Images: TF 2.5 and 2.6 images will no longer include PyTorch builds. For PyTorch 1.9, please use the combined TF 2.4/PyTorch 1.9 image. Images: TF 2.4, 2.5, 2.6, and PyTorch 1.9 images will now use Python 3.8. The legacy TF 1.15/PyTorch 1.7 image will continue to use Python 3.7. Changes WebUI: Change the task list page to open new tabs when user clicks on task links. WebUI: The trial detail page will no longer show workload-based start time information, including training time, validation time, and checkpoint time. Bug Fixes WebUI: Fix continuing trials with nested hyperparameters.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 111
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 112
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 113
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-5",
    "content": "Release Date: September 3, 2021 New Features Support custom PyTorch data loaders with PyTorchTrial. You may now call context.experimental.disable_dataset_reproducibility_checks() in your trial\u2019s __init__() method, which will allow you to return arbitrary DataLoader objects from build_training_data_loader() and build_validation_data_loader(). This is desirable when your data loader is not compatible with Determined\u2019s det.pytorch.DataLoader. The usual dataset reproducibility that det.pytorch.DataLoader provides is still possible to achieve, but it is your responsibility. You may find the Sampler classes in determined.pytorch.samplers to be helpful. Improvements Add the ability to disable agents while allowing currently running tasks to finish using det agent disable --drain AGENT_ID. Bug Fixes WebUI: Show metrics with a value of 0 in graphs. Properly load very old (pre-0.13.8) checkpoints with TFKerasTrial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 114
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 115
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-4",
    "content": "Release Date: August 23, 2021 New Features WebUI: Add a trial comparison modal, allowing comparison of information, metrics, and hyperparameters between specific trials within an experiment. This is available from the experiment trials and experiment visualization pages. Scheduling/CLI: Support changing task priorities using the det experiment/command/notebook/shell/tensorboard set priority commands. CLI: Allow command-line config overrides in experiment creation, e.g., det e create const.yaml . --config key=value. WebUI: Allow cluster admins to delete individual experiments. Bug Fixes Cluster: Fix breakage in trial fault tolerance caused by not sending enough state snapshots. WebUI: Prevent logs from potentially introducing harmful HTML/JS injections via Unicode. WebUI: Change y-axis of the profiler timing metrics chart from milliseconds to seconds. WebUI: Prevent the zoom from resetting when chart data series are added. WebUI: Fix the issue of learning curves not resizing properly.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 116
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 117
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-3",
    "content": "Release Date: July 22, 2021 New Features Add the ability to use Azure Blob Storage for checkpoint storage. Add support for Azure Kubernetes Service, including updating Helm to support Azure Blob Storage and adding additional docs for AKS. WebUI: Add support for nested hyperparameters in experiment config, trial hyperparameters, and hyperparameter visualization. WebUI: Add the ability to view trial logs and open TensorBoards directly from the trial list view. WebUI: Enable sorting and filtering trials by state on an experiment\u2019s trials page. WebUI: Add a server availability check on load. Bug Fixes Fix a bug where experiments with model definitions exceeding 50% of the maximum allowable size would cause trials to never start. WebUI: Prevent hyperparameter visualization from getting stuck showing a spinner after clicking through all the different tabs. WebUI: Fix the issue of experiments showing incorrect data if they were forked from another experiment or continued from a trial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 118
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 119
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-2",
    "content": "Release Date: July 9, 2021 New Features Make det deploy aws up automatically bind-mount FSx and EFS directories into task containers when available. Make det deploy local bind-mount the user\u2019s home directory into task containers. The mounted directory can be changed with the --auto-bind-mount=<path> option and mounting can be disabled entirely with --no-auto-bind-mount. Improvements PyTorchTrial: Improve support for custom batches in PyTorch, e.g., as used in pytorch_geometric. See get_batch_length() or examples/graphs/proteins_pytorch_geometric for further details. Bug Fixes WebUI: Avoid waiting for an extra polling cycle to load trial data when loading single-trial experiments. WebUI: Fix an issue with boolean hyperparameter values not being rendered in learning curve tables.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 120
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 121
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-1",
    "content": "Release Date: June 28, 2021 New Features Add support for CPU-based training. This makes it possible to run Determined on clusters without GPUs, including on-prem, AWS, GCP, and Kubernetes-based (default scheduler only) configurations. Support spinning up and down a Filestore instance when running det deploy gcp up/down. The Filestore instance will automatically be mounted to agents and bind-mounted into task containers. You can also use a pre-existing Filestore instance. Improvements Breaking Change: REST API: Rename gpu and cpu fields in ResourcePool object to compute and aux. Breaking Change: Deploy: In det deploy gcp and det deploy aws, rename the default compute pool from gpu-pool to compute-pool. When upgrading a cluster from a previous version, existing pending experiments may error out and need to be resubmitted. Bug Fixes Support using Docker images with EXPOSE commands as images for notebooks/shells/TensorBoards. Previously, the EXPOSE command could break proxying through the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 122
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 123
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.16",
      "lvl3": "Version 0.16.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-16-0",
    "content": "Release Date: June 14, 2021 New Features Python SDK: Extend the Checkpoint Export API into a Python SDK capable of launching and controlling experiments on the cluster directly from Python. See the documentation and examples in the client module. Trials: Add new support for profiling model code. For all frameworks, collecting system metrics, such as GPU utilization and memory, is supported. For PyTorch, additional profiling for timing is available. To quickly try out profiling, set profiling.enabled = true in the experiment configuration. Experiments: Add new notes and name fields to experiments. REST API: Add new parameters to /api/v1/experiments to filter and sort experiments by name. Master configuration: Support bind_mounts in task_container_defaults in the master configuration. The configured directories will be mounted for experiments, notebooks, commands, shells, and TensorBoards. Images: Add an environment image containing TensorFlow 2.5 and CUDA 11.2. Improvements Breaking change: JupyterLab: Upgrade the JupyterLab version to 3.0.16. JupyterLab will no longer work with previously released images. Custom image users should upgrade to JupyterLab 3.0 or higher. Scheduling: Support backfilling in the priority scheduler. If there are slots that cannot be filled with high-priority tasks, low-priority tasks will be scheduled onto them. This requires preemption to be enabled in the master configuration. WebUI: Improve task list filtering by moving column filters to the table header. REST API: Change filtering experiments by description to be case-insensitive when using the /api/v1/experiments endpoint. Bug Fixes Fix a bug where InvalidHP exceptions raised in the trial __init__() caused the trial to restart. WebUI: Fix an issue with representing some hyperparameter values as text. Kubernetes: Prevent Determined from sometimes crashing when handling concurrent job submissions. Master configuration: Fix a bug that was triggered when the master configuration had S3 secrets explicitly configured in checkpoint_storage. Experiments that did not override the master-provided checkpoint storage would fail. Deprecated Features The method create_trial_instance() is now deprecated. Users should instead use the more flexible TrialContext.from_config(), which is described in How to Debug Models. Removed Features The methods det.experimental.keras.init() and det.experimental.estimator.init() have been removed. They were deprecated in 0.13.5.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 124
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 125
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 126
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-6",
    "content": "Release Date: June 2, 2021 New Features Add PyTorch\u2019s word-level language modeling RNN example as a Determined example. Support using the Determined shell as a remote host inside Visual Studio Code and PyCharm IDEs. Improvements Deploy: Add support for terraform 0.15 when using det deploy gcp. REST API: Add a preview parameter to the Notebook launch API (POST /api/v1/notebooks). If set, this API will return a full configuration that is populated with the template and Notebook configuration. WebUI: Improve Experiment list filtering by moving column filters to the table header. WebUI: Improve the Trial details page by moving hyperparameters, workloads, and logs into separate \u201ctabs\u201d on the Trial detail page. Bug Fixes PyTorchTrial: Fix an issue where a DataLoader iterator that uses multiprocessing could cause a hang when exiting. WebUI: Prevent TQDM log lines from generating large quantities of whitespace when rendering logs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 127
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 128
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-5",
    "content": "Release Date: May 18, 2021 Bug Fixes Fix an issue where the master would attempt to schedule onto agents that had previously disconnected. Deprecated Features Deprecate the scheduler and provisioner fields in the master configuration in favor of resource_manager and resource_pools. They will be removed in the next minor release, Determined 0.16.0.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 129
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 130
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-4",
    "content": "Release Date: May 12, 2021 New Features Model Hub: Publish Determined\u2019s Model Hub library to make it easy to train models from supported third-party libraries with a Determined cluster. The first library supported in Model Hub is the HuggingFace transformers library for NLP. Minor Changes API: Remove redundant APIs for commands, shells, TensorBoards, and notebooks. The CLI now uses updated versions of these endpoints; related CLI commands on versions 0.15.4 and beyond are not backward-compatible with previous versions of Determined clusters. API: Update the trial detail endpoint (GET /api/v1/trials/:id), dropping prior_batches_processed and num_inputs in favor of total_batches.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 131
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 132
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-3",
    "content": "Release Date: May 5, 2021 Bug Fixes Images: Fix GPU support in CUDA 10.2 + TensorFlow 1.15 images. Trials: Update to match websockets>= 9.0 library API change. Trials: Fix a bug that caused trials to panic upon receiving too many rendezvous addresses.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 133
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 134
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-2",
    "content": "Release Date: April 29, 2021 New Features Kubernetes: Support priority scheduling with preemption. The preemption scheduler is able to preempt experiments when higher priority ones are submitted. APIs: Promote the custom metric reducer APIs for both pytorch and estimators from experimental status to general availability. Resource pools: Support =configuring distinct task_container_defaults for each resource pool configured on the cluster. This can allow different resource pools which may have very different hardware to configure tasks in each pool with the correct settings. Improvements Agent: Support configuring the name of the Fluent Bit logging container via the --fluent-container-name option. Docker: Support specifying the --devices, --cap-add, and --cap-drop arguments to the docker run command. These are configured in an experiment or command/notebook config via resources.devices, environment.add_capabilities, and environment.drop_capabilities. These settings can combine to allow an experiment to take advantage of cluster hardware not previously available to training or notebook task. These configurations are only honored by resource managers of type agent, and are ignored by resource managers of type kubernetes. Bug Fixes Agent: Support the --fluent-port option. PyTorchTrial: Fix learning rate scheduler behavior when used with gradient aggregation. PyTorchTrial\u2019s to_device() no longer throws errors on non-numeric NumPy-like data. As PyTorch is still unable to move such data to the GPU, non-numeric arrays will simply remain on the CPU. This is especially useful to NLP practitioners who wish to make use of NumPy\u2019s string manipulations anywhere in their data pipelines. TFKerasTrial: Fix support for TensorFlow v2.2.x. WebUI: Fix the issue of the WebUI crashing when user selects a row in experiment list page then changes the user filter. WebUI: Fix the issue of agents overview on the Cluster page not updating properly when agents shutdown. WebUI: Fix the issue of trial logs not rendering properly on Safari 14.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 135
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 136
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-1",
    "content": "Release Date: April 16, 2021 Bug Fixes Trials: Fix TFKerasTrial on TensorFlow 2 with disabled v2 behavior and/or disabled eager execution. Master: Fix two issues that caused experiments to not recover successfully on master crashes (after upgrading to version 0.15.0).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 137
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 138
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.15",
      "lvl3": "Version 0.15.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-15-0",
    "content": "Release Date: April 14, 2021 New Features WebUI: Provide historical allocation data on the Cluster page. This page breaks down GPU hours by user, label, and resource pool. WebUI: Add a gallery mode to the hyperparameter scatter plot and heatmap visualizaztions to allow users to inspect each scatter plot in full detail. Improvements Breaking Change CLI: Consolidate det and det-deploy executables into the determined package, which now includes all Determined libraries and tools. The determined-cli, determined-deploy, and determined-common packages are now deprecated. When upgrading from older versions, det command may break for some users because of pip limitations. Please uninstall outdated packages, and then reinstall Determined. PyTorch: Remove cloudpickle as a dependency for PyTorch checkpoints. This does not affect compatibility of existing checkpoints. This change will improve portability across Python versions. Deploy: Move default storage location for checkpoint data in local clusters deployed via det deploy local to an OS-specific user data directory (e.g. $XDG_DATA_HOME/determined or ~/.local/share/determined on Linux, and ~/Library/Application Support/determined on macOS). Previously, /tmp was used. This location can be changed using the --storage-host-path command line flag of det deploy local. If users provide their own custom master.yaml via --master-config-path, the configured checkpoint_storage in master.yaml will take precedence. Searcher: Remove support for adaptive and adaptive_simple searchers which were deprecated in Determined 0.13.7. Bug Fixes WebUI: Fix an issue where the metric value occasionally had the word \u201cundefined\u201d prepended.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 139
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 140
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 141
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-6",
    "content": "Release Date: April 1, 2021 New Features REST API: Add a new endpoint to delete experiments. This endpoint is only enabled for admin users and deletes all resources associated with an experiment. This includes checkpoint storage, TensorBoards, trial logs from all backends and metadata such as history and metrics, stored in PostgreSQL. REST API: Add a new endpoint to fetch aggregated historical resource allocation information. CLI: Add new commands det resources raw and det resources aggregated to access resource allocation information. PyTorch Lightning: Add an adapter to support LightningModule from PyTorch Lightning in the PyTorchTrial API. Improvements Images: The default environment images have been updated to CUDA 10.2, PyTorch 1.8, and TensorFlow 1.15.5 with Python 3.7. Previous images are still available but must be specified in the experiment or command configuration. It is recommended to validate the performance of models when changing CUDA versions as some models can experience significant changes in training time, etc. WebUI: Improve the hyperparameter scatter plot and heat map visualizations by adding support for showing categorical hyperparameters. Bug Fixes WebUI: Fix the hyperparameter visualization page crashing when viewing single trial or PBT experiments, both of which are intentionally unsupported for hyperparameter visualizations.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 142
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 143
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-5",
    "content": "Release Date: March 18, 2021 New Features REST API: Add a REST API endpoint exposing historical cluster resource allocation. Currently, information about experiment workloads (training, checkpoints, and validations) is included. Hyperparameter Search: Introduce a stopping-based variant of Adaptive (Asynchronous) Method that will continue training trials by default unless stopped by the algorithm. Compared to the default promotions-based algorithm, the stopping variant will promote to higher rungs faster and does not require fault tolerance since it will not resume stopped trials. PyTorch: Add an option to LRScheduler to accept a frequency option alongside batch and epoch step modes. Kubernetes: Add support for priority scheduling, with gang-scheduling for distributed training, on Kubernetes. Improvements WebUI: Add a margin of comparison to hyperparameter visualizations to enable better grouping of trials with a similar but not identical number of batches processed. Bug Fixes Correct model code uploaded to checkpoints so it now matches the model code provided during experiment creation. Previously, it may have included additional files that had been bind-mounted with a container_path that was either relative or was a subdirectory of /run/determined/workdir. Fix an unauthorized access issue when attempting to use the Determined CLI within a notebook.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 144
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 145
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-3",
    "content": "Release Date: March 4, 2021 New Features Examples: Add the Deformable DETR model for object detection in Determined. Check out our example in the Determined repository. Searcher: Support programmatic rejection of certain hyperparameters to further optimize your hyperparameter search. WebUI: Add additional hyperparameter visualizations to multi-trial experiments. The new parallel coordinate, scatter plot, and heat map visualizations will allow you to better explore relationships between hyperparameters and model performance. Improvements WebUI: Use anchor tags instead of click event listeners across all table rows. This increases accessibility and improves keyboard navigation support. Bug Fixes Keras: Ensure that keras.utils.Sequence objects receive their on_epoch_end() calls after validation is completed. WebUI: Fix the order of batches to be numeric instead of alphanumeric.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 146
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 147
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-2",
    "content": "Release Date: February 17, 2021 New Features Support CUDA 11. New Docker images are available for experiments and commands to support CUDA 11, as well as some updated versions of frameworks on CUDA 10.1. It is recommended to validate the performance of models when changing CUDA versions as some models can experience significant changes in training time, etc. Support startup-hook.sh for notebooks and shells. This is the same mechanism supported by experiments. Improvements Improve local test mode for experiment creation, det experiment create, to test with only a single batch. Invoke python as python3 rather than as python3.6. This makes it possible to use custom images containing higher versions of Python with Determined (3.6 is still the minimum required version). If the desired python cannot be found as python3, it is now possible to customize this invocation by setting the environment variable DET_PYTHON_EXECUTABLE=/path/to/python3, for experiments, notebooks, and shells. Bug Fixes Kubernetes: Fix a bug that caused the Cluster page to not render when using a Kubernetes cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 148
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 149
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-1",
    "content": "Release Date: February 9, 2021 Bug Fixes Trial: Fix a bug that prevented trial logs created before 0.13.8 from loading correctly.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 150
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 151
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.14",
      "lvl3": "Version 0.14.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-14-0",
    "content": "Release Date: February 4, 2021 New Features Add resource pools, which allows for different types of tasks to be scheduled onto different types of agents. det-deploy will now create clusters with two resource pools, one that uses GPU instances and one that uses CPU instances for tasks that only require CPUs. WebUI: Revamp cluster page with information about configured resource pools. Removed Features Trial API: Remove the old PyTorch APIs, including: the build_model, optimizer, and create_lr_scheduler methods in PyTorchTrial; the callback on_before_optimizer_step; the field optimizations.mixed_precision in the experiment configuration; the model arguments to train_batch(), evaluate_batch(), and evaluate_full_dataset(). Model code that uses these APIs will no longer run in Determined 0.14.0 or later. However, model checkpoints produced by old experiments that used these APIs will still be supported. Improvements Breaking Change REST API: The trial and checkpoint API endpoints can now return non-scalar metric values, which are represented as JSON objects or protobuf structs. Documentation: Add a topic guide on debugging models. The new guide will walk you step-by-step through solving problems with a model in Determined, with a focus on testing features incrementally until the model is fully working. It may also be useful when porting new models to Determined. Documentation: Add a topic guide on commands and shells. It describes how to use Determined\u2019s support for managing GPU-powered batch commands and interactive shells. REST API: Improve the performance of the experiments API. Bug Fixes Database: Migrate public.trial_logs.id to be an int8 in Postgres, instead of an int4. This avoids issues for customers with extremely large amounts of trial logs. Note: This migration will be more time-consuming than usual for deployments with large amounts of trial logs. REST API: Fix an issue where requesting checkpoint or trial details of a trial that had non-scalar metric values associated with it would fail. Trial: Fix an issue where the trial was not deallocating resources when it failed to write to the DB. WebUI: Show better messaging for different learning curve edge cases. WebUI: Fix sorting on the experiment trials table within the experiment detail page. WebUI: Fix issue of incorrect trial log order when viewing oldest logs first. WebUI: Update Cancel confirm button label to show Confirm to avoid double Cancel buttons. WebUI: Improve the sorting behavior for numeric table columns.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 152
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 153
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-13",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 154
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-13",
    "content": "Release Date: January 25, 2021 New Features Update experiment details pages to include a learning curve visualization. This will enable a comparison of hyperparameter performance among many different trials within an experiment. Support Elasticsearch as an alternative backend for logging. Read more about Elasticsearch-backed logging to see if it\u2019s appropriate for your Determined deployment. Improvements Breaking Change: REST API: Update trial logs API to return string IDs. WebUI: Enable filtering of trial logs by agent, container, rank, log level, and timestamp. WebUI: Improve section contrast on all pages. Deployment: Add the command det-deploy aws list, which shows all the CloudFormation stacks that are managed by det-deploy aws (using the tag managed-by: determined). This only applies to new deployments since this version, not previous deployments. Update examples to use the new PyTorch APIs. Deprecated Features The old PyTorch API was deprecated in 0.12.13 and will be removed in the next release. See the PyTorch migration guide for details on updating your PyTorch model code to use the new API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 155
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-12",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 156
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-12",
    "content": "Release Date: January 11, 2021 Bug Fixes WebUI: Fix the Okta sign-in workflow. WebUI: Fix an issue with unexpected hyperparameter types in experiment configuration. WebUI: Fix trial metric workload duration reporting in the trial detail page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 157
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-11",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 158
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-11",
    "content": "Release Date: January 6, 2021 Improvements Trials: Add experimental support for custom metric reducers with PyTorchTrial. This enables calculating advanced metrics like F1 score or mean IOU; returning multiple metrics from a single reducer is also supported. See determined.pytorch.PyTorchExperimentalContext.wrap_reducer() for detailed documentation and code snippets. See determined/examples/features/custom_reducers_mnist_pytorch for a complete example of how to use custom reducers. The example emits a per-class F1 score using the new custom reducer API. Trials: Support more than 1 backward pass per optimizer step for distributed training in PyTorchTrial. Logging: Allow the trial logging backend to be configured in Kubernetes-based deployments of Determined. Agents: Add support for labels when starting agents with det-deploy. Bug Fixes WebUI: Update the Trial Information Table to be usable on mobile devices. HP Search: Fix a bug where adaptive_asha could run with more maximum concurrent trials than intended. Scheduling: Fix a bug where command priority was not respected.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 159
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-10",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 160
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-10",
    "content": "Release Date: December 10, 2020 New Features WebUI: Add support for mobile and tablet devices. Check your experiment results on the go! Scheduler: Update the priority scheduler to support specifying priorities and preemption. Improvements Improve the scheduling and scaling behavior of CPU tasks, and allow the maximum number of CPU tasks per agent to be configured via the Configuring the Cluster. Add custom tagging support to AWS dynamic agents. Thank you to sean-adler for contributing this improvement! Support validation_steps in TFKerasTrial\u2019s context.configure_fit(). validation_steps means the same thing in Determined as it does in model.fit(), and has the same limitation (in that it only applies when validation_data is of type tf.data.Dataset). Kubernetes: Support a default user password for Kubernetes deployments. This affects the admin and determined default user accounts. Kubernetes: Release version 0.3.1 of the Determined Helm chart. Bug Fixes Fix a bug in --local --test mode where all GPUs were being passed to the training loop despite the distributed training code paths being disabled. Fix a bug causing active trials that have failed to not be restored properly on a master restart when max_restarts is greater than 0. Allow configurations with a . character in the keys for map fields in the Master Configuration Reference (e.g. task_container_defaults.cpu_pod_spec.metadata.labels). Fix a bug where restoring a large number of experiments after a failure could lead to deadlock. Fix an issue where templates with user-specified bind mounts would merge incorrectly. Thank you to zjorgensenbits for reporting this issue! Deprecated Features The previous version of the priority scheduler is now deprecated. It will remain available as the round_robin scheduler for a limited period of time.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 161
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-9",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 162
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-9",
    "content": "Release Date: November 20, 2020 Improvements Commands: Support configuring shmSize for commands (e.g., notebooks, shells, TensorBoards) in command configurations. Bug Fixes API: Fix a bug that caused the WebUI\u2019s log viewer to fail to render previous pages of trial logs. WebUI: Fix a bug in opening TensorBoards from the experiment list page via batch selection.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 163
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-8",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 164
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.8",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-8",
    "content": "Release Date: November 17, 2020 New Features API: Add support for models that subclass tf.keras.Model when using the Determined TFKerasTrial API. This is a new feature that became available starting in TensorFlow 2.2, allowing user to further customize their training process. Deployment: When using the simple deployment type with det-deploy aws, you can now use the --agent-subnet-id flag to specify which existing subnet to launch agents in. As each subnet is associated with a single availability zone, this allows users to explicitly choose an availability zone that has GPU instances (there is no public information about which availability zones have GPU instances so trial and error is the suggested approach). Logs: Support filtering trial logs by individual fields in the CLI. Log entries for trials can now be filtered by container ID, agent ID, log level, and other fields. Security: Allow the master to use a TLS certificate that is valid for a different name than the agents use to connect to it. This ability is useful in situations where the master is accessed using multiple different addresses (e.g., private and public IP addresses of a cloud instance). The agent now accepts a --security-tls-master-cert-name option to override the expected name in the master\u2019s TLS certificate. The CLI uses the DET_MASTER_CERT_NAME environment variable for the same purpose.\u201d Improvements Breaking Change: API: Perform salting and hashing on server-side for the password change endpoint. This makes this endpoint consistent with the new login endpoint described at https://docs.determined.ai/latest/rest-api/ . Breaking Change: Logging: Start using Fluent Bit for handling trial logs internally. The agent machines now need to have access to the fluent/fluent-bit:1.6 Docker image. If the Determined agent machines are able to connect to Docker Hub, they will pull it automatically and no changes are required; if not, the image must be manually made available beforehand. The Determined agent accepts a --fluent-logging-image option to specify an alternate name for the image. This change is part of an effort to improve the handling of trial logs by increasing scalability and allowing more options for log storage. Agent: Support configurable slot types for agents. Previously, Determined only supported auto-detecting the slot type for agents. If Determined did not detect any GPUs, the agents would fall back to mapping one slot to all the CPUs. With this change, this behavior can be configured to one of auto, gpu, and none in the field slot_type of the agent configuration agent.yaml. Dynamic agents having GPUs will be configured to gpu while those agents having no GPUs will be configured to none. For static agents this field defaults to auto. API: Add self.context.wrap_optimizer() to the Determined TFKerasTrial API. API: Add tf.keras DCGAN example that subclasses tf.keras.Model. API: Add self.context.configure_fit() to the Determined TFKerasTrial API. Many parameters which would be passed to model.fit(), such as class_weight, verbose, or workers, can now be passed to configure_fit() and will be honored by TFKerasTrial. Kubernetes: Add option to configure the service type of the Determined deployed database in the Determined Helm chart. This is useful if your cluster does not support ClusterIP, which is the service type that is used by default. WebUI: Make the page/tab title more descriptive. WebUI: Add navigation sidebar, breadcrumb, and back buttons to log view pages. WebUI: Update the trial and master log buttons to open in the same page by default, with the option to open in a new tab. WebUI: Update trial details URL to include the experiment id. Bug Fixes API: Fix support for Keras Callbacks. Previously, stateful Keras Callbacks (EarlyStopping and ReduceLROnPlateau) did not work in Determined across pause/activate boundaries. We have introduced Determined-friendly implementations, determined.keras.callbacks.EarlyStopping and determined.keras.callbacks.ReduceLROnPlateau, which address this shortcoming. User-defined callbacks may subclass determined.keras.callbacks.Callback (and define get_state and load_state methods) to also benefit from this and other new features. Previously, Keras Callbacks which relied on on_epoch_end in Determined would see their on_epoch_end called every scheduling_unit batches by default. Now, on_epoch_end will be reliably called at the end of each epoch, as defined by the records_per_epoch setting in the experiment config. As before, on_epoch_end will not contain validation metrics, as the validation data is not always fresh at epoch boundaries. Therefore, the Determined implementations of EarlyStopping and ReduceLROnPlateau are both based on on_test_end, which can be tuned using min_validation_period. API: Fix issue that occasionally made TFKerasTrial hang for multi-GPU training during COMPUTE_VALIDATION_STEP. Kubernetes: Gracefully handle cases where the Kubernetes API server responds with unexpected object types. Scheduler: Fix not being able to find resource pools for experiments. Scheduler: Fix not being able to disable slots. WebUI: Prevent navigation item tooltips from showing up when hovering outside of the navigation bar. WebUI: Fix an issue where the experiment archive action button was out of sync. WebUI: Fix experiment actions to not display a loading spinner. Deprecated Features API: Deprecate the name det.keras.TFKerasTensorBoard in favor of det.keras.callbacks.TensorBoard. The old name will be removed eventually, and user code should be updated accordingly. API: Deprecated the old det.keras.SequenceAdapter. SequenceAdapter will be removed in a future version. Users should use self.context.configure_fit() instead, which is both more capable and more similar to the normal tf.keras APIs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 165
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-7",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 166
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-7",
    "content": "Release Date: October 29, 2020 New Features Add support for running workloads on spot instances on AWS. Spot instances can be up to 70% cheaper than on-demand instances. If a spot instance is terminated, Determined\u2019s built-in fault tolerance means that model training will continue on a different agent automatically. Spot instances can be enabled by setting spot: true in the Configuring the Cluster. Support MMDetection, a popular library for object detection, in Determined. MMDetection allows users to easily train state-of-the-art object detection models; with Determined, users can take things one step further with cutting-edge distributed training and hyperparameter tuning to further boost performance. See the Determined implementation of MMDetection for more information on how to get started. WebUI: Allow the experiments list page to be filtered by labels. Selecting more than one label will filter experiments by the intersection of the selected labels. Deprecated Features Deprecate the simple and advanced adaptive hyperparameter search algorithms. They will be removed in a future release. Both algorithms have been replaced with Adaptive (Asynchronous) Method, which has state-of-the-art performance, as well as better scalability and resource-efficiency. Improvements Documentation: Add a guide for Set up and Manage an AWS Kubernetes (EKS) Cluster. Master: Support a minimum instance count for dynamic agents. The master will attempt to scale the cluster to at least the configured value at all times. This is configurable via provisioner.min_instances in the Configuring the Cluster. This will increase responsiveness to workload demand because agent(s) will be ready even when the cluster is idle. Kubernetes: Improve the performance of the /agents endpoint for Kubernetes deployments. This will improve the performance of the cluster page in the WebUI, as well as when using det slot list and det task list via the CLI. Kubernetes: Release version 0.3.0 of the Determined Helm chart. WebUI: Improve metric selection on the trial detail page. This should improve filtering for trials with many metrics. WebUI: Use scientific notation when appropriate for floating point metric values. WebUI: Show both experiment and trial TensorBoard sources when applicable. Bug Fixes WebUI: Fix an issue where TensorBoard sources did not display properly for TensorBoards started via the CLI. WebUI: Fix an issue with rendering boolean hyperparameters in the WebUI. CLI: Fix an issue where trial IDs were occasionally not displayed when running det task list or det slot list in the CLI. Master: Fix the default value for the fit field if the scheduler is set in the Configuring the Cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 167
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 168
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-6",
    "content": "Release Date: October 14, 2020 Improvements Agent: The boot_disk_source_image field for GCP dynamic agents and image_id field for AWS dynamic agents are now optional. If omitted, the default value is the Determined agent image that matches the Determined master being used. Documentation: Ship Swagger UI with Determined documentation. The /swagger-ui endpoint has been renamed to /docs/rest-api. Documentation: Add a guide on configuring TLS in Determined. Kubernetes: Add support for configuring memory and CPU requirements for the Determined database when installing via the Determined Helm chart. Kubernetes: Add support for configuring the storageClass that is used when deploying a database using the Determined Helm chart. Bug Fixes Harness: Do not require the master to present a full TLS certificate chain when the certificate is signed by a well-known Certificate Authority. Harness: Fix a bug which affected TFKerasTrial using TensorFlow 2 with gradient_aggregation > 1. Master: Fix a bug where the master instance would fail if an experiment could not be read from the database. WebUI: Preserve the colors used for multiple metrics on the metric chart. WebUI: Fix the ability to cancel a batch of experiments. WebUI: Fix a bug which caused the Experiment Details page to not render when the latest validation metric is not available.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 169
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 170
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-5",
    "content": "Release Date: September 30, 2020 Improvements Security: Use one TCP port for all incoming connections to the master and use TLS for all connections if configured. Breaking Change: The http_port and https_port options in the master configuration have been replaced by the single port option. The security.http option is no longer accepted; the master can no longer be configured to listen over HTTP and HTTPS simultaneously. Security: Support configuring TLS encryption when deploying Determined on Kubernetes. Agent: Increase default max agent starting and idle timeouts to 20 minutes and increase max disconnected period from 5 to 10 minutes. Deployment: Add support for det-deploy aws in the following new regions: ap-northeast-1, eu-central-1, eu-west-1, us-east-2. Docker: Publish new Docker task containers that upgrade TensorFlow versions from 1.15.0 to 1.15.4, and 2.2.0 to 2.2.1. Documentation: Add extra documentation and reorganize examples by use case. Documentation: Add a tf.layers-in-Estimator example. Kubernetes: Add support for users to specify initContainers and containers as part of their custom pod specs. Kubernetes: Publish version 0.2.0 of the Determined Helm chart. Native API: Deprecate Native API. Removed related examples and docs. Trials: Remove support for TensorpackTrial. WebUI: Improve polling behavior for experiment and trial details pages to avoid hanging indefinitely for very large experiments/trials. Bug Fixes Trials: Fix a bug where if only a subset of workers on a machine executed the on_trial_close() EstimatorTrial callback, the container would terminate as soon as one worker exited. Trials: Fix a bug where det e create --test would succeed when there were checkpointing failures. WebUI: Fix the issue of multiple selected rows dissappearing after a successful table batch action. WebUI: Remove unused TensorBoard sources column from the task list page. WebUI: Fix rendering metrics with the same name on the metric chart. WebUI: Make several fixes to improve select appearance and user experience. WebUI: Fix the issue of agent and cluster info not loading on slow connections. WebUI: Fix the issue where the chart in the Experiment page does not have the metric name in the legend.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 171
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 172
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-4",
    "content": "Release Date: September 16, 2020 Improvements Support configuring default values for the task image, Docker pull policy, and Docker registry credentials via the Master Configuration Reference and the Helm Chart Configuration Reference. In previous versions of Determined, these values had to be specified on a per-task basis (e.g., in the experiment configuration). Per-task configuration is still supported and will overwrite the default value (if any). Add connection checks for dynamic agents. A dynamically provisioned agent will be terminated if it is not actively connected to the master for at least five minutes. Emit a warning if DistributeConfig is specified for an Estimator. Configuring an Estimator via tf.distribute.Strategy can conflict with how Determined performs distributed training. With this change, Determined will attempt to catch this problem and surface an error message in the experiment logs. An Estimator can still be configured with an empty DistributeConfig without issue. Remove support for dataflow_to_tf_dataset in EstimatorTrial. Dataflows should be wrapped using wrap_dataset(shard=False) instead. WebUI: Add middle mouse button click detection on tables to open in a new tab/page. WebUI: Improve the trial detail metrics view. Support metrics with non-numeric values. Default to showing only the searcher metric on initial page load. Add search capability to the metric select filter. This should improve the experience when there are many metrics. Add support for displaying multiple metrics on the metric chart. WebUI: Move TensorBoard sources from a table column into a separate modal. WebUI: Optimize loading of active TensorBoards and notebooks. Bug Fixes Improve handling of certain corner cases where distributed training jobs could hang indefinitely. Fix an issue where detecting GPU availability in TensorFlow code would cause EstimatorTrial models to OOM. Fix an issue where accessing logs could create a memory leak. Fix an issue that prevents resuming from checkpoints that contain a large number of files. WebUI: Fix an issue where table page sizes were not saved between page loads. WebUI: Fix an issue where opening a TensorBoard on an experiment would not direct the user to an already running TensorBoard, but instead create a new one. WebUI: Fix an issue where batch actions on the experiments table would cause rows to disappear. Known Issues WebUI: In the trial detail metrics view, experiments that have both a training metric and a validation metric of the same name will not be displayed correctly on the metrics chart.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 173
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 174
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-3",
    "content": "Release Date: September 8, 2020 Bug Fixes Deployment: Fix a bug where det-deploy local cluster-up was failing. WebUI: Fix a bug where experiment labels were not displayed on the experiment list page. WebUI: Fix a bug with decoding API responses because of unexpected non-numeric metric values.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 175
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 176
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-2",
    "content": "Release Date: September 3, 2020 New Features Support deploying Determined on Kubernetes. Determined workloads run as a collection of pods, which allows standard Kubernetes tools for logging, metrics, and tracing to be used. Determined is compatible with Kubernetes >= 1.15, including managed Kubernetes services such as Google Kubernetes Engine (GKE) and AWS Elastic Kubernetes Service (EKS). When using Determined with Kubernetes, we currently do not support fair-share scheduling, priority scheduling, per-experiment weights, or gang-scheduling for distributed training experiments; workloads will be scheduled according the behavior of the default Kubernetes scheduler. Users can configure the behavior of the pods that are launched for Determined workloads by specifying a custom pod spec. A default pod spec can be configured when installing Kubernetes, but a custom pod spec can also be specified on a per-task basis (e.g., via the environment.pod_spec field in the experiment configuration file). Support running multiple distributed training jobs on a single agent. In previous versions of Determined, a distributed training job could only be scheduled on an agent if it was configured to use all of the GPUs on that agent. In this release, that restriction has been lifted: for example, an agent with 8 GPUs can now be used to run two 4-GPU distributed training jobs. This feature is particularly useful as a way to improve utilization and fair resource allocation for smaller clusters. Improvements WebUI: Update primary navigation. The primary navigation is all to one side, and is now collapsible to maximize content space. WebUI: Trial details improvements: Update metrics selector to show the number of metrics selected to improve readability. Add the \u201cHas Checkpoint or Validation\u201d filter. Persist the \u201cHas Checkpoint or Validation\u201d filter setting across all trials, and persist the \u201cMetrics\u201d filter on trials of the same experiment. WebUI: Improve table pagination behavior. This will improve performance on Determined instances with many experiments. WebUI: Persist the sort order and sort column for the experiments, tasks, and trials tables to local storage. WebUI: Improve the default axes\u2019 ranges for metrics charts. Also, update the range as new data points arrive. Add a warning when the PyTorch LR scheduler incorrectly uses an unwrapped optimizer. When using PyTorch with Determined, LR schedulers should be constructed using an optimizer that has been wrapped via the wrap_optimizer() method. Add a reminder to remove sys.exit() if SystemExit exception is caught. Bug Fixes WebUI: Fix an issue where the recent task list did not apply the limit filter properly. Fix Keras and Estimator wrapping functions not returning the original objects when exporting checkpoints. Fix progress reporting for adaptive_asha searches that contain failed trials. Fix an issue that was causing OOM errors for some distributed EstimatorTrial experiments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 177
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 178
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.1",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-1",
    "content": "Release Date: August 31, 2020 Bug Fixes Database migration: Fix a bug with a database migration in Determined version 0.13.0 which caused it to run slow and backfill incorrect values. Users on Determined versions 0.12.13 or earlier are recommended to upgrade to version 0.13.1. Users already on version 0.13.0 should upgrade to version 0.13.1 as usual. TensorBoard: Fix a bug that prevents TensorBoards from experiments with old experiment configuration versions from being loaded. WebUI: Fix an API response decoding issue on React where a null checkpoint resource was unhandled and could prevent trial detail page from rendering. WebUI: Fix an issue where terminated TensorBoard and notebook tasks were rendered as openable.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 179
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-0",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 180
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.13",
      "lvl3": "Version 0.13.0",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-13-0",
    "content": "Release Date: August 20, 2020 This release of Determined introduces several significant new features and modifications to existing features. When upgrading from a prior release of Determined, users should pay particular attention to the following changes: The concept of \u201csteps\u201d has been removed from the CLI, WebUI, APIs, and configuration files. Before upgrading, terminate all active and paused experiments (e.g., via det experiment cancel or det experiment kill). The format of the experiment config file has changed \u2013 configuration files that worked with previous versions of Determined will need to be updated to work with Determined >= 0.13.0. The WebUI has been partially rewritten, moving several components that were implemented in Elm to now being written in React and TypeScript. As part of this change, many improvements to the performance, appearance, and usability of the WebUI have been made. For more details, see the list of changes below. Please notify the Determined team of any regressions in functionality. The usability of the det shell feature has been significantly enhanced. As part of this change, the way in which arguments to det shell are parsed has changed; see details below. We recommend taking a backup of the database before upgrading Determined. New Features Allow trial containers to connect to the master using TLS. Allow agent\u2019s TLS verification to skip verification or use a custom certificate for the master. For TFKerasTrial and EstimatorTrial, add support for disabling automatic sharding of the training dataset when doing distributed training. When wrapping a dataset via context.wrap_dataset, users can now pass shard_dataset=False. If this is done, users are responsible for splitting their dataset in such a manner that every GPU (rank) sees unique data. Improvements Remove Steps from the UX: Remove the concept of a \u201cstep\u201d from the CLI, WebUI, and configuration files. Add new configuration settings to allow settings previously in terms of steps to be configured instead in terms of records, batches or epochs.. Many configuration settings can now be set in terms of records, batches or epochs. For example, a single searcher can be configured to run for 100 records by setting max_length: {records: 100}, 100 batches by setting max_length: {batches: 100}, or 100 epochs by setting records_per_epoch at the root of the config and max_length: {epochs: 100}. A new configuration setting, records_per_epoch, is added that must be specified when any quantity is configured in terms of epochs. Breaking Change: For single, random and grid searchers searcher.max_steps has been replaced by searcher.max_length Breaking Change: For ASHA based searchers, searcher.target_trial_steps and searcher.step_budget has been replaced by searcher.max_length and searcher.budget, respectively. Breaking Change: For PBT, searcher.steps_per_round has been replaced by searcher.length_per_round. Breaking Change: For all experiments, the names for min_validation_period and min_checkpoint_period are unchanged but they are now configured in terms of records, batches or epochs. Shell Mode Improvements: Determined supports launching GPU-attached terminal sessions via det shell. This release includes several changes to improve the usability of this feature, including: The determined and determined-cli Python packages are now automatically installed inside containers launched by det shell. Any user-defined environment variables for the task image will be passed into the ssh sessions opened via det shell start or det shell open. det shell should now work correctly in \u201chost\u201d networking mode. det shell should now work correctly with dynamic agents and in cloud environments. Breaking Change: Change how additional arguments to ssh are passed through det shell start and det shell open. Previously they were passed as a single string, like det shell open SHELL_ID --ssh-opt '-X -Y -o SomeSetting=\"some string\"', but now the --ssh-opt has been removed and all extra positional arguments are passed through without requiring double-layers of quoting, like det shell open SHELL_ID -- -X -Y -o SomeSetting=\"some string\" (note the use of -- to indicate all following arguments are positional arguments). WebUI changes Tasks List: /det/tasks Consolidate notebooks, tensorboards, shells, commands into single list page. Add type filter to control which task types to display. By default all task types are shown when none of the types are selected. Add type column with iconography to train users to familiarize task types with visual indicators. Convert State filter from multi-select to single-select. Convert actions from expanded buttons to overflow menu (triple vertical dots). Move notebook launch buttons to task list from notebook list page. Add pagination support that auto turns on when entries extend beyond 10 entries. Add list of TensorBoard sources in a table Source column. Experiment List: /det/experiments State filter converted from multi-select to single-select. Convert actions from expanded buttons to overflow menu (triple vertical dots). Batch operation logic change to available if the action can be applied to any of the selected experiments Add pagination support that auto turns on when entries extend beyond 10 entries. Experiment Detail: /det/experiments/<id> Implement charting with Plotly with zooming capability. Trial table paginates on the WebUI side in preparation for API pagination in the near future. Convert steps to batches in trials table and metric chart. Update continue trial flow to use batches, epochs or records. Use Monaco editor for the experiment config with YAML syntax highlighting. Add links to source for Checkpoint modal view, allowing users to navigate to the corresponding experiment or trial for the checkpoint. Trial Detail: /det/trials/<id> Add trial information table. Add trial metrics chart. Implement charting with Plotly with zooming capability. Trial info table paginates on the WebUI side in preparation for API pagination in the near future. Add support for batches, records and epochs for experiment config. Convert metric chart to show batches. Convert steps table to batches table. Master Logs: /det/logs, Trial Logs: /det/trials/<id>/logs, Task Logs: /det/<tasktype>/<id>/logs Limit logs to 1000 lines for initial load and load an additional 1000 for each subsequent fetch of older logs. Use new log viewer optimized for efficient rendering. Introduce log line numbers. Add ANSI color support. Add error, warning, and debug visual icons and colors. Add tailing button to enable tailing log behavior. Add scroll to top button to load older logs out Fix back and forth scrolling behavior on log viewer. Cluster: /det/cluster Separate out GPU from CPU resources. Show resource availability and resource count (per type). Render each resource as a donut chart. Navigation Update sidebar navigation for new task and experiment list pages. Add link to new swagger API documentation. Hide pagination controls for tables with less than 10 entries. Bug Fixes Configuration: Do not load the entire experiment configuration when trying to check if an experiment is valid to be archived or unarchived. Configuration: Improve the master to validation hyperparameter configurations when experiments are submitted. Currently, the master checks whether global_batch_size has been specified and if it is numeric. Logs: Fix issue of not detecting newlines in the log messages, particularly Kubernetes log messages. Logs: Add intermediate step to trial log download to alert user that the CLI is the recommended action, especially for large logs. Searchers: Fix a bug in the SHA searcher caused by the promotion of already-exited trials. Security: Apply user authentication to streaming endpoints. Tasks: Allow the master certificate file to be readable even for a non-root task. TensorBoard: Fix issue affecting TensorBoards on AWS in us-east-1 region. TensorBoard: Recursively search for tfevents files in subdirectories, not just the top level log directory. WebUI: Fix scrolling issue that occurs when older logs are loaded, the tailing behavior is enabled, and the view is scrolled up. WebUI: Fix colors used for different states in the cluster resources chart. WebUI: Correct the numbers in the Batches column on the experiment list page. WebUI: Fix cluster and dashboard reporting for disabled slots. WebUI: Fix issue of archive/unarchive not showing up properly under the task actions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 181
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 182
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-13",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 183
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.13",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-13",
    "content": "Release Date: August 6, 2020 New Features Model Registry: Determined now includes a built-in model registry, which makes it easy to organize trained models by providing versioning and labeling tools. New PyTorch API: Add a new version of the PyTorch API that is more flexible and supports deep learning experiments that use multiple models, optimizers, and LR schedulers. The old API is still supported but is now deprecated and will be removed in a future release. See the PyTorch migration guide for details on updating your PyTorch model code. Deprecated methods will be supported until at least the next minor release. The new API supports PyTorch code that uses multiple models, optimizers, and LR schedulers. In your trial class, you should instantiate those objects and wrap them with wrap_model(), wrap_optimizer(), and wrap_lr_scheduler() in the constructor of your PyTorch trial class. The previous API methods build_model, optimizer, and create_lr_scheduler in PyTorchTrial are now deprecated. Support customizing forward and backward passes in train_batch(). Gradient clipping should now be done by passing a function to the clip_grads argument of step_optimizer(). The callback on_before_optimizer_step is now deprecated. Configuring automatic mixed precision (AMP) in PyTorch should now be done by calling configure_apex_amp() in the constructor of your PyTorch trial class. The optimizations.mixed_precision experiment configuration key is now deprecated. The model arguments to train_batch(), evaluate_batch(), and evaluate_full_dataset() are now deprecated. More Efficient Hyperparameter Search: This release introduces a new hyperparameter search method, adaptive_asha. This is based on an asynchronous version of the adaptive algorithm, and should enable large searches to find high-quality hyperparameter configurations more quickly. Improvements Allow proxy environment variables to be set in the agent config. Preserve random state for PyTorch experiments when checkpointing and restoring. Remove determined.pytorch.reset_parameters(). This should have no effect except when using highly customized nn.Module implementations. WebUI: Show total number of resources in the cluster resource charts. Add support for NVIDIA T4 GPUs. det-deploy: Add support for g4 instance types on AWS. Upgrade NVIDIA drivers on the default AWS and GCP images from 410.104 to 450.51.05. Bug Fixes Fix an issue with the SHA searcher that could cause searches to stop making progress without finishing. Fix an issue where $HOME was not properly set in notebooks running in nonroot containers. Fix an issue where killed experiments had their state reset to the latest checkpoint. Randomize the notebook listening port to avoid port binding issues in host mode.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 184
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-12",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 185
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.12",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-12",
    "content": "Release Date: July 22, 2020 Improvements Remove support for on_train_step_begin and on_train_step_end, deprecate on_validation_step_end, and introduce new callback on_validation_end with same functionality. Add helper methods is_epoch_start and is_epoch_end to PyTorch context. Add a new API to support custom reducers in EstimatorTrial. CLI: Add the register_version command for registering a new version of a model. CLI: Add a --head option when printing trial logs. WebUI: Make it possible to launch TensorBoard from experiment dashboard cards. Bug Fixes Fix distributed training and Determined shell with non-root containers. The default task environments now include a user plugin to support running containers with arbitrary non-root users. Custom images based on the latest default task environments should also work. Fix convergence issue for TF 2 multi-GPU models. Change default TF1 version from 1.14 to 1.15. Fix issue affecting TensorFlow TensorBoard outputs. Use local log line IDs for trial logs. CLI: Improve the CLI\u2019s custom TLS certificate handling with non-self-signed certs. WebUI: Fix a parsing problem with task start times. WebUI: Fix log viewer timestamp copy/paste. Known Issues WebUI: Older trial logs are not loaded by scrolling to the top of the page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 186
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-11",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 187
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.11",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-11",
    "content": "Release Date: July 8, 2020 Add logging to console in test mode for the Native API when using determined.experimental.create. Improve reliability of saving checkpoints to GCS in the presence of transient network errors. Add an example using TensorFlow\u2019s Image Segmentation via UNet tutorial. WebUI: Improve trial log rendering performance. WebUI: Fix an issue where cluster utilization was displayed incorrectly. WebUI: Fix an issue where active experiments and commands would not appear on the dashboard. WebUI: Fix an issue where having telemetry enabled with an invalid key would cause the WebUI to render incorrectly.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 188
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-10",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 189
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.10",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-10",
    "content": "Release Date: June 26, 2020 Improvements WebUI: Add a dedicated page for master logs at /det/logs. WebUI: Provide a Swagger UI for exploring the Determined REST API. This can be accessed via the API link on the WebUI. WebUI: Default the Experiments view list length to 25 entries. More entries can be shown as needed. WebUI: Improve detection of situations where the WebUI version doesn\u2019t match the master version as a result of browser caching. CLI: Improve performance when retrieving trial logs. CLI: Add the det user rename command for administrators to change the username of existing users. Expand documentation on Checkpoints by including checkpoint metadata management. Reorganize examples by splitting the Trial examples into separate folders. Bug Fixes Allow det-deploy local agent-up to work with remote masters. Ensure network failures during checkpoint upload do not unrecoverably break the associated trial. Ensure shared_fs checkpoint storage is usable for non-root containers for some host_path values. Fix a timeout issue that affected large (40+ machines) distributed experiments. Ensure the CLI can make secure connections to the master. Fix an issue that affected multi-GPU in PyTorchTrial with mixed precision enabled. Add a timeout to trial containers to ensure they are terminated promptly.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 190
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-9",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 191
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.9",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-9",
    "content": "Release Date: June 16, 2020 Retry ConnectionError and ProtocolError types for uploads to Google Cloud Storage. Fix a bug where the CLI was unable to make secure websocket connections to the master. Add the det user rename CLI command for admins to change the username of existing users.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 192
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-7",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 193
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.7",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-7",
    "content": "Release Date: June 11, 2020 Breaking Change: Gradient clipping for PyTorchTrial should now be specified via determined.pytorch.PyTorchCallback via the on_before_optimizer_step() method instead of being specified via the experiment configuration. Determined provides two built-in callbacks for gradient clipping: determined.pytorch.ClipGradsL2Norm and determined.pytorch.ClipGradsL2Value. Add a metadata field to checkpoints. Checkpoints can now have arbitrary key-value pairs associated with them. Metadata can be added, queried, and removed via the Python SDK. Add support for Keras callbacks that stop training early, including the official EarlyStopping callback. When a stop is requested, Determined will finish the training (or validation) step we are in, checkpoint, and terminate the trial. Add support for Estimator callbacks that stop training early, including the official stop_if_no_decrease_hook. When a stop is requested, Determined will finish the training (or validation) step we are in, checkpoint, and terminate the trial. Add support for model code that stops training of a trial programmatically. We recommend using the official Keras callbacks or Estimator hooks if you are using those frameworks. For PyTorch, you can request that training be stopped by calling set_stop_requested() from a PyTorch callback. When a stop is requested, Determined will finish the current training or validation step, checkpoint, and terminate the trial. Trials that are stopped early are considered to be \u201ccompleted\u201d (e.g., in the WebUI and CLI). More robust error handling for hyperparameter searches where one of the trials in the search encounters a persistent error. Determined will automatically restart the execution of trials that fail within an experiment, up to max_restart failures. After this point, any trials that fail are marked as \u201cerrored\u201d but the hyperparameter search itself is allowed to continue running. This is particularly useful when some parts of the hyperparameter space result in models that cannot be trained successfully (e.g., the search explores a range of batch sizes and some of those batch sizes cause GPU OOM errors). An experiment can complete successfully as long as at least one of the trials within it completes successfully. Support multi-GPU training for TensorFlow 2 models that use IndexedSlices for model parameters. NaN values in training and validation metrics are now treated as errors. This will result in restarting the trial from the most recently checkpoint if it has been restarted fewer than max_restarts times. Previously, NaN values were converted to the maximum floating point value. Preserve the last used user name on the log-in page. Add on_trial_close method to determined.estimator.RunHook. Use this for post-trial cleanup. Finalize gradient communication prior to applying gradient clipping in PyTorchTrial when perfoming multi-GPU training. WebUI: Add pause, activate, and cancel actions to dashboard tasks. Add a det-nobody user (with UID 65533) to default images. This provides an out-of-the-box option for running non-privileged containers with a working home directory.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 194
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 195
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.6",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-6",
    "content": "Release Date: June 5, 2020 Add end of training callback to EstimatorTrial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 196
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-5",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 197
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.5",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-5",
    "content": "Release Date: May 27, 2020 Breaking Change: Alter command-line options for controlling test mode and local mode. Test experiments on the cluster were previously created with det e create --test-mode ... but now should be created with det e create --test .... Local testing is started with det e create --test --local .... Fully local training (meaning --local without --test) is not yet supported. Add support for TensorFlow 2.2. Add support for post-checkpoint callbacks in PyTorchTrial. Add support for checkpoint hooks in EstimatorTrial. Add support for TensorBoard backed by S3-compliant APIs that are not AWS S3. Add generic callback support for PyTorch. TensorBoards now shut down after 10 minutes if metrics are unavailable. Update to NCCL 2.6.4 for distributed training. Update minimum required task environment version to 0.4.0. Fix Native API training one step rather than one batch when using TensorFlow Keras and Estimator. CLI: Add support for producing CSV and JSON output to det slot list and det agent list. CLI: Include the number of containers on each agent in the output of det agent list. Enterprise: Add support for using SCIM (System for Cross-domain Identity Management) to provision users. Add support for using OAuth2 to secure Determined\u2019s SCIM integration. Add support for users to sign-on through an external IdP with SAML.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 198
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 199
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.4",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-4",
    "content": "Release Date: May 14, 2020 Breaking Change: Users are no longer automatically logged in as the \u201cdetermined\u201d user. Support multi-slot notebooks. The number of slots per notebook cannot exceed the size of the largest available agent. The number of slots to use for a notebook task can be configured when the notebook is launched: det notebook start --config resources.slots=2 Support fetching the configuration of a running master via the CLI (det master config). Authentication sessions now expire after 7 days. Improve log messages for tf.keras trial callbacks. Add nvidia-container-toolkit support. Fix an error in the experimental bert_glue_pytorch example. The tf.keras examples for the Native and Trial APIs now refer to the same model. Add a topic guide explaining Determined\u2019s approach to Elastic Infrastructure. Add a topic guide explaining the Native API (since deprecated). UI: The Determined favicon acquires a small dot when any slots are in use. UI: Fix an issue with command sorting in the WebUI. UI: Fix an issue with badges appearing as the wrong color.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 200
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 201
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-3",
    "content": "Release Date: April 27, 2020 Add a tutorial for the new (experimental) Native API. Add support for locally testing experiments via det e create --local. Add determined.experimental.Determined class for accessing ExperimentReference, TrialReference, and Checkpoint objects. TensorBoard logs now appear under the storage_path for shared_fs checkpoint configurations. Allow commands, notebooks, shells, and TensorBoards to be killed before they are scheduled. Print container exit reason in trial logs. Choose a better default for the --tail option of command logs. Add REST API endpoints for trials. Support the execution of a startup script inside the agent Docker container Master and agent Docker containers will have the \u2018unless-stopped\u2019 restart policy by default when using det-deploy local. Prevent the det trial logs -f command from waiting for too long after the trial being watched reaches a terminal state. Fix bug where logs disappear when an image is pulled. Fix bug that affected the use of LRScheduler in PyTorchTrial for multi-GPU training. Fix bug after master restart where some errored experiments would show progress indicators. Fix ordering of steps from det trial describe --json. Docs: Added topic guide for effective distributed training. Docs: Reorganize install documentation. UI: Move the authenticated user to the top of the users list filter on the dashboard, right after \u201cAll\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 202
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 203
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Release Notes",
      "lvl1": "Release Notes",
      "lvl2": "Version 0.12",
      "lvl3": "Version 0.12.2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "release-notes.html#version-0-12-2",
    "content": "Release Date: April 21, 2020 Breaking Changes Rename PEDL to Determined. The canonical way to import it is via import determined as det. Reorganize source code. The frameworks module was removed, and each framework\u2019s submodules were collapsed into the main framework module. For example: det.frameworks.pytorch.pytorch_trial.PyTorchTrial is now det.pytorch.PyTorchTrial det.frameworks.pytorch.data.DataLoader is now det.pytorch.DataLoader det.frameworks.pytorch.checkpoint.load is now det.pytorch.load det.frameworks.pytorch.util.reset_parameters is now det.pytorch.reset_parameters det.frameworks.keras.tf_keras_trial.TFKerasTrial is now det.keras.TFKerasTrial det.frameworks.tensorflow.estimator_trial.EstimatorTrial is now det.estimator.EstimatorTrial det.frameworks.tensorpack.tensorpack_trial is now det.tensorpack.TensorpackTrial det.frameworks.util and det.frameworks.pytorch.util have been removed entirely Unify all plugin functions under the Trial class. make_data_loaders has been moved to two functions that should be implemented as part of the Trial class. For example, PyTorchTrial data loaders should now be implemented in build_training_data_loader() and build_validation_data_loader() in the trial definition. Please see updated examples and documentation for changes in each framework. Trial classes are now required to define a constructor function. The signature of the constructor function is: def __init__(self, context) -> None: ... where context is an instance of the new det.TrialContext class. This new object is the primary mechanism for querying information about the system. Some of its methods include: get_hparam(name): get a hyperparameter by name get_trial_id(): get the trial ID being trained get_experiment_config(): get the experiment config for this experiment get_per_slot_batch_size(): get the batch size appropriate for training (which will be adjusted from the global_batch_size hyperparameter in distributed training experiments) get_global_batch_size(): get the effective batch size (which differs from per-slot batch size in distributed training experiments) distributed.get_rank(): get the unique process rank (one process per slot) distributed.get_local_rank(): get a unique process rank within the agent distributed.get_size(): get the number of slots distributed.get_num_agents: get the number of agents (machines) being used The global_batch_size hyperparameter is required (that is, a hyperparameter with this name must be specified in the configuration of every experiment). Previously, the hyperparameter batch_size was required and was manipulated automatically for distributed training. Now global_batch_size will not be manipulated; users should train based on context.get_per_slot_batch_size(). Remove download_data(). If users wish to download data at runtime, they should make sure that each process (one process per slot) downloads to a unique location. This can be accomplished by appending context.get_rank() to the download path. Remove det.trial_controller.util.get_rank() and det.trial_controller.util.get_container_gpus(). Use context.distributed.get_rank() and context.distributed.get_num_agents() instead. General Improvements tf.data.Dataset is now supported as input for all versions of TensorFlow (1.14, 1.15, 2.0, 2.1) for TFKerasTrial and EstimatorTrial. Please note that Determined currently does not support checkpointing tf.data.Dataset inputs. Therefore, when resuming training, it resumes from the start of the dataset. Model weights are loaded correctly as always. TFKerasTrial now supports five different types of inputs: A tuple (x_train, y_train) of NumPy arrays. x_train must be a NumPy array (or array-like), a list of arrays (in case the model has multiple inputs), or a dict mapping input names to the corresponding array, if the model has named inputs. y_train should be a NumPy array. A tuple (x_train, y_train, sample_weights) of NumPy arrays. A tf.data.Dataset returning a tuple of either (inputs, targets) or (inputs, targets, sample_weights). A keras.utils.Sequence returning a tuple of either (inputs, targets) or (inputs, targets, sample weights). A det.keras.SequenceAdapter returning a tuple of either (inputs, targets) or (inputs, targets, sample weights). PyTorch trial checkpoints no longer save in MLflow\u2019s MLmodel format. The det trial download command now accepts -o to save a checkpoint to a specific path. PyTorch checkpoints can then be loaded from a specified local file system path. Allow the agent to read configuration values from a YAML file. Include experiment ID in the downloaded trial logs. Display checkpoint storage location in the checkpoint info modal for trials and experiments. Preserve recent tasks\u2019 filter preferences in the WebUI. Add task name to det slot list command output. Model definitions are now downloaded as compressed tarfiles (.tar.gz) instead of zipfiles (.zip). startup-hook.sh is now executed in the same directory as the model definition. Rename projects to examples in the Determined repository. Improve documentation: Add documentation page on the lifecycle of an experiment. Add how-to and topic guides for multi-GPU (both for single-machine parallel and multi-machine) training. Add a topic guide on best practices for writing model definitions. Fix bug that occasionally caused multi-machine training to hang on initialization. Fix bug that prevented TensorpackTrial from successfully loading checkpoints. Fix a bug in TFKerasTrial where runtime errors could cause the trial to hang or would silently drop the stack trace produced by Keras. Fix trial lifecycle bugs for containers that exit during the pulling phase. Fix bug that led to some distributed trials timing out. Fix bug that caused tf.keras trials to fail in the multi-GPU setting when using an optimizer specified by its name. Fix bug in the CLI for downloading model definitions. Fix performance issues for experiments with very large numbers of trials. Optimize performance for scheduling large hyperparameter searches. Add configuration for telemetry in master.yaml. Add a utility function for initializing a trial class for development (det.create_trial_instance) Add security.txt. Add det.estimator.load() to load TensorFlow Estimator saved_model checkpoints into memory. Ensure AWS EC2 keypair exists in account before creating the CloudFormation stack. Add support for gradient aggregation in Keras trials for TensorFlow 2.1. Add TrialReference and Checkpoint experimental APIs for exporting and loading checkpoints. Improve performance when starting many tasks simultaneously. Web Improvements Improve discoverability of dashboard actions. Add dropdown action menu for killing and archiving recent tasks on the dashboard. Add telemetry for web interactions. Fix an issue around cluster utilization status showing as \u201cNo Agent\u201d for a brief moment during initial load. Add Ace editor to attributions list. Set UI preferences based on the logged-in user. Fix an issue where the indicated user filter was not applied to the displayed tasks. Improve error messaging for failed actions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 204
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined AI Documentation",
      "lvl1": "Determined AI Documentation",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "index.html#determined-ai-documentation",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined AI Documentation",
      "lvl1": "Determined AI Documentation",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "index.html#determined-ai-documentation",
    "content": "Find setup guides, examples, tutorials, API references, and more to learn how to quickly train almost any deep learning model using Determined. <div class=\"landing\"> <div class=\"tiles-flex\"> <div class=\"tile-container\"> <a class=\"tile\" href=\"architecture/index.html\"> <img class=\"tile-icon\" src=\"_static/images/tools.png\" alt=\"tools icon\"> <h2 class=\"tile-title\">How It Works</h2> <p class=\"tile-description\">Learn about core concepts, key features, and system architecture.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"tutorials/index.html\"> <img class=\"tile-icon\" src=\"_static/images/getting-started.png\" alt=\"getting started icon\"> <h2 class=\"tile-title\">Tutorials</h2> <p class=\"tile-description\">Try Determined and learn the basics including how to port your existing code to the Determined environment.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"setup-cluster/deploy-cluster/index.html\"> <img class=\"tile-icon\" src=\"_static/images/integrations.png\" alt=\"integrations icon\"> <h2 class=\"tile-title\">Set Up Determined</h2> <p class=\"tile-description\">Set up an on-premise or cloud-based cluster, including AWS, GCP, and Azure.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"tutorials/quickstart-mdldev.html\"> <img class=\"tile-icon\" src=\"_static/images/setup.png\" alt=\"setup icon\"> <h2 class=\"tile-title\">Model Developer Quickstart</h2> <p class=\"tile-description\">Learn the basic steps needed to set up a Determined environment and train models.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"training/index.html\"> <img class=\"tile-icon\" src=\"_static/images/developer-guide.png\" alt=\"developer guide icon\"> <h2 class=\"tile-title\">Model Developer Guide</h2> <p class=\"tile-description\">Find user guides. Learn how to work with Training APIs and configure your distributed training experiments.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"reference/index.html\"> <img class=\"tile-icon\" src=\"_static/images/reference.png\" alt=\"reference icon\"> <h2 class=\"tile-title\">Reference</h2> <p class=\"tile-description\">Explore API libraries and configuration settings.</p> </a> </div> </div> </div>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How-To Articles",
      "lvl1": "How-To Articles",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/index.html#how-to-articles",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How-To Articles",
      "lvl1": "How-To Articles",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/index.html#how-to-articles",
    "content": "How to View Epoch-Based Metrics in the WebUI: Learn how to view epoch-based metrics in the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#how-to-view-epoch-based-metrics-in-the-webui",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#how-to-view-epoch-based-metrics-in-the-webui",
    "content": "Sometimes, you want to analyze and visualize your model\u2019s training progress and validation performance over multiple epochs. In this article, we\u2019ll show you how to view epoch-based metric data in the WebUI by reporting an epoch metric to the Determined master via the Core API. To do this, we\u2019ll define an epoch metric and use it as the X-Axis label in the WebUI. Recommended Quickstart for Model Developers Core API User Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Set Up Your Training Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#set-up-your-training-environment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Set Up Your Training Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#set-up-your-training-environment",
    "content": "To begin, you\u2019ll need a Determined cluster. If you are new to Determined AI (Determined), you can install the Determined library and start a cluster locally. Ensure you have Docker running and then run the following command: pip install determined # If your machine has GPUs: det deploy local cluster-up # If your machine does not have GPUs: det deploy local cluster-up --no-gpu The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 1: Get the Tutorial Files & Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-1-get-the-tutorial-files-run-the-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 1: Get the Tutorial Files & Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-1-get-the-tutorial-files-run-the-experiment",
    "content": "To follow along, you\u2019ll need the tutorial files. Create a new directory. Access the tutorial files via the core_api_pytorch_mnist.tgz download link or directly from the Github repository. For this step, we\u2019ll use our model_def.py script and its accompanying const.yaml experiment configuration file. From the directory containing our files, we\u2019ll begin by running the following command: det e create const.yaml . -f We don\u2019t have any data to plot yet, but we\u2019ll open the Determined WebUI to see that our experiment is running. Go to http://localhost:8080/. Accept the default username of determined and leave the password empty. Click Sign In. In the WebUI, we can select our experiment and visit the Logs tab.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-report-epoch-based-metrics",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-report-epoch-based-metrics",
    "content": "In this section, we\u2019ll define our epoch metric. To follow along, use the model_def_metrics.py script and its accompanying metrics.yaml experiment configuration file. Our script, model_def_metrics.py, is a modification of the model_def.py script. It already reports training and validation metrics to the Determined master and contains a steps_completed variable that is needed to plot metrics on a graph in the WebUI. For a full description of the Core API PyTorch MNIST Tutorial files, visit the Core API User Guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": "Step 2.1: Modify the Train and Validation Methods",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-1-modify-the-train-and-validation-methods",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": "Step 2.1: Modify the Train and Validation Methods",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-1-modify-the-train-and-validation-methods",
    "content": "Our script, model_def_metrics.py, contains core_context.train. This is used to report training and validation metrics. However, we also want to report epoch-based metrics and to allow Determined to keep track of the specific epoch for which training loss is being reported. To do this, we\u2019ll modify the train() method to include epoch_idx as a metric: core_context.train.report_training_metrics( steps_completed=batches_completed + epoch_idx * len(train_loader), metrics={\"train_loss\": loss.item(), \"epoch\": epoch_idx}, ) Similarly, we\u2019ll include epoch as a metric in the reported validation metrics. This allows Determined to track the specific epoch for which the validation loss is being reported: core_context.train.report_validation_metrics( steps_completed=steps_completed, metrics={\"test_loss\": test_loss, \"epoch\": epoch}, ) Now that we\u2019ve reported an epoch value, Epoch will be an available option for the X-Axis when we view our metric data graph in the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": "Step 2.2: Run the Experiment & View Epoch-Based Metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-2-run-the-experiment-view-epoch-based-metrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Step 2: Report Epoch-Based Metrics",
      "lvl3": "Step 2.2: Run the Experiment & View Epoch-Based Metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#step-2-2-run-the-experiment-view-epoch-based-metrics",
    "content": "Our modified script is ready to report epoch-based metrics to the Determined master. To run our experiment, we\u2019ll run the following command: det e create metrics.yaml . To view our epoch-based metrics, we\u2019ll open the Determined WebUI and select our experiment. Our experiment opens in the Overview tab. We\u2019ll go to the Metrics tab, select the X-Axis menu and then choose Epoch. If we scroll down, we\u2019ll be able to see the epoch-based metrics graph.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Summary",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#summary",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Summary",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#summary",
    "content": "In this article, you learned how to add a few lines of code to a script for the purpose of reporting epoch-based metrics in addition to training and validation metrics. You also learned how to view epoch-based metric data in the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to View Epoch-Based Metrics in the WebUI",
      "lvl1": "How to View Epoch-Based Metrics in the WebUI",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "articles/viewing-epoch-based-metrics.html#next-steps",
    "content": "Now you can try editing your own script for the purpose of reporting epoch-based metrics to the Determined master. For more tutorials, visit the Tutorials to learn the basics of working with Determined and how to port your existing code to the Determined environment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Works with Determined",
      "lvl1": "Works with Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/ecosystem/ecosystem-integration.html#works-with-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Works with Determined",
      "lvl1": "Works with Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/ecosystem/ecosystem-integration.html#works-with-determined",
    "content": "Determined is designed to easily integrate with other popular ML ecosystem tools for tasks that are related to model training, such as ETL, ML pipelines, and model serving. It is recommended to use the Python SDK to interact with Determined. Our Works with Determined repository includes examples of how to use Determined with a variety of ML ecosystem tools, including Pachyderm, DVC, Delta Lake, Seldon, Spark, Argo, Airflow, and Kubeflow.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#monitoring-experiment-through-webhooks",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#monitoring-experiment-through-webhooks",
    "content": "Monitoring experiment status is a vital part of working with Determined. In order to integrate Determined into your existing workflows, you can make use of webhooks to update other systems, receive emails, slack messages, and more when an experiment is updated.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#security-and-signed-payload",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#security-and-signed-payload",
    "content": "Each webhook request will include a signed payload that users can use to verify that webhook calls from Determined are genuine. This will require that users define a webhook_signing_key for signing. If a webhook signing key is not provided then one will be generated for the user.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Setting the Key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#setting-the-key",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Setting the Key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#setting-the-key",
    "content": "The signing key can be set in the following ways: In the master yaml configuration file by adding: webhooks: signing_key: <signing_key> By setting a DET_WEBHOOKS_SIGNING_KEY environment variable. By specifying a ---security-webhooks-signing-key flag.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Retrieving the Key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#retrieving-the-key",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Retrieving the Key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#retrieving-the-key",
    "content": "The key can be found in the cluster configuration. For example it will be returned in api/v1/master/config.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Event Payload",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#event-payload",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Event Payload",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#event-payload",
    "content": "Currently we support two types of webhooks: Slack and Default. A payload for a Default webhook will contain information about the event itself, the trigger for the event, and the entity that triggered the event. The shape of event_data is determined by event_type. Below is an example payload for EXPERIMENT_STATE_CHANGE; other types may be structured differently. { \"event_id\": \"4cd26e62-60c6-4a8b-8d03-7629091a4ef5\", // unique event UUID \"event_type\": \"EXPERIMENT_STATE_CHANGE\", // the trigger type for the event \"timestamp\": 1665689991, // the timestamp of the event occurrence \"condition\": { \"state\": \"COMPLETED\" // the condition that triggered the event; for now the condition will always be of this format and contain either \"COMPLETED\" or \"ERRORED\" }, \"event_data\": { \"experiment\": { \"id\": 41, \"state\": \"COMPLETED\", \"name\": \"cifar10_pytorch_const\", \"slots_per_trial\": 2, \"duration\": 41, // experiment duration measured in seconds \"resource_pool\": \"default\", \"workspace\": \"test workspace\", // experiment workspace name \"project\": \"test project\" // experiment project name } } }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Signed Payload",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#signed-payload",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Security and Signed Payload",
      "lvl3": "Signed Payload",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#signed-payload",
    "content": "For every webhook request Determined will generate two headers, X-Determined-AI-Signature and X-Determined-AI-Signature-Timestamp, which can be used to verify each request to a webhook endpoint. The X-Determined-AI-Signature-Timestamp will represent the time at which the request was generated and sent. You can choose to inspect this timestamp and decide whether to discard any requests with a timestamp that is too distant from the current time. The X-Determined-AI-Signature will be a representation of a \u201csigned\u201d request payload. The signed request payload will be generated in the following way: Combine the timestamp in X-Determined-AI-Signature-Timestamp, the comma character \u201c,\u201d and the request body, which will be the entire event payload. Create an HMAC using SHA256 hashing, with the webhook_signing_key and the event payload from previous step. You can then check to make sure the X-Determined-AI-Signature header value and the generated signed payload match. Below is an example of handling a signed payload in Python. import hashlib, hmac, json # User-defined function to authenticate webhook requests def authenticate_webhook_request(request_body, request_headers, webhook_signing_key): timestamp = request_headers[\"X-Determined-AI-Signature-Timestamp\"] signed_payload = request_headers[\"X-Determined-AI-Signature\"] request_body = json.dumps(separators=(\",\", \":\"), obj=json.loads(request_body)) calculated_signed_payload = hmac.new( webhook_signing_key.encode(), f\"{timestamp},{request_body}\".encode(), digestmod=hashlib.sha256, ).hexdigest() return calculated_signed_payload == signed_payload The request body in the function shown above will be the JSON payload from the request. Ensure that the JSON payload does not contain spaces between keys and their values when creating the signed payload. For example \u201c{\u201ckey_one\u201d: \u201cvalue_one\u201d}\u201d will fail authentication, while \u201c{\u201ckey_one\u201d:\u201dvalue_one\u201d}\u201d will yield the correct signed payload value.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Creating Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#creating-webhooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Creating Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#creating-webhooks",
    "content": "To create a webhook, navigate to /det/webhooks or click on the \u201cWebhooks\u201d item in navigation side menu, and click on the top right corner button \u201cNew Webhook\u201d. You must have the relevant permission to be able to view this page. Consult a system admin if you are unsure about your permissions. At the modal input: URL: webhook URL. Type: Default or Slack. The Slack type can automatically format message content for better readability on Slack. Trigger: the experiment state change you want to monitor, either Completed or Error. Once created, your webhook will begin executing for the chosen events.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Testing Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#testing-webhooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Testing Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#testing-webhooks",
    "content": "To test a webhook, click on the triple dots on the right of webhook record to expand available actions. Clicking on \u201cTest Webhook\u201d will trigger a test event to be sent to the defined webhook URL with a mock payload as stated below: { \"event_id\": \"b8667b8a-e14d-40e5-83ee-a64e31bdc5f4\", \"event_type\": \"EXPERIMENT_STATE_CHANGE\", \"timestamp\": 1665695871, \"condition\": { \"state\": \"COMPLETED\" }, \"event_data\": { \"data\": \"test\" } }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Deleting Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#deleting-webhooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Monitoring Experiment Through Webhooks",
      "lvl1": "Monitoring Experiment Through Webhooks",
      "lvl2": "Deleting Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/index.html#deleting-webhooks",
    "content": "To delete a webhook, click on the triple dots on the right of webhook record to expand available actions. We do not support editing webhooks. You can delete and recreate webhooks if needed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#through-zapier",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#through-zapier",
    "content": "This section will walk through the steps needed to set up Zapier webhook to to receive updates from Determined. The steps to set up Zapier webhook are: Creating a Zap with Webhook Setting up the Webhook in Determined Testing the Webhook Verifing the Signature Configuring Destination",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Creating a Zap with Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#creating-a-zap-with-webhook",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Creating a Zap with Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#creating-a-zap-with-webhook",
    "content": "First, you need to create a Zap with webhook. Visit the Zapier Website, signup if you haven\u2019t already, and click on the Create Zap button. Select Webhooks by Zapier as trigger Catch Raw Hook as event. Using Catch Raw Hook intead of Catch Hook because headers are needed to verify each webhook request. You need to upgrade to premium account to access Webhooks by Zapier",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Setting up the Webhook in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#setting-up-the-webhook-in-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Setting up the Webhook in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#setting-up-the-webhook-in-determined",
    "content": "Then, you need to create a webhook in Determined using the Webhook URL from Zapier. Navigate to /det/webhooks or click on the \u201cWebhooks\u201d item in navigation side menu, then click the New Webhook button in the top right corner of the page. Paste the Webhook URL that was copied from Zapier in the URL field. Select Default for the webhook type and then select the triggers that you want to receive notifications for. Finally, select Create Webhook and your webhook will be created.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Testing the Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#testing-the-webhook",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Testing the Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#testing-the-webhook",
    "content": "To send a test payload, click on the triple dots on the right of webhook record and click on Test Webhook. Then navigate back to Zapier and click on Test Trigger, then you should be able to see the test request.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Verifing the Signature",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#verifing-the-signature",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Verifing the Signature",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#verifing-the-signature",
    "content": "Refer to Security and Signed Payload for the details behind verifing signature. In Zapier, you can use Code by Zapier to compute signature based on payload and timestamp, then compare it with the signature in the request to verify each request. Add a new action and choose Code by Zapier, select Run Python as an example. Construct input data as following: webhook_signing_key: match the webhook_signing_key in Determined. timestamp: X-Determined-AI-Signature-Timestamp from request header. signature: X-Determined-AI-Signature from request header. payload: raw body of request. Input code as following: import hmac, hashlib, json signing_key = input_data['webhook_signing_key'] timestamp = input_data['timestamp'] signature = input_data['signature'] payload = json.loads(input_data['payload']) calculated_signature = hmac.new(signing_key.encode(), f\"{timestamp},{payload}\".encode(), digestmod=hashlib.sha256).hexdigest() if calculated_signature == signature: return {\"result\": \"PASS\", \"payload\": payload} return {\"result\": \"Signature cannot be verified, request might not be legit\"} Under Test Action, test the code above, you should be able to see that verification has passed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Configuring Destination",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#configuring-destination",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Zapier",
      "lvl1": "Through Zapier",
      "lvl2": "Configuring Destination",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/zapier.html#configuring-destination",
    "content": "Finally, you can configure where to proceed under each scenario by adding more actions. For example, send out an alert when verification fails, or send out an email with experiment information when verification pass.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#through-slack",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#through-slack",
    "content": "This section will walk through the steps needed to set up Slack to receive updates from Determined in a specific Slack channel using Slack Webhook Integrations. The steps for enabling slack notifications are: Creating a Slack Application Enabling Incoming Webhooks in Slack Configuring Determined for Slack Webhooks Setting up the Webhook in Determined Testing the Webhook",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Creating a Slack Application",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#creating-a-slack-application",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Creating a Slack Application",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#creating-a-slack-application",
    "content": "First, we need to create a Slack application and give the application permissions to post in the appropriate Slack channel. Visit the Slack App Managment page and click on the Create New App button. In app configuration, select From scratch. In the next window you will input an \u201cApp Name\u201d and select the Workspace for the application.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Enabling Incoming Webhooks in Slack",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#enabling-incoming-webhooks-in-slack",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Enabling Incoming Webhooks in Slack",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#enabling-incoming-webhooks-in-slack",
    "content": "Next, we need to configure incoming webhooks for our Slack application. In your Slack application\u2019s management page go to the Incoming Webhooks section. Enable the toggle for Activate Incoming Webhooks as shown below. Now that webhooks are enabled we can set up a new webhook integration. Click the Add New Webhook to Workspace button at the bottom of the page. On the next page you will be asked to select the channel that will receive webhook updates. Choose a channel and then press the Allow button and you will be taken back to the Incoming Webhooks page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Configuring Determined for Slack Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#configuring-determined-for-slack-webhooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Configuring Determined for Slack Webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#configuring-determined-for-slack-webhooks",
    "content": "Note: The following section is optional but encouraged. Determined has the ability to send links to experiments, projects, and workspaces in Slack messages. To enable Determined to send correctly formatted links you must set the Base URL in the Determined cluster configuration. The Base URL is the website address that is used to access the Determined user interface. The value should be in the format of https://yourdomain.com There are three ways to set the Base URL. Setting a DET_WEBHOOK_BASE_URL environment variable. Using the flag --webhook-base-url Adding a base_url entry to the webhook portion of the master configuration file. An example is shown below: webhook: base_url: https://yourdomain.com If the Base URL is set correctly then Slack messages will include links as shown below. If no Base URL is set then links will not be present in Slack messages.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Setting up the Webhook in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#setting-up-the-webhook-in-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Setting up the Webhook in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#setting-up-the-webhook-in-determined",
    "content": "Finally, we will need to add a webhook in Determined using Webhook URL provided by Slack. In the Webhook URLs for Your Workspace section of Incoming Webhooks page you should see a list of Webhook URLs for all of the channels that you have added. Click the Copy button for the appropriate Webhook URL and then navigate to the Webhooks page in Determined. On the Webhooks page in Determined click the New Webhook button in the top right corner of the page. In the pop up, paste the Webhook URL that was copied from Slack in the URL field. Choose Slack for the webhook type and then choose the triggers that you want to receive notifications for. Finally, select Create Webhook and your webhook will be created.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Testing the Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#testing-the-webhook",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Through Slack",
      "lvl1": "Through Slack",
      "lvl2": "Testing the Webhook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/notification/slack.html#testing-the-webhook",
    "content": "To test a Slack webhook in Determined go to the Webhooks page and click on the three vertical dots on the right side of any of the listed webhooks. If everything has been configured correctly you should receive a message from the Slack application you created with the message \u201ctest\u201d as shown above.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Pachyderm",
      "lvl1": "Pachyderm",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/pachyderm/pachyderm.html#pachyderm",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Pachyderm",
      "lvl1": "Pachyderm",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/pachyderm/pachyderm.html#pachyderm",
    "content": "Pachyderm provides data-driven pipelines with version control and autoscaling that can be used alongside Determined. Pachyderm runs across all major cloud providers and on-premise installations. Use Pachyderm to store and version your data via repositories and pipelines Use Determined to train your models on Pachyderm data To get started with Pachyderm, visit the Pachyderm documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-determined-with-prometheus-and-grafana",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-determined-with-prometheus-and-grafana",
    "content": "Supported Versions Grafana 8.3.0+ Prometheus 2.14.0 Determined 0.17.6+ This document describes the setup and configuration to enable a Grafana dashboard to monitor Determined hardware and system metrics on a cloud cluster, such as AWS or Kubernetes. Determined provides a Prometheus endpoint that contains mappings between internal task, GPU, and container definitions, which are used by Prometheus to collect relevant metrics on a cluster running Determined. The endpoint is not enabled by default but can be enabled in the master configuration file.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#reference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#reference",
    "content": "Grafana Prometheus cAdvisor dcgm-exporter",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#constraints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#constraints",
    "content": "The Determined Prometheus endpoint is configured to work with cAdvisor for CPU metrics and dcgm-exporter (DCGM) for GPU metrics. The default ports for cAdvisor, 8080, and dcgm-exporter, 9400, are hardcoded into the Prometheus endpoint. If an agent is running on the same machine as the master, the master must be running on a port other than 8080 for cAdvisor metrics to be scraped. Although other monitoring tools can be used with the setup, this guide describes only cAdvisor and DCGM tool configuration. Prometheus queries on metrics collected by other tools can differ, depending on the format and organization of the returned metrics.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#prerequisites",
    "content": "A Grafana installation for dashboard monitoring. An on-cluster Prometheus instance for time-series data collection.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-determined",
    "content": "Install and run Determined on a cluster. When launching the master instance, enable the Prometheus endpoints by adding a flag to the master.yaml configuration file: observability: enable_prometheus: true This enables the following two Prometheus API endpoints on the instance. {$DET_MASTER_ADDR}/prom/det-state-metrics: The det-state-metrics endpoint includes various machine-level label mappings to internal Determined entities, such as GPU UUIDs and container IDs to task, allocation, and experiment labels, which are used by PromQL to join vectors. {$DET_MASTER_ADDR}/prom/det-http-sd-config: The det-http-sd-config endpoint contains address and resource pool information for currently active agents. These are used by Prometheus as targets for scraping. This endpoint is configured to support running default cAdvisor, port 8080, and DCGM, port 9400, monitoring. Other tools exposing Prometheus metrics can be used instead of cAdvisor and DCGM if they are running on these ports.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure cAdvisor and dcgm-exporter",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-cadvisor-and-dcgm-exporter",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure cAdvisor and dcgm-exporter",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-cadvisor-and-dcgm-exporter",
    "content": "The cAdvisor and dcgm-exporter monitoring tools must be running on the cluster agents to be monitored. These can be installed manually or run as individual Docker containers. To configure dynamic agents to start up with cAdvisor and dcgm-exporter, add the following startup script to the master.yaml file: - pool_name: compute-pool provider: startup_script: | # Run dcgm-exporter on 9400 docker run -d --gpus all --rm -p 9400:9400 nvcr.io/nvidia/k8s/dcgm-exporter:2.3.2-2.6.3-ubuntu20.04 # Run cAdvisor on 8080 VERSION=v0.36.0 docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:ro \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=8080:8080 \\ --detach=true \\ --name=cadvisor \\ --privileged \\ --device=/dev/kmsg \\ gcr.io/cadvisor/cadvisor:$VERSION This example startup script includes the default setup docker commands provided by dcgm-exporter and cAdvisor.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Prometheus",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-prometheus",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Prometheus",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-prometheus",
    "content": "Install Prometheus on any node in the monitored cluster. Launch Prometheus with the provided prometheus.yml configuration file. To replace the placeholder master address, you\u2019ll need to edit the Prometheus configuration file. The metric_relabel_configs parameter edits certain label names in jobs for joining in PromQL. The scrape_interval parameter values can be modified to optimize for resolution/size/time. The $PATH_TO_TOKEN specifies a path to an authorization token for the Determined master. This can be kept in a local file by running the token-refresh.sh script in the same directory with a CRON job (set to run daily).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Grafana",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-grafana",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Configure Grafana",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#configure-grafana",
    "content": "A Grafana instance can be installed on any machine that adds the above Prometheus address as a data source. After the Grafana server is running and the Web UI is accessible, follow these steps: Add a Prometheus data source in Grafana -> Configuration -> Data Sources -> Add data source. Configure the Prometheus data source set up in the previous section by setting the URL to your running Prometheus server address. By default, this is the machine address on port 9090. After the Prometheus data source connects, import the Determined Hardware Metrics dashboard JSON file in Grafana -> Create -> Import -> Import using panel JSON.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#example",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Determined with Prometheus and Grafana",
      "lvl1": "Configure Determined with Prometheus and Grafana",
      "lvl2": "Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "integrations/prometheus/prometheus.html#example",
    "content": "Following the above configuration steps and after submitting experiments on the cluster, you should see populated panels in the imported Grafana dashboard: Grafana -> Dashboards. Each panel in the dashboard is powered by one or more Prometheus queries and tracks a specific metric on the cluster as a percentage of total capacity. Results can be further filtered using tags and resource pool and time range in Grafana.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "System Architecture",
      "lvl1": "System Architecture",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/system-architecture.html#system-architecture",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "System Architecture",
      "lvl1": "System Architecture",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/system-architecture.html#system-architecture",
    "content": "Determined consists of a single master and one or more agents. There is typically one agent per compute server; a single machine can serve as both a master and an agent. Determined AI System Architecture The master is the central component of the Determined system. It is responsible for Storing experiment, trial, and workload metadata. Scheduling and dispatching work to agents. Managing provisioning and deprovisioning of agents in clouds. Advancing the experiment, trial, and workload state machines over time. Hosting the WebUI and the REST API. An agent manages a number of slots, which are computing devices (typically a GPU or CPU). An agent has no state and only communicates with the master. Each agent is responsible for Discovering local computing devices (slots) and sending metadata about them to the master. Running the workloads that are requested by the master. Monitoring containers and sending information about them to the master. The task container runs a training task or other task(s) in a containerized environment. Training tasks are expected to have access to the data that will be used in training. The agents are responsible for reporting the status of the task container to the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How Determined Works",
      "lvl1": "How Determined Works",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/index.html#how-determined-works",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How Determined Works",
      "lvl1": "How Determined Works",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/index.html#how-determined-works",
    "content": "With Determined you can: Use state-of-the-art distributed training to train models faster without changing model code. Automatically find high-quality models using advanced hyperparameter tuning. Get more from your GPUs and reduce cloud GPU costs with preemptible instances and smart scheduling. Leverage experiment tracking out-of-the-box to track and reproduce your work, tracking code versions, metrics, checkpoints, and hyperparameters. Continue using popular deep learning libraries, such as TensorFlow, Keras, and PyTorch by simply integrating the Determined API with your existing model code. Determined integrates these features into an easy-to-use, high-performance deep learning environment so you can spend your time building models instead of managing infrastructure. Determined AI System Architecture Learn more: Intro to Determined: Conceptual information about Determined including its features and benefits. System Architecture: Learn about the main components of the Determined system architecture. Distributed Training: A conceptual overview of distributed training with Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#introduction-to-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#introduction-to-determined",
    "content": "Determined is an all-in-one deep learning platform, compatible with PyTorch and TensorFlow. It takes care of: Distributed training for faster results. Hyperparameter tuning for obtaining the best models. Resource management for cutting cloud GPU costs. Experiment tracking for analysis and reproducibility.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#id1",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Configurable Interactive Jobs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#configurable-interactive-jobs",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Configurable Interactive Jobs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#configurable-interactive-jobs",
    "content": "The behavior of interactive jobs, such as TensorBoards, notebooks, commands, and shells, can be influenced by setting a variety of configuration variables. These configuration variables are similar but not identical to the configuration options supported by experiments. Configuration settings can be specified by passing a YAML configuration file when launching the workload via the Determined CLI. Configuration variables can also be set directly on the command line when any Determined task, except a TensorBoard, is launched. Options set via --config take precedence over values specified in the configuration file. Configuration settings are compatible with any Determined task unless otherwise specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Determined CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#determined-cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Determined CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#determined-cli",
    "content": "One of the key components of the Determined platform is the command-line interface (CLI). The CLI serves as a primary entry point for interacting with Determined, providing a way to efficiently manage and control various aspects of the system. The following list describes some of the tasks you can perform with the Determined CLI: Experiment management: Running experiments is a fundamental part of the machine learning process. With the CLI, you can effortlessly create, list, and manage experiments, as well as access important experiment metrics and logs. Queue management: The CLI enables users to manage their job queues, monitor the progress of ongoing tasks, and even prioritize or cancel jobs as needed. Notebook management: Jupyter notebooks are an essential tool for data scientists and machine learning engineers. The CLI simplifies the process of creating, launching, and managing Jupyter notebooks within the platform. TensorBoard integration: TensorBoard is a popular visualization tool for TensorFlow projects. The CLI allows users to easily launch and manage TensorBoard instances, making it simple to visualize and analyze the training progress of their models.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Commands and Shells",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#commands-and-shells",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Commands and Shells",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#commands-and-shells",
    "content": "Commands and shells support free-form tasks. In Determined, a developer uses an experiment, to run a trial. Outside of trials, a developer can use the det cmd Command (the capitalization indicates it is a specific feature of Determined). This Command facilitates the execution of a user-defined program on the cluster. On the other hand, shells initiate SSH servers, enabling the interactive use of cluster resources. Commands and shells enable developers to use a Determined cluster and its GPUs without having to write code conforming to the trial APIs. Commands are useful for running existing code in a batch manner; shells provide access to the cluster in the form of interactive SSH sessions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Configuration Templates",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#configuration-templates",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Configuration Templates",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#configuration-templates",
    "content": "At a typical organization, many Determined configuration files will contain similar settings. For example, all of the training workloads run at a given organization might use the same checkpoint storage configuration. One way to reduce this redundancy is to use configuration templates. With this feature, you can move settings that are shared by many experiments into a single YAML file that can then be referenced by configurations that require those settings. Each configuration template has a unique name and is stored by the Determined master. If a configuration specifies a template, the effective configuration of the task will be the result of merging the two YAML files (configuration file and template). The semantics of this merge operation is described under Configuration Templates: Merge Behavior. Determined stores this expanded configuration so that future changes to a template will not affect the reproducibility of experiments that used a previous version of the configuration template. A single configuration file can use at most one configuration template. A configuration template cannot use another configuration template.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Queue Management",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#queue-management",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Queue Management",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#queue-management",
    "content": "The Determined Queue Management system extends scheduler functionality to offer better visibility and control over scheduling decisions. It does this using the Job Queue, which provides better information about job ordering, such as which jobs are queued, and permits dynamic job modification. Queue Management is a new feature that is available to the fair share scheduler and the priority scheduler. Queue Management, described in detail in the following sections, shows all submitted jobs and their states and lets you modify some configuration options, such as priority, position in the queue, and resource pool. To begin managing job queues, go to the WebUI Job Queue section or use the det job set of CLI commands.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Model Registry",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#model-registry",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Model Registry",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#model-registry",
    "content": "The Model Registry is a way to group conceptually related checkpoints (including ones across different experiments), store metadata and long-form notes about a model, and retrieve the latest version of a model for use or further development. The Model Registry can be accessed through the WebUI, Python SDK, REST API, or CLI, though the WebUI has some features that the others are missing. The Model Registry is a top-level option in the navigation bar. This will take you to a page listing all of the models that currently exist in the registry, and allow you to create new models. You can select any of the existing models to go to the Model Details page, where you can view and edit detailed information about the model. There will also be a list of every version associated with the selected model, and you can go to the Version Details page to view and edit that version\u2019s information. For more information about how to use the model registry, see Organizing Models in the Model Registry",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Notebooks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#notebooks",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Notebooks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#notebooks",
    "content": "Jupyter Notebooks are a convenient way to develop and debug machine learning models, visualize the behavior of trained models, or even manage the training lifecycle of a model manually. Determined makes it easy to launch and manage notebooks. Determined Notebooks have the following benefits: Jupyter Notebooks run in containerized environments on the cluster. We can easily manage dependencies using images and virtual environments. The HTTP requests are passed through the master proxy from and to the container. Jupyter Notebooks are automatically terminated if they are idle for a configurable duration to release resources. A notebook instance is considered to be idle if it is not receiving any HTTP traffic and it is not otherwise active (as defined by the notebook_idle_type option in the task configuration). Once a Notebook is terminated, it is not possible to restore the files that are not stored in the persistent directories. You need to ensure that the cluster is configured to mount persistent directories into the container and save files in the persistent directories in the container. See Save and Restore Notebook State for more information. If you open a Notebook tab in JupyterLab, it will automatically open a kernel that will not be shut down automatically so you need to manually terminate the kernels.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "TensorBoards",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#tensorboards",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "TensorBoards",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#tensorboards",
    "content": "TensorBoard is a widely used tool for visualizing and inspecting deep learning models. Determined makes it easy to use TensorBoard to examine a single experiment or to compare multiple experiments. TensorBoard instances can be launched via the WebUI or the CLI. To launch TensorBoard instances from the CLI, first install the CLI on your development machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Workspaces and Projects",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#workspaces-and-projects",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Features",
      "lvl3": "Workspaces and Projects",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#workspaces-and-projects",
    "content": "Workspaces and projects provide a way to organize experiments. A project is a collection of experiments, and a workspace is a collection of projects. Learn more about workspaces and projects at Workspaces and Projects.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Benefits",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#benefits",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Benefits",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#benefits",
    "content": "Determined is a deep learning training platform that simplifies infrastructure management for domain experts while enabling configuration-based deep learning functionality that engineering-oriented practitioners might find inconvenient to implement. The Determined cohesive, end-to-end training platform provides best-in-class functionality for deep learning model training, including the following benefits: Implementation Benefit Automated model tuning Optimize models by searching through conventional hyperparameters or macro- architectures, using a variety of search algorithms. Hyperparameter searches are automatically parallelized across the accelerators in the cluster. See Hyperparameter Tuning. Cluster-backed notebooks, commands, and shells Leverage your shared cluster computing devices in a more versatile environment. See Jupyter Notebooks and Commands and Shells. Cluster management Automatically manage ML accelerators, such as GPUs, on-premise or in cloud VMs using your own environment, automatically scaling for your on-demand workloads. Determined runs in either AWS or GCP, so you can switch easily according to your requirements. See Resource Pools, Scheduling, and Elastic Infrastructure. Containerization Develop and train models in customizable containers that enable simple, consistent dependency management throughout the model development lifecycle. See Customizing Your Environment. Distributed training Easily distribute a single training job across multiple accelerators to speed up model training and reduce model development iteration time. Determined uses synchronous, data-parallel distributed training, with key performance optimizations over other available options. See Distributed Training Concepts. Experiment collaboration Automatically track your experiment configuration and environment to facilitate reproducibility and collaboration among teams. See Submit Experiment. Fault tolerance Models are checkpointed throughout the training process and can be restarted from the latest checkpoint, automatically. This enables training jobs to automatically tolerate transient hardware or system issues in the cluster. Framework support Broad framework support leverages these capabilities using any of the leading machine learning frameworks without needing to manage a different cluster for each. Different frameworks for different models can be used without risking future lock-in. See Training APIs. Profiling Out-of-the-box system metrics (measurements of hardware usage) and timings (durations of actions taken during training, such as data loading). Visualization Visualize your model and training procedure by using The built-in WebUI and by launching managed Using TensorBoard instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#concepts",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Elastic Infrastructure",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#elastic-infrastructure",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Elastic Infrastructure",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#elastic-infrastructure",
    "content": "When running in an AWS or GCP cloud environment, Determined can automatically provision and terminate GPU instances as the set of workloads on the cluster changes. This capability is called elastic infrastructure. The agents that are provisioned by the system are called dynamic agents. The diagram below outlines the high-level system architecture when using dynamic agents: Following the diagram, the execution would be: The master collects information on idle agents (agents with no active workloads) and pending workloads (agents waiting to be scheduled). The master calculates the ideal size of the cluster and decides how many agents to launch and which agents to terminate. The calculation is based on the total resource requests of all jobs submitted to the cluster, configured scaling behavior (minimum and maximum amount of instances the master can spawn), and the specification of the resource pools. An agent that is not running any containers is considered idle. By default, idle dynamic agents will automatically be terminated after 5 minutes of inactivity. This behavior gives agents a chance to run multiple workloads after they have been provisioned. The master makes API calls to agent providers, such as AWS and GCP, to provision and terminate agents as necessary. Once the agent instance has been created, it will automatically connect to the current master. The time it takes to create a new instance depends on the cloud provider and the configured instance type, but >60 seconds is typical.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#experiment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#experiment",
    "content": "An experiment represents the basic unit of running the model training code. An experiment is a collection of one or more trials that are exploring a user-defined hyperparameter space. For example, during a learning rate hyperparameter search, an experiment might consist of three trials with learning rates of .001, .01, and .1. To run experiments, you need to write your model training code. A model definition represents a specification of a deep learning model and its training procedure. It contains training code that implements training APIs. Visit the Training API Guides for more information. For each experiment, you can configure a searcher, also known as a search algorithm. The search algorithm determines how many trials will be run for a particular experiment and how the hyperparameters will be set. More information can be found at Hyperparameter Tuning.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#resource-pools",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#resource-pools",
    "content": "To run tasks such as experiments or notebooks, Determined needs to have resources (CPUs, GPUs) on which to run the tasks. However, different tasks have different resource requirements and, given the cost of GPU resources, it is important to choose the right resources for specific goals so that you get the most value out of your money. For example, you may want to run your training on beefy V100 GPU machines, while you want your TensorBoards to run on cheap CPU machines with minimal resources. Determined has the concept of a resource pool, which is a collection of identical resources that are located physically close to each other. Determined allows you to configure your cluster to have multiple resource pools and to assign tasks to a specific resource pool so that you can use different sets of resources for different tasks. Each resource pool handles scheduling and instance provisioning independently. When you configure a cluster, you set which pool is the default for auxiliary tasks and which pool is the default for compute tasks. CPU-only tasks such as TensorBoards will run on the default auxiliary pool unless you specify that they should run in a different pool when launching the task. Tasks that require a slot, such as experiments or GPU notebooks, will use the default compute pool unless otherwise specified. For this reason it is recommended that you always create a cluster with at least two pools, one with low-cost CPU instances for auxiliary tasks and one with GPU instances for compute tasks. This is the default setup when launching a cluster on AWS or GCP using det deploy. Here are some scenarios where it can be valuable to use multiple resource pools: Use GPU for training while using CPUs for TensorBoard. You create one pool, aws-v100, that provisions p3dn.24xlarge instances (large V100 EC2 instances) and another pool, aws-cpu that provisions m5.large instances (small and cheap CPU instances). You train your experiments using the aws-v100 pool, while you run your TensorBoards in the aws-cpu pool. When your experiments complete, the aws-v100 pool can scale down to zero to save money, but you can continue to run your TensorBoard. Without resource pools, you would have needed to keep a p3dn.24xlarge instance running to keep the TensorBoard alive. By default TensorBoard will always run on the default CPU pool. Use GPUs in different availability zones on AWS. You have one pool aws-v100-us-east-1a that runs p3dn.24xlarge in the us-east-1a availability zone and another pool aws-v100-us-east-1b that runs p3dn.24xlarge instances in the us-east-1b availability zone. You can launch an experiment into aws-v100-us-east-1a and, if AWS does not have sufficient p3dn.24xlarge capacity in that availability zone, you can launch the experiment in aws-v100-us-east-1b to check if that availability zone has capacity. Note that the \u201cAWS does not have capacity\u201d notification is only visible in the master logs, not on the experiment itself. Use spot/preemptible instances and fall back to on-demand if needed. You have one pool aws-v100-spot that you use to try to run training on spot instances and another pool aws-v100-on-demand that you fall back to if AWS does not have enough spot capacity to run your job. Determined will not switch from spot to on-demand instances automatically, but by configuring resource pools appropriately, it should be easy for users to select the appropriate pool depending on the job they want to run and the current availability of spot instances in the AWS region they are using. For more information on using spot instances, refer to Use Spot Instances. Use cheaper GPUs for prototyping on small datasets and expensive GPUs for training on full datasets. You have one pool with less expensive GPUs that you use for initial prototyping on small data sets and another pool that you use for training more mature models on large datasets.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Limitations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#limitations",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Limitations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#limitations",
    "content": "Currently resource pools are completely independent from each other so it is not possible to launch an experiment that tries to use one pool and then falls back to another one if a certain condition is met. You will need to manually decide to shift an experiment from one pool to another. A cluster is not currently allowed to have resource pools in multiple AWS/GCP regions or across multiple cloud providers. If the master is running in one AWS/GCP region, all resource pools must also be in that AWS/GCP region. If you create a task that needs slots and specify a pool that will never have slots (i.e. a pool with CPU-only instances), that task can never get scheduled. Currently that task will appear to be PENDING permanently.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Set up Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#set-up-resource-pools",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Set up Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#set-up-resource-pools",
    "content": "Resource pools are configured using the master configuration. For each resource pool, you can configure scheduler and provider information. If you are using static resource pools and launching agents by hand, you will need to update the agent configuration to specify which resource pool the agent should join.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Migrate to Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#migrate-to-resource-pools",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Migrate to Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#migrate-to-resource-pools",
    "content": "Resource pools were introduced with Determined 0.14.0, resulting in changes to the master configuration format. Since the change is backwards-compatible, cluster configurations that use earlier formats (prior to Determined 0.14.0) will still work. A configuration in the earlier format is interpreted as a cluster with a single resource pool that is the default for both CPU and GPU tasks. To take full advantage of resource pools, convert to the latest format. Converting is a simple process of moving around and renaming a small number of top-level fields. The earlier format had the top-level fields of scheduler and provisioner which set the scheduler and provisioner settings for the cluster. By contrast, the latest format has the top-level fields of resource_manager and resource_pools. The resource_manager section is for cluster level setting such as which pools should be used by default and the default scheduler settings. The scheduler information is identical to the scheduler field in the legacy format. The resource_pools section is a list of resource pools each of which has a name, description and resource pool level settings. Each resource pool can be configured with a provider field that contains the same information as the provisioner field in the legacy format. Each resource pool can also have a scheduler field that sets resource pool specific scheduler settings. If the scheduler field is not set for a specific resource pool, the default settings are used. Note that defining resource pool-specific scheduler settings is all-or-nothing. If the pool-specific scheduler field is blank, all scheduler settings will be inherited from the settings defined in resource_manager.scheduler. If any fields are set in the pool-specific scheduler section, no settings will be inherited from resource_manager.scheduler - you need to redefine everything. Here is an example master configuration illustrating the potential problem. resource_manager: type: agent scheduler: type: round_robin fitting_policy: best default_aux_resource_pool: pool1 default_compute_resource_pool: pool1 resource_pools: - pool_name: pool1 scheduler: fitting_policy: worst This example sets the cluster-wide scheduler defaults to use a best-fit, round robin scheduler in resource_manager.scheduler. The scheduler settings at the pool level for pool1 are then overwritten. Because scheduler.fitting_policy=worst is set, no settings are inherited from resource_manager.scheduler so pool1 uses a worst-fit, fair share scheduler because for a blank scheduler.type field, the default value is fair_share. If you want to have pool1 use a worst-fit, round robin scheduler, you need to make sure you redefine the scheduler type at the pool-specific level: resource_manager: type: agent scheduler: type: round_robin fitting_policy: best default_aux_resource_pool: pool1 default_compute_resource_pool: pool1 resource_pools: - pool_name: pool1 scheduler: type: round_robin fitting_policy: worst",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Launch Tasks into Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#launch-tasks-into-resource-pools",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Resource Pools",
      "lvl4": "Launch Tasks into Resource Pools",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#launch-tasks-into-resource-pools",
    "content": "When creating a task, the job configuration file has a section called \u201cresources\u201d. You can set the resource_pool subfield to specify the resource_pool that a task should be launched into. resources: resource_pool: pool1 If this field is not set, the task will be launched into one of the two default pools defined in the master configuration. Experiments will be launched into the default compute pool. TensorBoards will be launched into the default auxiliary pool. Commands, shells, and notebooks that request a slot (which is the default behavior if the resources.slots field is not set) will be launched into the default compute pool. Commands, shells, and notebooks that explicitly request 0 slots (for example the \u201cLaunch CPU-only Notebook\u201d button in the WebUI) will use the auxiliary pool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#scheduling",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#scheduling",
    "content": "This document covers the supported scheduling policies. The first section describes the native scheduling capabilities supported by Determined. The next section describes how Determined schedules tasks when running on Kubernetes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#native-scheduler",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#native-scheduler",
    "content": "Administrators can configure the desired scheduler in master configuration file. It is also possible to configure different scheduling behavior for different resource pools. Once the scheduling policy has been defined for the current master and/or resource pool, the scheduling behavior of an individual task is influenced by several task configuration values: For the fair-share scheduler, resources.weight lets users set the resource demand of a task relative to other tasks. For the priority scheduler, resources.priority lets users assign a priority order to tasks. Regardless of the scheduler, searcher.max_concurrent_trials lets users cap the number of slots that an adaptive_asha hyperparameter search experiment will request at any given time. Zero-slot tasks (e.g., CPU-only notebooks, TensorBoards) are scheduled independently of tasks that require slots (e.g., experiments, GPU notebooks). The fair-share scheduler schedules zero-slot tasks on a FIFO basis. The priority scheduler schedules zero-slot tasks based on priority.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": "Fair-Share Scheduler",
      "lvl6": null
    },
    "url": "architecture/introduction.html#fair-share-scheduler",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": "Fair-Share Scheduler",
      "lvl6": null
    },
    "url": "architecture/introduction.html#fair-share-scheduler",
    "content": "The master allocates cluster resources (slots) among the active experiments using a weighted fair-share scheduling policy. This policy aims for fair distribution of resources, taking into account each experiment\u2019s request. More specifically, slots are divided among the active experiments according to the demand of each experiment, where demand is the number of desired concurrent slots. For example, in an eight-GPU cluster with two experiments demanding 10 and 30 single-slot trials, the fair-share scheduler allocates two slots to the first experiment and allocates the six remaining slots to the second experiment. When new experiments start or active experiments change their resource demands, the scheduler adjusts the slot allocations accordingly. You can modify the behavior of the fair-share scheduler by changing the weight of a workload. A workload demand for slots is multiplied by the workload weight for scheduling purposes. A workload with a higher weight will be assigned proportionally more resources than a workload with lower weight. The default weight is 1. For example, in the scenario above, if the weight of the first experiment is set to 3 and the weight of the second experiment is set to 1, each experiment will be assigned four slots.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": "Task Priority",
      "lvl6": null
    },
    "url": "architecture/introduction.html#task-priority",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Native Scheduler",
      "lvl5": "Task Priority",
      "lvl6": null
    },
    "url": "architecture/introduction.html#task-priority",
    "content": "The master allocates cluster resources (slots) to active tasks based on their priority. High-priority tasks are preferred to low-priority tasks. Low-priority tasks will be preempted to make space for pending high-priority tasks if possible. Tasks of equal priority are scheduled in the order in which they were created. By default, the priority scheduler does not use preemption. If preemption is enabled in the master configuration file, when a higher priority task is pending and cannot be scheduled because no idle resources are available, the scheduler will attempt to schedule it by preempting lower priority tasks, starting with the task with the lowest priority. If there are no tasks to preempt, lower priority tasks might be backfilled on the idle resources. When a trial is preempted, its state is checkpointed so that the progress of the trial is not lost. Enabling preemption ensures that cluster resources can be reallocated to high priority tasks more promptly and backfilled to make the most use of the idle resources; however, preemption can also result in additional overhead due to checkpointing low priority tasks, which might be expensive for some models. Notebooks, TensorBoards, shells, and commands are not preemptible. These tasks will continue to occupy cluster resources until they complete or are terminated. The priority of any task can be changed after it is created using one of the following commands: det experiment set priority <ID> <priority> det command set priority <ID> <priority> det notebook set priority <ID> <priority> det shell set priority <ID> <priority> det tensorboard set priority <ID> <priority> However, since only experiments are preemptible, changing the priority of any other kind of task after it is scheduled has no effect. (It can still be useful to change the priorities of such tasks before they are scheduled in order to affect when they ultimately start running.) An example of priority scheduler behavior with preemption enabled: User submits a priority 2 adaptive_asha experiment with max_concurrent_trials 20 and slots_per_trial 1. 8 trials run and utilize all 8 GPUs. User submits a priority 1 distributed training experiment with slots_per_trial 4. 4 ASHA trials are preempted so the new distributed training experiment can run. Note that if preemption was not enabled, the new experiment would not get scheduled until the ASHA experiment GPU demand becomes <= 4. User starts a priority 3 notebook with resources.slots 1. The notebook has a lower priority than the two active experiments, so it will run as soon as the two active experiments collectively need <= 7 GPUs. ASHA and the distributed training experiment both complete, and the notebook task with priority 3 will run. User submits a priority 1 distributed training experiment with slots_per_trial 8. Although this workload has a higher priority than the active notebook task, it cannot be scheduled because it requires 8 slots, notebooks are not preemptible, and therefore only 7 slots are available. User submits a priority 2 distributed training experiment with slots_per_trial 4. One trial will be scheduled to make use of the idle 7 slots. The notebook is killed. The priority 2 distributed training experiment is preempted. And then the priority 1 distributed training experiment starts running. Once that experiment is complete, distributed training experiment with priority 2 restarts. The priority scheduler can be used with the Determined job queue, which provides more insight into scheduling decisions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#scheduling-with-kubernetes",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#scheduling-with-kubernetes",
    "content": "When using Determined on Kubernetes, Determined workloads, such as experiments, notebooks, and shells, are started by launching Kubernetes pods. The scheduling behavior that applies to those workloads depends on how the Kubernetes scheduler has been configured.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": "Gang Scheduling",
      "lvl6": null
    },
    "url": "architecture/introduction.html#gang-scheduling",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": "Gang Scheduling",
      "lvl6": null
    },
    "url": "architecture/introduction.html#gang-scheduling",
    "content": "By default, the Kubernetes scheduler does not perform gang scheduling or support preemption of pods. While it does take pod priority into account, it greedily schedules pods without consideration for the job each pod belongs to. This can result in problematic behavior for deep learning workloads, particularly for distributed training jobs that use many GPUs. A distributed training job that uses multiple pods requires all pods to be scheduled and running in order to make progress. Because Kubernetes does not support gang scheduling by default, cluster deadlocks can arise. For example, suppose that two experiments are launched simultaneously that each require 16 GPUs on a cluster with only 16 GPUs. It is possible that Kubernetes will assign some GPUs to one experiment and some GPUs to the other. Because neither experiment will receive the resources it needs to begin executing, the system will wait indefinitely. One way Determined addresses these problems is through the use of the lightweight coscheduling plugin, which extends the Kubernetes scheduler to support priority-based gang scheduling. To implement gang scheduling, the coscheduling plugin will not schedule a pod unless there are enough available resources to also schedule the rest of the pods in the same job. To function, the plugin requires special labels to be set that specify the number of nodes that each job needs for execution. Determined automatically calculates and sets these labels for GPU experiments that it launches. The coscheduling plugin is in beta and is therefore not enabled by default. To enable it, edit values.yaml in the Determined Helm chart to set the defaultScheduler field to coscheduler. There are several limitations to the coscheduling plugin to be aware of: The coscheduling plugin does not work with Kubernetes\u2019 cluster autoscaling feature. Static node pools must be used to achieve gang scheduling The plugin does not support preemption. For example, if the cluster is full of low priority jobs and a new high priority job is submitted, the high priority job will not be scheduled until one of the low priority jobs finishes. The Determined capability to automatically set pod labels is restricted to GPU experiments. Determined does not currently set labels for CPU experiments or user commands. When scheduling experiments that utilize the entire cluster, the plugin may take several minutes to schedule the next job. Because the coscheduler only approves of jobs when all of its pods are available, it may repeatedly reject partially-ready jobs, causing them to wait further. To enable gang scheduling with commands or CPU experiments, enable the coscheduler in values.yaml and modify the experiment config to contain the following: environment: pod_spec: metadata: labels: pod-group.scheduling.sigs.k8s.io/name: <unique task name> pod-group.scheduling.sigs.k8s.io/min-available: <# of GPUs required> spec: schedulerName: coscheduler You can also use schedulerName: default-scheduler to use the default Kubernetes scheduler. Additionally, please note that when running Determined on Kubernetes, a higher priority value means a higher priority (e.g. a priority 50 task will run before a priority 40 task).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": "Priority Scheduling with Preemption",
      "lvl6": null
    },
    "url": "architecture/introduction.html#priority-scheduling-with-preemption",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Scheduling",
      "lvl4": "Scheduling with Kubernetes",
      "lvl5": "Priority Scheduling with Preemption",
      "lvl6": null
    },
    "url": "architecture/introduction.html#priority-scheduling-with-preemption",
    "content": "Determined also makes available a priority scheduler that extends the Kubernetes scheduler to support preemption with backfilling. This plugin will preempt existing pods if higher priority pods are submitted. If there is still space in the cluster, backfilling will attempt to fill the nodes by scheduling lower priority jobs. Additionally, if there are leftover slots on partially-filled nodes, the scheduler will attempt to assign single-slot tasks until the space is filled. This packing behavior only occurs with single-slot tasks. This plugin is also in beta and is not enabled by default. To enable it, edit values.yaml in the Determined Helm chart to set the defaultScheduler field to preemption. Autoscaling is not supported and Determined can only automatically set labels for GPU experiments. Determined provides a default priority class, determined-medium-priority that has a priority of 50 and is used for all tasks. If users want to set a different priority level for an experiment, they may either specify a priority in the resources field of the experiment config or create a priorityClass and specify it in the pod_spec of the config. If both are specified, the specified priorityClass will take precedence over the priority field. In Kubernetes, a higher priority value means a higher priority (e.g. a priority 50 task will run before a priority 40 task). Additionally, if using a cluster with tainted nodes or labels, users must specify the tolerations or node selectors in the pod_spec. It is recommended that you use both tolerations and node selectors to better constrain where your experiments can run, especially on clusters that contain multiple GPU types. Below is an example that illustrates how to set priorities, tolerations, and node selectors. resources: priority: 42 # priorityClass, if set, takes precedence over this value environment: pod_spec: apiVersion: v1 kind: Pod spec: priorityClassName: determined-medium-priority # don't set if using priority value nodeSelector: key: value tolerations: - key: \"key1\" operator: \"Equal\" value: \"value\" effect: \"NoSchedule\" The Kubernetes priority scheduler can be used with the Determined job queue feature, which allows more insight into scheduling decisions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#trial",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "Trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#trial",
    "content": "A trial is a training task with a defined set of hyperparameters. A common degenerate case is an experiment with a single trial, which corresponds to training a single deep learning model.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "RBAC and User Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#rbac-and-user-groups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "RBAC and User Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#rbac-and-user-groups",
    "content": "Role Based Access Control (RBAC) enables administrators to control user access to various actions and data within Determined. RBAC feature requires Determined Enterprise Edition. Learn more about RBAC and User Group usage at RBAC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 56
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#yaml-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 57
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#yaml-configuration",
    "content": "YAML is a markup language often used for configuration. Determined uses YAML for configuring tasks such as experiments and notebooks, as well as configuring the Determined cluster as a whole. This guide describes a subset of YAML that is recommended for use with Determined. This is not a full description of YAML; see the specification or other online guides for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 58
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#yaml-types",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 59
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#yaml-types",
    "content": "A value in YAML can be a null or number, string, or Boolean scalar, or an array or map collection. Collections can contain other collections nested to any depth, although, the Determined YAML files generally have a fixed structure. A comment in a YAML file starts with a # character and extends to the end of the line. If you are familiar with JSON, you can think of YAML as an alternative way of expressing JSON objects that is meant to be easier for humans to read and write, since it allows comments and has fewer markup characters around the content.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 60
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Maps",
      "lvl6": null
    },
    "url": "architecture/introduction.html#maps",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 61
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Maps",
      "lvl6": null
    },
    "url": "architecture/introduction.html#maps",
    "content": "Maps represent unordered mappings from strings to YAML values. A map is written as a sequence of key-value pairs. Each key is followed by a colon and the corresponding value. The value can be on the same line as the key if it is a scalar (in which case it must be preceded by a space) or on subsequent lines (in which case it must be indented, conventionally by two spaces). A map is used in the experiment configuration to configure hyperparameters: hyperparameters: base_learning_rate: 0.001 weight_cost: 0.0001 global_batch_size: 64 n_filters1: 40 n_filters2: 40 The snippet above describes a map with one key, hyperparameters; the corresponding value is itself a map whose keys are base_learning_rate, weight_cost, etc.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 62
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Arrays",
      "lvl6": null
    },
    "url": "architecture/introduction.html#arrays",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 63
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Arrays",
      "lvl6": null
    },
    "url": "architecture/introduction.html#arrays",
    "content": "An array contains multiple other YAML values in some order. An array is written as a sequence of values, each one preceded by a hyphen and a space. The hyphens for one list must all be indented by the same amount. An array is used in the experiment configuration to configure environment variables: environment: environment_variables: - A=A - B=B - C=C",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 64
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Scalars",
      "lvl6": null
    },
    "url": "architecture/introduction.html#scalars",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 65
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "YAML Types",
      "lvl5": "Scalars",
      "lvl6": null
    },
    "url": "architecture/introduction.html#scalars",
    "content": "Scalars generally behave naturally: null, true, 2.718, and \"foo\" all have the same meanings that they would in JSON (and many programming languages). However, YAML allows strings to be unquoted: foo is the same as \"foo\". This behavior is often convenient, but it can lead to unexpected behavior when small edits to a value change its type. For example, the following YAML block represents a list containing several values whose types are listed in the comments: - true # Boolean - grue # string - 0.0 # number - 0.0. # string - foo: bar # map - foo:bar # string - foo bar # string",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 66
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "Example Experiment Configuration",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#example-experiment-configuration",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 67
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "Example Experiment Configuration",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#example-experiment-configuration",
    "content": "A Determined configuration file consists of a YAML object with a particular structure: a map at the top level that is expected to have certain keys, with the value for each key expected to have a certain structure in turn. In this example experiment configuration, numbers, strings, maps, and an array are demonstrated: name: mnist_tf_const data: base_url: https://s3-us-west-2.amazonaws.com/determined-ai-datasets/mnist/ training_data: train-images-idx3-ubyte.gz training_labels: train-labels-idx1-ubyte.gz validation_set_size: 10000 hyperparameters: base_learning_rate: 0.001 weight_cost: 0.0001 global_batch_size: 64 n_filters1: 40 n_filters2: 40 searcher: name: single metric: error max_length: batches: 500 smaller_is_better: true environment: environment_variables: - A=A - B=B - C=C",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 68
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "Reference",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#reference",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 69
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Introduction to Determined",
      "lvl1": "Introduction to Determined",
      "lvl2": "Concepts",
      "lvl3": "YAML Configuration",
      "lvl4": "Reference",
      "lvl5": null,
      "lvl6": null
    },
    "url": "architecture/introduction.html#reference",
    "content": "YAML: https://learnxinyminutes.com/docs/yaml/ Validate YAML: http://www.yamllint.com/ Convert YAML to JSON: https://www.json2yaml.com/convert-yaml-to-json",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 70
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#examples",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#examples",
    "content": "Get started quickly by using an example machine learning model that has been converted to Determined\u2019s APIs. Visit the examples/ subdirectory of the Determined GitHub repo or download the link below. Each example includes a model definition and one or more experiment configuration files. To run an example, download the appropriate .tgz file, extract it, cd into the directory, and use det experiment create to create a new experiment, passing in the appropriate configuration file. For example, here is how to train the mnist_pytorch example with a fixed set of hyperparameters: tar xzvf mnist_pytorch.tgz cd mnist_pytorch det experiment create const.yaml . For an introduction to using the training API, please visit the Training APIs section.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Computer Vision",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#computer-vision",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Computer Vision",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#computer-vision",
    "content": "Framework Dataset Filename PyTorch CIFAR-10 cifar10_pytorch.tgz PyTorch MNIST mnist_pytorch.tgz PyTorch Penn-Fudan Dataset fasterrcnn_coco_pytorch.tgz PyTorch (Model Hub MMDetection) COCO mmdetection.tgz PyTorch COCO detr_coco_pytorch.tgz PyTorch COCO deformabledetr_coco_pytorch.tgz PyTorch COCO efficientdet_pytorch.tgz PyTorch COCO detectron2_coco_pytorch.tgz TensorFlow (tf.keras) Fashion MNIST fashion_mnist_tf_keras.tgz TensorFlow (tf.keras) CIFAR-10 cifar10_tf_keras.tgz TensorFlow (tf.keras) Iris Dataset iris_tf_keras.tgz TensorFlow (tf.keras) Oxford-IIIT Pet Dataset unets_tf_keras.tgz PyTorch CIFAR-10 / STL-10 / ImageNet byol_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Natural Language Processing (NLP)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#natural-language-processing-nlp",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Natural Language Processing (NLP)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#natural-language-processing-nlp",
    "content": "Framework Dataset Filename PyTorch SQuAD 2.0 albert_squad_pytorch.tgz PyTorch GLUE bert_glue_pytorch.tgz PyTorch WikiText-2 word_language_model.tgz PyTorch (Model Hub Transformers) WikiText-2 language-modeling.tgz PyTorch (Model Hub Transformers) SWAG multiple-choice.tgz PyTorch (Model Hub Transformers) SQuAD v1 and v2 question-answering.tgz PyTorch (Model Hub Transformers) GLUE and XNLI text-classification.tgz PyTorch (Model Hub Transformers) CoNLL-2003 token-classification.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "DeepSpeed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#deepspeed",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "DeepSpeed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#deepspeed",
    "content": "Framework Dataset Filename DeepSpeed (PyTorch) Enron Email Corpus gpt_neox.tgz DeepSpeed (PyTorch) CIFAR-10 cifar10_moe.tgz DeepSpeed (PyTorch) CIFAR-10 pipeline_parallelism.tgz DeepSpeed (PyTorch) MNIST / CIFAR-10 deepspeed_dcgan.tgz DeepSpeed (PyTorch) CIFAR-10 cifar10_cpu_offloading.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "DeepSpeed Autotune",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#deepspeed-autotune",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "DeepSpeed Autotune",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#deepspeed-autotune",
    "content": "Framework Dataset Filename DeepSpeed (PyTorch) ImageNet (Generated) torchvision.tgz HuggingFace (DeepSpeed/PyTorch) Beans (HuggingFace) hf_image_classification.tgz HuggingFace (DeepSpeed/PyTorch) WikiText (HuggingFace) hf_language_modeling.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "HP Search Benchmarking",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#hp-search-benchmarking",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "HP Search Benchmarking",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#hp-search-benchmarking",
    "content": "Framework Dataset Filename PyTorch CIFAR-10 darts_cifar10_pytorch.tgz PyTorch Penn Treebank Dataset darts_penntreebank_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Neural Architecture Search (NAS)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#neural-architecture-search-nas",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Neural Architecture Search (NAS)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#neural-architecture-search-nas",
    "content": "Framework Dataset Filename PyTorch DARTS gaea_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Meta Learning",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#meta-learning",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Meta Learning",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#meta-learning",
    "content": "Framework Dataset Filename PyTorch Omniglot protonet_omniglot_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Diffusion",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#diffusion",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Diffusion",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#diffusion",
    "content": "Framework Dataset Filename PyTorch det_logos textual_inversion_stable_diffusion.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Generative Adversarial Networks (GANs)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#generative-adversarial-networks-gans",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Generative Adversarial Networks (GANs)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#generative-adversarial-networks-gans",
    "content": "Framework Dataset Filename PyTorch MNIST gan_mnist_pytorch.tgz TensorFlow (tf.keras) MNIST dcgan_tf_keras.tgz TensorFlow (tf.keras) pix2pix pix2pix_tf_keras.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Graphs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#graphs",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Graphs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#graphs",
    "content": "Framework Dataset Filename PyTorch PROTEINS proteins_pytorch_geometric.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: Custom Reducers",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-custom-reducers",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: Custom Reducers",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-custom-reducers",
    "content": "Framework Dataset Filename PyTorch MNIST custom_reducers_mnist_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: HP Search Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-hp-search-constraints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: HP Search Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-hp-search-constraints",
    "content": "Framework Dataset Filename PyTorch MNIST hp_constraints_mnist_pytorch.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: Custom Search Method",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-custom-search-method",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": "Features: Custom Search Method",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "example-solutions/examples.html#features-custom-search-method",
    "content": "Framework Dataset Filename PyTorch MNIST asha_search_method.tgz",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#tutorials",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Quickstart",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#quickstart",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Quickstart",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#quickstart",
    "content": "If you are new to Determined, visit the Quickstart for Model Developers where you\u2019ll learn how to perform the following tasks: Train on a local, single CPU or GPU. Run a distributed training job on multiple GPUs. Use hyperparameter tuning.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Get Started with a Trial API",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#get-started-with-a-trial-api",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Get Started with a Trial API",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#get-started-with-a-trial-api",
    "content": "Title Description PyTorch MNIST Tutorial Based on the PyTorch MNIST example, this tutorial shows you how to port a simple image classification model for the MNIST dataset. TensorFlow Keras Fashion MNIST Tutorial The TensorFlow Keras Fashion MNIST tutorial describes how to port a tf.keras model to Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Train Your Model in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#train-your-model-in-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Train Your Model in Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#train-your-model-in-determined",
    "content": "Training API Guides include the Core API User Guide and walk you through how to take your existing model code and train your model in Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#examples",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorials",
      "lvl1": "Tutorials",
      "lvl2": "Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/index.html#examples",
    "content": "Examples let you build off of an existing model that already runs on Determined. Visit our Examples to see if the model you\u2019d like to train is already available.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#pytorch-mnist-tutorial",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#pytorch-mnist-tutorial",
    "content": "In this tutorial, you\u2019ll learn how to port an existing PyTorch model to Determined. We will port a simple image classification model for the MNIST dataset. This tutorial is based on the official PyTorch MNIST example.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "About Model Porting",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#about-model-porting",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "About Model Porting",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#about-model-porting",
    "content": "To use a PyTorch model in Determined, you need to port the model to Determined\u2019s API. For most models, this porting process is straightforward, and once the model has been ported, all of the features of Determined will then be available. For example, you can perform distributed training and hyperparameter search without changing your model code. Determined will store and visualize your model metrics automatically. When training a PyTorch model, Determined provides a built-in training loop that feeds each batch of training data into your train_batch function, which should perform the forward pass, backpropagation, and compute training metrics for the batch. Determined also handles checkpointing, log management, and device initialization. To plug your model code into the Determined training loop, you define methods to perform the following tasks: Initialize the models, optimizers, and LR schedulers. Define the training function for forward and backward passes. Define the evaluation function to compute the loss and other metrics on the validation data set. Load the training data set. Load the validation data set. The Determined training loop will then invoke these functions automatically. These methods should be organized into a trial class, which is a user-defined Python class that inherits from determined.pytorch.PyTorchTrial. The following sections walk through how to write your first trial class and then how to run a training job with Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#prerequisites",
    "content": "Access to a Determined cluster. If you have not yet installed Determined, refer to the installation instructions. Access to the Determined CLI on your local machine. See the installation instructions if you do not already have it installed. After installing the CLI, configure it to connect to your Determined cluster by setting the DET_MASTER environment variable to the hostname or IP address where Determined is running. For basic instructions on how to start a Determined cluster locally and run an experiment using the mnist_pytorch example, visit Run Your First Experiment in Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Getting the Tutorial Files",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#getting-the-tutorial-files",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Getting the Tutorial Files",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#getting-the-tutorial-files",
    "content": "Download the complete code for this tutorial from mnist_pytorch.tgz. After downloading the file, open a terminal window, extract the file, and cd into the mnist_pytorch directory: tar xzvf mnist_pytorch.tgz cd mnist_pytorch Follow along with the code as you complete the tutorial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#creating-the-pytorchtrial-class",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#creating-the-pytorchtrial-class",
    "content": "Outlined below is a basic structure for our trial class: import torch.nn as nn from determined.pytorch import DataLoader, PyTorchTrial, PyTorchTrialContext class MNISTTrial(PyTorchTrial): def __init__(self, context: PyTorchTrialContext): # Initialize the trial class and wrap the models, optimizers, and LR schedulers. pass def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int): # Run forward passes on the models and backward passes on the optimizers. pass def evaluate_batch(self, batch: TorchData): # Define how to evaluate the model by calculating loss and other metrics # for a batch of validation data. pass def build_training_data_loader(self): # Create the training data loader. # This should return a determined.pytorch.Dataset. pass def build_validation_data_loader(self): # Create the validation data loader. # This should return a determined.pytorch.Dataset. pass Let\u2019s dive deeper into the implementation of each of these methods.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#initialization",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#initialization",
    "content": "As with any Python class, the __init__ method is invoked to construct our trial class. Determined passes this method a single parameter, an instance of PyTorchTrialContext, which inherits from TrialContext. The trial context contains information about the trial, such as the values of the hyperparameters to use for training. All the models and optimizers must be wrapped with wrap_model and wrap_optimizer respectively, which are provided by PyTorchTrialContext. In this MNIST example, the model code uses the Torch Sequential API and torch.optim.Adadelta. The current values of the model\u2019s hyperparameters can be accessed via the get_hparam() method of the trial context. def __init__(self, context: PyTorchTrialContext): # Store trial context for later use. self.context = context # Create a unique download directory for each rank so they don't overwrite each # other when doing distributed training. self.download_directory = f\"/tmp/data-rank{self.context.distributed.get_rank()}\" self.data_downloaded = False # Initialize the model and wrap it using self.context.wrap_model(). self.model = self.context.wrap_model( nn.Sequential( nn.Conv2d(1, self.context.get_hparam(\"n_filters1\"), 3, 1), nn.ReLU(), nn.Conv2d( self.context.get_hparam(\"n_filters1\"), self.context.get_hparam(\"n_filters2\"), 3, ), nn.ReLU(), nn.MaxPool2d(2), nn.Dropout2d(self.context.get_hparam(\"dropout1\")), Flatten(), nn.Linear(144 * self.context.get_hparam(\"n_filters2\"), 128), nn.ReLU(), nn.Dropout2d(self.context.get_hparam(\"dropout2\")), nn.Linear(128, 10), nn.LogSoftmax(), ) ) # Initialize the optimizer and wrap it using self.context.wrap_optimizer(). self.optimizer = self.context.wrap_optimizer( torch.optim.Adadelta( model.parameters(), lr=self.context.get_hparam(\"learning_rate\") ) )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#load-data",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#load-data",
    "content": "The next two methods we need to define are build_training_data_loader and build_validation_data_loader. Determined uses these methods to load the training and validation datasets, respectively. Both methods should return a determined.pytorch.DataLoader, which is very similar to torch.utils.data.DataLoader. def build_training_data_loader(self): if not self.data_downloaded: self.download_directory = data.download_dataset( download_directory=self.download_directory, data_config=self.context.get_data_config(), ) self.data_downloaded = True train_data = data.get_dataset(self.download_directory, train=True) return DataLoader(train_data, batch_size=self.context.get_per_slot_batch_size()) def build_validation_data_loader(self): if not self.data_downloaded: self.download_directory = data.download_dataset( download_directory=self.download_directory, data_config=self.context.get_data_config(), ) self.data_downloaded = True validation_data = data.get_dataset(self.download_directory, train=False) return DataLoader( validation_data, batch_size=self.context.get_per_slot_batch_size() )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Define train_batch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#define-train-batch",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Define train_batch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#define-train-batch",
    "content": "The train_batch() method is passed a single batch of data from the training data set; it should run the forward passes on the models, the backward passes on the losses, and step the optimizers. This method should return a dictionary with user-defined training metrics; Determined will automatically average all the metrics across batches. If an optimizer is set to automatically handle zeroing out the gradients, step_optimizer will zero out the gradients and there will be no need to call optim.zero_grad(). def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int): batch = cast(Tuple[torch.Tensor, torch.Tensor], batch) data, labels = batch # Define the training forward pass and calculate loss. output = self.model(data) loss = torch.nn.functional.nll_loss(output, labels) # Define the training backward pass and step the optimizer. self.context.backward(loss) self.context.step_optimizer(self.optimizer) return {\"loss\": loss}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Define evaluate_batch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#define-evaluate-batch",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Creating the PyTorchTrial Class",
      "lvl3": "Define evaluate_batch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#define-evaluate-batch",
    "content": "The evaluate_batch() method is passed a single batch of data from the validation data set; it should compute the user-defined validation metrics on that data, and return them as a dictionary that maps metric names to values. The metric values for each batch are reduced (aggregated) to produce a single value of each metric for the entire validation set. By default, metric values are averaged but this behavior can be customized by overridding evaluation_reducer(). def evaluate_batch(self, batch: TorchData): batch = cast(Tuple[torch.Tensor, torch.Tensor], batch) data, labels = batch output = self.model(data) validation_loss = torch.nn.functional.nll_loss(output, labels).item() pred = output.argmax(dim=1, keepdim=True) accuracy = pred.eq(labels.view_as(pred)).sum().item() / len(data) return {\"validation_loss\": validation_loss, \"accuracy\": accuracy}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Train the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#train-the-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Train the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#train-the-model",
    "content": "Now that we have ported our model code to the trial API, we can use Determined to train a single instance of the model or to do a hyperparameter search. In Determined, a trial is a training task that consists of a dataset, a deep learning model, and values for all of the model\u2019s hyperparameters. An experiment is a collection of one or more trials: an experiment can either train a single model (with a single trial), or can define a search over a user-defined hyperparameter space. To create an experiment, we start by writing a configuration file that defines the kind of experiment we want to run. In this case, we want to train a single model for a single epoch, using fixed values for the model\u2019s hyperparameters: name: mnist_pytorch_const data: url: https://s3-us-west-2.amazonaws.com/determined-ai-test-data/pytorch_mnist.tar.gz hyperparameters: learning_rate: 1.0 global_batch_size: 64 n_filters1: 32 n_filters2: 64 dropout1: 0.25 dropout2: 0.5 records_per_epoch: 50_000 searcher: name: single metric: validation_loss max_length: epochs: 1 smaller_is_better: true entrypoint: model_def:MNistTrial The entrypoint specifies the name of the trial class to use. This is useful if the model code contains more than one trial class. In this case, we use an entrypoint of model_def:MNistTrial because our trial class is named MNistTrial and it is defined in a Python file named model_def.py. For more information on experiment configuration, see the experiment configuration reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Run an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#run-an-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Run an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#run-an-experiment",
    "content": "The Determined CLI can be used to create a new experiment, which will immediately start running on the cluster. To do this, we run: det experiment create const.yaml . Here, the first argument (const.yaml) is the name of the experiment configuration file and the second argument (.) is the location of the directory that contains our model definition files. You may need to configure the CLI with the network address where the Determined master is running, via the -m flag or the DET_MASTER environment variable. Once the experiment is started, you will see a notification: Preparing files (.../mnist_pytorch) to send to master... 2.5KB and 4 files Created experiment xxx",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Evaluate the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#evaluate-the-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Evaluate the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#evaluate-the-model",
    "content": "Model evaluation is done automatically for you by Determined. To access information on both training and validation performance, simply go to the WebUI by entering the address of the Determined master in your web browser. Once you are on the Determined landing page, you can find your experiment using the experiment\u2019s ID (xxx in the example above) or description.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch MNIST Tutorial",
      "lvl1": "PyTorch MNIST Tutorial",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-tutorial.html#next-steps",
    "content": "Now that you are familiar with porting model code to Determined, you can keep working with the PyTorch MNIST model and learn how to get up and running with the Core API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#tensorflow-keras-fashion-mnist-tutorial",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#tensorflow-keras-fashion-mnist-tutorial",
    "content": "This tutorial describes how to port an existing tf.keras model to Determined. We will port a simple image classification model for the Fashion MNIST dataset. This tutorial is based on the official TensorFlow Basic Image Classification Tutorial. To use a TensorFlow model in Determined, you need to port the model to Determined\u2019s API. For most models, this porting process is straightforward, and once the model has been ported, all of the features of Determined will then be available: for example, you can do distributed training or hyperparameter search without changing your model code, and Determined will store and visualize your model metrics automatically. When training a tf.keras model, Determined provides a built-in training loop that feeds batches of data into your model, performs backpropagation, and computes training metrics. Determined also handles evaluating your model on the validation set, as well as other details like checkpointing, log management, and device initialization. To plug your model code into the Determined training loop, you define methods to perform the following tasks: initialization build the model graph load the training dataset load the validation dataset The Determined training loop will then invoke these functions automatically. These methods should be organized into a trial class, which is a user-defined Python class that inherits from determined.keras.TFKerasTrial. The following sections walk through how to write your first trial class and then how to run a training job with Determined. The complete code for this tutorial can be downloaded here: fashion_mnist_tf_keras.tgz. After downloading this file, open a terminal window, extract the file, and cd into the fashion_mnist_tf_keras directory: tar xzvf fashion_mnist_tf_keras.tgz cd fashion_mnist_tf_keras We suggest you follow along with the code as you read through this tutorial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#prerequisites",
    "content": "Access to a Determined cluster. If you have not yet installed Determined, refer to the Install and Set Up Determined. The Determined CLI should be installed on your local machine. For installation instructions, see here. After installing the CLI, configure it to connect to your Determined cluster by setting the DET_MASTER environment variable to the hostname or IP address where Determined is running.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#build-a-trial-class",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#build-a-trial-class",
    "content": "Here is what the skeleton of our trial class looks like: import keras from determined.keras import TFKerasTrial, TFKerasTrialContext class FashionMNISTTrial(TFKerasTrial): def __init__(self, context: TFKerasTrialContext): # Initialize the trial class. pass def build_model(self): # Define and compile model graph. pass def build_training_data_loader(self): # Create the training data loader. This should return a keras.Sequence, # a tf.data.Dataset, or NumPy arrays. pass def build_validation_data_loader(self): # Create the validation data loader. This should return a keras.Sequence, # a tf.data.Dataset, or NumPy arrays. pass We now discuss how to implement each of these methods in more detail.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#initialization",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#initialization",
    "content": "As with any Python class, the __init__ method is invoked to construct our trial class. Determined passes this method a single parameter, TrialContext. The trial context contains information about the trial, such as the values of the hyperparameters to use for training. For the time being, we don\u2019t need to access any properties from the trial context object, but we assign it to an instance variable so that we can use it later: def __init__(self, context: TFKerasTrialContext): # Store trial context for later use. self.context = context",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Build the Model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#build-the-model",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Build the Model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#build-the-model",
    "content": "The build_model() method returns a compiled tf.keras.Model object. The Fashion MNIST model code uses the Keras Sequential API and we can continue to use that API in our implementation of build_model. The only minor differences are that the model needs to be wrapped by calling self.context.wrap_model() before it is compiled and the optimizer needs to be wrapped by calling self.context.wrap_optimizer(). def build_model(self): model = keras.Sequential( [ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(self.context.get_hparam(\"dense1\"), activation=\"relu\"), keras.layers.Dense(10), ] ) # Wrap the model. model = self.context.wrap_model(model) # Create and wrap optimizer. optimizer = tf.keras.optimizers.Adam() optimizer = self.context.wrap_optimizer(optimizer) model.compile( optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")], ) return model",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#load-data",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Build a Trial Class",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#load-data",
    "content": "The last two methods we need to define are build_training_data_loader() and build_validation_data_loader(). Determined uses these methods to load the training and validation datasets, respectively. Determined supports three ways of loading data into a tf.keras model: as a tf.keras.utils.Sequence, a tf.data.Dataset, or as a pair of NumPy arrays. Because the dataset is small, the Fashion MNIST model represents the data using NumPy arrays. def build_training_data_loader(self): train_images, train_labels = data.load_training_data() train_images = train_images / 255.0 return train_images, train_labels The implementation of build_validation_data_loader is similar: def build_validation_data_loader(self): test_images, test_labels = data.load_validation_data() test_images = test_images / 255.0 return test_images, test_labels",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Train the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#train-the-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Train the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#train-the-model",
    "content": "Now that we have ported our model code to the trial API, we can use Determined to train a single instance of the model or to do a hyperparameter search. In Determined, a trial is a training task that consists of a dataset, a deep learning model, and values for all of the model\u2019s hyperparameters. An experiment is a collection of one or more trials: an experiment can either train a single model (with a single trial), or it can perform a search over a user-defined hyperparameter space. To create an experiment, we start by writing a configuration file which defines the kind of experiment we want to run. In this case, we want to train a single model for five epochs, using fixed values for the model\u2019s hyperparameters: name: fashion_mnist_keras_const hyperparameters: global_batch_size: 32 dense1: 128 records_per_epoch: 50000 searcher: name: single metric: val_accuracy max_length: epochs: 5 entrypoint: model_def:FashionMNISTTrial For this model, we have chosen two hyperparameters: the size of the Dense layer and the batch size. Training the model for five epochs should reach about 85% accuracy on the validation set, which matches the original tf.keras implementation. The entrypoint specifies the name of the trial class to use. This is useful if the model code contains more than one trial class. In this case, we use an entrypoint of model_def:FashionMNISTTrial because our trial class is named FashionMNISTTrial and it is defined in a Python file named model_def.py. For more information on experiment configuration, see the experiment configuration reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Run an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#run-an-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Run an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#run-an-experiment",
    "content": "The Determined CLI can be used to create a new experiment, which will immediately start running on the cluster. To do this, we run: det experiment create const.yaml . Here, the first argument (const.yaml) is the name of the experiment configuration file and the second argument (.) is the location of the directory that contains our model definition files. You may need to configure the CLI with the network address where the Determined master is running, via the -m flag or the DET_MASTER environment variable. Once the experiment is started, you will see a notification: Preparing files (../fashion_mnist_tf_keras) to send to master... 2.5KB and 4 files Created experiment xxx",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Evaluate the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#evaluate-the-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl1": "TensorFlow Keras Fashion MNIST Tutorial",
      "lvl2": "Evaluate the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/tf-mnist-tutorial.html#evaluate-the-model",
    "content": "Model evaluation is done automatically for you by Determined. To access information on both training and validation performance, simply go to the WebUI by entering the address of the Determined master in your web browser. Once you are on the Determined landing page, you can find your experiment either via the experiment ID (xxx) or via its description.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#run-your-first-experiment-in-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#run-your-first-experiment-in-determined",
    "content": "In this tutorial, we\u2019ll show you how to integrate a training example with the Determined environment. We\u2019ll run our experiment on a local training environment requiring only a single CPU or GPU. This tutorial is recommended as an introduction for model developers who are new to Determined AI. Objective Our goal is to integrate the PyTorch MNIST training example into Determined in four steps: Download and extract the files Set up our training environment Run the experiment View the experiment in our browser Prerequisites Installation Requirements",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Download the Files",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#download-the-files",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Download the Files",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#download-the-files",
    "content": "To get started, we\u2019ll first download and extract the files we need and cd into the directory. Download the mnist_pytorch.tgz file. Open a terminal window, extract the files, and cd into the mnist_pytorch directory: tar xzvf mnist_pytorch.tgz cd mnist_pytorch",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Set Up Your Training Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#set-up-your-training-environment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Set Up Your Training Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#set-up-your-training-environment",
    "content": "To start your experiment, you\u2019ll need a Determined cluster. If you are new to Determined AI (Determined), you can install the Determined library and start a cluster locally: pip install determined # If your machine has GPUs: det deploy local cluster-up # If your machine does not have GPUs: det deploy local cluster-up --no-gpu The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#run-the-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#run-the-experiment",
    "content": "To run the experiment, enter the following command: det experiment create const.yaml . -f A notification displays letting you know the experiment has started. Preparing files (.../mnist_pytorch) to send to master... Created experiment xxx",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "View the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#view-the-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "View the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#view-the-experiment",
    "content": "To view the experiment progress in your browser: Enter the following URL: http://localhost:8080/. This is the cluster address for your local training environment. Accept the default username of determined, and click Sign In. A password is not required.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Run Your First Experiment in Determined",
      "lvl1": "Run Your First Experiment in Determined",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/pytorch-mnist-local-qs.html#next-steps",
    "content": "In four simple steps, we\u2019ve successfully configured our training environment in Determined to start training the PyTorch MNIST example. In this article, we learned how to run an experiment on a local, single CPU or GPU. If you want to learn more details about the basic structure shown in the trial class, visit the PyTorch MNIST Tutorial. To learn how to change your configuration settings, including how to run a distributed training job on multiple GPUs, visit the Quickstart for Model Developers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#quickstart-for-model-developers",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#quickstart-for-model-developers",
    "content": "This quickstart uses the MNIST dataset to demonstrate basic Determined functionality and walks you through the steps needed to install Determined, run training jobs, and visualize experiment results in your browser. Three examples show the scalability and enhanced functionality gained from simple configuration setting changes: Train on a local, single CPU or GPU. Run a distributed training job on multiple GPUs. Use hyperparameter tuning. An experiment is a training job that consists of one or more variations, or trials, on the same model. By calling Determined API functions from your training loops, you automatically get metric frequency output, plots, and checkpointing for every experiment without writing extra code. You can use the WebUI to view model information, configuration settings, output logs, and training metrics for all of your experiments. Each of these quickstart examples uses the same model code and example dataset, differing only in their configuration settings. For a list of all experiment configuration settings and more detailed information about each, visit the Experiment Configuration Reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Software",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#software",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Software",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#software",
    "content": "Determined agent and master nodes must be configured with Ubuntu 16.04 or higher, CentOS 7, or macOS 10.13 or higher. Agent nodes must have Docker installed. To run jobs with GPUs, install NVIDIA drivers, version 384.81 or higher, on each agent. The drivers can be installed as part of a CUDA installation but the rest of the CUDA toolkit is not required.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Hardware",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#hardware",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Hardware",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#hardware",
    "content": "Master node: At least 4 CPU cores, Intel Broadwell or later. The master node does not require GPUs. 8GB RAM 200GB of free disk space. Agent Node: At least 2 CPU cores, Intel Broadwell or later. If you are using GPUs, NVIDIA GPUs with compute capability 3.7 or greater are required: K80, P100, V100, A100, GTX 1080, GTX 1080 Ti, TITAN, or TITAN XP. 4GB RAM 50GB of free disk space.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Docker",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#docker",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Prerequisites",
      "lvl3": "Docker",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#docker",
    "content": "Install Docker to run containerized workloads. If you do not already have Docker installed, visit Install Docker to learn how to install and run Docker on Linux or macOS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#get-the-quickstart-training-examples",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#get-the-quickstart-training-examples",
    "content": "Download and extract the files used in this quickstart to a local directory: Download link: mnist_pytorch.tgz. Extract the configuration and model files: tar xzvf mnist_pytorch.tgz You should see the following files in your local directory: adaptive.yaml const.yaml data.py distributed.yaml layers.py model_def.py README.md",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": "Description of the Configuration Files",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#description-of-the-configuration-files",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": "Description of the Configuration Files",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#description-of-the-configuration-files",
    "content": "Each YAML-formatted configuration file corresponds an example experiment. Configuration Filename Example Experiment const.yaml Train a single model on a single GPU/CPU, with constant hyperparameter values. distributed.yaml Train a single model using multiple, distributed GPUs. adaptive.yaml Perform a hyperparameter search using the Determined adaptive hyperparameter tuning algorithm.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": "Description of Model and Pipeline Definition Files",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#description-of-model-and-pipeline-definition-files",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Get the Quickstart Training Examples",
      "lvl3": "Description of Model and Pipeline Definition Files",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#description-of-model-and-pipeline-definition-files",
    "content": "Although the Python model and data pipeline definition files are not explained in this quickstart, you can review them to find out how to call the Determined API from your own code: Filename Experiment Type data.py Model data loading and preparation code. layers.py Convolutional layers used by the model. model_def.py Model definition and training/validation loops. After gaining basic familiarity with Determined tools and operations, you can replace these files with your model data and code, and set configuration parameters for the kind of experiments you want to run.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Install Determined and Run a Local Single CPU/GPU Training Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#install-determined-and-run-a-local-single-cpu-gpu-training-job",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Install Determined and Run a Local Single CPU/GPU Training Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#install-determined-and-run-a-local-single-cpu-gpu-training-job",
    "content": "This exercise trains a single model for a fixed number of batches, using constant values for all hyperparameters on a single slot. A slot is a CPU or GPU computing device, which the master schedules to run. To install the Determined library and start a cluster locally, run the following commands: pip install determined det deploy local cluster-up If your local machine does not have a supported NVIDIA GPU, include the no-gpu option: pip install determined det deploy local cluster-up --no-gpu In the mnist_pytorch directory, create an experiment specifying the const.yaml configuration file: det experiment create const.yaml . The last dot (.) argument uploads all of the files in the current directory as the context directory for your model. Determined copies the model context directory contents to the trial container working directory. You should receive confirmation that the experiment is created: Preparing files (.../mnist_pytorch) to send to master... 8.6KB and 7 files Created experiment 1 To automatically stream log messages for the first trial in an experiment to stdout, specifying the configuration file and context directory, enter: det e create const.yaml . -f The -f option is the short form of --follow. Enter the cluster address in the browser address bar to view experiment progress in the WebUI. If you installed locally using the det deploy local command, the URL is http://localhost:8080/. Accept the default username of determined and click Sign In. A password is not required. The figure shows two experiments. Experiment 11 has COMPLETED and experiment 12 is still ACTIVE. Your experiment number and status can differ depending on how many times you run the examples. While an experiment is in the ACTIVE, training state, click the experiment name to see the Metrics graph update for your currently defined metrics: In this example, the graph displays the loss. After the experiment completes, click the experiment name to view the trial page: Now that you have a fundamental understanding of Determined, follow the next example to learn how to scale to distributed training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Run a Remote Distributed Training Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#run-a-remote-distributed-training-job",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Run a Remote Distributed Training Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#run-a-remote-distributed-training-job",
    "content": "In the distributed training example, a Determined cluster comprises a master and one or more agents. The master provides centralized management of the agent resources. This example requires a Determined cluster with multiple GPUs and, while it does not fully demonstrate the benefits of distributed training, it does show how to work with added hardware resources. The distributed.yaml configuration file for this example is the same as the const.yaml file in the previous example, except that a resources.slots_per_trial field is defined and set to a value of 8: resources: slots_per_trial: 8 This is the number of available GPU resources. The slots_per_trial value must be divisible by the number of GPUs per machine. You can change the value to match your hardware configuration. To connect to a Determined master running on a remote instance, set the remote IP address and port number in the DET_MASTER environment variable: export DET_MASTER=<ipAddress>:8080 Create and run the experiment: det experiment create distributed.yaml . You can also use the -m option to specify a remote master IP address: det -m http://<ipAddress>:8080 experiment create distributed.yaml . To view the WebUI dashboard, enter the cluster address in your browser address bar, accept determined as the default username, and click Sign In. A password is not required. Click the Experiment name to view the experiment\u2019s trial display. The loss curve is similar to the single-GPU experiment in the previous exercise but the time to complete the trial is reduced by about half.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Run a Hyperparameter Tuning Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#run-a-hyperparameter-tuning-job",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Run a Hyperparameter Tuning Job",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#run-a-hyperparameter-tuning-job",
    "content": "This example demonstrates hyperparameter search. The example uses the adaptive.yaml configuration file, which is similar to the const.yaml file in the first example but includes additional hyperparameter settings: hyperparameters: global_batch_size: 64 learning_rate: type: double minval: .0001 maxval: 1.0 n_filters1: type: int minval: 8 maxval: 64 n_filters2: type: int minval: 8 maxval: 72 dropout1: type: double minval: .2 maxval: .8 dropout2: type: double minval: .2 maxval: .8 Hyperparameter searches involve multiple trials or model variations per experiment. The The adaptive_asha search method and maximum number of trials, max_trials` are also specified: searcher: name: adaptive_asha metric: validation_loss smaller_is_better: true max_trials: 16 max_length: batches: 937 This example uses a fixed batch size and searches on dropout size, filters, and learning rate. The max_trials setting of 16 indicates how many model configurations to explore. Create and run the experiment: det experiment create adaptive.yaml . To view the WebUI dashboard, enter your cluster address in the browser address bar, accept the default username of determined, and click Sign In. A password is not required. The experiment can take some time to complete. You can monitor progress in the WebUI Dashboard by clicking the Experiment name. Notice that more trials have started: Determined runs the number of max_trials trials and automatically starts new trials as resources become available. For 16 trials, it should take about 10 minutes to train with at least one trial performing at about 98 percent validation accuracy. The hyperparameter search halts poorly performing trials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Learn More",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#learn-more",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quickstart for Model Developers",
      "lvl1": "Quickstart for Model Developers",
      "lvl2": "Learn More",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "tutorials/quickstart-mdldev.html#learn-more",
    "content": "For installation guides including how to quickly install Determined locally, visit Install and Set Up Determined. The Core API User Guide walks you through adapting your existing model code to Determined and uses the PyTorch MNIST model. The Examples contain machine learning models that have been converted to the Determined APIs. Each example includes a model definition and one or more experiment configuration files, and instructions on how to run the example. To learn more about the hyperparameter search algorithm, visit Hyperparameter Tuning. For faster, less structured ways to run a Determined cluster without writing a model, consult the following resources: Commands and Shells Jupyter Notebooks",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#workspaces-and-projects",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#workspaces-and-projects",
    "content": "You can organize your experiments into projects and workspaces. A project is a collection of experiments, and a workspace is a collection of projects. Experiment Configuration specifies the location of a newly created experiment. If a workspace and project are not specified, the experiment is created in the default, Uncategorized project. Experiments can be moved between projects, and projects can be moved between workspaces.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#getting-started",
    "content": "Initially, a Determined installation has one workspace containing one project, both titled Uncategorized. Both are considered immutable, which means that they cannot be renamed, archived, or deleted, and the project cannot be moved to a different workspace. However, you can move an experiment into or out of an Uncategorized project at any time. To create workspaces and projects for individuals or teams who are using Determined, use det workspace create and det project create. This is recommended for larger teams. det workspace create <workspace name> det project create <workspace name> <project name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Usage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#usage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Usage",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#webui",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Usage",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#webui",
    "content": "After signing in, the dashboard displays. This is the default landing page for the WebUI. The dashboard is where you\u2019ll find the most recently submitted jobs and your recently viewed projects. Selecting the navigation sidebar Workspaces button opens the Workspaces List page. This page displays all workspaces that currently exist on a cluster. Selecting the icon in the upper right corner of a workspace card displays the action menu. The action menu always contains the option to pin a workspace, which creates an easy access link to the workspace on the sidebar. If the workspace was created by the currently signed-in user, or if the current user is an administrator, the action menu also provides the options to edit the workspace name, archive the workspace, or delete the workspace. Deleting a workspace is permanent and also deletes all projects contained within it. A workspace cannot be deleted if its projects contain experiments. Selecting a workspace card opens the Workspace Details page. This page shows all currently selected workspace projects. If a project was created by the currently signed-in user, or if the current user is an administrator, click the icon in the upper right corner of the project card to bring up another action menu. This action menu contains the options to edit the project name and description, move the project to a different workspace, archive the project, or delete the project if it does not contain experiments. Selecting a project card opens the Project Details page. This page shows the experiments that currently exist for the selected project. The Notes tab lets you create, read, edit, and delete notes about the selected project.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Usage",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Workspaces and Projects",
      "lvl1": "Workspaces and Projects",
      "lvl2": "Usage",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces.html#cli",
    "content": "In the CLI, use the det workspace and det project commands to interact with workspaces and projects. Use the -h flag to get a list of all possible commands. det workspace -h det project -h",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#historical-cluster-usage-data",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#historical-cluster-usage-data",
    "content": "Our goal is to give users insights on how their Determined cluster is used. Historical cluster usage is measured in the number of compute hours allocated by Determined. Note that this is not based on resource utilization, so if a user gets 1 GPU allocated but only utilizes 20% of the GPU, we would still report one GPU hour. The total used compute hours reported by Determined may be less than the hours reported by the cloud because we do not include the time that the slots are idle (e.g., time waiting for a GPU to spin up, or when a GPU is not scheduled with any jobs) in that. Our data is aggregated by Determined metadata (e.g., label, user). This aggregation is performed nightly, so any data visualized on the WebUI or downloaded via the endpoint is fresh as of the last night. It will not reflect changes to the metadata of a previously run experiment (e.g., labels) until the next nightly aggregation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": "WebUI Visualization",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#webui-visualization",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": "WebUI Visualization",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#webui-visualization",
    "content": "We build WebUI visualizations for a quick snapshot of the historical cluster usage:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": "Command-line Interface",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#command-line-interface",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Historical Cluster Usage Data",
      "lvl1": "Historical Cluster Usage Data",
      "lvl2": "Command-line Interface",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/historical-cluster-usage-data.html#command-line-interface",
    "content": "Alternatively, you can use the CLI or the API endpoints to download the resource allocation data for analysis: det resources raw <start time> <end time>: get raw allocation information, where the times are full times in the format yyyy-mm-ddThh:mm:ssZ. det resources aggregated <start date> <end date>: get aggregated allocation information, where the dates are in the format yyyy-mm-dd.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Upgrade",
      "lvl1": "Upgrade",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/upgrade.html#upgrade",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Upgrade",
      "lvl1": "Upgrade",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/upgrade.html#upgrade",
    "content": "There are occasionally incompatible changes introduced in new versions of Determined \u2013 for example, the format of the master and agent configuration files might change. While we try to preserve backward compatibility whenever possible, you should read the Release Notes for a description of recent changes before upgrading Determined. To upgrade, follow the same steps as you did during the initial installation of Determined. For example, if you deployed your Determined cluster on Amazon Web Services (AWS), you would run det deploy aws up --cluster-id CLUSTER_ID --keypair KEYPAIR_NAME. The specific upgrade commands vary by environment. You\u2019ll need to run the same commands (including any flags) that were run when you installed Determined. Before starting an upgrade, first follow the steps below to safely shut down the cluster. Once the upgrade is complete and Determined is restarted, all suspended experiments will be resumed automatically. Disable all Determined agents in the cluster: det -m <MASTER_ADDRESS> agent disable --all where MASTER_ADDRESS is the IP address or host name where the Determined master can be found. This will cause all tasks running on those agents to be checkpointed and terminated. The checkpoint process might take some time to complete; you can monitor which tasks are still running via det slot list. Take a backup of the Determined database using pg_dump. This is a safety precaution in case any problems occur after upgrading Determined. All users should also upgrade the CLI by running pip install --upgrade determined",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#binding-resource-pools-to-workspaces",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#binding-resource-pools-to-workspaces",
    "content": "You can associate resource pools to specific workspaces similar to how you associate certain artifacts, like experiments, to workspaces. Modifying resource pool bindings requires either an Admin or a Cluster Admin role.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Overview",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#overview",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Overview",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#overview",
    "content": "Binding and unbinding resource pools allows administrators to control resource pool availability within the cluster. Resource pools can be either unbound, meaning they are shared across the entire cluster, or bound to specific workspaces. Experiments, notebooks, TensorBoards, shells, or commands associated with a particular workspace can only use resource pools that are either unbound or bound to a particular workspace. In addition, you can set a bound resource pool as the default compute or auxiliary pool for the workspace. If a user leaves the resource pool configuration option blank for their task, workloads will be sent to the default compute or auxiliary pool. When combined with Role-Based Access Control (RBAC), administrators can restrict compute resources to specific users and groups, enabling resource multi-tenancy for experiments and related artifacts.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#binding-or-unbinding-a-resource-pool",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#binding-or-unbinding-a-resource-pool",
    "content": "You can bind or unbind a resource pool to a workspace. By default, all resource pools are unbound, making them globally available to all workspaces in the cluster. Default resource pools cannot be bound to a workspace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#webui",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#webui",
    "content": "An administrator who is an Admin in Determined or a user with the Cluster Admin role (requires Determined Enterprise Edition) can change resource pool bindings in the WebUI by following these steps: Go to the Cluster option in the left menu pane. Click the options \u201c\u2026\u201d menu of the resource pool you want to bind. Select Manage bindings from the menu. On the right side, choose the workspace you want to bind by clicking on it in the available workspaces list. You can use the search bar to narrow down the list. The selected workspace will be added to the list of bound workspaces on the left. To remove a bound workspace, click on it in the list of bound workspaces on the left. If you want to remove all workspace bindings, click Remove all below the list of bound workspaces. Once you are satisfied with the list of bound workspaces, click Apply.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Binding Resource Pools to Workspaces",
      "lvl1": "Binding Resource Pools to Workspaces",
      "lvl2": "Binding or Unbinding a Resource Pool",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/workspaces-rpools.html#cli",
    "content": "You can use the resource pool command, det rp bindings, to add, list, replace, bind, or unbind a resource pool using the CLI. To get help, run the following command: det rp bindings -h For example, to bind a resource pool, run the following command: det rp bindings add \"<resource_pool_name>\" \"<workspace_name>\" To bind multiple workspaces to a resource pool, run the following command: det rp bindings add \"<resource_pool_name>\" \"<workspace1_name>\" \"<workspace2_name>\" \"<workspace3_name>\" To unbind a resource pool, run the following command: det rp bindings remove \"<resource_pool_name>\" \"<workspace_name>\" In the Cluster view, a bound resource pool is indicated by a lock symbol and the number of workspaces it is bound to. Moreover, clicking on a resource pool card from the Cluster view displays all the workspaces that are bound to that resource pool. The resource pool binding to workspaces follows a many-to-many relationship. This gives administrators the flexibility to bind multiple resource pools to the same workspace or the same resource pool to multiple workspaces. If a resource pool has tasks running from a particular workspace and that resource pool is unbound from that workspace, the existing tasks will continue running. However, new tasks from the unbound workspace will not be scheduled on that resource pool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#user-accounts",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#user-accounts",
    "content": "Initially, a Determined installation has two user accounts: admin and determined. Both of these accounts have blank passwords by default. The admin user has the sole privilege to create users, change other users\u2019 passwords, and activate/deactivate users. Use det user change-password via the CLI to set a password for the admin user. This is highly encouraged for new installs. det -u admin user change-password The determined user is designed for ease of use on a single-user installation. However, teams will benefit from creating a Determined user account for each individual. Namely, having individual user accounts provides clearer authorship and improved filtering of entities. To create users in a Determined installation, use the admin user to create user accounts for each individual that would like to use Determined: det -u admin user create <username> Then, the determined user can be deactivated: det -u admin user deactivate determined This ensures that no one can access the Determined cluster as the determined user (any objects that were created by this user will remain).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Authentication",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#authentication",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Authentication",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#webui",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Authentication",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#webui",
    "content": "The WebUI will automatically redirect users to a sign-in page if there is no valid Determined session established on that browser. After signing in, the user will be redirected to the URL they initially attempted to access. Users can end their Determined session by selecting their profile name in the upper left corner and choosing Sign Out.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Authentication",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Authentication",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#cli",
    "content": "In the CLI, the user login subcommand can be used to authenticate a user: det user login <username> Logging in results in a persistent session, which lasts for 30 days. The session can be terminated using: det user logout",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Temporary authentication",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#temporary-authentication",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Temporary authentication",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#temporary-authentication",
    "content": "In some cases, it may be useful to execute a single command as a specific user without starting a persistent session for that user (think of the sudo command on a Unix-like system). In Determined, this can be achieved with the -u flag: det -u <username> ... This will execute the command as the given user without creating a permanent session for that user. Although no persistent session is created, an authentication token is stored for that user so that future attempts to execute commands as that user will not require re-authenticating. This token can be discarded using the user logout subcommand: det -u <username> user logout",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Change Passwords",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#change-passwords",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Change Passwords",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#change-passwords",
    "content": "Users have blank passwords by default. This might be sufficient for low-security or experimental clusters, and it still provides the organizational benefits of associating each Determined object with the user that created it. If desired, a user can change their own password using the user change-password subcommand: det user change-password An admin can also change another user\u2019s password: det -u admin user change-password <target-user> Although Determined supports password-based authentication, communication between the CLI, WebUI, and master does not take place over an encrypted channel by default. See Security for information on configuring secure connections over HTTPS. Users should not be assigned \u201cvaluable\u201d passwords, and passwords used with Determined should not be reused for other purposes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "List Assets",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#list-assets",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "List Assets",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#id1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "List Assets",
      "lvl3": "WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#id1",
    "content": "Just as in the CLI, by default the WebUI will only show assets created by the current user. To see assets belonging to all users, uncheck the \u201cShow only mine\u201d checkbox in the filter panel found in the tab for each asset type.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "List Assets",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#cli-1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "List Assets",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#cli-1",
    "content": "When using the CLI to list experiments, commands, etc., the default behavior is to only show assets belonging to the current user. It is possible to show assets owned by all users by passing the -a flag to the respective commands: det experiment list -a # List all experiments. det command list -a # List all commands. det notebook list -a # List all notebooks. det tensorboard list -a # List all TensorBoards.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Activate and Deactivate Users",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#activate-and-deactivate-users",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Activate and Deactivate Users",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#activate-and-deactivate-users",
    "content": "When a user is created, they are designated as active by default. Only active users can interact with Determined. The admin user can deactivate a user with the user deactivate subcommand: det -u admin user deactivate <target-user> All assets created by a deactivated user will remain available through both the WebUI and the CLI. To reactivate a user, user activate can be used: det -u admin user activate <target-user>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Run Tasks as Specific Agent Users",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#run-tasks-as-specific-agent-users",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Run Tasks as Specific Agent Users",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#run-tasks-as-specific-agent-users",
    "content": "If an experiment, notebook, or command task uses the bind_mount option in its Experiment Configuration Reference, it is often useful to set the Unix user and group on the agent that the task runs as. This allows the file permissions on the agent to be reflected in the task and vice versa. This can be configured by linking a Determined user with the user and group configuration on an agent: det user link-with-agent-user <target-user> --agent-uid <uid> --agent-user <username> --agent-gid <gid> --agent-group <group-name> All arguments are required. This command can only be run by a system administrator. Once set, any tasks created by the target user will be run as the specified user and group. By default, if a user is not linked with a user and group on an agent, tasks created by that user will run as the root user on the agent. If deploying on a Slurm/PBS cluster, running as the root user is only permitted if the launcher user_name is also set to the root user, as described in Configure and Verify Determined Master on HPC Cluster. This behavior may change in the future. If the task does not use bind_mount option, the effect of running as root will be limited to the task container and not intrude on the agent itself. The default user and group that will be used when a Determined user is not explicitly linked to a user and group on an agent can be configured in the master.yaml file located at /usr/local/determined/etc on the Determined master instance: security: default_task: user: root uid: 0 group: root gid: 0",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Run Unprivileged Tasks by Default",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#run-unprivileged-tasks-by-default",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "User Accounts",
      "lvl1": "User Accounts",
      "lvl2": "Run Unprivileged Tasks by Default",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/users.html#run-unprivileged-tasks-by-default",
    "content": "Some administrators of Determined may wish to run tasks as unprivileged users by default. In Linux, unprivileged processes are sometimes run under the nobody user, which has very few privileges. However, the nobody user does not have a writable HOME directory, which causes problems for some common tools like gsutil. For convenience, the default Determined environments contain an unprivileged user named det-nobody, which does have a writable HOME directory. The det-nobody user is a suitable default user when using the default Determined environment images and when running containers as root is not desired. To use det-nobody by default, add the following configuration to master.yaml: security: default_task: user: det-nobody uid: 65533 group: det-nobody gid: 65533 When combining the det-nobody user with custom Docker images, administrators should either build the custom image as layers on top of the default Determined Environments as illustrated in Custom Images, or they should create the det-nobody user themselves in their custom images using groupadd and useradd.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#troubleshooting",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Error messages",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#error-messages",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Error messages",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#error-messages",
    "content": "docker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused \"process_linux.go:424: container init caused \\\"process_linux.go:407: running prestart hook 1 caused \\\\\\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig --device=all --compute --utility --require=cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411 --pid=35777 /var/lib/docker/devicemapper/mnt/7b5b6d59cd4fe9307b7523f1cc9ce3bc37438cc793ff4a5a18a0c0824ec03982/rootfs]\\\\\\\\nnvidia-container-cli: requirement error: unsatisfied condition: brand = tesla\\\\\\\\n\\\\\\\"\\\"\": unknown. If you see the above error message, the GPU hardware and/or NVIDIA drivers installed on the agent are not compatible with CUDA 10, but you are trying to run a Docker image that depends on CUDA 10. Please run the commands below; if the first succeeds and the second fails, you should be able to use Determined as long as you use Docker images based on CUDA 9. docker run --gpus all --rm nvidia/cuda:9.0-runtime nvidia-smi docker run --gpus all --rm nvidia/cuda:10.0-runtime nvidia-smi",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Debug Database Migration Failures",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#debug-database-migration-failures",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Debug Database Migration Failures",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#debug-database-migration-failures",
    "content": "Dirty database version <a long number>. Fix and force version. If you see the above error message, a database migration was likely interrupted while running and the database is now in a dirty state. Make sure you back up the database and temporarily shut down the master before proceeding further. To fix this error message, locate the up migration with a suffix of .up.sql and a prefix matching the long number in the error message in this directory <https://github.com/determined-ai/determined/tree/master/master/static/migrations>_ and carefully run the SQL within the file manually against the database used by Determined. For convenience, all the information needed to connect except the password can be found with: det master config | jq .db If this proceeds successfully, then mark the migration as successful by running the following SQL: UPDATE schema_migrations SET dirty = false; And restart the master. Otherwise, please seek assistance in the community Slack.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Validate NVIDIA Container Toolkit",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#validate-nvidia-container-toolkit",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": "Validate NVIDIA Container Toolkit",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/troubleshooting.html#validate-nvidia-container-toolkit",
    "content": "To verify that a Determined agent instance can run containers that use GPUs, run: docker run --gpus all --rm debian:10-slim nvidia-smi You should see output that describes the GPUs available on the agent instance, such as: +-----------------------------------------------------------------------------+ | NVIDIA-SMI 418.39 Driver Version: 418.39 CUDA Version: 10.1 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 108... Off | 00000000:05:00.0 Off | N/A | | 56% 84C P2 177W / 250W | 10729MiB / 11176MiB | 76% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 108... Off | 00000000:06:00.0 Off | N/A | | 28% 62C P0 56W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GeForce GTX 108... Off | 00000000:09:00.0 Off | N/A | | 31% 64C P0 57W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 TITAN Xp Off | 00000000:0A:00.0 Off | N/A | | 20% 36C P0 57W / 250W | 0MiB / 12196MiB | 6% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 4638 C python3 10719MiB | +-----------------------------------------------------------------------------+",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Elasticsearch-backed logging",
      "lvl1": "Elasticsearch-backed logging",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/elasticsearch-logging-backend.html#elasticsearch-backed-logging",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Elasticsearch-backed logging",
      "lvl1": "Elasticsearch-backed logging",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/elasticsearch-logging-backend.html#elasticsearch-backed-logging",
    "content": "This guide covers the limitations of the default logging backend, as a guideline on when to migrate to Elasticsearch, and some tips for how to tune Elasticsearch to work best with Determined. Elasticsearch is a search engine commonly used for storing application logs for search and analytics. Determined supports using Elasticsearch as the storage backend for task logs. Configuring Determined to use Elasticsearch is simple; however, managing an Elasticsearch cluster at scale is an involved task, so this guide is recommended for users who have hit the limitations of the default logging backend. Using the default logging backend, with a standard deployment using det deploy, the cluster can ingest logs about as fast as Postgres can persist them. For example, with det deploy aws using Aurora Serverless with 2 capacity units, ingestion speed maxes out around 10-15 MB/s (where the database\u2019s CPU hits ~90%). To get a little more mileage from the default, we recommend increasing the capacity of the database. At a certain point, the master instance itself will become the bottleneck, since it has limited incoming network bandwidth for HTTP requests delivering logs and limited resources to process them. The master instance size can be increased, but vertical scaling is likely to be limited to a log throughput of around hundreds of megabytes per second; we recommend moving to Elasticsearch to get past that limit. Determined offers some additional recommendations for the Elasticsearch cluster configuration based on how the cluster will be used: Tune the default shards per index to your expected throughput (or use index templates). Determined ships logs in Logstash format rolling over to a new index each day. Depending on your log volume, the default number of shards could be too high or too low. The general rule of thumb is not to exceed 50 GB per shard while minimizing the number of shards per index. For high-utilization clusters, this may entail increasing the shards per index and rotating indices older than a few months out of the cluster periodically, to avoid the overhead accumulated from having too many shards. A more in-depth guide can be found here. Though it may increase latency for end users, increasing the refresh interval may help increase total throughput. Apply the following index template to optimize the mappings in Determined log indices for ingest speed. This turns off analysis and in some cases indexing on properties for which Determined does not use these features. { \"index_patterns\": [\"determined-tasklogs-*\"], \"mappings\": { \"properties\": { \"task_id\": {\"type\": \"keyword\", \"index\": true}, \"allocation_id\": {\"type\": \"keyword\": \"index\": true}, \"agent_id\": {\"type\": \"keyword\", \"index\": true}, \"container_id\": {\"type\": \"keyword\", \"index\": true}, \"level\": {\"type\": \"keyword\", \"index\": true}, \"log\": {\"type\": \"text\", \"index\": false}, \"message\": {\"type\": \"text\", \"index\": false}, \"source\": {\"type\": \"keyword\", \"index\": true}, \"stdtype\": {\"type\": \"keyword\", \"index\": true} } } } The configuration settings to enable Elasticsearch as the task log backend are described in the cluster configuration reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#openid-connect-integration",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#openid-connect-integration",
    "content": "OpenID Connect Integration applies only to Determined Enterprise Edition. Determined EE provides an OpenID Connect (OIDC) integration allowing users to use single sign-on (SSO) with their organization\u2019s identity provider (IdP). OIDC is an extension of OAuth 2.0 which allows applications to request information about authenticated users. Note that users can only log in via OpenID Connect if they have already been provisioned into Determined. This can be done manually, or via SCIM.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#configure-your-idp",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#configure-your-idp",
    "content": "When configuring your IdP to allow users to SSO to Determined, you will need to specify the location of Determined\u2019s callback URL. This is the URL to which users will be redirected after authentication. The callback URL should be set to the Determined master\u2019s base URL with a path of /oidc/callback.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#configure-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#configure-determined",
    "content": "Determined requires your IdP\u2019s SSO URL and name, the client id and client secret provided to you by your IdP, and the public hostname of the master. These are all configured in master.yaml. Many IdPs require their callback to be sent over HTTPS. If this is the case for your IdP, you should configure the master to use TLS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#example-setup-with-okta",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#example-setup-with-okta",
    "content": "In this example, we assume the Determined master will run at https://determined.example.com. First, in Okta, you\u2019ll need to create a new App Integration. You should select OIDC as the sign-in method and Web Application as the application type. Then configure the following options: Field Example Value App Integration Name My Determined Cluster Allowed Callback URLs https://determined.example.com/oidc/callback Sign-out redirect URIs https://determined.example.com/det/logout Take note of the Domain, Client ID, and Client Secret. You will need to add these to the Determined Determined master configuration in master.yaml. The Domain corresponds to the idp_sso_url field. oidc: enabled: true provider: \"Okta\" idp_recipient_url: \"https://determined.example.com\" idp_sso_url: \"https://dev-00000000.okta.com\" client_id: \"xx0xXXXxxxXxXXXxXXX0XxX0XXxXXxXX\" client_secret: \"Xxx0xXXXxxXXXxXXxxXX0xxxXXxxxXXxXXXXxXXXxXxXXxxXXXX0XXxXxX-XX0-X\" Once the master is started with this configuration, users will be able to log in to Determined by clicking the \u2018Sign in with Okta\u2019 button on the sign-in page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Manually provision user for OIDC",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#manually-provision-user-for-oidc",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OpenID Connect Integration",
      "lvl1": "OpenID Connect Integration",
      "lvl2": "Manually provision user for OIDC",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oidc.html#manually-provision-user-for-oidc",
    "content": "If SCIM is not used, users can be manually provisioned into Determined through the CLI. This requires Determined admin privileges. Note the remote option is required for users to be able to login through OIDC. det user create email@exmple.com --remote",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Security",
      "lvl1": "Security",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/index.html#security",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Security",
      "lvl1": "Security",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/index.html#security",
    "content": "These security features apply only to Determined Enterprise Edition, except for TLS. Security Feature Documentation OAuth 2.0 Configuration Enable, list, and remove OAuth clients. Transport Layer Security Set up the master and agents to use TLS security. OpenID Connect Integration Integrate OpenID Connect, with and Okta example. SAML Integration Integrate Security Assertion Markup Language (SAML) authentication to use single sign-on (SSO) with your organizationidentity provider (IdP). SCIM Integration Integrate System for Cross-domain Identity Management (SCIM) for administrators to easily and securely provision users and groups. RBAC Configure Role-Based Access Control.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#oauth-2-0-configuration",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#oauth-2-0-configuration",
    "content": "OAuth 2.0 applies only to Determined Enterprise Edition. Only the SCIM endpoints are supported. Determined EE allows requests to certain endpoints to be authenticated using OAuth 2.0 with the authorization code flow.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "Enable OAuth Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#enable-oauth-support",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "Enable OAuth Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#enable-oauth-support",
    "content": "To enable OAuth support, set scim.auth.type to oauth in the Determined master configuration. The values you\u2019ll need to configure an OAuth client application are as follows: The authorization endpoint, which is the hostname of the Determined master followed by /oauth2/authorize. The access token endpoint, which is the hostname of the Determined master followed by /oauth2/token. The client ID and secret, which are obtained using the Determined CLI: det oauth client add <descriptive client name> <domain of redirect URI> # For example: det oauth client add okta https://system-admin.okta.com The output of that command will look like the following: Client ID: 5d9bb6c1b423215f7eb0d719fffb39dda2d0d864252389da5061615d8da6887a Client secret: 37e96a2a27e20004477dbdc60c2143ee984817bc6b3a0016182a2fc15707b9c2 There is no other way to obtain the secret. Make sure not to lose it before configuring your client.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "List OAuth Clients",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#list-oauth-clients",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "List OAuth Clients",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#list-oauth-clients",
    "content": "Use the CLI to listing OAuth clients: det oauth client list",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "Remove OAuth Clients",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#remove-oauth-clients",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "OAuth 2.0 Configuration",
      "lvl1": "OAuth 2.0 Configuration",
      "lvl2": "Remove OAuth Clients",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/oauth.html#remove-oauth-clients",
    "content": "Use the CLI to remove OAuth clients: det oauth client remove <client ID>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#scim-integration",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#scim-integration",
    "content": "SCIM integration applies only to Determined Enterprise Edition. Determined EE provides a System for Cross-domain Identity Management (SCIM) integration to allow administrators to easily and securely provision users and groups through their standard identity provider (IdP). Currently, the only officially supported provider is Okta; however, Determined implements a minimal working subset of the protocol as specified by RFC 7644 and is expected to work with most IdPs that adhere to this RFC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#configure-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#configure-determined",
    "content": "Determined only requires you to enable SCIM and set your authentication mode and any necessary credentials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#configure-your-idp",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#configure-your-idp",
    "content": "When configuring your IdP to automatically push users and groups to Determined, you will need to enable SCIM for Determined in your IdP and provide it with some information about Determined\u2019s SCIM API. This includes the SCIM connector base URL, the unique ID for users that are provisioned, which provisioning actions should be supported, and the authentication mode to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#example-setup-with-okta",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SCIM Integration",
      "lvl1": "SCIM Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/scim.html#example-setup-with-okta",
    "content": "In this example, we assume the Determined master will run at https://determined.example.com and that we are using the basic authentication mode. For more information on configuring Determined to use the OAuth2 authentication mode, see the OAuth topic guide. First, in Okta, you\u2019ll need to create a new Okta application for Determined or alter your existing one. Under Determined -> General -> App Settings -> Provisioning, select the SCIM radio button. A new tab Determined -> Provisioning should appear\u2014navigate to its Integration tab and specify the following configurations for the integration: Field Example Value SCIM connector base URL https://determined.example.com/scim/v2 Unique identifier for users userName Supported provisioning actions Check all boxes your organization wants to support Authentication Mode Basic Auth Username determined Password password The username and password shown here are arbitrary and only expected to match the values specified in the scim.auth master configuration. Then navigate to Determined -> Provisioning -> To App and enable the provisioning features your organization wants to use with Okta. To configure Determined for this integration, update the master configuration to provide the client\u2019s credentials and enable the SCIM server. scim: enabled: true auth: type: basic username: \"determined\" password: \"password\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#transport-layer-security",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#transport-layer-security",
    "content": "Transport Layer Security (TLS) is a protocol for secure network communication. TLS prevents the data being transmitted from being modified or read while it is in transit and allows clients to verify the identity of the server (in this case, the Determined master). Determined can be configured to use TLS for all connections made to the master. That means that all CLI and WebUI connections will be secured by TLS, as well as connections from agents and tasks to the master. Communication between agents that occur as part of distributed training will not use TLS, nor will proxied connections from the master to a TensorBoards or notebook instance. After the master and agent are configured to use TLS, no additional configuration is needed for tasks run in the cluster. In shells and notebooks, the Determined Python libraries automatically make connections to the master using TLS with the appropriate certificate.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Master Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#master-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Master Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#master-configuration",
    "content": "To configure the master to use TLS, set the security.tls.cert and security.tls.key options to paths to a TLS certificate file and key file. When TLS is in use, the master will listen on TCP port 8443 by default, rather than 8080. If the master\u2019s certificate is not signed by a well-known CA, then the configured certificate file must contain a full certificate chain that goes all the way to a root certificate.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Agents Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#agents-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Agents Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#agents-configuration",
    "content": "When the Determined master is using TLS, set the security.tls.enabled agent configuration option to true. If the master\u2019s certificate is signed by a well-known CA, then no other TLS-specific configuration is necessary. Otherwise, for the best security, place the master\u2019s certificate file somewhere accessible to the agent and set the agent\u2019s security.tls.master_cert option to the path to that file. For a more convenient but less secure setup, instead set the security.tls.skip_verify option to true. With the latter configuration, the agent will be unable to verify the identity of the master, but the data sent over the connection will still be protected by TLS. If the master\u2019s certificate does not contain the address that the agent is using to connect to the master (but is otherwise valid), set the security.tls.master_cert_name option to one of the addresses in the certificate. For example, the master\u2019s certificate may contain a DNS hostname corresponding to the public IP address of the master, while the agent connects to the master using its private IP address to prevent traffic from being routed over the public Internet. In that case, the option should be set to the DNS name contained in the certificate. Due to a limitation of Fluent Bit, which Determined uses internally, the certificate must be valid for at least one hostname that is not an IP address and the security.tls.master_cert_name option must be set to that hostname if the agent is configured to connect to the master using an IP address. The hostname does not need to be an actual DNS name for the master\u2014it is only used for certificate verification. When dynamic agents and TLS are both in use, the dynamic agents that the master creates will automatically be configured to connect securely to the master over TLS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "CLI Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#cli-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "CLI Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#cli-configuration",
    "content": "To use TLS, the CLI must be configured with a master address starting with https:// using either the -m flag or DET_MASTER environment variable. If the master\u2019s certificate is signed by a well-known CA, then the connection should proceed immediately. If not, the CLI will indicate on the first connection that the master is presenting an untrusted certificate and display a hash of the certificate. You may wish to confirm the hash with your system administrator; in any case, if you confirm the connection to the master, the certificate will be stored on the computer where the CLI is being run and future connections to the master will be made without confirmation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#let-s-encrypt-tls-certificate-setup",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#let-s-encrypt-tls-certificate-setup",
    "content": "This section describes how to set up a TLS certificate from Let\u2019s Encrypt using Certbot and either the HTTP-01 or the DNS-01 challenge type. For more information about the challenge types, visit the Let\u2019s Encrypt documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-snapd-and-certbot",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-snapd-and-certbot",
    "content": "This section provides information about installing snapd and Certbot and adding EPEL to RHEL 8 or CentOS 8. The following websites provide more information about installing snapd and Certbot: Installing snap on Red Hat Enterprise Linux (RHEL) Installing snap on CentOS certbot instructions",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Adding EPEL to RHEL 8",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#adding-epel-to-rhel-8",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Adding EPEL to RHEL 8",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#adding-epel-to-rhel-8",
    "content": "To add the EPEL repository to a RHEL 8 system, run the following commands: sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm sudo dnf upgrade",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Adding EPEL to CentOS 8",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#adding-epel-to-centos-8",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Adding EPEL to CentOS 8",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#adding-epel-to-centos-8",
    "content": "To add the EPEL repository to a CentOS Stream 8/9 system, run the following commands: sudo dnf install epel-release sudo dnf upgrade",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Installing snapd",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-snapd",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Installing snapd",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-snapd",
    "content": "To install snapd, run the following commands: sudo yum install snapd sudo systemctl enable --now snapd.socket sudo ln -s /var/lib/snapd/snap /snap",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Installing Certbot",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-certbot",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Installing snapd and Certbot",
      "lvl4": "Installing Certbot",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#installing-certbot",
    "content": "To install Certbot on RHEL or CentOS, run the following command: sudo snap install --classic certbot To install Certbot on Debian/Ubuntu, run the following command: sudo apt-get install certbot",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certbot-certificate-request",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certbot-certificate-request",
    "content": "To complete the Certbot certificate request, execute the following steps as the root user: Register a Let\u2019s Encrypt account Perform a certificate request Update the Determined master configuration to use the certificate The steps are described in detail in the following sections.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Register a Let&#8217;s Encrypt Account",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#register-a-let-s-encrypt-account",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Register a Let&#8217;s Encrypt Account",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#register-a-let-s-encrypt-account",
    "content": "To register an account on Let\u2019s Encrypt, run the following command: certbot register Certbot responds letting you know the account is registered. To check the account status, run the following command: certbot show_account Certbot responds with the account details including the account URL, thumbprint, and email contact.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#perform-a-certificate-request",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation",
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certificate-creation",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation",
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certificate-creation",
    "content": "If port 80 of the Determined Master is accessible, you can use a simple HTTP-01 challenge type.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certificate-creation-when-the-determined-master-is-behind-a-vpn",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certificate-creation-when-the-determined-master-is-behind-a-vpn",
    "content": "This section provides information about requesting the Let\u2019s Encrypt certificate in environments that do not provide inbound access from Let\u2019s Encrypt to port 80 of the Determined master (e.g., when the Determined master is behind a VPN).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Request a Certificate Using the DNS-01 Challenge"
    },
    "url": "setup-cluster/security/tls.html#request-a-certificate-using-the-dns-01-challenge",
    "content": null,
    "type": "lvl6",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 40,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Request a Certificate Using the DNS-01 Challenge"
    },
    "url": "setup-cluster/security/tls.html#request-a-certificate-using-the-dns-01-challenge",
    "content": "Run the following command to request a Let\u2019s Encrypt certificate using the DNS-01 challenge type: certbot certonly --manual --preferred-challenges dns -d <domain> Certbot responds with a domain token and lets you know that before continuing you should verify that the TXT record has been deployed: Saving debug log to /var/log/letsencrypt/letsencrypt.log Requesting a certificate for <domain> Please deploy a DNS TXT record under the name: _acme-challenge.<domain>. with the following value: <XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX domain token> Before continuing, verify the TXT record has been deployed. Depending on the DNS provider, this may take some time, from a few seconds to multiple minutes. You can check if it has finished deploying with the aid of online tools, such as the Google Admin Toolbox: https://toolbox.googleapps.com/apps/dig/#TXT/_acme-challenge.<domain>. Look for one or more bolded line(s) below the line ';ANSWER'. It should show the value(s) you've just added. Press Enter to Continue Do not press Enter before setting up the DNS record.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Set Up the DNS Record"
    },
    "url": "setup-cluster/security/tls.html#set-up-the-dns-record",
    "content": null,
    "type": "lvl6",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 40,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Set Up the DNS Record"
    },
    "url": "setup-cluster/security/tls.html#set-up-the-dns-record",
    "content": "In the DNS configuration for the domain the Determined master is using, create a record with the following values: FQDN RECORD TYPE TTL Value _acme-challenge.<domain>. TXT 900 <XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX domain token> Ensure the _acme-challenge.<domain>. DNS record has been propagated using one of the following: https://toolbox.googleapps.com/apps/dig/#TXT/_acme-challenge.<domain>., or nslookup -type=TXT _acme-challenge.<domain>. You may need to install the nslookup utility. On CentOS: yum install bind-utils On Debian/Ubuntu: apt install dnsutils",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Complete the Certificate Request"
    },
    "url": "setup-cluster/security/tls.html#complete-the-certificate-request",
    "content": null,
    "type": "lvl6",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 40,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Perform a Certificate Request",
      "lvl5": "Certificate Creation When the Determined Master is Behind a VPN",
      "lvl6": "Complete the Certificate Request"
    },
    "url": "setup-cluster/security/tls.html#complete-the-certificate-request",
    "content": "Once you have set up the DNS record, press Enter. Certbot lets you know it has received the certificate and provides the certificate location, key location, and certificate expiration date.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Update the Determined Master TLS Configuration",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#update-the-determined-master-tls-configuration",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Request",
      "lvl4": "Update the Determined Master TLS Configuration",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#update-the-determined-master-tls-configuration",
    "content": "This section describes how to update the Determined master configuration to use the TLS certificate provided by the Let\u2019s Encrypt service. First, stop the Determined master using the appropriate command. For example, if you installed Determined using Linux packages, run the following command: systemctl stop determined-master Then, change the security section of the master configuration file by adding the following lines: security: tls: cert: /etc/letsencrypt/live/<domain>/fullchain.pem key: /etc/letsencrypt/live/<domain>/privkey.pem If appropriate, change the master port: port: 443 You\u2019ll need to configure the agents to reach this port. Finally, start the Determined master using the appropriate command. For example, if you installed Determined using Linux packages, run the following command: systemctl start determined-master",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Renewal",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certbot-certificate-renewal",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transport Layer Security",
      "lvl1": "Transport Layer Security",
      "lvl2": "Let&#8217;s Encrypt TLS Certificate Setup",
      "lvl3": "Certbot Certificate Renewal",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/tls.html#certbot-certificate-renewal",
    "content": "To renew the certificate, repeat the certificate creation steps, and restart the Determined master using the appropriate command. For example, if you installed Determined using Linux packages, run the following command: systemctl restart determined-master Most Certbot installations come with automatic renewal. Visit Setting up automated renewals to find out more. To learn how to test automatic renewal, visit the Certbot instructions (CentOS or Debian/Ubuntu).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#rbac",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#rbac",
    "content": "RBAC is only available on Determined Enterprise Edition.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#getting-started",
    "content": "If you are looking to enable RBAC on an existing Determined installation, please see the migration guide below. By default, a Determined installation comes with role-based access control disabled. To enable RBAC, set the following option in the master config: security: authz: type: rbac Brand new Determined installations include two user accounts: The admin user has full cluster access by default through the pre-canned ClusterAdmin role. The determined user has no permissions. Both accounts have empty passwords. You are encouraged to set strong passwords or deactivate these accounts for security reasons.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Getting Started",
      "lvl3": "Example Setup (CLI)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#example-setup-cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Getting Started",
      "lvl3": "Example Setup (CLI)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#example-setup-cli",
    "content": "In this section, we will configure a Determined instance to support a cluster administrator account, and a few engineers with varying level of access. First, create a new user alice, set a password, make it an admin, and deactivate the default accounts: det -u admin user create alice det user change-password alice det rbac assign-role -u alice ClusterAdmin det user login alice det user deactivate admin det user deactivate determined We want to enable two teams, one working on a traffic light detection model, and another one working on a stop signs detection model. We\u2019d like these two teams to have their separate, compartmentalized workspaces. Start with creating non-priviledged users and workspaces: det user create mle-traffic-00 det user create mle-traffic-01 det user create mle-traffic-02 det user create mle-stop-00 det workspace create \"Traffic Lights\" det workspace create \"Stop Signs\" We have several users on the traffic lights team, so we will create a user group to simplify the permission management: det user-group create \"Traffic Lights Team\" det user-group add-user \"Traffic Lights Team\" mle-traffic-00,mle-traffic-01,mle-traffic-02 Give Editor role on traffic lights workspace to entire traffic lights team, and WorkspaceAdmin role to the mle-traffic-00 and mle-stop-00 users on their respective workspace. det rbac assign-role -g \"Traffic Lights Team\" -w \"Traffic Lights\" Editor det rbac assign-role -u mle-traffic-00 -w \"Traffic Lights\" WorkspaceAdmin det rbac assign-role -u mle-stop-00 -w \"Stop Signs\" WorkspaceAdmin We now have two independent workspaces, one for each team. You can learn more about pre-canned roles such as Editor, WorkspaceAdmin in the Pre-Canned Roles section. Determined requires the projects to exist within the workspaces to run and organize the experiments. Project creation requires PERMISSION_TYPE_CREATE_PROJECT permission which is included in Editor, WorkspaceAdmin, and ClusterAdmin roles. Since mle-traffic-01 user is a member of Traffic Lights Team which has the Editor role on the Traffic Lights workspace, they can create the project themselves, no cluster admin access or participation is necessary: det -u mle-traffic-01 project create \"Traffic Lights\" \"Green\" We use det -u USER_NAME to dynamically change the username for the current command here. Similarly, you can run det user login USER_NAME to switch the current CLI user permanently. As a non-privileged user, we can now submit an experiment into this project: # Per quickstart, `cd` into the example directory before the next command. det -u mle-traffic-01 experiment create const.yaml . --config workspace=\"Traffic Lights\" --config project=\"Green\" --config name=\"green light\" Repeat the process to submit a second test experiment as a Stop Signs engineer: det -u mle-stop-00 project create \"Stop Signs\" \"Euro\" det -u mle-stop-00 experiment create const.yaml . --config workspace=\"Stop Signs\" --config project=\"Euro\" --config name=\"euro stop\" Since the admin and non-admin users on various teams have different access, listing all experiments will produce different results. The admin will see both experiments. Traffic lights and stop signs engineers will only have access to the experiments in their respective workspaces. Compare: det -u alice experiment list --all det -u mle-stop-00 experiment list --all det -u mle-traffic-00 experiment list --all",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#manage-rbac",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Inspecting the Setup",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#inspecting-the-setup",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Inspecting the Setup",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#cli",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Inspecting the Setup",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#cli",
    "content": "To get the current user\u2019s permission list: det rbac my-permissions To list all permissions on the role as well as all users and groups who bear it, whether globally or at a workspace level: det rbac describe-role ROLE To list all existing roles and their permissions: det rbac list-roles To list existing users, group and their membership: det user list det user-group list det user-group describe GROUP_NAME To list the role assignments for a user or a group: det rbac list-groups-roles GROUP_NAME det rbac list-users-roles USER_NAME",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Inspecting the Setup",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#webui",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Inspecting the Setup",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#webui",
    "content": "To see the user and group management UI, Click on your username in the upper left corner. Click \u201cSettings\u201d See \u201cUser Management\u201d and \u201cGroup Management\u201d tabs at the top. To create new users, use \u201cNew User\u201d button at the \u201cUser Management\u201d screen. To see or modify user roles assigned at the global scope, Click triple-dot icon on the right of the user entry. Select \u201cEdit\u201d option in the dropdown. To see or modify group roles assigned at the global scope, Click triple-dot icon on the right of the group entry. Select \u201cAdd Roles\u201d option in the dropdown. To see group membership, click on the plus icon on the left of the group entry. To remove member users, open group membership list and \u201cRemove\u201d button next to the user entry. To add member users, Click triple-dot icon on the right of the group entry. Select \u201cEdit/Add Users\u201d option in the dropdown.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing User Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#managing-user-groups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing User Groups",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id2",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing User Groups",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id2",
    "content": "To create a group GROUP_NAME, add and remove users USER_NAME1, USER_NAME2, and USER_NAME3: det user-group create GROUP_NAME det user-group add-user GROUP_NAME USER_NAME1,USER_NAME2,USER_NAME3 det user-group remove-user GROUP_NAME USER_NAME1,USER_NAME2,USER_NAME3 To rename a group: det user-group change-name GROUP_NAME To delete a group: det user-group delete GROUP_NAME To list existing groups, or a particular group membership: det user-group list det user-group describe GROUP_NAME",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing User Groups",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id3",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing User Groups",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id3",
    "content": "Only users with the ClusterAdmin role can add/remove users and groups. To see user group management UI, Click on your username in the upper left corner. Click \u201cAdmin\u201d. Click the \u201cGroups\u201d tab at the top. To create new groups, use \u201cNew Group\u201d button at the \u201cGroups\u201d screen. To delete a group, Click triple-dot icon on the right of the group entry. Select \u201cDelete\u201d option in the dropdown.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing Role Assignments",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#managing-role-assignments",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing Role Assignments",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id4",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing Role Assignments",
      "lvl4": "CLI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id4",
    "content": "To assign or unassign a role for a user or a group globally: det rbac assign-role -u USER_NAME ROLE_NAME det rbac unassign-role -u USER_NAME ROLE_NAME det rbac assign-role -g GROUP_NAME ROLE_NAME det rbac unassign-role -g GROUP_NAME ROLE_NAME To assign or unassign a role for a user or a group on a particular workspace, use -w WORKSPACE_NAME switch: det rbac assign-role -u USER_NAME ROLE_NAME -w WORKSPACE_NAME det rbac unassign-role -u USER_NAME ROLE_NAME -w WORKSPACE_NAME det rbac assign-role -g GROUP_NAME ROLE_NAME -w WORKSPACE_NAME det rbac unassign-role -g GROUP_NAME ROLE_NAME -w WORKSPACE_NAME",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing Role Assignments",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id5",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Manage RBAC",
      "lvl3": "Managing Role Assignments",
      "lvl4": "WebUI",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id5",
    "content": "To assign or unassign a role for a user or a group globally, first go to user or group management UI: Only users with the ClusterAdmin role can add/edit global role assignments for users and groups from the \u201cAdmin\u201d menu as described immediately below. Click on your username in the upper left corner. Click \u201cAdmin\u201d. See \u201cUsers\u201d and \u201cGroups\u201d tabs at the top. Then, for users: Click triple-dot icon on the right of the user entry. Select \u201cEdit\u201d option in the dropdown. For groups: Click triple-dot icon on the right of the group entry. Select \u201cAdd Roles\u201d option in the dropdown. To assign or unassign a role for a user or a group on a particular workspace, Only users with the WorkspaceAdmin role can add/edit workspace-scoped role assignments for users and groups. Go to the workspaces page, select the target workspace. Click \u201cMembers\u201d tab at the top. To create new role assignments, click the \u201cAdd Members\u201d button at the top right. To remove existing role assignments, click the triple-dot menu for a user/group and select \u201cRemove\u201d. To edit the role, click on the dropdown in the role column for a user/group and make your selection.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#about-rbac-concepts",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "User Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#user-groups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "User Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#user-groups",
    "content": "User groups in Determined are organizational units containing one or more Determined users. User groups currently have no inherent functionality and are not directly useful unless paired with the RBAC feature. Users with cluster admin permissions may create groups and add as many users to them as needed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#rbac-permissions-and-scopes",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#rbac-permissions-and-scopes",
    "content": "RBAC allows granting users or user groups a permission to do certain actions, such as various API calls, on certain resources, such as experiments. This is achieved using role assignments, which are comprised of security principal, role, and scope. Roles, in turn, are comprised of permissions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Security Principal",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#security-principal",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Security Principal",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#security-principal",
    "content": "A security principal is an entity that is performing an action on a resource. Determined supports individual users or user groups as security principals.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Scope",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#scope",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Scope",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#scope",
    "content": "A scope in Determined refers to where a user may exercise their permitted actions and currently has two possible values: global and workspace-specific. A global-level permission is valid anywhere in Determined, allowing the user to perform the action on any workspace. A workspace-level permission restricts actions so that they are only permissible on the specified workspaces. When using workspace-level permissions, the admin must specify which workspace(s) the permission is valid for.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Role",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#role",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Role",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#role",
    "content": "A role is a collection of permissions. It allows combining commonly used permissions, for example when several permissions are used by the same persona, like an ML engineer. Determined currently supports several built-in roles.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Permission",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#permission",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "About RBAC Concepts",
      "lvl3": "RBAC Permissions and Scopes",
      "lvl4": "Permission",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#permission",
    "content": "A permission is a description of a type of access to a resource or set of resources. Permissions typically map to an action on an entity type, for example: PERMISSION_TYPE_VIEW_EXPERIMENT_METADATA: view high-level experiment properties. PERMISSION_TYPE_VIEW_EXPERIMENT_ARTIFACTS: view experiment code and checkpoints. PERMISSION_TYPE_ADMINISTRATE_USER: manage user accounts. This is only available on the global scope. PERMISSION_TYPE_ASSIGN_ROLES: assign roles.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Usage Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#usage-reference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Usage Reference",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id6",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Usage Reference",
      "lvl3": "CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#id6",
    "content": "The Determined CLI has built-in help. Please see help for the top-level commands, as well as their subcommands: det user -h det user-group -h det rbac -h det rbac assign-role -h",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#pre-canned-roles",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#pre-canned-roles",
    "content": "Determined ships with several pre-canned roles. We are looking to add an ability to edit or create custom roles in a future release. To list all existing cluster roles and the concrete permissions they include: det rbac list-roles",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "Viewer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#viewer",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "Viewer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#viewer",
    "content": "The Viewer role allows a user to see workspaces, projects, notebooks, TensorBoards, shells, commands (NTSC), and experiments, as well as experiment metadata and artifacts within its scope.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "Editor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#editor",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "Editor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#editor",
    "content": "The Editor role supersedes the Viewer role, and includes permissions to create, edit, or delete projects, NTSC, and experiments within its scope.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "WorkspaceAdmin",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#workspaceadmin",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "WorkspaceAdmin",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#workspaceadmin",
    "content": "The WorkspaceAdmin role supersedes the Editor role, and includes permissions to edit or delete workspaces, and modify role assignments within its scope. Users who take this role on a particular workspace can assign roles to other users on this workspace, that is, add other members (viewers, editors, or workspace admins) to the workspace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "WorkspaceCreator",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#workspacecreator",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "WorkspaceCreator",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#workspacecreator",
    "content": "The WorkspaceCreator role grants the single permission to create new workspaces. It can only be assigned globally. By default, when a user creates a workspace, they automatically get assigned the WorkspaceAdmin role. This behavior can be configured using master config: security: authz: workspace_creator_assign_role: enabled: true role_id: ROLE_ID where ROLE_ID is the integer role identifier, as listed in det rbac list-roles. To disable the assignment of any roles to the newly created workspace, set enabled: false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "ClusterAdmin",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#clusteradmin",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Pre-Canned Roles",
      "lvl3": "ClusterAdmin",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#clusteradmin",
    "content": "ClusterAdmin is the highest role intended for cluster administrators or superusers. It includes all permissions, and can only be assigned globally.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Migrating Existing Installation to RBAC",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#migrating-existing-installation-to-rbac",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "RBAC",
      "lvl1": "RBAC",
      "lvl2": "Migrating Existing Installation to RBAC",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/rbac.html#migrating-existing-installation-to-rbac",
    "content": "Upgrade Determined to the latest RBAC-enabled version. Enable RBAC UI in the master config: security: authz: rbac_ui_enabled: true Restart Determined for the config change to take effect. This config option will enable RBAC APIs and UI, but the RBAC rules will not be enforced, allowing administrators to set it up first. For all cluster administrators or superusers, grant the ClusterAdmin role. This will ensure the admins are not \u201clocked out\u201d once strict RBAC enforcement is enabled. det rbac assign-role -u ADMIN_USER_NAME ClusterAdmin Enable RBAC enforcement in the master config: security: authz: type: rbac Restart master for the change to take effect. Proceed to configure RBAC as desired. Workspace creators for workspaces created after upgrading to 0.19.6+ will have WorkspaceAdmin role assigned for their workspaces. Users will have no default access otherwise.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#saml-integration",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#saml-integration",
    "content": "SAML integration applies only to Determined Enterprise Edition. Determined EE provides a SAML integration to allow users to use single sign-on (SSO) with their organization\u2019s identity provider (IdP) and to provide system administrators better control over access to resources. Currently, the only officially supported identity provider is Okta.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#configure-your-idp",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Configure Your IdP",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#configure-your-idp",
    "content": "When configuring your IdP to allow users to SSO to Determined, you will need to specify the location of Determined\u2019s SSO URL and the audience URL. The audience URL should be set to the Determined master\u2019s base URL and the SSO endpoint is at that base URL with a path of /saml/sso. Determined also requires an additional attribute named userName with name format unspecified set to the username of the user attempting SSO (e.g., for Okta, this is the attribute value user.login).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#configure-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Configure Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#configure-determined",
    "content": "Determined requires your IdP\u2019s SSO URL, descriptor SSO URL, public certificate, and name as well as the hostname your IdP intends to use to communicate with Determined. These are all supplied in the master.yaml.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#example-setup-with-okta",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "SAML Integration",
      "lvl1": "SAML Integration",
      "lvl2": "Example Setup with Okta",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/security/saml.html#example-setup-with-okta",
    "content": "In this example, we assume the Determined master will run at https://determined.example.com. First, in Okta, you\u2019ll need to create a new SAML application and specify the following options: Field Example Value Single sign on URL https://determined.example.com/saml/sso Audience URI (SP Entity ID) https://determined.example.com Name ID format Unspecified Application username Okta username Determined also requires an attribute statement named userName with the name format unspecified and a value user.login. Okta will show that more steps are required to complete the configuration and link to a page with their IdP SSO URL, IdP Issuer URL (synonymous to IdP Descriptor URL), and public certificate. Use these to configure the Determined master in master.yaml. The cert will need to be saved and mounted into the master\u2019s container. saml: enabled: true provider: \"Okta\" idp_recipient_url: \"https://determined.example.com/saml/sso\" idp_sso_url: \"https://myorg.okta.com/app/.../sso/saml\" idp_sso_descriptor_url: \"http://www.okta.com/...\" idp_cert_path: \"okta.cert\" Once the master is started with this configuration, users should be able to log in to Determined from Okta by clicking the Determined tile after they have been provisioned.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#install-and-set-up-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#install-and-set-up-determined",
    "content": "Install and set up Determined using the cluster deployment guide for your environment. Store your installation commands and flags in a shell script for future use, particularly for upgrading. To configure your cluster, visit Configuring the Cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Local",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#local",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Local",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#local",
    "content": "Install Determined on a single machine, for your own use. Compatible with Windows, Mac, and Linux. Ideal for getting started with Determined. Quick Installation Install Determined Using det deploy Install Determined Using Homebrew (macOS) Install Determined Using Windows Subsystem for Linux (Windows)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Determined Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#determined-agent",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Determined Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#determined-agent",
    "content": "Use Determined\u2019s built-in resource management. This is an easier alternative to installing and administering via Kubernetes or Slurm. Ideal for teams of any size to share dedicated compute resources. Compatible with on-prem clusters and cloud auto-scaling (AWS and GCP). Deploy on Prem Install Determined Using Linux Packages Install Determined Using Docker Deploy on AWS Deploy on GCP",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#kubernetes",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#kubernetes",
    "content": "Allow Determined to submit jobs to a Kubernetes cluster. Compatible with on-prem, GKE, and EKS clusters. Deploy on Kubernetes Install Determined on Kubernetes Set up and Manage an Azure Kubernetes Service (AKS) Cluster Set up and Manage an AWS Kubernetes (EKS) Cluster Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Slurm",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#slurm",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install and Set Up Determined",
      "lvl1": "Install and Set Up Determined",
      "lvl2": "Slurm",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/index.html#slurm",
    "content": "Enable Determined to submit jobs to a Slurm cluster. This method is only available on Determined Enterprise Edition. Deploy on Slurm/PBS",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuring the Cluster",
      "lvl1": "Configuring the Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/cluster-configuration.html#configuring-the-cluster",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuring the Cluster",
      "lvl1": "Configuring the Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/cluster-configuration.html#configuring-the-cluster",
    "content": "This guide contains basic cluster configuration information and links to reference information. Common Configuration Options Master Configuration Reference Agent Configuration Reference",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuring the Cluster",
      "lvl1": "Configuring the Cluster",
      "lvl2": "Basic Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/cluster-configuration.html#basic-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuring the Cluster",
      "lvl1": "Configuring the Cluster",
      "lvl2": "Basic Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/cluster-configuration.html#basic-configuration",
    "content": "The master and agent can each be configured with a configuration file, environment variables, or command-line options. The master and agent both accept an optional --config-file command-line option, which specifies the path of the configuration file to use. Note that when running the master or agent inside a container, you will need to make the configuration file accessible inside the container (e.g., via a bind mount). For example, this command starts the agent using a configuration file: docker run \\ -v `pwd`/agent-config.yaml:/etc/determined/agent-config.yaml \\ determinedai/determined-agent --config-file /etc/determined/agent-config.yaml The agent.yaml file might contain master_host: 127.0.0.1 master_port: 8080 to configure the address of the Determined master that the agent will attempt to connect to. Each option in the master or agent configuration file can also be specified as an environment variable or a command-line option. To configure the behavior of the master or agent using environment variables, specify an environment variable starting with DET_ followed by the name of the configuration variable. Underscores (_) should be used to indicate nested options: for example, the logging.type master configuration option can be specified via an environment variable named DET_LOGGING_TYPE. The equivalent of the agent configuration file shown above can be specified by setting two environment variables, DET_MASTER_HOST and DET_MASTER_PORT. When starting the agent as a container, environment variables can be specified as part of docker run: docker run \\ -e DET_MASTER_HOST=127.0.0.1 \\ -e DET_MASTER_PORT=8080 \\ determinedai/determined-agent The equivalent behavior can be achieved using command-line options: determined-agent run --master-host=127.0.0.1 --master-port=8080 The same behavior applies to master configuration settings as well. For example, configuring the host where the Postgres database is running can be done via a configuration file containing: db: host: the-db-host Equivalent behavior can be achieved by setting the DET_DB_HOST=the-db-host environment variable or --db-host the-db-host command-line option. See also: Job Configuration Reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Internet Access",
      "lvl1": "Setting Up Internet Access",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/internet-access.html#setting-up-internet-access",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Internet Access",
      "lvl1": "Setting Up Internet Access",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/internet-access.html#setting-up-internet-access",
    "content": "The Determined Docker images are hosted on Docker Hub. Determined agents need access to Docker Hub for such tasks as building new images for user workloads. If packages, data, or other resources needed by user workloads are hosted on the public Internet, Determined agents need to be able to access them. Note that agents can be configured to use proxies when accessing network resources. For best performance, it is recommended that the Determined master and agents use the same physical network or VPC. When using VPCs on a public cloud provider, additional steps might need to be taken to ensure that instances in the VPC can access the Internet: On GCP, the instances need to have an external IP address, or a GCP Cloud NAT should be configured for the VPC. On AWS, the instances need to have a public IP address, and a VPC Internet Gateway should be configured for the VPC. See also: Firewall Rules.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#setting-up-clients",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#setting-up-clients",
    "content": "You can set up clients for interacting with the Determined Master through the Determined CLI. Follow these instructions to set up clients.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": "Step 1 - Set DET_MASTER Environment Variable",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#step-1-set-det-master-environment-variable",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": "Step 1 - Set DET_MASTER Environment Variable",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#step-1-set-det-master-environment-variable",
    "content": "Set the DET_MASTER environment variable, which is the network address of the Determined master. You can override the value in the command line using the -m option. You can skip this step when deploying locally.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": "Step 2 - Install the Determined CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#step-2-install-the-determined-cli",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Setting Up Clients",
      "lvl1": "Setting Up Clients",
      "lvl2": "Step 2 - Install the Determined CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/setup-clients.html#step-2-install-the-determined-cli",
    "content": "The Determined CLI is a command-line tool that lets you launch new experiments and interact with a Determined cluster. The CLI can be installed on any machine you want to use to access Determined. To install the CLI, follow the installation instructions. The -m or --master flag determines the network address of the Determined master that the CLI connects to. If this flag is not specified, the value of the DET_MASTER environment variable is used; if that environment variable is not set, the default address is localhost. The master address can be specified in three different formats: example.org:port (if port is omitted, it defaults to 8080) http://example.org:port (if port is omitted, it defaults to 80) https://example.org:port (if port is omitted, it defaults to 443) Examples: # Connect to localhost, port 8080. $ det experiment list # Connect to example.org, port 8888. $ det -m example.org:8888 e list # Connect to example.org, port 80. $ det -m http://example.org e list # Connect to example.org, port 443. $ det -m https://example.org e list # Connect to example.org, port 8080. $ det -m example.org e list # Set default Determined master address to example.org, port 8888. $ export DET_MASTER=\"example.org:8888\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#firewall-rules",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#firewall-rules",
    "content": "The firewall rules must satisfy the following network access requirements for the master and agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": "Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#master",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": "Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#master",
    "content": "Inbound TCP to the master\u2019s network port from the Determined agent instances, as well as all machines where developers want to use the Determined CLI or WebUI. The default port is 8443 if TLS is enabled and 8080 if not. Outbound TCP to all ports on the Determined agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": "Agents",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#agents",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Firewall Rules",
      "lvl1": "Firewall Rules",
      "lvl2": "Agents",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/firewall-rules.html#agents",
    "content": "Inbound TCP from all ports on the master to all ports on the agent. Outbound TCP from all ports on the agent to the master\u2019s network port. Outbound TCP to the services that host the Docker images, packages, data, and other resources that need to be accessed by user workloads. For example, if your data is stored on Amazon S3, ensure the firewall rules allow access to this data. Inbound and outbound TCP on all ports to and from each Determined agent. The details are as follows: Inbound and outbound TCP ports 1734 and 1750 are used for synchronization between trial containers. Inbound and outbound TCP port 12350 is used for internal SSH-based communication between trial containers. When using DeepSpeedTrial, port 29500 is used by for rendezvous between trial containers. When using PyTorchTrial with the \u201ctorch\u201d distributed training backend, port 29400 is used for rendezvous between trial containers For all other distributed training modes, inbound and outbound TCP port 12355 is used for GLOO rendezvous between trial containers. Trials use OS-selected ephemeral ports for communication via GLOO and NCCL. Each TensorBoard uses a port in the range 2600\u20132899 Each notebook uses a port in the range 2900\u20133199 Each shell uses a port in the range 3200\u20133599 See also: Setting Up Internet Access.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#quick-installation",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#quick-installation",
    "content": "If you have not used Determined before, and you want to quickly set up a new training environment, you are at the right place!",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#prerequisites",
    "content": "Your system must meet the software and hardware requirements described in the Installation Requirements.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 1 - Install Docker",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-1-install-docker",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 1 - Install Docker",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-1-install-docker",
    "content": "Install Docker on your machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 2 - Install Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-2-install-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 2 - Install Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-2-install-determined",
    "content": "Install the Determined library and start a cluster locally. Ensure you have Docker running and then run the following commands: pip install determined # If your machine has GPUs: det deploy local cluster-up # If your machine does not have GPUs: det deploy local cluster-up --no-gpu The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 3 - Sign In",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-3-sign-in",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Quick Installation",
      "lvl1": "Quick Installation",
      "lvl2": "Step 3 - Sign In",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/basic.html#step-3-sign-in",
    "content": "Once Determined is installed and Docker is running, you can sign in. Go to http://localhost:8080/. Accept the default username of determined and leave the password empty. Click Sign In.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Prem",
      "lvl1": "Deploy on Prem",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/index.html#deploy-on-prem",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Prem",
      "lvl1": "Deploy on Prem",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/index.html#deploy-on-prem",
    "content": "On-premise deployments are useful if you already have access to the machines that you would like to install Determined on, whether that means a single laptop for local development or a fleet of multi-GPU servers. det deploy is the most convenient on-premise option; once installed, it will allow you to start a cluster by running a single command on each machine. If you would like more control over the process, you can instead manually manage the Docker images that det deploy uses internally. If you are using Ubuntu, you also have the option of installing most components of Determined using Debian packages and running them as systemd services. To install Determined on-premise, first install Docker. Then install Determined by your preferred method. Store your installation commands and flags in a shell script for future use, particularly for upgrading.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#requirements",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#system-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#system-requirements",
    "content": "A Determined cluster has the following requirements.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": "Software",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#software",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": "Software",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#software",
    "content": "The Determined agent and master nodes must be configured with Ubuntu 20.04 or later, CentOS 7, or macOS 10.13 or later. The agent nodes must have Docker installed. To run jobs with GPUs, the NVIDIA drivers must be installed on each Determined agent. Determined requires a version greater than or equal to 450.80 of the NVIDIA drivers. The NVIDIA drivers can be installed as part of a CUDA installation but the rest of the CUDA toolkit is not required. Determined supports the active Python versions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": "Hardware",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#hardware",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "System Requirements",
      "lvl3": "Hardware",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#hardware",
    "content": "The Determined master node should be configured with at least four Intel Broadwell or later CPU cores, 8GB of RAM, and 200GB of free disk space. The Determined master node does not need GPUs. Each Determined agent node should be configured with at least two Intel Broadwell or later CPU cores, 4GB of RAM, and 50GB of free disk space. If you are using GPUs, NVIDIA GPUs with compute capability 6.0 or greater are required. These include P100, V100, A100, RTX 2080 Ti, RTX 3090, TITAN X, and TITAN XP. Most of the disk space required by the master is because of the experiment metadata database. If PostgreSQL is set up on a different machine, the disk space requirements for the master are minimal (~100MB).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-docker",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-docker",
    "content": "Docker is a dependency of several Determined system components. For example, every agent node must have Docker installed to run containerized workloads.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": "Install on Linux",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-on-linux",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": "Install on Linux",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-on-linux",
    "content": "Install Docker. Docker version 20.10 or later is required on the machine where the agent is running. On Ubuntu: sudo apt-get update && sudo apt-get install -y software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" sudo apt-get update && sudo apt-get install -y --no-install-recommends docker-ce sudo systemctl reload docker sudo usermod -aG docker $USER On CentOS: sudo yum install -y yum-utils device-mapper-persistent-data lvm2 sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce sudo systemctl start docker If the machine has GPUs that you want to use with Determined, install the NVIDIA Container Toolkit to allow Docker to run containers that use the GPUs. For more information, see the NVIDIA documentation. On Ubuntu: curl -fsSL https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update sudo apt-get install -y --no-install-recommends nvidia-container-toolkit sudo systemctl restart docker On CentOS: distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -fsSL https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo sudo yum install -y nvidia-container-toolkit sudo systemctl restart docker Log out and start a new terminal session. Verify that the current user is in the docker group and, if the machine has GPUs, that Docker can start a container using them: groups docker run --gpus all --rm debian:10-slim nvidia-smi If you are using CentOS 7, enable the journalctl log messages persistent storage so logs are saved on machine reboot: sudo mkdir /var/log/journal sudo systemd-tmpfiles --create --prefix /var/log/journal sudo systemctl restart systemd-journald",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": "Install on macOS",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-on-macos",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Requirements",
      "lvl1": "Requirements",
      "lvl2": "Install Docker",
      "lvl3": "Install on macOS",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/requirements.html#install-on-macos",
    "content": "Install Docker for macOS by following the Docker documentation. The Docker documentation describes system requirements, chipset dependencies, and installation steps. Start Docker: open /Applications/Docker.app Docker on macOS does not support containers that use GPUs. Because of this, macOS Determined agents are only able to run CPU-based workloads.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-determined-using-linux-packages",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-determined-using-linux-packages",
    "content": "This user guide provides step-by-step instructions for installing Determined using Linux packages. Determined releases Debian and RPM packages for installing the Determined master and agent as systemd services on machines running Linux. You have two options for installing the Determined master and agent: Using Debian packages on Ubuntu 16.04 or 18.04, or Using Red Hat 7-based Linux distributions (e.g., Red Hat Enterprise Linux, CentOS, Oracle Linux, and Scientific Linux).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#preliminary-setup",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#postgresql",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#postgresql",
    "content": "Determined uses a PostgreSQL database to store experiment and trial metadata. You may either use a Docker container or your Linux distribution\u2019s package and service. If you are using an existing PostgreSQL installation, we recommend confirming that max_connections is at least 96, which is sufficient for Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": "Run PostgreSQL in Docker",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#run-postgresql-in-docker",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": "Run PostgreSQL in Docker",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#run-postgresql-in-docker",
    "content": "Pull the official Docker image for PostgreSQL. We recommend using version 10 or greater. docker pull postgres:10 This image is not provided by Determined AI; please see its Docker Hub page for more information. Start PostgreSQL as follows: docker run \\ -d \\ --restart unless-stopped \\ --name determined-db \\ -p 5432:5432 \\ -v determined_db:/var/lib/postgresql/data \\ -e POSTGRES_DB=determined \\ -e POSTGRES_PASSWORD=<Database password> \\ postgres:10 If the master will connect to PostgreSQL via Docker networking, exposing port 5432 via the -p argument isn\u2019t necessary; however, you may still want to expose it for administrative or debugging purposes. In order to expose the port only on the master machine\u2019s loopback network interface, pass -p 127.0.0.1:5432:5432 instead of -p 5432:5432.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": "Install PostgreSQL using apt or yum",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-postgresql-using-apt-or-yum",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "PostgreSQL",
      "lvl4": "Install PostgreSQL using apt or yum",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-postgresql-using-apt-or-yum",
    "content": "Install PostgreSQL 10 or greater. Debian Distributions On Debian distributions, use the following command: sudo apt install postgresql-10 Red Hat Distributions On Red Hat distributions, you\u2019ll need to configure the PostgreSQL yum repository as described in the Red Hat Linux documentation. Then, install version 10: sudo yum install postgresql-server -y sudo postgresql-setup initdb sudo systemctl start postgresql.service sudo systemctl enable postgresql.service The authentication methods enabled by default may vary depending on the provider of your PostgreSQL distribution. To enable the determined-master to connect to the database, ensure that an appropriate authentication method is configured in the pg_hba.conf file. When configuring the database connection as described in Configure and Start the Cluster, note the following: If you specify the db.hostname property, you must use a PostgreSQL host (TCP/IP) connection. If you omit the db.hostname property, you must use a PostgreSQL local (Unix domain socket) connection. Finally, create a database for Determined\u2019s use and configure a system account that Determined will use to connect to the database. For example, executing the following commands will create a database named determined, create a user named determined with the password determined-password, and grant the user access to the database: sudo -u postgres psql postgres=# CREATE DATABASE determined; postgres=# CREATE USER determined WITH ENCRYPTED PASSWORD 'determined-password'; postgres=# GRANT ALL PRIVILEGES ON DATABASE determined TO determined;",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "Install the Determined Master and Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-the-determined-master-and-agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Preliminary Setup",
      "lvl3": "Install the Determined Master and Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#install-the-determined-master-and-agent",
    "content": "Find the latest release of Determined by visiting the Determined repo. Download the appropriate Debian or RPM package file, which will have the name determined-master_VERSION_linux_amd64.[deb|rpm] (where VERSION is the actual version, e.g., 0.26.1-dev0). Similarly, the agent package is named determined-agent_VERSION_linux_amd64.[deb|rpm]. Install the master package on one machine in your cluster, and the agent package on each agent machine. Debian Distributions On Debian distributions, use the following command: sudo apt install <path to downloaded package> Red Hat Distributions On Red Hat distributions, use the following command: sudo rpm -i <path to downloaded package> Before running the Determined agent, install Docker on each agent machine. If the machine has GPUs, ensure that the NVIDIA Container Toolkit is working as expected.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#configure-and-start-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#configure-and-start-the-cluster",
    "content": "Ensure that an instance of PostgreSQL is running and accessible from the machine where the Determined master will run. Edit the YAML configuration files at /etc/determined/master.yaml (for the master) and /etc/determined/agent.yaml (for each agent) as appropriate for your setup. Ensure that the user, password, and database name correspond to your PostgreSQL configuration. db: host: <PostgreSQL server IP or hostname, e.g., 127.0.0.1 if running on the master> port: <PostgreSQL port, e.g., 5432 by default> name: <Database name, e.g., determined> user: <PostgreSQL user, e.g., postgres> password: <Database password> Start the master by typing the following command: sudo systemctl start determined-master You can also run the master directly using the command determined-master. This may be useful when experimenting with Determined, such as when you want to quickly test different configuration options before writing them to the configuration file. Optionally, configure the master to start on boot. sudo systemctl enable determined-master Verify that the master started successfully by viewing the log. journalctl -u determined-master You should see logs indicating that the master can successfully connect to the database, and the last line should indicate http server started on the configured WebUI port (8080 by default). You can also validate that the WebUI is running by navigating to http://<master>:8080 with your web browser (or https://<master>:8443 if TLS is enabled). You should see No Agents on the right-hand side of the top navigation bar. Start the agent on each agent machine. sudo systemctl start determined-agent Similarly, the agent can be run with the command determined-agent. Optionally, configure the agent to start on boot. sudo systemctl enable determined-agent Verify that each agent started successfully by viewing the log. journalctl -u determined-agent You should see logs indicating that the agent started successfully, detected compute devices, and connected to the master. On the Determined WebUI, you should now see slots available, both on the right-hand side of the top navigation bar, and if you select the Cluster view in the left-hand navigation panel.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Socket Activation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#socket-activation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Socket Activation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#socket-activation",
    "content": "The master can be configured to use systemd socket activation, allowing it to be started automatically on demand (e.g., when a client makes a network connection to the port) and restarted with reduced loss of connection state. To switch to socket activation, run the following commands: sudo systemctl disable --now determined-master sudo systemctl enable --now determined-master.socket When socket activation is in use, the port on which the master listens is configured differently; the port listed in the master config file is not used, since systemd manages the listening socket. The default socket unit for Determined is configured to listen on port 8080. To use a different port, run: sudo systemctl edit determined-master.socket which will open a text editor window. To change the listening port, insert the following text (with the port number substituted appropriately) into the editor and then exit the editor: [Socket] ListenStream= ListenStream=0.0.0.0:<port> For example, you might want to configure the master to listen on port 80 for HTTP traffic or on port 443 if using TLS. After updating the configuration, run the following commands to put the change into effect (this will restart the master): sudo systemctl stop determined-master sudo systemctl restart determined-master.socket See the systemd documentation on socket unit files or systemctl for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Manage the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#manage-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Linux Packages",
      "lvl1": "Install Determined Using Linux Packages",
      "lvl2": "Manage the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/linux-packages.html#manage-the-cluster",
    "content": "To configure a service to start running automatically when its machine boots up, run sudo systemctl enable <service>, where the service is determined-master or determined-agent. You can also use sudo systemctl enable --now <service> to enable and immediately start a service in one command. To view the logging output of a service, run journalctl -u <service>. To manually stop a service, run sudo systemctl stop <service>.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#install-determined-using-docker",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#install-determined-using-docker",
    "content": "This user guide provides step-by-step instructions for installing Determined using Docker.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Preliminary Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#preliminary-setup",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Preliminary Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#preliminary-setup",
    "content": "Install Docker on all machines in the cluster. If the agent machines have GPUs, ensure that the NVIDIA Container Toolkit on each one is working as expected. Pull the official Docker image for PostgreSQL. We recommend using the version listed below. docker pull postgres:10 This image is not provided by Determined AI; please see its Docker Hub page for more information. Pull the Docker image for the master or agent on each machine where these services will run. There is a single master container running in a Determined cluster, and typically there is one agent container running on a given machine. A single machine can host both the master container and an agent container. Run the commands below, replacing VERSION with a valid Determined version, such as the current version, 0.26.1-dev0: docker pull determinedai/determined-master:VERSION docker pull determinedai/determined-agent:VERSION",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#configure-and-start-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the PostgreSQL Container",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-postgresql-container",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the PostgreSQL Container",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-postgresql-container",
    "content": "Run the following command to start the PostgreSQL container: docker run \\ --name determined-db \\ -p 5432:5432 \\ -v determined_db:/var/lib/postgresql/data \\ -e POSTGRES_DB=determined \\ -e POSTGRES_PASSWORD=<DB password> \\ postgres:10 In order to expose the port only on the master machine\u2019s loopback network interface, pass -p 127.0.0.1:5432:5432 instead of -p 5432:5432. If you choose to run in host networking mode, pass --network host instead of -p 5432:5432.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-determined-master",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-determined-master",
    "content": "Determined master configuration values can come from a file, environment variables, or command-line arguments. To start the master with a configuration file, we recommend starting from our default master configuration file, which contains a listing of the available options and descriptions for them. Download and edit the master.yaml configuration file as appropriate and start the master container with the edited configuration: docker run \\ -v \"$PWD\"/master.yaml:/etc/determined/master.yaml \\ determinedai/determined-master:VERSION To start the master with environment variables instead of a configuration file: docker run \\ --name determined-master \\ -p 8080:8080 \\ -e DET_DB_HOST=<PostgreSQL hostname or IP> \\ -e DET_DB_NAME=determined \\ -e DET_DB_PORT=5432 \\ -e DET_DB_USER=postgres \\ -e DET_DB_PASSWORD=<DB password> \\ determinedai/determined-master:VERSION Regarding the hostname for PostgreSQL, if the determined-db container and the determined-master container are running on the same machine, you may find it easier to run both of them with host networking (--network host) and use 127.0.0.1 here. In order to prevent the master from listening on port 8080 on all network interfaces on the master machine, you may specify the loopback interface in the published port mapping, i.e., -p 127.0.0.1:8080:8080.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the Determined Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-determined-agents",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Start the Determined Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#start-the-determined-agents",
    "content": "Similar to the master configuration, Determined agent configuration values can come from a file, environment variables, or command-line arguments. To start the agent with a configuration file, we recommend starting from our default agent configuration file, which contains a listing of the available options and descriptions for them. Download and edit the agent.yaml configuration file as appropriate and start the agent container with the edited configuration: docker run \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v \"$PWD\"/agent.yaml:/etc/determined/agent.yaml \\ determinedai/determined-agent:VERSION The agent container must bind mount the host\u2019s Docker daemon socket. This allows the agent container to orchestrate the containers that execute trials and other tasks. If you are providing command-line arguments to the container (e.g., using --master-port as opposed to the DET_MASTER_PORT environment variable), run must be provided as the first argument: docker run \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v \"$PWD\"/agent.yaml:/etc/determined/agent.yaml \\ determinedai/determined-agent:VERSION \\ run --master-port=8080 To start an agent container with environment variables instead of a configuration file: docker run \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --name determined-agent \\ -e DET_MASTER_HOST=<Determined master hostname or IP> \\ -e DET_MASTER_PORT=8080 \\ determinedai/determined-agent:VERSION Agents and Master on Different Machines: If your agents and master are on different machines, the Determined master hostname or IP address should be set to a value that allows your agent machines to connect to the master machine. Agents and Master on the Same Machine: If your agents and master are on the same machine, using 127.0.0.1 typically will not work unless both the master and agent containers were started with --network host. If the --network host option is used, you must also configure workload containers to use host network mode, as described below. Alternatively, if the master machine has a static IP address from your router, you can use that. The key is ensuring that the master machine can be reliably addressed from both inside and outside of Docker containers (because the Fluent Bit container will always use host networking). Determined uses Fluent Bit internally. The agent uses the fluent/fluent-bit:1.9.3 Docker image at runtime and will attempt to pull this image automatically. If the agent machines in the cluster cannot connect to Docker Hub, you\u2019ll need to manually load this image onto them before Determined can run. To use a different image for running Fluent Bit\u2014generally to leverage a custom Docker registry, as the image doesn\u2019t usually require changing otherwise\u2014you can use the agent\u2019s --fluent-logging-image command-line option or fluent_logging_image config file option. The --gpus flag should be used to specify which GPUs the agent container will have access to; without it, the agent will not have access to any GPUs. For example: # Use all GPUs. docker run --gpus all ... # Use any four GPUs (selected by Docker). docker run --gpus 4 ... # Use the GPUs with the given IDs or UUIDs. docker run --gpus '\"device=1,3\"' ... GPUs can also be disabled and enabled at runtime using the det slot disable and det slot enable CLI commands, respectively.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Docker Networking for Master, Agents, and Workloads",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#docker-networking-for-master-agents-and-workloads",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Docker Networking for Master, Agents, and Workloads",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#docker-networking-for-master-agents-and-workloads",
    "content": "As with any Docker container, the networking mode of the master and agent containers can be changed using the --network option to docker run. In particular, host mode networking (--network host) can be useful to optimize performance and in situations where a container needs to handle a large range of ports, as it does not require network address translation (NAT) and no \u201cuserland-proxy\u201d is created for each port. if you want to run workload containers in host networking mode, you will have to configure the task_container_defaults in the master.yaml; the --network argument to master or agent containers will not affect how the workload containers are lauched. The host networking driver only works on Linux hosts, and is not supported on Docker Desktop for Mac, Docker Desktop for Windows, or Docker EE for Windows Server. See Docker\u2019s documentation for more details. Even if you run the agents in a named Docker network (e.g. --network my-named-network), the workloads launched by the agent will execute in a different Docker network. This difference in networks will affect address resolution if you attempt to set the master hostname as the master\u2019s container name, because the workload containers will not be able to reach the master using that name.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Manage the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#manage-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Docker",
      "lvl1": "Install Determined Using Docker",
      "lvl2": "Manage the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/docker.html#manage-the-cluster",
    "content": "By default, docker run will run in the foreground, so that a container can be stopped simply by pressing Control-C. If you wish to keep Determined running for the long term, consider running the containers detached and/or with restart policies. Using our deployment tool is also an option.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Options to Deploy on Prem",
      "lvl1": "Options to Deploy on Prem",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/index.html#options-to-deploy-on-prem",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Options to Deploy on Prem",
      "lvl1": "Options to Deploy on Prem",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/index.html#options-to-deploy-on-prem",
    "content": "To install Determined on-premise, first install Docker. Then install Determined by one of the following methods: Store your installation commands and flags in a shell script for future use, particularly for upgrading. Install Determined Using det deploy Install Determined Using Linux Packages Install Determined Using Docker Install Determined Using Homebrew (macOS) Install Determined Using Windows Subsystem for Linux (Windows)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#install-determined-using-det-deploy",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#install-determined-using-det-deploy",
    "content": "This user guide provides instructions for using the det deploy command-line tool to deploy Determined locally or in a production cluster. det deploy automates the process of starting Determined as a collection of Docker containers. You can also use det deploy to install Determined on the cloud. For more information, see the AWS and GCP installation guides. In a typical production setup, the master and agent nodes run on separate machines. The master and agent nodes can also run on a single machine, which is useful for local development. This user guide provides instructions for both scenarios.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Preliminary Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#preliminary-setup",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Preliminary Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#preliminary-setup",
    "content": "To use det deploy for local installations, Docker must be installed. For Docker installation instructions, visit installation. Install the determined Python package by running pip install determined The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#configure-and-start-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#configure-and-start-the-cluster",
    "content": "A configuration file is needed to set important values in the master, such as where to save model checkpoints. For information about how to create a configuration file, see Configuring the Cluster. There are also sample configuration files available. det deploy will use a default configuration file if you don\u2019t provide one. It also transparently manages PostgreSQL along with the master, so the configuration options related to those services do not need to be set.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy a Single-Node Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-a-single-node-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy a Single-Node Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-a-single-node-cluster",
    "content": "For local development or small clusters (such as a GPU workstation), you may wish to install both a master and an agent on the same node. To do this, run one of the following commands: # If the machine has GPUs: det deploy local cluster-up # If the machine doesn't have GPUs: det deploy local cluster-up --no-gpu This will start a master and an agent on that machine. To verify that the master is running, navigate to http://<master-hostname>:8080 in a browser, which should bring up the Determined WebUI. If you\u2019re using your local machine, for example, navigate to http://localhost:8080. In the WebUI, go to the Cluster page. You should now see slots available (either CPU or GPU, depending on what hardware is available on the machine). For single-agent clusters launched with: det deploy local cluster-up --auto-work-dir <absolute directory path> the cluster will automatically make the specified directory available to tasks on the cluster as ./shared_fs. If --auto-work-dir is not specified, the cluster will default to mounting your home directory. This will allow you to access your local preferences and any relevant files stored in the specified directory with the cluster\u2019s notebooks, shells, and tensorboard tasks. To disable this feature, use: det deploy local cluster-up --no-auto-work-dir For production deployments, you\u2019ll want to use a cluster configuration file. To provide this configuration file to det deploy, use: det deploy local cluster-up --master-config-path <path to master.yaml>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Stop a Single-Node Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#stop-a-single-node-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Stop a Single-Node Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#stop-a-single-node-cluster",
    "content": "To stop a Determined cluster, on the machine where a Determined cluster is currently running, run det deploy local cluster-down det deploy local cluster-down will not remove any agents created with det deploy local agent-up. To remove these agents, use det deploy local agent-down.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy a Standalone Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-a-standalone-master",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy a Standalone Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-a-standalone-master",
    "content": "In many cases, your Determined cluster will consist of multiple nodes. In this case you will need to start a master and agents separately. In order to start a standalone master, run: det deploy local master-up For production deployments, you\u2019ll want to use a cluster configuration file. To provide this configuration file to det deploy, use the flag --master-config-path <path to master.yaml>. To stop a running master, run: det deploy local master-down",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-agents",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using det deploy",
      "lvl1": "Install Determined Using det deploy",
      "lvl2": "Configure and Start the Cluster",
      "lvl3": "Deploy Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/deploy.html#deploy-agents",
    "content": "To deploy a standalone agent on a machine, run one of the following commands: # If the machine has GPUs: det deploy local agent-up <master_hostname> # If the machine doesn't have GPUs: det deploy local agent-up --no-gpu <master_hostname> This will create an agent on that machine. To verify whether it has successfully connected to the master, navigate to the WebUI and check whether slots have appeared on the Cluster page. To launch the agent into a specific resource pool, use the --agent-resource-pool flag: det deploy local agent-up --agent-resource-pool=<resource_pool> <master_hostname> For more information about resource pools, see Resource Pools. To stop a running agent, run: det deploy local agent-down",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-determined-using-windows-subsystem-for-linux-windows",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-determined-using-windows-subsystem-for-linux-windows",
    "content": "This user guide provides step-by-step instructions for installing Determined on the Windows Subsystem for Linux (WSL). You have two options for installation: using the Debian or RPM packages provided by Determined, or using Docker containers published by Determined with Docker Desktop. In this user guide, we\u2019ll focus on achieving a single-machine installation of Determined, with both the master and agent running on the same machine within WSL.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#requirements",
    "content": "Minimum Windows 10 version 1903, or later. WSL 2 installed and enabled on your Windows machine. An Ubuntu or Red Hat Enterprise Linux-based WSL distribution installed from the Microsoft Store, such as: Ubuntu 22.04 LTS AlmaLinux 9 Oracle Linux 9 Pengwin Enterprise systemd enabled within your chosen WSL distribution. Recommended Windows 10 version 1903, or later. Recommended: Windows 11 version 22H2. Windows Terminal.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Requirements",
      "lvl3": "Enable systemd",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#enable-systemd",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Requirements",
      "lvl3": "Enable systemd",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#enable-systemd",
    "content": "Edit the configuration file to enable systemd within your WSL distribution. To do this: Open a terminal window in your WSL distribution. Add systemd=true to the [boot] section of /etc/wsl.conf in your WSL distribution: echo '[boot]' >> /etc/wsl.conf && echo 'systemd=true' >> /etc/wsl.conf Then restart your WSL distribution: wsl --shutdown <distribution name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-using-debian-or-rpm-packages",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-using-debian-or-rpm-packages",
    "content": "This section provides instructions for installing Determined on WSL using Debian or RPM packages.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Install PostgreSQL using apt or yum",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-postgresql-using-apt-or-yum",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Install PostgreSQL using apt or yum",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-postgresql-using-apt-or-yum",
    "content": "Since Determined uses a PostgreSQL database to store experiment and trial metadata, start by installing PostgreSQL. You\u2019ll need PostgreSQL 10 or later. Debian Distributions On Debian distributions, use the following command: sudo apt install postgresql Red Hat Distributions On Red Hat distributions, you\u2019ll need to configure the PostgreSQL yum repository as described in the Red Hat Linux documentation. Then, install version 10: sudo yum install postgresql-server -y sudo postgresql-setup initdb sudo systemctl start postgresql.service sudo systemctl enable postgresql.service The authentication methods enabled by default may vary depending on the provider of your PostgreSQL distribution. To enable the determined-master to connect to the database, ensure that an appropriate authentication method is configured in the pg_hba.conf file. When configuring the database connection in Configure and Start the Cluster, note the following: If you specify the db.hostname property, you must use a PostgreSQL host (TCP/IP) connection. If you omit the db.hostname property, you must use a PostgreSQL local (Unix-domain socket) connection. Finally, create a database for Determined\u2019s use and configure a system account that Determined will use to connect to the database. For example, executing the following commands will create a database named determined, create a user named determined with the password determined-password, and grant the user access to the database: sudo -u postgres psql postgres=# CREATE DATABASE determined; postgres=# CREATE USER determined WITH ENCRYPTED PASSWORD 'determined-password'; postgres=# GRANT ALL PRIVILEGES ON DATABASE determined TO determined;",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Install the Determined Master and Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-the-determined-master-and-agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Install the Determined Master and Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-the-determined-master-and-agent",
    "content": "To find the latest release of Determined, visit the Determined repo. Download the appropriate Debian or RPM package file, which will have the name determined-master_VERSION_linux_amd64.[deb|rpm] (where VERSION is the actual version, e.g., 0.26.1-dev0). Similarly, the agent package is named determined-agent_VERSION_linux_amd64.[deb|rpm]. Install the master and agent package on one machine. Debian Distributions On Debian distributions, use the following command: sudo apt install <path to downloaded package> Red Hat Distributions On Red Hat distributions, use the following command: sudo rpm -i <path to downloaded package> Before running the Determined agent, install Docker on each agent machine. If you are not using Docker Desktop, you may disregard the prompt to use Docker Desktop and allow Docker to be installed within the WSL distribution.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Configure and Start the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#configure-and-start-the-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Debian or RPM packages",
      "lvl3": "Configure and Start the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#configure-and-start-the-cluster",
    "content": "Ensure that an instance of PostgreSQL is running and accessible from the machine where the Determined master will run. To start the Determined master, you\u2019ll need to first edit the master and agent configuration files. Edit the YAML configuration files at /etc/determined/master.yaml (for the master) and /etc/determined/agent.yaml (for the agent) as appropriate for your setup. Ensure that the user, password, and database name correspond to your PostgreSQL configuration. In /etc/determined/master.yaml: db: host: localhost port: <PostgreSQL port, e.g., 5432 by default> name: <Database name, e.g., determined> user: <PostgreSQL user, e.g., postgres> password: <Database password> In /etc/determined/agent.yaml: master_host: localhost master_port: <Master port, e.g., 8080 by default> Start the master by typing the following command: sudo systemctl start determined-master You can also run the master directly using the command determined-master. This may be useful when experimenting with Determined such as when you want to quickly test different configuration options before writing them to the configuration file. Optionally, you can configure the master to start upon launching the WSL distro by using the following command: sudo systemctl enable determined-master Verify that the master started successfully by viewing the log. journalctl -u determined-master You should see logs indicating that the master can successfully connect to the database, and the last line should indicate http server started on the configured WebUI port (8080 by default). You can also validate that the WebUI is running by navigating to http://<master>:8080 with your web browser (or https://<master>:8443 if TLS is enabled). You should see No Agents on the right side of the top navigation bar. Start the agent on each agent machine. sudo systemctl start determined-agent Similarly, the agent can be run with the command determined-agent. Optionally, you can configure the agent to start upon launching the WSL distro by using the following command: sudo systemctl enable determined-agent Verify that each agent started successfully by viewing the log. journalctl -u determined-agent You should see logs indicating that the agent started successfully, detected compute devices, and connected to the master. On the Determined WebUI, you should now see slots available, both on the right-hand side of the top navigation bar and if you select the Cluster view in the left-hand navigation panel. Launch the Determined WebUI from within WSL. powershell.exe /C start http://localhost:8080 The Determined WebUI opens in your browser.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-using-docker-desktop",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-using-docker-desktop",
    "content": "This section provides instructions for installing Determined on WSL using Docker Desktop.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Install Docker Desktop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-docker-desktop",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Install Docker Desktop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#install-docker-desktop",
    "content": "Install Docker Desktop on Windows. Ensure the Docker daemon is reachable from your WSL distribution. Open the Settings dialog from the Docker Desktop tray icon, and select Resources. Under WSL Integration, select Enable integration with my default WSL distro, and enable integration for the WSL distribution where you will be working with Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Pull the PostgreSQL Image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#pull-the-postgresql-image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Pull the PostgreSQL Image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#pull-the-postgresql-image",
    "content": "Pull the official Docker image for PostgreSQL. We recommend using the version listed below. docker pull postgres:10 This image is not provided by Determined AI. For more information, visit its Docker Hub page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Pull the Determined AI Image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#pull-the-determined-ai-image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Pull the Determined AI Image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#pull-the-determined-ai-image",
    "content": "Pull the Docker image for the master or agent on each machine where these services will run. There is a single master container running in a Determined cluster and typically there is one agent container running on a given machine. A single machine can host both the master container and an agent container. To run the commands below, replace VERSION with a valid Determined version, such as the current version, 0.26.1-dev0: docker pull determinedai/determined-master:VERSION docker pull determinedai/determined-agent:VERSION",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-cluster",
    "content": "The cluster can now be started, first by starting the database, then by launching the Determined master and agent containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the PostgreSQL Container",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-postgresql-container",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the PostgreSQL Container",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-postgresql-container",
    "content": "To start the PostgreSQL container, use the following command. Replace <DB password> with the password you would like to use for the database: docker run \\ --name determined-db \\ -p 5432:5432 \\ -v determined_db:/var/lib/postgresql/data \\ -e POSTGRES_DB=determined \\ -e POSTGRES_PASSWORD=<DB password> \\ postgres:10",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Obtain the WSL IP Address",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#obtain-the-wsl-ip-address",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Obtain the WSL IP Address",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#obtain-the-wsl-ip-address",
    "content": "To allow Determined to reach the PostgreSQL container, you will need to determine the IP address. Run the following command to determine the IP address of the WSL distribution and store it as an environment variable: export WSL_IP=$(hostname -I | awk '{print $1}')",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-determined-master",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-determined-master",
    "content": "To start the master container, run the following command, replacing <DB password> with the database password: code: docker run \\ --name determined-master \\ -p 8080:8080 \\ -e DET_DB_HOST=$WSL_IP \\ -e DET_DB_NAME=determined \\ -e DET_DB_PORT=5432 \\ -e DET_DB_USER=postgres \\ -e DET_DB_PASSWORD=<DB password> \\ determinedai/determined-master:VERSION Optionally, you may now launch the Determined WebUI from within WSL: powershell.exe /C start http://localhost:8080",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Determined Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-determined-agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Start the Determined Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#start-the-determined-agent",
    "content": "To start the agent container, run the following command: docker run \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --name determined-agent \\ -e DET_MASTER_HOST=$WSL_IP \\ -e DET_MASTER_PORT=8080 \\ determinedai/determined-agent:VERSION Optionally, you may now launch the Determined WebUI from within WSL to verify the agent is running and connected: powershell.exe /c start http://$WSLIP:8080/det/clusters Determined internally makes use of Fluent Bit. The agent uses the fluent/fluent-bit:1.9.3 Docker image at runtime. It will attempt to pull the image automatically. If the agent machines in the cluster are not able to connect to Docker Hub, you must manually place the image onto the agent machines in the cluster before Determined can run. To specify a different image to use for running Fluent Bit (generally to make use of a custom Docker registry\u2014the image should not normally need to be changed otherwise), use the agent\u2019s --fluent-logging-image command-line option or fluent_logging_image config file option. To ensure proper GPU access for the agent container, use the --gpus flag to specify the GPUs. Failure to include this flag will result in the agent not having access to any GPUs. For example: # Use all GPUs. docker run --gpus all ... # Use any four GPUs (selected by Docker). docker run --gpus 4 ... # Use the GPUs with the given IDs or UUIDs. docker run --gpus '\"device=1,3\"' ... You can also disable and enable GPUs at runtime using the det slot disable and det slot enable CLI commands, respectively.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Manage the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#manage-the-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl1": "Install Determined Using Windows Subsystem for Linux (Windows)",
      "lvl2": "Install using Docker Desktop",
      "lvl3": "Manage the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/wsl.html#manage-the-cluster",
    "content": "By default, docker run runs in the foreground. You can stop a container simply by pressing Control-C. If you wish to keep Determined running for the long term, consider running the containers detached and/or with restart policies. You can also use the deployment tool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#install-determined-using-homebrew-macos",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#install-determined-using-homebrew-macos",
    "content": "This user guide provides step-by-step instructions for installing Determined using Homebrew. Determined publishes a Homebrew tap for installing the Determined master and agent as Homebrew services on macOS, for both Apple silicon and Intel hardware. While it is most common to install the master and agent on the same machine, it is also possible to install the master and agent on separate nodes, or install agents on multiple machines and connect them to one master. Due to the limitations of Docker networking on macOS, distributed training across multiple macOS agents is not supported.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": "Installation - Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#installation-master",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": "Installation - Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#installation-master",
    "content": "Add Homebrew tap. brew tap determined-ai/determined Install determined-master package. Determined uses a PostgreSQL database to store metadata, and postgresql@14 will be pulled in as a dependency. brew install determined-master Start the PostgreSQL server, and set up a database and default user. brew services start postgresql@14 createuser postgres createdb determined Start the Determined master service. brew services start determined-master If needed, you can configure the master by editing $(brew --prefix)/etc/determined/master.yaml and restarting the service.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": "Installation - Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#installation-agent",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined Using Homebrew (macOS)",
      "lvl1": "Install Determined Using Homebrew (macOS)",
      "lvl2": "Installation - Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/on-prem/options/homebrew.html#installation-agent",
    "content": "The Determined agent uses Docker to run your workloads. For more information, visit Docker for Mac installation instructions. By default, Determined will store checkpoints in $(brew --prefix)/var/determined/data, which is typically /usr/local/var/determined/data or /opt/homebrew/var/determined/data. Make sure to configure it as a shared path for Docker for Mac in Docker -> Preferences\u2026 -> Resources -> File Sharing. When installing on a different machine than the master, add Homebrew tap. brew tap determined-ai/determined Install determined-agent package. brew install determined-agent When installing on a different machine than the master, edit $(brew --prefix)/etc/determined/agent.yaml and change master_host and container_master_host to your master network hostname, and master_port to your master network port. Start the determined-agent service. brew services start determined-agent",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#known-issues",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Agent-Specific Scheduling Options are Ignored",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#agent-specific-scheduling-options-are-ignored",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Agent-Specific Scheduling Options are Ignored",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#agent-specific-scheduling-options-are-ignored",
    "content": "When using the HPC Launcher, Determined delegates all job scheduling and prioritization to the HPC workload manager (either Slurm or PBS) and the following experiment configuration options are ignored. resources.agent_label resources.max_slots resources.priority resources.weight",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Singularity and Docker Differences",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#singularity-and-docker-differences",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Singularity and Docker Differences",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#singularity-and-docker-differences",
    "content": "Some constraints are due to differences in behavior between Docker and Singularity, summarized here: Singularity tends to explicitly share resources/devices from the host compute node on which it is running which results in more opportunities for conflicts with other programs running on the cluster, or between multiple determined experiments that are launched concurrently on the same compute node. By default /tmp and /dev/shm are mounted from the compute node instead of private to the container. If multiple containers are running on the same node there can be more sharing than they expect. The contents of /tmp persist beyond the container lifetime and are visible to other trials. The experiment configuration might need to be updated to accommodate these issues. Determined mitigates potential file name and disk space conflicts on /tmp content by automatically using space in job_storage_root for a per-job /tmp directory. You can override this behavior by providing an explicit bind mount of the container_path /tmp folder in the Singularity container. You can restore the default Singularity behavior of sharing /tmp on the compute node by including the following bind mount in your experiment configuration or globally by using the task_container_defaults section in your master configuration: bind_mounts: - host_path: /tmp container_path: /tmp The singularity.conf options can also be used to change this behavior, or by using individual environment variables added to your experiment. Here are some configuration options that might be useful to tune sharing available in the singularity.conf file: Option Description sessiondir max size Controls the disk space, in MB, allocated to support directories not shared from the host compute node, such as /tmp and /usr/tmp, depending upon your configuration. mount tmp Isolates /tmp from the host compute node. The size of this area is configured by sessiondir max size. Singularity attempts to automatically download and convert Docker images, however, the behavior is somewhat different than with Docker. By default converted Singularity images are stored per user in ~/.singularity. Determined environment images are relatively large and this can result in excessive duplication. You likely want to predownload images under singularity_image_root as described in Provide a Container Image Cache or configure SINGULARITY_CACHEDIR to point to a shared directory. Some Docker features do not have an exact replacement in Singularity, and therefore the associated Determined features are not supported. Feature Description resources.devices By default /dev is mounted from the compute host, so all devices are available. This can be overridden by the singularity.conf mount dev option. resources.shm_size By default /dev/shm is mounted from the compute host. This can be overridden by the singularity.conf mount tmp option. When enabled, the size can be increased using compute node /etc/fstab settings. environment.registry_auth.server No equivalent setting in Singularity. environment.registry_auth.email No equivalent setting in Singularity.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Singularity Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#singularity-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Singularity Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#singularity-known-issues",
    "content": "Launching a PBS job with an experiment configuration that includes an embedded double quote character (\u201d) may cause the job to fail unless you have Singularity 3.10 or greater or Apptainer 1.1 or greater. For example, the error might be the json.decoder.JSONDecodeError or the experiment log may contain source: /.inject-singularity-env.sh:224:1563: \"export\" must be followed by names or assignments and RuntimeError: missing environment keys [DET_MASTER, DET_CLUSTER_ID, DET_AGENT_ID, DET_SLOT_IDS, DET_TASK_ID, DET_ALLOCATION_ID, DET_SESSION_TOKEN, DET_TASK_TYPE], is this running on-cluster? The version of Singularity is detected by the HPC Launcher invoking the singularity command and checking for the --no-eval option. If the singularity command is not on the path for the HPC launcher or is of an inconsistent version with the compute nodes, embedded double quote characters may still not work.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Apptainer Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#apptainer-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Apptainer Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#apptainer-known-issues",
    "content": "Starting with Apptainer version 1.1.0 some changes may trigger permission problems inside of Determined containers for shells, tensorboards, and experiments. For example, a tensorboard log may contain ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device, or a shell may fail to function and the shell logs contain the message chown(/dev/pts/1, 63200, 5) failed: Invalid argument, or an experiment may fail to launch due to FATAL: container creation failed: mount /var/tmp->/var/tmp error: while mounting /var/tmp: could not mount /var/tmp: operation not supported. This likely indicates an installation or configuration error for unprivileged containers. Review the Installing Apptainer documentation. These errors are sometimes resolved by additionally installing the apptainer-setuid package.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Podman Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#podman-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Podman Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#podman-known-issues",
    "content": "Determined uses Podman in rootless mode. There are several configuration errors that may be encountered: stat /run/user/NNN: no such file or directory likely indicates that the environment variable XDG_RUNTIME_DIR is referencing a directory that does not exist. stat /run/user/NNN: permission denied may indicate a problem with default the runroot configuration. Error: A network file system with user namespaces is not supported. Please use a mount_program: backing file system is unsupported for this graph driver indicates that the graphroot references a distributed file system. Refer to Podman Requirements for recommendations. On a Slurm cluster, it is common to rely upon /etc/hosts (instead of DNS) to resolve the addresses of the login node and other compute nodes in the cluster. If jobs are unable to resolve the address of the Determined master or other compute nodes in the job and you are relying on /etc/hosts, check the following: Ensure that the /etc/hosts file is being mounted in the container by a bind mount in the task_container_defaults section of your master configuration as shown below. Unlike Singularity, Podman V4.0+ no longer maps /etc/hosts from the host into the running container by default. On the initial startup, the Determined Slurm launcher automatically adds the task_container_defaults fragment below when adding the resource_manager section. If, however, you have since changed the file you may need to manually add the bind mount to ensure that jobs can resolve all host addresses in the cluster: task_container_defaults: bind_mounts: - host_path: /etc/hosts container_path: /etc/hosts Ensure that the names and addresses of the login node, admin node, and all compute nodes are consistently available in /etc/hosts on all nodes. Podman containers only inherit environment variables that have been explicitly specified. Determined adds Podman arguments to provide any Determined-configured environment variables, and the launcher enables inheritance of the following variables: SLURM_*, CUDA_VISIBLE_DEVICES, NVIDIA_VISIBLE_DEVICES, ROCR_VISIBLE_DEVICES, HIP_VISIBLE_DEVICES. You may enable the inheritance of additional variables from the host environment by specifying the variable name with an empty value in the environment_variables of your experiment configuration or task container defaults. environment_variables: - INHERITED_ENV_VAR= Terminating a Determined AI job may cause the following conditions to occur: Compute nodes go into drain state. Processes inside the container continue to run. An attempt to run another job results in Running a job gets the error level=error msg=\"invalid internal status, try resetting the pause process with \\\"/usr/local/bin/podman system migrate\\\": could not find any running process: no such process\". Podman creates several processes when running a container, such as podman, conmon, and catatonit. When a user terminates a Determined AI job, Slurm will send a SIGTERM to the podman processes. However, sometimes the container will continue running, even after the SIGTERM has been sent. On Slurm versions prior to version 22, Slurm will place the node in the drain state, requiring the use of the scontrol command to set the node back to the idle state. It may also require podman system migrate to be run to clean up the running containers. To ensure the container associated with the job is stopped when a Determined AI job is terminated, create a Slurm task epilog script to stop the container. Set the Task Epilog script in the slurm.conf file, as shown below, to point to a script that resides in a shared filesystem accessible from all compute nodes. TaskEpilog=/path/to/task_epilog.sh Set the contents of the Task Epilog script as shown below. #!/usr/bin/env bash slurm_job_name_suffix=$(echo ${SLURM_JOB_NAME} | sed 's/^\\S\\+-\\([a-z0-9]\\+-[a-z0-9]\\+\\)$/\\1/') if ps -fe | grep -E \"[p]odman run .*-name ${SLURM_JOB_USER}-\\S+-${slurm_job_name_suffix}\" > /dev/null then timeout -k 15s 15s bash -c \"while ps -fe | grep -E \\\"[c]onmon .*-n ${SLURM_JOB_USER}-\\S+-${slurm_job_name_suffix}\\\" > /dev/null 2>&1; do sleep 1; done\" podman_container_stop_command=\"podman container stop --filter name='.+-${slurm_job_name_suffix}'\" echo \"$(date):$0: Running \\\"${podman_container_stop_command}\\\"\" 1>&2 eval ${podman_container_stop_command} fi exit 0 Restart the slurmd daemon on all compute nodes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Enroot Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#enroot-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Enroot Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#enroot-known-issues",
    "content": "Enroot uses XDG_RUNTIME_DIR which is not provided to the compute jobs by Slurm/PBS by default. The error mkdir: cannot create directory \u2018/run/enroot\u2019: Permission denied indicates that the environment variable XDG_RUNTIME_DIR is not defined on the compute nodes. See Podman Requirements for recommendations. Enroot requires manual download and creation of containers. The error [ERROR] No such file or directory: /home/users/test/.local/share/enroot/determinedai+environments+cuda-11.1-base-gpu-mpi-0.18.5 indicates the user test has not created an Enroot container for Docker image determinedai/environments:cuda-11.1-base-gpu-mpi-0.18.5. Check the available containers using the enroot list command. See Enroot Requirements for guidance on creating Enroot containers. Enroot does not provide a mechanism for sharing containers. Each user must create any containers needed by their Determined experiments prior to creating the experiment. Some Docker features do not have an exact replacement in Enroot, and therefore the associated Determined features are not supported. Feature Description resources.devices Managed via Enroot configuration files. resources.shm_size Managed via Enroot configuration files. environment.registry_auth.server No equivalent setting in Enroot. environment.registry_auth.email No equivalent setting in Enroot.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Slurm Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#slurm-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Slurm Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#slurm-known-issues",
    "content": "Jobs may fail to submit with Slurm version 22.05.5 through 22.05.8 with the message error: Unable to allocate resources: Requested node configuration is not available. Slurm 22.05.5 through 22.05.8 are not supported due to Slurm Bug 15857. The bug was addressed in 22.05.09 or 23.02.00. A Determined experiment remains QUEUEUED for an extended period: If Slurm provides a reason code for the QUEUEUED state of the job, the reason description from JOB REASON CODES will be added to the experiment/task log as an informational message such as: INFO: HPC job waiting to be scheduled: Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions In some cases, it may be helpful to inspect the details of your queued jobs using the Slurm scontrol show jobs command using the HPC Job ID displayed in the experiment/task log. An example of the command output is shown below. $ scontrol show job 109084 JobId=109084 JobName=det-ai_exp-2221-trial-15853-2221.33b6fcca-564d-47a7-ab2e-0d2a4a90a0f1.1 UserId=user(1234) GroupId=users(100) MCS_label=N/A Priority=4294866349 Nice=0 Account=(null) QOS=normal JobState=PENDING Reason=Priority Dependency=(null) Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:00 TimeLimit=1-00:00:00 TimeMin=N/A SubmitTime=2023-07-03T16:01:35 EligibleTime=2023-07-03T16:01:35 AccrueTime=2023-07-03T16:01:35 StartTime=Unknown EndTime=Unknown Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2023-07-03T16:06:15 Scheduler=Backfill:* Partition=mlde_rocm AllocNode:Sid=o184i054:755599 ReqNodeList=o186i[122-123] ExcNodeList=(null) NodeList= NumNodes=1-1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:* ReqTRES=cpu=1,mem=256G,node=1,billing=1,gres/gpu=1 AllocTRES=(null) Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=* MinCPUsNode=1 MinMemoryNode=0 MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/cstor/determined/o184i054-jobs/jobs/environments/vishnu/2221.33b6fcca-564d-47a7-ab2e-0d2a4a90a0f1.1/ai_exp-2221-trial-15853-job.sh WorkDir=/var/tmp StdErr=/cstor/determined/o184i054-jobs/jobs/environments/vishnu/2221.33b6fcca-564d-47a7-ab2e-0d2a4a90a0f1.1/ai_exp-2221-trial-15853-error.log StdIn=/dev/null StdOut=/cstor/determined/o184i054-jobs/jobs/environments/vishnu/2221.33b6fcca-564d-47a7-ab2e-0d2a4a90a0f1.1/ai_exp-2221-trial-15853-output.log Power= CpusPerTres=gres:gpu:64 MemPerTres=gres:gpu:262144 TresPerJob=gres:gpu:1 The Slurm job state (See JOB STATE CODES) may help identify the delay in scheduling. If the Slurm job state is PENDING, review the resources being requested and the Reason code to identify the cause. To better understand how resource requests are derived by Determined, see HPC Launching Architecture. Some common reason codes for PENDING are: PartitionNodeLimit: Ensure that the job is not requesting more nodes than MaxNodes of the partition. Ensure that the MaxNodes setting for the partition is at least as high as the number of GPUs in the partition. The MaxNodes value for a partition can be viewed in the JOBS_SIZE column of the command: sinfo -O Partition,Size,Gres,OverSubscribe,NodeList,StateComplete,Reason PARTITION JOB_SIZE GRES OVERSUBSCRIBE NODELIST STATECOMPLETE REASON defq* 1-infinite gpu:tesla:4 NO node002 idle none Until scheduled, the job\u2019s NumNodes is shown as the range 1-slots_per_trial. Ensure the slots_per_trial shown is not larger than the value shown in the JOB_SIZE column for the partition. A second potential cause of PartitionNodeLimit is submitting CPU experiments (or when the Determined cluster is configured with gres_supported: false ), without specifying slurm.slots_per_node to enable multiple CPUs to be used on each node. Without slurm.slots_per_node the job will request slots_per_trial nodes. Priority: One or more higher priority jobs exist for this partition or advanced reservation. Resources: Expected when resources are in use by other jobs. Otherwise, verify you have not requested more resources (GPUs, CPUs, nodes, memory) than are available in your cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "PBS Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#pbs-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "PBS Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#pbs-known-issues",
    "content": "Jobs are treated as successful even in the presence of a failure when PBS job history is not enabled. Without job history enabled, the launcher is unable to obtain the exit status of jobs and therefore they are all reported as successful. This will prevent failed jobs from automatically restarting, and in the case of a job that fails to start running at all, it may be reported as completed with no error message reported. Refer to PBS Requirements.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "AMD/ROCm Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#amd-rocm-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "AMD/ROCm Known Issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#amd-rocm-known-issues",
    "content": "AMD/ROCm support is available only with Singularity containers. While Determined does add the proper Podman arguments to enable ROCm GPU support, the capabilities have not yet been verified. Launching experiments with slot_type: rocm, may fail with the error RuntimeError: No HIP GPUs are available. Ensure that the compute nodes are providing ROCm drivers and libraries compatible with the environment image that you are using and that they are available in the default locations, or are added to the path and/or ld_library_path variables in the slurm configuration. Depending upon your system configuration, you may need to select a different ROCm image. See Set Environment Images for the images available. Launching experiments with slot_type: rocm, may fail in the AMD/ROCm libraries with with the error terminate called after throwing an instance of 'boost::filesystem::filesystem_error' what(): boost::filesystem::remove: Directory not empty: \"/tmp/miopen-.... A potential workaround is to disable the per-container /tmp by adding the following bind mount in your experiment configuration or globally by using the task_container_defaults section in your master configuration: bind_mounts: - host_path: /tmp container_path: /tmp",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Determined AI Experiment Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#determined-ai-experiment-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Determined AI Experiment Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#determined-ai-experiment-requirements",
    "content": "Ensure that the following requirements are met in your experiment configuration. Distributed jobs must allocate the same number of resources on each compute node. Slurm/PBS will not enforce this constraint by default. It is, therefore, recommended that you include a slots_per_node in your experiment configuration to ensure that Slurm/PBS provides a consistent allocation on each node. Your slots_per_trial configuration should then be a multiple of slots_per_node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Additional Known issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#additional-known-issues",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Additional Known issues",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#additional-known-issues",
    "content": "The Determined master may fail to show HPC cluster information and report Failed to communicate with launcher due to error: in the Master Logs tab of the Determined UI. If so, verify the following: Ensure that the launcher service is up and running. sudo systemctl status launcher If the full error is Failed to communicate with launcher due to error: {401 Unauthorized}, the Determined master does not have an up-to-date authorization token to access the launcher. Restart the launcher, to ensure all configuration changes have been applied. sudo systemctl restart launcher sudo systemctl status launcher Once it has successfully started, you should see the message INFO: launcher server ready ..., then restart the Determined master so it will likewise load the latest configuration: sudo systemctl restart determined-master sudo systemctl status determined-master Additional diagnostic messages may be present in the system log diagnostics, such as /var/log/messages or journalctl --since=yesterday -u launcher, and journalctl --since=yesterday -u determined-master The SSH server process within Determined Environment images can fail with a free(): double free detected in tcache 2 message, a Fatal error: glibc detected an invalid stdio handle message, or simply close the connection with no message. This problem has been observed when using the det shell start command and when running distributed, multi-node, training jobs. It is suspected to be triggered by passwd/group configurations that use NIS/YP/LDAP accounts on the compute host. By default these settings are propagated to the Singularity container and can result in sshd aborting the connection with or without an error message, depending on the exact configuration. A workaround is to specify a customized nsswitch.conf file to the Singularity container and enable only files for passwd/group elements. This can be accomplished using the following steps: Create a file on a shared file system such as /home/shared/determined/nsswitch.conf file with the content, potentially further tuned for your environment: passwd: files determined shadow: files determined group: files determined hosts: files dns Update the Determined cluster configuration to supply a default bind mount to override the /etc/nsswitch.conf in the container. task_container_defaults: bind_mounts: - host_path: /home/shared/determined/nsswitch.conf container_path: /etc/nsswitch.conf Reload the Determined master to allow it to pull in the updated configuration. The user/group configuration is typically injected in /etc/passwd within the Singularity container so disabling the NIS/YP/LDAP accounts within the container should not result in any lost capability. Determined CLI can fail with a Your requested host \"localhost\" could not be resolved by DNS. message. This has been observed when the http_proxy or https_proxy environment variables are set but have not excluded sending localhost, or the Determined master hostname, to the proxy server. Update the environment settings configured for the proxy to also include: export no_proxy=localhost,127.0.0.1 The automated download of Docker containers by Singularity may fail with the error loading registries configuration: reading registries.conf.d: lstat /root/.config/containers/registries.conf.d: permission denied when Docker login information is not provided. This happens when access to an otherwise public container image is being blocked by the Docker Hub download rate limit, or if the container is in a private registry. You can avoid this problem by either: Manually downloading the container image as described in Provide a Container Image Cache. Providing a Docker login via the experiment configuration using the environment.registry_auth.username and environment.registry_auth.password options. Use of NVIDIA Multi-Process Service (MPS) with Determined may trigger the error RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable. By default, MPS depends upon a shared /tmp directory between the compute node and the container to function properly. As noted in Singularity and Docker Differences, sharing /tmp between the compute node and the container is not the default behavior for Determined Slurm integration. When using MPS, use one of the following workarounds: If the capabilities of MPS are not required, disable or uninstall the MPS service. See nvidia-cuda-mps-control or the relevant documentation associated with your installation package. Configure the MPS variable CUDA_MPS_PIPE_DIRECTORY to use a directory other than /tmp (e.g. /dev/shm). Restore the sharing of /tmp between the compute node and the container as described in Singularity and Docker Differences. For more information on MPS, refer to the NVIDIA Multi-Process Service (MPS) Documentation. Experiments on CPU-only clusters will fail when the requested slot count exceeds the maximum number of CPUs on any single node. This behavior is due to a limitation of the Slurm workload manager. Slurm does not provide an option to request a certain number of CPUs without specifying the number of nodes/tasks. To overcome this limitation of Slurm, Determined will set a default value of 1 for the number of nodes. With this workaround, when the users launch an experiment on a CPU-only cluster, Slurm tries to identify a single node that can completely satisfy the requested number of slots (CPUs). If such a node is available, Slurm will allocate the resources and continue the execution of the experiment. Otherwise, Slurm will error stating the resource request could not be satisfied, as shown in the below example. ERROR: task failed without an associated exit code: sbatch: error: CPU count per node can not be satisfied sbatch: error: Batch job submission failed: Requested node configuration is not available. A job may fail with the message resources failed with non-zero exit code, Determined reports the exit code in the experiment logs. For example, the experiment logs contain srun: error: node002: task 0: Exited with exit code 7. The det slot enable and det slot disable commands are not supported. Use of these commands will print an error message. det slot list will not display the name of any active Determined tasks.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Package Verification",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#package-verification",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Known Issues",
      "lvl1": "Known Issues",
      "lvl2": "Package Verification",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-known-issues.html#package-verification",
    "content": "The launcher installation package supports the verification of both RPM and DEB packages. There will be several configuration files that the package manager will identify as modified, and with RPM-based installs, some files will show user/group modifications. For an RPM-based installation, run sudo rpm -V hpe-hpc-launcher which should produce output similar to that shown below: S.5....T. c /etc/launcher/launcher.conf S.5....T. /etc/launcher/suid.conf S.5....T. /etc/sudoers.d/zz_launcher .....U... /opt/launcher/bin/capsules-dev-keytool.jar .....U... /opt/launcher/bin/dev-keytool .....U... /opt/launcher/bin/user-keytool .....U... /opt/launcher/jetty/base/etc/keystore S.5....T. /opt/launcher/jetty/base/resources/dispatcher.properties .....U... /opt/launcher/sbin ......G.. /opt/launcher/sbin/suid INFO: The following file modifications are expected: /etc/launcher/launcher.conf /etc/launcher/suid.conf /etc/sudoers.d/zz_launcher /opt/launcher/jetty/base/resources/dispatcher.properties INFO: The following file owner/group changes are expected: /opt/launcher/bin/capsules-dev-keytool.jar /opt/launcher/bin/dev-keytool /opt/launcher/bin/user-keytool /opt/launcher/sbin /opt/launcher/sbin/suid On Debian distributions, run sudo dpkg -V hpe-hpc-launcher which should produce output similar to that shown below: ??5?????? c /etc/launcher/launcher.conf ??5?????? c /etc/launcher/suid.conf ??5?????? c /etc/sudoers.d/zz_launcher ??5?????? /opt/launcher/jetty/base/resources/dispatcher.properties",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Slurm/PBS",
      "lvl1": "Deploy on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/overview.html#deploy-on-slurm-pbs",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Slurm/PBS",
      "lvl1": "Deploy on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/overview.html#deploy-on-slurm-pbs",
    "content": "Supported Versions Slurm >= 20.02 (excluding 22.05.5 through 22.05.8 - see Slurm Known Issues) PBS >= 2021.1.2 Apptainer >= 1.0 Singularity >= 3.7 or Enroot >= 3.4.0 or Podman >= 3.3.1 Launcher (hpe-hpc-launcher) >= 3.3.8 Java >= 1.8 Slurm/PBS deployment applies to the Enterprise Edition. This document describes how Determined can be configured to utilize HPC cluster scheduling systems via the Determined HPC launcher. In this type of configuration, Determined delegates all job scheduling and prioritization to the HPC workload manager (either Slurm or PBS). This integration enables existing HPC workloads and Determined workloads to coexist and Determined workloads to access all of the advanced capabilities of the HPC workload manager. To install Determined on the HPC cluster, ensure that the Installation Requirements are met, then follow the steps in the Install Determined on Slurm/PBS document.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Slurm/PBS",
      "lvl1": "Deploy on Slurm/PBS",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/overview.html#reference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Slurm/PBS",
      "lvl1": "Deploy on Slurm/PBS",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/overview.html#reference",
    "content": "Determined Installation Requirements Slurm OpenPBS\u00ae PBS Professional\u00ae Singularity Apptainer NVIDIA Enroot Podman",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#agent-on-slurm-pbs",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#agent-on-slurm-pbs",
    "content": "As an alternative to using the HPC Launcher, you may instead utilize the Determined agent. In this usage model, the system administrator creates a custom resource pool for each Determined user. You then start a Determined agent on one or more compute nodes of the cluster using Slurm or PBS commands to provide the resources for your resource pool. As work is submitted to this resource pool, it is distributed to the set of available agents. If your Slurm/PBS job is terminated (for example due to a time limit) before your Determined work is completed, your Determined work remains in your resource pool until additional agents are started. You may add additional resources to your resource pool by starting additional agents on your cluster. If your Determined work is complete before any time limits are hit on the Slurm/PBS job providing resources, you terminate the agent jobs manually using Slurm/PBS commands. The primary advantages of this model are: You have dedicated access to the compute resources provided by the agents you start for the duration of your HPC job. This can provide more predictable throughput as it avoids contention in a highly utilized cluster. Your Determined experiments are seen by the workload manager as a single large job, rather than many smaller jobs. In some HPC environments, larger jobs are given preference in workload manager scheduling. If you have jobs of different sizes sharing the same set of resources, you reduce the potential for fragmentation where larger jobs may be delayed in running because the free resources are distributed across many nodes. It eliminates the need for user impersonation, which the HPC Launcher uses to submit jobs to the Slurm or PBS workload manager on your behalf, using a sudo configuration. There are several disadvantages to this model as well: You must interact with Slurm or PBS directly to submit and terminate jobs. Using the HPC launcher provides a more seamless user experience that focuses solely on interacting with Determined commands and interfaces. Overall system utilization will likely be less. Direct human control over resource allocation and release introduces inefficiency. If you fail to keep sufficient work queued up in your resource pool or fail to terminate the Determined agents when you are through, you prevent other users from accessing those resources.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Install the Determined Master and Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#install-the-determined-master-and-agent",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Install the Determined Master and Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#install-the-determined-master-and-agent",
    "content": "Before users can make use of Determined agents, a system administrator must provide the following: The system administrator installs the on-premise Determined master component, as described in Install Determined Using Linux Packages, and the Determined agent on all nodes of the cluster, but does not enable or start the determined-agent.service. The system administrator creates a custom resource pool in the resource_pools configuration for each Determined user in the master.yaml. A fragment for creating custom resource pools for user and user2 using the default settings is as follows: resource_pools: - pool_name: user1 - pool_name: user2 It is recommended that RBAC be used to limit access to the intended user of each of these resource pools.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Create a per-user Agent Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#create-a-per-user-agent-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Create a per-user Agent Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#create-a-per-user-agent-configuration",
    "content": "This step may be completed either by the system administrator or the intended user. In a cluster-wide shared directory (examples in this section use $HOME), create an agent.yaml file. Below is a minimal example using a resource pool named for the user ($USER) and singularity as the container runtime platform. If configured using variables such as $HOME, a single agent.yaml could be shared by all users. master_host: master.mycluster.com master_port: 8090 resource_pool: $USER container_runtime: singularity There are several other settings commonly configured in the agent.yaml which are listed in the table below. For the full list of options, see Agent Configuration Reference. Option Description image_root To avoid multiple image downloads, configure an image cache as per Configuring an Apptainer/Singularity Image Cache Directory container_runtime Instead of singularity, you could specify podman as the container runtime. security Secure the communications between the master and agent using TLS. Configure the sections of the security block as per Transport Layer Security.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Start Per-User Agents to Provide Compute Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#start-per-user-agents-to-provide-compute-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Start Per-User Agents to Provide Compute Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#start-per-user-agents-to-provide-compute-resources",
    "content": "The user may then start one or more agents to provide resources to their resource pool using the agent.yaml configured above. In the command examples below, it is assumed that the agent.yaml for a given user is provided in $HOME`. Paths may need to be updated depending on your local configuration. On Slurm, you can allocate resources with the srun or sbatch commands with the desired resource configuration options. srun --gpus=8 /usr/bin/determined-agent --config-file $HOME/agent.yaml or sbatch -N4 --gpus-per-node=tesla:4 --wrap=\"srun /usr/bin/determined-agent --config-file $HOME/agent.yaml\" On PBS, you can launch the agent on multiple nodes with the qsub command. qsub -l select=2:ngpus=4 -- /opt/pbs/bin/pbsdsh -- /usr/bin/determined-agent --config-file $HOME/agent.yaml You can add incremental resources to your resource pool, by submitting an additional job and starting additional agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Launch Jobs and Experiments on the Resource Pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#launch-jobs-and-experiments-on-the-resource-pool",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Launch Jobs and Experiments on the Resource Pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#launch-jobs-and-experiments-on-the-resource-pool",
    "content": "You can then submit experiments or other tasks to the agents you have started by selecting the proper resource pool. The resource pool to be used can be specified on the command line or via the experiment config using the resources.resource_pool setting. det command run --config resources.resource_pool=$USER hostname",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Release the Cluster Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#release-the-cluster-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent on Slurm/PBS",
      "lvl1": "Agent on Slurm/PBS",
      "lvl2": "Release the Cluster Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-with-agent.html#release-the-cluster-resources",
    "content": "When your jobs and experiments have been completed, be sure to release the resources by canceling your Slurm/PBS job.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launching-architecture",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launching-architecture",
    "content": "When configured to perform training on an HPC cluster (cluster configuration resource_manager.type: slurm/pbs), Determined delegates all job scheduling and prioritization to the HPC workload manager (either Slurm or PBS) and does not utilize any Determined agents. Instead, Determined interfaces with the workload managers through the Determined HPC launcher component.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launcher",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launcher",
    "content": "The launcher is a passive server component that translates and forwards Determined master requests to an HPC cluster with a Slurm or PBS workload manager. While it is generally co-located with the Determined master and hosted on an HPC cluster login or admin node, that is not a hard requirement. The launcher interacts with the HPC cluster solely via the Slurm/PBS command line interface and by generated batch scripts and jobs logs on the shared file system. Therefore, it can be hosted on any system that meets these requirements.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": "HPC Launcher Feature Summary",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launcher-feature-summary",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": "HPC Launcher Feature Summary",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#hpc-launcher-feature-summary",
    "content": "Secure, private internal REST interface for use by Determined master. High-level abstraction to enable Determined to manage Slurm/PBS jobs. Generates the batch script and ancillary files to enable job submission (sbatch, qsub). User impersonation via a setuid program to enable the configured Determined user agent to submit jobs to the cluster. Existing OS and workload manager permissions and resource enforcement are maintained. Launcher need not be configured to run as the root user. Job submission and launch failure logs. On-demand job status query (sinfo, squery, pbsnodes, qstat). Job cancellation (scancel, qdel). Support for various workload managers (Slurm/PBS) and container runtimes (Apptainer/Singularity/Podman/Enroot). Image caching model for Apptainer/Singularity. Minimal state stored solely on the file system.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": "Job Management Overview",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#job-management-overview",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "HPC Launcher",
      "lvl3": "Job Management Overview",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#job-management-overview",
    "content": "Temporary files (generated batch files, model Python code, startup-hook.sh, etc.), per-rank local directories in each container (/tmp, /run/determined/workdir, etc.), and job log files are all stored under the cluster-wide directory specified via resource_manager.job_storage_root. The lifetime of these files is limited to that of the submitted job, and are removed when job failure or completion is detected by Determined. Determined submits a job to the launcher. A directory tree is created by the launcher for the job. Files provided by Determined are staged. A batch script is generated to describe the required resource request (see Job Resource Scheduling) from the workload manager and context (environment variables, and container launch commands). The ownership of the files is transferred to the launching user (sudo chown). The batch script is submitted for execution on behalf of the user (sudo sbatch, sudo qsub). See HPC Launcher Security Considerations for the details of how sudo is configured and used with the launcher. Upon being scheduled by the workload manager, the batch script is executed and tasks are launched on the allocated compute nodes. One Determined environment image is started per node (srun, pbs_tmrsh) using the specified container runtime (Apptainer, Singularity, Podman, Enroot). During container initialization, per-rank local directories are configured using soft links (/tmp, /run/determined), and the container stdout/stderr starts streaming output directly to the Determined master. For distributed training, horovodrun is invoked within the container to distribute work within multiple processes across the containers. Once started, the job ID from the workload manager is displayed in the experiment log. Determined polls the launcher for job status waiting for completion. Determined sends a request to the launcher to clean up the job. File ownership is transferred back to the launcher (sudo chown) which then deletes all temporary files and logs associated with the job.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#job-resource-scheduling",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#job-resource-scheduling",
    "content": "As mentioned previously, when using the HPC launcher, Determined delegates all job scheduling and prioritization to the HPC workload manager (Slurm/PBS). Resource requests are generated into the submitted batch file derived from the following configuration attributes described in the following sections.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Cluster Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#cluster-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Cluster Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#cluster-configuration",
    "content": "The resource_manager section of the cluster configuration contributes the following resource scheduling configuration. See the slurm/pbs section of the cluster configuration reference for the full list of configuration options. slot_type: The default slot type (cuda, rocm, cpu) when users request resources from Determined in terms of slots_per_trial. May be overridden per partition/resource pool. tres_supported: Indicates if SelectType=select/cons_tres is set in the Slurm configuration. gres_supported: For Slurm, it indicates that GresTypes=gpu is set in the Slurm configuration, and nodes with GPUs have properly configured GRES indicating the presence of any GPUs. T For PBS, the ngpus resource can be used to identify the number of GPUs available on a node. default_aux_resource_pool: The default resource pool to use for tasks that do not need dedicated compute resources, auxiliary, or systems tasks. Defaults to the Slurm/PBS default partition if no resource pool is specified. default_compute_resource_pool: The default resource pool to use for tasks that require compute resources, e.g. GPUs or dedicated CPUs. Defaults to the Slurm/PBS default partition if it has GPU resources and if no resource pool is specified. job_project_source: Identifies the source to be used when generating a Slurm Workload Characterization Key (WCKey), or PBS project name.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Experiment Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#experiment-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Experiment Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#experiment-configuration",
    "content": "The experiment contributes the following resource scheduling configuration. See the Experiment Configuration Reference for the full details for these configuration options. resource_pool: Identifies the queue/partition to be used. slots_per_trial: The number of slots to use for each trial of this experiment. slurm: sbatch_args: Array of Slurm options added as #SBATCH options in the generated batch script. slots_per_node: The minimum number of slots required for a node to be scheduled during a trial. gpu_type: The Slurm gres type of the GPU to be injected into any generated --gpus/\u2013gres expressions. By default, no type is specified. pbs: pbsbatch_args: Array of PBS options added as #PBS options in the generated batch script. slots_per_node: The minimum number of slots required for a node to be scheduled during a trial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-scheduling",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-scheduling",
    "content": "All information is passed to Slurm through options in the generated sbatch file. You may identify the location of the generated sbatch file and logs using the Slurm command scontrol show job, and then inspect the content any time prior to job completion. These temporary files are removed upon job termination. On job startup failures a portion of the error log is added to the experiment log to assist in diagnosing the problem.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Common Slurm Options",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#common-slurm-options",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Common Slurm Options",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#common-slurm-options",
    "content": "The following options are generated by Determined and cannot be directly specified by the user. Additional options specified by slurm.sbatch_args will be added to the generated batch file provided that they do not conflict with Determined-controlled settings. Option Description --error --output Captures error/output logs. On job startup failure, a portion of the error log is added to the experiment log to assist in diagnosing the problem. During normal operation, logs are piped directly to the Determined master and these files are not used. --job-name Generated job name of the form det-ai_ followed by the Determined job type (exp, cmd, gc) then an internal HPC launcher unique job id. --partition Partition name as determined by the selected resource pool. --wckey A value identified by the resource_manager.job_project_source configuration. --no-requeue Disable any potential automatic requeue of the job by SLURM. Determined will handle the checkpoint and restart for its experiments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Slurm Resource Calculations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-resource-calculations",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Slurm Resource Calculations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-resource-calculations",
    "content": "Resource requirements for Slurm jobs submitted by Determined are generated according to the table below. You can specify a --gres expression via slurm.sbatch_args as long as it does not reference a GPU resource. All other --gres options from the slurm.sbatch_args will be generated into the generated batch script. Slot Type Tres 1 Gres 2 Resulting Slurm Options Description cuda rocm true true --gpus= [gpu_type:] slots_per_trial --nodes= 1 - slots_per_trial --tasks-per-node= 1 --gpus-per-task= [gpu_type:] slots_per_node Slurm determines the number of nodes necessary to allocate the requested GPUs. One container is started per node. Multiple GPUs will be allocated per node when available. If slots_per_node is specified, it is added as --gpus_per_task to ensure each node has at least the specified number of GPUs. cuda rocm false true --nodes= slots_per_trial/slots_per_node --ntasks= slots_per_trial/slots_per_node --gres=gpu [:gpu_type]:slots_per_node Allocates the calculated slots_per_trial / slots_per_node nodes, and slots_per_node GPUs per node and starts one container per node. cpu n/a n/a --nodes= slots_per_trial/slots_per_node --ntasks= slots_per_trial/slots_per_node --cpus-per-task= slots_per_node Allocates the calculated slots_per_trial / slots_per_node nodes, and slots_per_node CPUs per node and starts one container per node. If specified, slots_per_node is add as --cpus_per_task to ensure we get nodes with the desired number of CPUs per node. cuda rocm false false --nodes= slots_per_trial/slots_per_node --ntasks= slots_per_trial/slots_per_node Allocates the calculated slots_per_trial / slots_per_node nodes, and slots_per_node GPUs per node and starts one container per node. It is the user\u2019s responsibility to ensure that slots_per_node GPUs will be available on the nodes selected for the job using other configurations such as targeting a specific resource pool with only slots_per_node GPU nodes or specifying a Slurm constraint in the experiment configuration. 1 The tres_supported option of the cluster configuration resource_manager.type: slurm. 2 The gres_supported option of the cluster configuration resource_manager.type: slurm.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Slurm Task Distribution",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-task-distribution",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "Slurm Scheduling",
      "lvl4": "Slurm Task Distribution",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#slurm-task-distribution",
    "content": "Distribution of tasks among the nodes allocated by Slurm is accomplished using the Slurm srun command within the generated sbatch file (no special options are required). Environment variables from the experiment configuration and all variables needed by Determined are exported from the generated sbatch file. For those container platforms that do not inherit environment variables by default, each variable is explicitly passed to the container via command line arguments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-scheduling",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-scheduling",
    "content": "All information is passed to PBS through options in the generated PBS batch file. You may identify the location of the generated PBS batch file and logs using the command qstat -f, and then inspect the content any time prior to job completion. These temporary files are removed upon job termination. On job startup failure, a portion of the error log is added to the experiment log to assist in diagnosing the problem.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "Common PBS Options",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#common-pbs-options",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "Common PBS Options",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#common-pbs-options",
    "content": "The following options are generated by Determined and cannot be directly specified by the user. Additional options specified by pbs.pbsbatch_args will be added to the generated batch file provided that they do not conflict with Determined-controlled settings. Option Description -N Generated job name of the form det-ai_ followed by the Determined job type (exp_#_trial, cmd, or gc) then an internal HPC launcher unique job identifier. Example: det-ai_exp-2-trial-2-f53889084a0b4510-b19cc33ba8a50203 -q Queue name as determined by the selected resource pool. -e -o Captures error/output logs. On job startup failures a portion of the error log is added to the experiment log to assist in diagnosing the problem. During normal operation, logs are piped directly to the Determined master and these files are not used. --V Inherit environment variables. -r n No automatic restart of the job. Allow Determined to handle restarts. -W umask=0022 Allows the HPC launcher to read the error/output logs. -P A value identified by the resource_manager.job_project_source configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "PBS Resource Calculations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-resource-calculations",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "PBS Resource Calculations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-resource-calculations",
    "content": "Resource requirements for PBS jobs submitted by Determined are generated according to the table below. You can specify a -l select expression via pbs.pbsbatch_args, however chunk count, chunk arrangement, and GPU or CPU counts per chunk (depending on the value of slot_type) are controlled by Determined; any values specified for these quantities will be ignored. All other resource requests from the pbs.pbsbatch_args will be appended to the select expression generated into the generated batch script. Slot Type Gres 3 Resulting PBS Options Description cuda rocm true #PBS -l select= slots_per_trial / slots_per_node :ngpus= slots_per_node The calculated slots_per_trial/slots_per_node GPUs are allocated, One container is started per node (manually implemented via the generated PBS batch script). Multiple nodes are used when needed. If slots_per_node is not specified, 1 is used in the calculation. cuda rocm false #PBS -l select= slots_per_trial / slots_per_node The calculated slots_per_trial/slots_per_node GPUs are allocated. It is the user\u2019s responsibility to ensure that``slots_per_node`` GPUs will be available on nodes selected for the job using other configurations such as targeting a specific resource pool with only slots_per_node GPU nodes, or specifying a PBS PBS resource request in the experiment configuration. It is up to the user to set the CUDA_VISIBLE_DEVICES environment variable in their experiment. cpu n/a #PBS -l select= slots_per_trial / slots_per_node :ncpus= slots_per_node Allocates the calculated slots_per_trial/slots_per_node nodes, and slots_per_node CPUs per node. If slots_per_node is not specified, 1 is used in the calculation. 3 The gres_supported option of the cluster configuration resource_manager.type: pbs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "PBS Task Distribution",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-task-distribution",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launching Architecture",
      "lvl1": "HPC Launching Architecture",
      "lvl2": "Job Resource Scheduling",
      "lvl3": "PBS Scheduling",
      "lvl4": "PBS Task Distribution",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-launching-architecture.html#pbs-task-distribution",
    "content": "The distribution of tasks among the nodes allocated by PBS is accomplished by custom support in the generated batch file. For each unique host in the $PBS_NODEFILE, an asynchronous pbs_tmrsh command invocation is generated to launch the task on the node to launch the specified container and arguments. The batch script waits for the completion of those processes before exiting. A non-zero status return from any of those invocations causes the entire job to be terminated. Environment variables from the experiment configuration and all variables needed by Determined are explicitly passed to the container as arguments as there is no environment variable inheritance from the PBS batch script to the containers on the nodes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#provide-a-container-image-cache",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#provide-a-container-image-cache",
    "content": "When the cluster does not have Internet access or if you want to provide a local cache of container images to improve performance, you can download the desired container images to a shared directory and then reference them using file system paths instead of Docker registry references. There are two mechanisms you can use to reference cached container images depending upon the container runtime in use. Referencing Local Image Paths Configuring an Apptainer/Singularity Image Cache Directory Managing the Singularity Image Cache using the manage-singularity-cache script Managing the Enroot Image Cache using the manage-enroot-cache script",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Default Docker Images",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#default-docker-images",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Default Docker Images",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#default-docker-images",
    "content": "Each version of Determined utilizes specifically-tagged Docker containers. The image tags referenced by default in this version of Determined are described below. Environment File Name CPUs determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-2b7e2a1 NVIDIA GPUs determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-2b7e2a1 AMD GPUs determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-2b7e2a1 See Set Environment Images for the images Docker Hub location, and add each tagged image needed by your experiments to the image cache.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Referencing Local Image Paths",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#referencing-local-image-paths",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Referencing Local Image Paths",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#referencing-local-image-paths",
    "content": "Singularity and Podman each support various local container file formats and reference them using a slightly different syntax. Utilize a cached image by referencing a local path using the experiment configuration environment.image. When using this strategy, the local directory needs to be accessible on all compute nodes. When using Podman, you could save images in OCI archive format to files in a local directory /shared/containers podman save determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-096d730 \\ --format=oci-archive \\ -o /shared/containers/cuda-11.3-pytorch-1.10-tf-2.8-gpu and then reference the image in your experiment configuration using the syntax below. environment: image: oci-archive:/shared/containers/cuda-11.3-pytorch-1.10-tf-2.8-gpu When using Singularity, you could save SIF files in a local directory /shared/containers singularity pull /shared/containers/cuda-11.3-pytorch-1.10-tf-2.8-gpu \\ determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-096d730 and then reference in your experiment configuration using a full path using the syntax below. environment: image: /shared/containers/cuda-11.3-pytorch-1.10-tf-2.8-gpu.sif Set these image file references above as the default for all jobs by specifying them in the task_container_defaults section of the /etc/determined/master.yaml file. Note: If you specify an image using task_container_defaults, you prevent new environment container image versions from being adopted on each update of Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Configuring an Apptainer/Singularity Image Cache Directory",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#configuring-an-apptainer-singularity-image-cache-directory",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Configuring an Apptainer/Singularity Image Cache Directory",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#configuring-an-apptainer-singularity-image-cache-directory",
    "content": "When using Apptainer/Singularity, you may use Referencing Local Image Paths as described above, or you may instead configure a directory tree of images to be searched. To utilize this capability, configure a shared directory in resource_manager.singularity_image_root. The shared directory needs to be accessible to the launcher and on all compute nodes. Whenever an image is referenced, it is translated to a local file path as described in environment.image. If found, the local path is substituted in the singularity run command to avoid the need for Singularity to download and convert the image for each user. You can manually manage the content of this directory tree, or you may use the manage-singularity-cache script which automates those same steps. To manually populate the cache, add each tagged image required by your environment and the needs of your experiments to the image cache using the following steps: Create a directory path using the same prefix as the image name referenced in the singularity_image_root directory. For example, the image determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-096d730 is added in the directory determinedai. cd $singularity_image_root mkdir determinedai If your system has internet access, you can download images directly into the cache. cd $singularity_image_root image=\"determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-096d730\" singularity pull $image docker://$image Otherwise, from an internet-connected system, download the desired image using the Singularity pull command then copy it to the determinedai folder under singularity_image_root. singularity pull \\ temporary-image \\ docker://$image scp temporary-image mycluster:$singularity_image_root/$image",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Managing the Singularity Image Cache using the manage-singularity-cache script",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#managing-the-singularity-image-cache-using-the-manage-singularity-cache-script",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Managing the Singularity Image Cache using the manage-singularity-cache script",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#managing-the-singularity-image-cache-using-the-manage-singularity-cache-script",
    "content": "A convenience script, /usr/bin/manage-singularity-cache, is provided by the HPC launcher installation to simplify the management of the Singularity image cache. The script simplifies the management of the Singularity image cache directory content and helps ensure proper name, placement, and permissions of content added to the cache. Adding container images to the Singularity image cache avoids the overhead of downloading the images and allows for sharing of images between multiple users. It provides the following features: Download the Determined default cuda, cpu, or rocm environment images Download an arbitrary Docker image reference Copy a local Singularity image file into the cache List the currently available images in the cache If your system has internet access, you can download images directly into the cache. Use the --cuda, --cpu, or --rocm options to download the current default CUDA, CPU, or ROCM environment container image into the cache. For example, to download the default CUDA container image, use the following command: manage-singularity-cache --cuda If your system has internet access, you can download any desired Docker container image (e.g. determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-096d730) into the cache using the command: manage-singularity-cache determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-096d730 Otherwise, from an internet-connected system, download the desired image using the Singularity pull command, then copy it to a system with access to the singularity_image_root folder. You can then add the image to the cache by specifying the local file name using -i and the Docker image reference which determines the name to be added to the cache. manage-singularity-cache -i localfile.sif determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-096d730 You can view the current set of Docker image names in the cache with the -l option. manage-singularity-cache -l determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-096d730 determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-096d730",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Managing the Enroot Image Cache using the manage-enroot-cache script",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#managing-the-enroot-image-cache-using-the-manage-enroot-cache-script",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Provide a Container Image Cache",
      "lvl1": "Provide a Container Image Cache",
      "lvl2": "Managing the Enroot Image Cache using the manage-enroot-cache script",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/singularity.html#managing-the-enroot-image-cache-using-the-manage-enroot-cache-script",
    "content": "This script, /usr/bin/manage-enroot-cache, simplifies the management of a set of shared Enroot .sqsh file downloads and then creates an Enroot container for use by the current user. It provides the following features: Download the Determined default cuda, cpu, or rocm environment images Download an arbitrary Docker image reference Share a directory of re-usable imported .sqsh files Optionally, create a per-user container from a shared .sqsh file List the currently available images in the shared .sqsh file cache When using manage-enroot-cache you must provide a temporary directory via the -s option which is used to download (enroot import) the associated enroot .sqsh file. The .sqsh file is read by the enroot create command to generate the container. The directory need only be accessible on the local host. If the directory you specify is shared with other users, the script will re-use any downloaded .sqsh files and directly enroot create an enroot container without needing a separate download. Download the shared cache .sqsh file for the current default Determined CUDA and CPU images (enroot import), and then create the associated containers from them for the current user (enroot create) use the following command: manage-enroot-cache -s /shared/enroot --cuda --cpu Download the shared cache .sqsh file for an arbitrary docker image (enroot import), and then create a container from it for the current user (enroot create) use the following command: manage-enroot-cache -s /shared/enroot determinedai/environments:cuda-10.2-base-gpu-mpi-0.19.4 If you only want the sharable .sqsh file without the overhead of container creation, use the --nocreate option: manage-enroot-cache -s /shared/enroot --nocreate determinedai/environments:cuda-10.2-base-gpu-mpi-0.19.4 To optionally configure credentials for image downloads, follow the enroot documentation. Specify the user name with the --username option: manage-enroot-cache -s /shared/enroot --username <username-here> --cuda --cpu --username is positional \u2013 if used it should appear before any image reference. You can view the current set of Docker image names in the cache with the -l option. manage-enroot-cache -s /shared/enroot -l",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#install-determined-on-slurm-pbs",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#install-determined-on-slurm-pbs",
    "content": "This document describes how to deploy Determined on an HPC cluster managed by the Slurm or PBS workload managers. Store your installation commands and flags in a shell script for future use, particularly for upgrading. The Determined master and launcher installation packages are configured for installation on a single login or administrator Slurm/PBS cluster node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": "Install Determined Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#install-determined-master",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": "Install Determined Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#install-determined-master",
    "content": "After the node has been selected and the Installation Requirements have been fulfilled and configured, install and configure the Determined master: Install the on-premises Determined master component (not including the Determined agent) as described in Install Determined Using Linux Packages. Perform the installation and configuration steps, but stop before starting the determined-master service, and continue with the steps below. Install the launcher. For an RPM-based installation, run: sudo rpm -ivh hpe-hpc-launcher-<version>.rpm On Debian distributions, instead run: sudo apt install ./hpe-hpc-launcher-<version>.deb The installation configures and enables the systemd launcher service, which provides HPC management capabilities. If launcher dependencies are not satisfied, warning messages are displayed. Install or update missing dependencies or adjust the path and ld_library_path in the next step to locate the dependencies. You may verify the installation integrity using the appropriate package manager command. See Package Verification.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": "Configure and Verify Determined Master on HPC Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#configure-and-verify-determined-master-on-hpc-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Slurm/PBS",
      "lvl1": "Install Determined on Slurm/PBS",
      "lvl2": "Configure and Verify Determined Master on HPC Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/install-on-slurm.html#configure-and-verify-determined-master-on-hpc-cluster",
    "content": "The launcher automatically adds a prototype resource_manager section for Slurm/PBS if not already present upon startup of the launcher service. Edit the provided resource_manager configuration section for your particular deployment. For Linux package-based installations, the configuration file is typically the /etc/determined/master.yaml file. In this example, with Determined and the launcher colocated on a node named login, the section might resemble: port: 8080 ... resource_manager: type: slurm master_host: login master_port: 8080 host: localhost port: 8181 protocol: http container_run_type: singularity auth_file: /root/.launcher.token job_storage_root: path: ld_library_path: tres_supported: true slot_type: cuda The installer provides default values, however, you should explicitly configure the following cluster options: Option Description type The cluster workload manager (slurm or pbs). master_host The host name of the Determined master. This is the name the compute nodes will utilize to communicate with the Determined master. port Communication port used by the launcher. Update this value if there are conflicts with other services on your cluster. job_storage_root Shared directory where job-related temporary files are stored. The directory must be visible to the launcher and from the compute nodes. If user_name is configured as a user account other than root, then the default value is $HOME/.launcher. container_run_type The container type to be launched on Slurm (apptainer, singularity, enroot, or podman). The default is singularity. Specify singularity when using Apptainer. apptainer_image_root singularity_image_root Shared directory on all compute nodes where Apptainer/Singularity images are hosted. Unused unless container_run_type is singularity. See Provide a Container Image Cache for details on how this option is used. user_name and group_name By default, the launcher runs from the root account. Create a local account and group and update these values to enable running from another account. This account must have access to the Slurm/PBS command line to discover partitions and summarize cluster usage. See HPC Launcher Security Considerations. path If any of the launcher dependencies are not on the default path, you can override the default by updating this value. gres_supported Indicates that Slurm/PBS identifies available GPUs. The default is true. See Slurm Requirements or PBS Requirements for details. See the slurm/pbs section of the cluster configuration reference for the full list of configuration options. After changing values in the resource_manager section of the /etc/determined/master.yaml file, restart the launcher service: sudo systemctl restart launcher Verify successful launcher startup using the systemctl status launcher command. If the launcher fails to start, check system log diagnostics, such as /var/log/messages or journalctl --since=\"10 minutes ago\" -u launcher, make the needed changes to the /etc/determined/master.yaml file, and restart the launcher. If the installer reported incorrect dependencies, verify that they have been resolved by changes to the path and ld_library_path in the previous step: sudo /etc/launcher/scripts/check-dependencies.sh Reload the Determined master to get the updated configuration: sudo systemctl restart determined-master Verify successful determined-master startup using the systemctl status determined-master command. If the launcher fails to start, check system log diagnostics, such as /var/log/messages or journalctl --since=\"10 minutes ago\" -u determined-master, make the needed changes to the /etc/determined/master.yaml file, and restart the determined-master. If the compute nodes of your cluster do not have internet connectivity to download Docker images, see Provide a Container Image Cache. If internet connectivity requires use of a proxy, make sure the proxy variables are defined as per Proxy Configuration Requirements. Log into Determined, see User Accounts. The Determined user must be linked to a user on the HPC cluster. If signed in with a Determined administrator account, the following example creates a Determined user account that is linked to the current user\u2019s Linux account. det user create $USER det user link-with-agent-user --agent-uid $(id -u) --agent-gid $(id -g) --agent-user $USER --agent-group $(id -gn) $USER det user login $USER If an agent user has not been configured for a Determined username, jobs will run as user root. For more details see Run Tasks as Specific Agent Users. Verify the configuration by sanity-checking your Determined configuration: det command run hostname A successful configuration reports the hostname of the compute node selected by Slurm to run the job. Run a simple distributed training job such as the PyTorch MNIST Tutorial to verify that it completes successfully. This validates Determined master and launcher communication, access to the shared filesystem, GPU scheduling, and highspeed interconnect configuration. For more complete validation, ensure that the slots_per_trial is at least twice the number of GPUs available on a single node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launcher Security Considerations",
      "lvl1": "HPC Launcher Security Considerations",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-security-considerations.html#hpc-launcher-security-considerations",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launcher Security Considerations",
      "lvl1": "HPC Launcher Security Considerations",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-security-considerations.html#hpc-launcher-security-considerations",
    "content": "User authentication in Determined is enforced using User Accounts. Determined sends requests on behalf of those authenticated users to the HPC launcher which then interacts with the underlying workload manager to submit and control jobs via the user agent configured for the user account. A Determined administrator must configure a Determined user\u2019s agent to enable them to launch Slurm/PBS jobs. Several security issues should be considered when deploying the launcher: The specified resource_manager.user_name should be a unique, non-privileged user with authorization to interact with the deployed workload manager (Slurm/PBS). The launcher executes as a service using the configured resource_manager.user_name and resource_manager.group_name as specified in the slurm/pbs section of the cluster configuration. The launcher can also be run as the root user but with the corresponding reduction in security isolation. The launcher installs the necessary sudoers(5) configuration with the file /etc/sudoers.d/zz_launcher to enable the specified resource_manager.user_name to perform the following actions: Change the ownership of a directory tree to another user (from resource_manager.user_name to the Determined user before the job starts, and from the Determined user back to the resource_manager.user_name after completion). Enable the execution Slurm/PBS commands on behalf of the Determined user to submit and control their jobs. The set of users sudo authorizes for Slurm/PBS launch is controlled by resource_manager.sudo_authorized. The default value is ALL. The configuration of users always includes the !root to prevent privilege elevation. The launcher installs the necessary sudoers(5) configuration to enable all users to generate a token for read-only interaction with the launcher REST API. This capability is intended for use when other components integrate with the launcher.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launcher Security Considerations",
      "lvl1": "HPC Launcher Security Considerations",
      "lvl2": "Configuration of sudo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-security-considerations.html#configuration-of-sudo",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "HPC Launcher Security Considerations",
      "lvl1": "HPC Launcher Security Considerations",
      "lvl2": "Configuration of sudo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/hpc-security-considerations.html#configuration-of-sudo",
    "content": "The sudo configuration necessary to enable the launcher to perform Slurm/PBS job management on behalf of the requesting Determined user is automatically generated and applied during the startup of the launcher service as specified in the slurm/pbs section of the cluster configuration. Configuration is added to the sudo configuration by the file /etc/sudoers.d/zz_launcher. The configuration is dervied from the following values: The authorized user is configured as resource_manager.user_name (shown below as launcher). The run-as user list is configured to authorize resource_manager.sudo_authorized (shown below as the default value of ALL). A comma-separated list of user/group specifications identifying users for which the launcher can submit/control Slurm/PBS jobs using sudo. The specification !root is automatically appended to this list to prevent privilege elevation. This may be a list of users or groups with exclusions (e.g. %slurmusers,localadmin,!guest ). See the sudoers(5) definition of Runas_List for the full syntax of this value. For Slurm, the authorized commands are the full path to each of the commands sacct, salloc, sbatch, scancel, scontrol, sinfo, squeue, srun. For PBS, the authorized commands are the full path to qsub, qstat, qdel, pbsnodes. The content of a typical /etc/sudoers.d/zz_launcher generated for Slurm is shown below: launcher ALL= (root) NOPASSWD: /bin/chown -R * * launcher ALL= (root) NOPASSWD: /usr/bin/chown -R * * ALL ALL = (root) NOPASSWD: /opt/launcher/bin/user-keytool launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/sacct launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/salloc launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/sbatch launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/scancel launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/scontrol launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/sinfo launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/squeue launcher ALL= (ALL, !root) NOPASSWD:SETENV: /usr/bin/srun As noted above, this file is regenerated during the startup of the launcher service. It should not be edited directly and should be configured using the attributes provided in the slurm/pbs section of the cluster configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Upgrade Determined on Slurm/PBS",
      "lvl1": "Upgrade Determined on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/upgrade-on-hpc.html#upgrade-determined-on-slurm-pbs",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Upgrade Determined on Slurm/PBS",
      "lvl1": "Upgrade Determined on Slurm/PBS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/upgrade-on-hpc.html#upgrade-determined-on-slurm-pbs",
    "content": "This procedure describes how to upgrade Determined on an HPC cluster managed by the Slurm or PBS workload managers. Use this procedure when an earlier version of Determined is installed, configured, and functioning properly. Review the latest Installation Requirements and ensure all dependencies have been met. Upgrade the launcher. For an example RPM-based installation, run: sudo rpm -Uv hpe-hpc-launcher-<version>.rpm On Debian distributions, run: sudo apt install ./hpe-hpc-launcher-<version>.deb The upgrade automatically updates and restarts the systemd launcher service. Upgrade the on-premises Determined master component (not including the Determined agent) as described in the Upgrade document. The upgrade does not automatically update the Determine master service. Reload the systemd configuration and restart the Determine master service with the following commands. sudo systemctl daemon-reload sudo systemctl restart determined-master.service",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#installation-requirements",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Basic Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#basic-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Basic Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#basic-requirements",
    "content": "To deploy the Determined HPC Launcher on Slurm/PBS, the following requirements must be met. The login node, admin node, and compute nodes must be installed and configured with one of the following Linux distributions: Red Hat\u00ae Enterprise Linux (RHEL) or CentOS 7.9 RHEL or Rocky Linux\u00ae 8.5, 8.6 RHEL 9 SUSE\u00ae Linux Enterprise Server (SLES) 12 SP3 , 15 SP3, 15 SP4 Ubuntu\u00ae 20.04, 22.04 Cray OS (COS) 2.3, 2.4 Note: More restrictive Linux distribution dependencies may be required by your choice of Slurm/PBS version and container runtime (Singularity/Apptainer\u00ae, Podman, or NVIDIA\u00ae Enroot). Slurm 20.02 or greater (excluding 22.05.5 through at least 22.05.8 - see Slurm Known Issues) or PBS 2021.1.2 or greater. Apptainer 1.0 or greater, Singularity 3.7 or greater, Enroot 3.4.0 or greater or Podman 3.3.1 or greater. A cluster-wide shared filesystem with consistent path names across the HPC cluster. User and group configuration must be consistent across all nodes. All nodes must be able to resolve the hostnames of all other nodes. To run jobs with GPUs, the NVIDIA or AMD drivers must be installed on each compute node. Determined requires a version greater than or equal to 450.80 of the NVIDIA drivers. The NVIDIA drivers can be installed as part of a CUDA installation but the rest of the CUDA toolkit is not required. Determined supports the active Python versions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Launcher Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#launcher-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Launcher Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#launcher-requirements",
    "content": "The launcher has the following additional requirements on the installation node: Support for an RPM or Debian-based package installer Java 1.8 or greater Sudo is configured to process configuration files present in the /etc/sudoers.d directory Access to the Slurm or PBS command-line interface for the cluster Access to a cluster-wide file system with a consistent path names across the cluster",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Proxy Configuration Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#proxy-configuration-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Proxy Configuration Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#proxy-configuration-requirements",
    "content": "If internet connectivity requires a use of a proxy, verify the following requirements: Ensure that the proxy variables are defined in /etc/environment (or /etc/sysconfig/proxy on SLES). Ensure that the no_proxy setting covers the login and admin nodes. If these nodes may be referenced by short names known only within the cluster, they must explicitly be included in the no_proxy setting. If your experiment code communicates between compute nodes with a protocol that honors proxy environment variables, you should additionally include the names of all compute nodes in the no_proxy variable setting. The HPC launcher imports http_proxy, https_proxy, ftp_proxy, rsync_proxy, gopher_proxy, socks_proxy, socks5_server, and no_proxy from /etc/environment and /etc/sysconfig/proxy. These environment variables are automatically exported in lowercase and uppercase into any launched jobs and containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Slurm Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#slurm-config-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Slurm Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#slurm-config-requirements",
    "content": "Determined should function with your existing Slurm configuration. To optimize how Determined interacts with Slurm, we recommend the following steps: Enable Slurm for GPU Scheduling. Configure Slurm with SelectType=select/cons_tres. This enables Slurm to track GPU allocation instead of tracking only CPUs. When enabled, Determined submits batch jobs by specifying --gpus={slots_per_trial}. If this is not available, you must change the slurm section tres_supported option to false. Configure GPU Generic Resources (GRES). Determined works best when allocating GPUs. Information about what GPUs are available is available using GRES. You can use the AutoDetect feature to configure GPU GRES automatically. Otherwise, you should manually configure GRES GPUs such that Slurm can schedule nodes with the GPUs you want. For the automatic selection of nodes with GPUs, Slurm must be configured for GresTypes=gpu and nodes with GPUs must have properly configured GRES indicating the presence of any GPUs. When enabled, Determined can ensure GPUs are available by specifying --gres=gpus:1. If Slurm GRES cannot be properly configured, specify the slurm section gres_supported option to false, and it is the user\u2019s responsibility to ensure that GPUs will be available on nodes selected for the job using other configurations such as targeting a specific resource pool with only GPU nodes, or specifying a Slurm constraint in the experiment configuration. Ensure homogeneous Slurm partitions. Determined maps Slurm partitions to Determined resource pools. It is recommended that the nodes within a partition be homogeneous for Determined to effectively schedule GPU jobs. A Slurm partition with GPUs is identified as a CUDA/ROCm resource pool. The type is inherited from the resource_manager.slot_type configuration. It can be also be specified-per partition using resource_manager.partition_overrides A Slurm partition with no GPUs is identified as an AUX resource pool. The Determined default resource pool is set to the Slurm default partition. Override this default using the slurm section default_compute_resource_pool or default_aux_resource_pool option. If a Slurm partition is not homogeneous, you may create a resource pool that provides homogenous resources out of that partition using a custom resource pool. Configure a resource pool with provider_type: hpc, specify the underlying Slurm partition name to receive the job and include a task_container_defaults section with the necessary slurm options to select the desired homogenous set of resources from that partition. Ensure the MaxNodes value for each partition is not less than the number of GPUs in the partition. Determined delegates node selection for a job to Slurm by specifying a node range (1-slots_per_trial). If slots_per_trial exceeds the MaxNodes value for the partition, the job will remain in state PENDING with reason code PartitionNodelimit. Make sure that all partitions that have MaxNodes specified use a value larger than the number of GPUs in the partition. Enable multiple jobs per compute node. Determined uses GPU or CPU resource requests to Slurm. When Slurm schedules jobs, however, it also considers the memory requirements of the job. In order to enable multiple jobs to be scheduled on a node concurrently, configuration is required in slurm.conf. The default memory allocated for a job is UNLIMITED. This prevents multiple jobs from executing on the same node unless this value is reduced. The default memory allocation for a job is derived from one of the slurm.conf configuration variables DefMemPerNode, DefMemPerGPU, or DefMemPerCPU. In order to enable individual GPUs/CPUs scheduling by default configure DefMemPerNode (which provides a total amount of memory for each job) or DefMemPerGPU and DefMemPerCPU (which derives the memory allocation from the number of GPU or CPU associated with the job). Configure one or more of these values to reduce the default memory allocation and enable jobs to divide up the available memory on compute nodes. An alternative to changing the default memory configuration via slurm.conf, is to provide explicit options on each job via the Determined configuration (task_container_defaults, resource pool configuration, or experiment configuration slurm.sbatch_args). For details about how those requests are derived, see HPC Launching Architecture. Enable resource separation using cgroups. While Slurm always allocates distinct resources for each job, by default there is no enforced separation when the resources are co-located in the same compute node. Such enforcement can be enabled using cgroups. GPU allocation is communicated to the application via the environment variables CUDA_VISIBLE_DEVICES or ROCR_VISIBLE_DEVICES. Determined uses those specifications to utilize only the GPU resources scheduled by Slurm for the job, but CPU and memory have no enforcement. If desired, you can enable such enforcement with the Slurm cgroups configuration. Enable cgroups support in slurm.conf, then enable enforcement of specific resource classes in cgroup.conf (ConstrainCores for CPU, ConstrainDevices for GPU, and ConstrainRAMSpace for memory). Tune the Slurm configuration for Determined job preemption. Slurm preempts jobs using signals. When a Determined job receives SIGTERM, it begins a checkpoint and graceful shutdown. To prevent unnecessary loss of work, it is recommended to set GraceTime (secs) high enough to permit the job to complete an entire Determined scheduling_unit. To enable GPU job preemption, use PreemptMode=CANCEL or PreemptMode=REQUEUE, because PreemptMode=SUSPEND does not release GPUs so does not allow a higher-priority job to access the allocated GPU resources. Determined manages the requeue of a successfully preempted job so even with PreemptMode=REQUEUE, the Slurm job will be canceled and resubmitted.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "PBS Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#pbs-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "PBS Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#pbs-requirements",
    "content": "Determined should function with your existing PBS configuration. To optimize how Determined interacts with PBS, we recommend the following steps: Enable PBS to store job history. Job completion detection requires that the job history feature be enabled. PBS administrators can employ the following command to set the value of job_history_enable: sudo qmgr -c \"set server job_history_enable = True\" Configure PBS to manage GPU resources. Determined works best when allocating GPUs. By default, Determined selects compute nodes with GPUs using the option -select={slots_per_trial}:ngpus=1. If PBS cannot be configured to identify GPUs in this manner, specify the pbs section gres_supported option to false when configuring Determined, and it will then be the user\u2019s responsibility to ensure that GPUs will be available on nodes selected for the job using other configurations such as targeting a specific resource pool with only GPU nodes, or specifying a PBS constraint in the experiment configuration. PBS should be configured to provide the environment variable CUDA_VISIBLE_DEVICES (ROCR_VISIBLE_DEVICES for ROCm) using a PBS cgroup hook as described in the PBS Administrator\u2019s Guide. If PBS is not configured to set CUDA_VISIBLE_DEVICES, Determined will utilize a single GPU on each node. To fully utilize multiple GPUs, you must either manually define CUDA_VISIBLE_DEVICES appropriately or provide the pbs.slots_per_node setting in your experiment configuration to indicate how many GPU slots are intended for Determined to use. Configure PBS to report GPU Accelerator type. It is recommended that PBS administrators set the value for resources_available.accel_type on each node that contains an accelerator. Otherwise, the Cluster tab on the Determined WebUI will show unconfigured for the Accelerator field in the Resource Pool information. PBS administrators can use the following set of commands to set the value of resources_available.accel_type on a single node: Check if the resources_available.accel_type value is set. pbsnodes -v node001 | grep resources_available.accel_type If required, set the desired value for resources_available.accel_type. sudo qmgr -c \"set node node001 resources_available.accel_type=tesla\" When there are multiple types of GPUs on the node, use a comma-separated value. sudo qmgr -c \"set node node001 resources_available.accel_type=tesla,kepler\" Verify that the resources_available.accel_type value is now set. pbsnodes -v node001 | grep resources_available.accel_type Repeat the above steps to set the resources_available.accel_type value for every node containing GPU. Once the resources_available.accel_type value is set for all the necessary nodes, admins can verify the Accelerator field on the Cluster pane of the WebUI. Ensure homogeneous PBS queues. Determined maps PBS queues to Determined resource pools. It is recommended that the nodes within a queue be homogeneous for Determined to effectively schedule GPU jobs. A PBS queue with GPUs is identified as a CUDA/ROCm resource pool. The type is inherited from the resource_manager.slot_type configuration. It can be also be specified per partition using resource_manager.partition_overrides. A PBS queue with no GPUs is identified as an AUX resource pool. The Determined default resource pool is set to the PBS default queue. Override this default using the pbs section default_compute_resource_pool or default_aux_resource_pool option. If a PBS queue is not homogeneous, you may create a resource pool that provides homogenous resources out of that queue using a custom resource pool. Configure a resource pool with provider_type: hpc, specify the underlying PBS queue name to receive the job and include a task_container_defaults section with the necessary pbs options to select the desired homogenous set of resources from that queue. Tune the PBS configuration for Determined job preemption. PBS supports a wide variety of criteria to trigger job preemption, and you may use any per your system and job requirements. Once a job is identified for preemption, PBS supports four different options for job preemption which are specified via the preemption_order scheduling parameter. The preemption order value is 'SCR'. The preemption methods are specified by the following letters: S - Suspend the job. This is not applicable for GPU jobs. C - Checkpoint the job. This requires a custom checkpoint script is added to PBS. R - Requeue the job. Determined does not support the re-queueing of a task. Determined jobs specify the -r n option to PBS to prevent this case. D - Delete the job. Determined jobs support this option without configuration. Given those options, the simplest path to enable Determined job preemption is by including D in the preemption_order. You may include R in the preemption_order, but it is disabled for Determined jobs. You may include C to the preemption_order if you additionally configure a checkpoint script. Refer to the PBS documentation for details. If you choose to implement a checkpoint script, you may initiate a Determined checkpoint by sending a SIGTERM signal to the Determined job. When a Determined job receives a SIGTERM, it begins a checkpoint and graceful shutdown. To prevent unnecessary loss of work, it is recommended that you wait for at least one Determined scheduling_unit for the job to complete after sending the SIGTERM. If after that period of time the job has not terminated, then send a SIGKILL to forcibly release all resources.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Apptainer/Singularity Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#apptainer-singularity-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Apptainer/Singularity Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#apptainer-singularity-requirements",
    "content": "Apptainer/Singularity is the recommended container runtime for Determined on HPC clusters. Apptainer is a fork of Singularity 3.8 and provides both the apptainer and singularity commands. For purposes of this documentation, you can consider all references to Singularity to also apply to Apptainer. The Determined launcher interacts with Apptainer/Singularity using the singularity command. Singularity has numerous options that may be customized in the singularity.conf file. Determined has been verified using the default values and therefore does not require any special configuration on the compute nodes of the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Podman Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#podman-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Podman Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#podman-requirements",
    "content": "When Determined is configured to use Podman, the containers are launched in rootless mode. Your HPC cluster administrator should have completed most of the configuration for you, but there may be additional per-user configuration that is required. Before attempting to launch Determined jobs, verify that you can run simple Podman containers on a compute node. For example: podman run hello-world If you are unable to do that successfully, then one or more of the following configuration changes may be required in your $HOME/.config/containers/storage.conf file: Podman does not support rootless container storage on distributed file systems (e.g. NFS, Lustre, GPSF). On a typical HPC cluster, user directories are on a distributed file system and the default container storage location of $HOME/.local/share/containers/storage is therefore not supported. If this is the case on your HPC cluster, configure the graphroot option in your storage.conf to specify a local file system available on compute nodes. Alternatively, you can request that your system administrator configure the rootless_storage_path in /etc/containers/storage.conf on all compute nodes. Podman utilizes the directory specified by the environment variable XDG_RUNTIME_DIR. Normally, this is provided by the login process. Slurm and PBS, however, do not provide this variable when launching jobs on compute nodes. When XDG_RUNTIME_DIR is not defined, Podman attempts to create the directory /run/user/$UID for this purpose. If /run/user is not writable by a non-root user, then Podman commands will fail with a permission error. To avoid this problem, configure the runroot option in your storage.conf to a writeable local directory available on all compute nodes. Alternatively, you can request your system administrator to configure the /run/user to be user-writable on all compute nodes. Create or update $HOME/.config/containers/storage.conf as required to resolve the issues above. The example storage.conf file below uses the file system /tmp, but there may be a more appropriate file system on your HPC cluster that you should specify for this purpose. [storage] driver = \"overlay\" graphroot = \"/tmp/$USER/storage\" runroot = \"/tmp/$USER/run\" Any changes to your storage.conf should be applied using the command: podman system migrate",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Enroot Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#enroot-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Installation Requirements",
      "lvl1": "Installation Requirements",
      "lvl2": "Enroot Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/slurm/slurm-requirements.html#enroot-requirements",
    "content": "Install and configure Enroot on all compute nodes of your cluster as per the Enroot Installation instructions for your platform. There may be additional per-user configuration that is required. Enroot utilizes the directory ${ENROOT_RUNTIME_PATH} (with default value ${XDG_RUNTIME_DIR}/enroot) for temporary files. Normally XDG_RUNTIME_DIR is provided by the login process, but Slurm and PBS do not provide this variable when launching jobs on compute nodes. When neither ENROOT_RUNTIME_PATH/XDG_RUNTIME_DIR is defined, Enroot attempts to create the directory /run/enroot for this purpose. This typically fails with a permission error for any non-root user. Select one of the following alternatives to ensure that XDG_RUNTIME_DIR or ENROOT_RUNTIME_PATH is defined and points to a user-writable directory when Slurm/PBS jobs are launched on the cluster. Have your HPC cluster administrator configure Slurm/PBS to provide XDG_RUNTIME_DIR, or change the default ENROOT_RUNTIME_PATH defined in /etc/enroot/enroot.conf on each node in your HPC cluster. If using Slurm, provide an ENROOT_RUNTIME_PATH definition in task_container_defaults.environment_variables in master.yaml. task_container_defaults: environment_variables: - ENROOT_RUNTIME_PATH=/tmp/$(whoami) If using Slurm, provide an ENROOT_RUNTIME_PATH definition in your experiment configuration. Unlike Singularity or Podman, you must manually download the Docker image file to the local file system (enroot import) and then each user must create an Enroot container using that image (enroot create). When the HPC launcher generates the enroot command for a job, it automatically applies the same transformation to the name that Enroot does on import (/ and : characters are replaced with +) to enable Docker image references to match the associated Enroot container. The following shell commands will download and then create an Enroot container for the current user. If other users have read access to /shared/enroot/images, they need only perform the enroot create step to make the container available for their use. image=determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-2b7e2a1 cd /shared/enroot/images enroot import docker://$image enroot create /shared/enroot/images/${image//[\\/:]/\\+}.sqsh The Enroot container storage directory for the user ${ENROOT_CACHE_PATH} (which defaults to $HOME/.local/share/enroot) must be accessible on all compute nodes. A convenience script, /usr/bin/manage-enroot-cache, is provided by the HPC launcher installation to simplify the management of enroot images.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#set-up-and-manage-a-google-kubernetes-engine-gke-cluster",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#set-up-and-manage-a-google-kubernetes-engine-gke-cluster",
    "content": "Determined can be installed on a cluster that is hosted on a managed Kubernetes service such as GKE. This document describes how to set up a GKE cluster with GPU-enabled nodes. The recommended setup includes deploying a cluster with a single non-GPU node that will host the Determined master and database, and an autoscaling group of GPU nodes. After creating a suitable GKE cluster, you can then proceed with the standard instructions for installing Determined on Kubernetes. Determined requires GPU-enabled nodes and the Kubernetes cluster to be running version >= 1.19 and <= 1.21, though later versions may work.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#prerequisites",
    "content": "Before setting up a GKE cluster, the user should have Google Cloud SDK and kubectl installed on their local machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Set up the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#set-up-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Set up the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#set-up-the-cluster",
    "content": "# Set a unique name for your cluster. GKE_CLUSTER_NAME=<any unique name, e.g. \"determined-cluster\"> # Set a unique name for your node pool. GKE_GPU_NODE_POOL_NAME=<any unique name, e.g., \"determined-node-pool\"> # Set a unique name for the GCS bucket that will store your checkpoints. # When installing Determined, set checkpointStorage.bucket to the value defined here. GCS_BUCKET_NAME=<any unique name, e.g., \"determined-checkpoint-bucket\"> # Set the GPU type for your node pool. Other options include p100, p4, and v100. GPU_TYPE=nvidia-tesla-t4 # Set the number of GPUs per node. GPUS_PER_NODE=4 # Launch the GKE cluster that will contain a single non-GPU node. gcloud container clusters create ${GKE_CLUSTER_NAME} \\ --region us-west1 \\ --node-locations us-west1-b\\ --num-nodes=1 \\ --machine-type=n1-standard-16 # Create a node pool. This will not launch any nodes immediately but will # scale up and down as needed. If you change the GPU type or the number of # GPUs per node, you may need to change the machine-type. gcloud container node-pools create ${GKE_GPU_NODE_POOL_NAME} \\ --cluster ${GKE_CLUSTER_NAME} \\ --accelerator type=${GPU_TYPE},count=${GPUS_PER_NODE} \\ --zone us-west1 \\ --num-nodes=0 \\ --enable-autoscaling \\ --min-nodes=0 \\ --max-nodes=4 \\ --machine-type=n1-standard-32 \\ --scopes=storage-full,cloud-platform # Deploy a DaemonSet that enables the GPUs. kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml # Create a GCS bucket to store checkpoints. gsutil mb gs://${GCS_BUCKET_NAME}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Manage a GKE Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#manage-a-gke-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Manage a GKE Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#manage-a-gke-cluster",
    "content": "For general instructions on adding taints and tolerations to nodes, see the Taints and Tolerations section in our Guide to Kubernetes. There, you can find an explanation of taints and tolerations, as well as instructions for using kubectl to add them to existing clusters. It is important to note that if you use the gcloud CLI to create nodes with taints, you must also add tolerations using kubectl; otherwise, Kubernetes will be unable to schedule pods on the tainted node. To create a nodepool or a cluster with a taint in GKE, use the --node-taints flag to specify the type, tag, and effect. gcloud container clusters create ${GKE_CLUSTER_NAME} \\ --node-taints ${TAINT_TYPE}=${TAINT_TAG}:${TAINT_EFFECT} The following command is an example of using the gcloud CLI to make a cluster that with a taint with type dedicated equal to experimental with the PreferNoSchedule effect. gcloud container clusters create ${GKE_CLUSTER_NAME} \\ --node-taints dedicated=experimental:PreferNoSchedule gcloud container node-pools create ${GKE_NODE_POOL_NAME} \\ --cluster ${GKE_CLUSTER_NAME} \\ --node-taints ${TAINT_TYPE}=${TAINT_TAG}:${TAINT_EFFECT} The following CLI command is an example of using the gcloud CLI to make a node with a taint with type special equal to gpu with the NoExecute effect. gcloud container node-pools create ${GKE_NODE_POOL_NAME} \\ --cluster ${GKE_CLUSTER_NAME} \\ --node-taints special=gpu:NoExecute",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl1": "Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-gke-cluster.html#next-steps",
    "content": "Install Determined on Kubernetes Development Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#deploy-on-kubernetes",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#deploy-on-kubernetes",
    "content": "This document describes how the Determined runs on Kubernetes. For instructions on installing Determined on Kubernetes, see the installation guide. In this topic guide, we will cover: How Determined works on Kubernetes. Limitations of Determined on Kubernetes. Useful Helm and Kubectl commands.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "How Determined Works on Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#how-determined-works-on-kubernetes",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "How Determined Works on Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#how-determined-works-on-kubernetes",
    "content": "Installing Determined on Kubernetes deploys an instance of the Determined master and a Postgres database in the Kubernetes cluster. Once the master is up and running, you can launch experiments, notebooks, TensorBoards, commands, and shells. When new workloads are submitted to the Determined master, the master launches pods and configMaps on the Kubernetes cluster to execute those workloads. Users of Determined shouldn\u2019t need to interact with Kubernetes directly after installation, as Determined handles all the necessary interaction with the Kubernetes cluster. It is also important to note that when running Determined on Kubernetes, a higher priority value means a higher priority (e.g. a priority 50 task will run before a priority 40 task). This is different from priority scheduling in non-Kubernetes deployments, where lower priority values mean a higher priority (e.g. a priority 40 task will run before a priority 50 task).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#limitations-on-kubernetes",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#limitations-on-kubernetes",
    "content": "This section outlines the current limitations of Determined on Kubernetes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#scheduling",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Scheduling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#scheduling",
    "content": "By default, the Kubernetes scheduler does not support gang scheduling or preemption. This can be problematic for distributed deep learning workloads that require multiple pods to be scheduled before execution starts. Determined includes built-in support for the lightweight coscheduling plugin, which extends the default Kubernetes scheduler to support gang scheduling. Determined also includes support for priority-based preemption scheduling. Neither are enabled by default. For more details and instructions on how to enable the coscheduling plugin, refer to Gang Scheduling and Priority Scheduling with Preemption.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Dynamic Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#dynamic-agents",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Dynamic Agents",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#dynamic-agents",
    "content": "Determined is not able to autoscale your cluster, but equivalent functionality is available by using the Kubernetes Cluster Autoscaler, which is supported on GKE and EKS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Pod Security",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#pod-security",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Limitations on Kubernetes",
      "lvl3": "Pod Security",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#pod-security",
    "content": "By default, Determined runs task containers as root. However, it is possible to associate a Determined user with a Unix user and group, provided that the Unix user and group already exist. Tasks initiated by the associated Determined user will run under the linked Unix user rather than root. For more information, see: Run Tasks as Specific Agent Users.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#useful-helm-and-kubectl-commands",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#useful-helm-and-kubectl-commands",
    "content": "kubectl is a command-line tool for interacting with a Kubernetes cluster. Helm is used to install and upgrade Determined on Kubernetes. This section covers some of the useful kubectl and helm commands when running Determined on Kubernetes. For all the commands listed below, include -n <kubernetes namespace name> if running Determined in a non-default namespace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "List Installations of Determined",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#list-installations-of-determined",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "List Installations of Determined",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#list-installations-of-determined",
    "content": "To list the current installation of Determined on the Kubernetes cluster: # To list in the current namespace. helm list # To list in all namespaces. helm list -A It is recommended to have just one instance of Determined per Kubernetes cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Get the IP Address of the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#get-the-ip-address-of-the-determined-master",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Get the IP Address of the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#get-the-ip-address-of-the-determined-master",
    "content": "To get the IP and port address of the Determined master: # Get all services. kubectl get services # Get the master service. The exact name of the master service depends on # the name given to your helm deployment, which can be looked up by running # ``helm list``. kubectl get service determined-master-service-<helm deployment name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Check the Status of the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#check-the-status-of-the-determined-master",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Check the Status of the Determined Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#check-the-status-of-the-determined-master",
    "content": "Logs for the Determined master are available via the CLI and WebUI. Kubectl commands are useful for diagnosing any issues that arise during installation. # Get all deployments. kubectl get deployments # Describe the current state of Determined master deployment. The exact name # of the master deployment depends on the name given to your helm deploy # which can be looked up by running `helm list`. kubectl describe deployment determined-master-deployment-<helm deployment name> # Get all pods associated with the Determined master deployment. Note this # will only include pods that are running the Determined master, not pods # that are running tasks associated with Determined workloads. kubectl get pods -l=app=determined-master-<helm deployment name> # Get logs for the pod running the Determined master. kubectl logs <determined-master-pod-name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Get All Running Task Pods",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#get-all-running-task-pods",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on Kubernetes",
      "lvl1": "Deploy on Kubernetes",
      "lvl2": "Useful Helm and Kubectl Commands",
      "lvl3": "Get All Running Task Pods",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/overview.html#get-all-running-task-pods",
    "content": "These kubectl commands list and delete pods which are running Determined tasks: # Get all pods that are running Determined tasks. kubectl get pods -l=determined # Delete all Determined task pods. Users should never have to run this, # unless they are removing a deployment of Determined. kubectl get pods --no-headers=true -l=determined | awk '{print $1}' | xargs kubectl delete pod",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#development-guide",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#prerequisites",
    "content": "Before setting up the Determined master, set up a Kubernetes cluster with GPU-enabled nodes and Kubernetes version >= 1.19 and <= 1.21. Later versions of Kubernetes may also work. You can set up Kubernetes manually, or you can use a managed Kubernetes service such as GKE or EKS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Set up a Development Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#set-up-a-development-environment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Set up a Development Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#set-up-a-development-environment",
    "content": "To deploy a custom version of the Determined master, we deploy a long-running pod in Kubernetes, command it to sleep, then exec into it and build our master. To add a sleep command, modify the template helm/charts/determined/templates/master-deployment.yaml to include the command and args: spec: ... containers: - name: determined-master-{{ .Release.Name }} ... command: [\"sleep\"] args: [\"99999m\"] ... Next apply the Determined Helm chart and exec into the pod containing the master. helm install <deployment-name> helm/charts/determined # List pods and find the master pod. kubectl get pods kubectl exec -it <master-pod-name> -- /bin/bash",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Set up a Determined Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#set-up-a-determined-environment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Set up a Determined Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#set-up-a-determined-environment",
    "content": "Before installing Determined, install the dependencies specified in the contributing guide. You can use apt and pip to install most of the dependencies, but you will need to download and manually install Go, Node, the protobuf compiler, and Helm. Here is an example of installing all the necessary dependencies: apt-get update DEBIAN_FRONTEND=noninteractive apt-get install -y software-properties-common DEBIAN_FRONTEND=noninteractive add-apt-repository -y ppa:deadsnakes/ppa DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends git-all python3.8-dev python3.8-venv default-jre curl build-essential libkrb5-dev unzip jq # Download and install Go 1.21. curl -L https://go.dev/dl/go1.21.0.linux-amd64.tar.gz | tar -xz chown -R root:root go mv go /usr/local/ # Download and install Node and TypeScript. curl -sL https://deb.nodesource.com/setup_16.x | bash - apt-get install -y nodejs npm install typescript -g # Download and install the protobuf compiler. PB_REL=\"https://github.com/protocolbuffers/protobuf/releases\" curl -LO $PB_REL/download/v3.19.0/protoc-3.19.0-linux-x86_64.zip unzip protoc-3.19.0-linux-x86_64.zip -d $HOME/.local # Download and install Helm. curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh In addition to installing these packages, update .bashrc with the new paths. export GOPATH=$HOME/go export PATH=$PATH:/usr/local/go/bin:$GOPATH/bin export PATH=\"$PATH:$HOME/.local/bin\" After completing these steps, clone the Determined repository and create and activate a virtual environment for Determined. To create a virtual environment, you may use conda or python3-venv. Here is an example for cloning the repository, then creating and activating an environment with python3-venv: git clone https://github.com/determined-ai/determined.git mkdir ~/.virtualenvs python3.8 -m venv ~/.virtualenvs/determined . ~/.virtualenvs/determined/bin/activate",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Prepare to run the Determined Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#prepare-to-run-the-determined-master",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Prepare to run the Determined Master",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#prepare-to-run-the-determined-master",
    "content": "Once the dependencies are installed, prepare the repository to run devcluster, a tool for running Determined. First, enter the Determined repository and run: ``make all`` Once that has finished, create a new file at ~/.devcluster.yaml and populate it with the following fields: startup_input: \"p\" cwd: /root/determined commands: p: make -C harness build # rebuild Python w: make -C webui build # rebuild WebUI c: make -C docs build # rebuild docs stages: - master: pre: - sh: make -C proto build - sh: make -C master build - sh: make -C tools prep-root config_file: checkpoint_storage: type: \"gcs\" bucket: <name of your bucket> save_experiment_best: 0 save_trial_best: 1 save_trial_latest: 1 db: user: \"postgres\" password: \"postgres\" host: <name of determined db service from `kubectl get services`> port: 5432 name: \"determined\" port: 8081 resource_manager: type: \"kubernetes\" namespace: default max_slots_per_pod: 1 master_service_name: <name of determined master service from `kubectl get services`> log: level: debug root: tools/build You are now ready to build and run the Determined master! From the Determined repo, run devcluster --no-guess-host to build and run the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Development Guide",
      "lvl1": "Development Guide",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/k8s-dev-guide.html#next-steps",
    "content": "Customize a Pod",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#install-determined-on-kubernetes",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#install-determined-on-kubernetes",
    "content": "Configuration Reference Helm Chart Configuration Reference This user guide describes how to install Determined on Kubernetes. using the Determined Helm Chart. Store your installation commands and flags in a shell script for future use, particularly for upgrading. When the Determined Helm chart is installed, the following entities will be created: Deployment of the Determined master. ConfigMap containing configurations for the Determined master. LoadBalancer service to make the Determined master accessible. Later in this guide, we describe how it is possible to replace this with a NodePort service. ServiceAcccount which will be used by the Determined master. Deployment of a Postgres database. Later in this guide, we describe how an external database can be used instead. PersistentVolumeClaim for the Postgres database. Omitted if using an external database. Service to allow the Determined master to communicate with the Postgres database. Omitted if using an external database. When installing Determined on Kubernetes using Helm, the deployment should be configured by editing the values.yaml and Chart.yaml files in the Determined Helm Chart.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#prerequisites",
    "content": "Before installing Determined on a Kubernetes cluster, please ensure that the following prerequisites are satisfied: The Kubernetes cluster should be running Kubernetes version >= 1.19 and <= 1.21, though later versions may work. You should have access to the cluster via kubectl. Helm 3 should be installed. If you are using a private image registry or the enterprise edition, you should add a secret using kubectl create secret. The nodes in the cluster already have or can pull the fluent/fluent-bit:1.9.3 Docker image from Docker Hub. Optional: for GPU-based training, the Kubernetes cluster should have GPU support enabled. You should also download a copy of the Determined Helm Chart and extract it on your local machine. If you do not yet have a Kubernetes cluster deployed and you want to use Determined in a public cloud environment, we recommend using a managed Kubernetes offering such as Google Kubernetes Engine (GKE) on GCP or Elastic Kubernetes Service (EKS) on AWS. For more info on configuring GKE for use with Determined, refer to the Instructions for setting up a GKE cluster. For info on configuring EKS, refer to the Instructions for setting up an EKS cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#configuration",
    "content": "When installing Determined using Helm, first configure some aspects of the Determined deployment by editing the values.yaml and Chart.yaml files in the Helm chart.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Image Registry Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#image-registry-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Image Registry Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#image-registry-configuration",
    "content": "To configure which image registry of Determined will be installed by the Helm chart, change imageRegistry in values.yaml. You can specify the Docker Hub public registry determinedai or specify any private registry that hosts the Determined master image.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Image Pull Secret Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#image-pull-secret-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Image Pull Secret Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#image-pull-secret-configuration",
    "content": "To configure which image pull secret will be used by the Helm chart, change imagePullSecretName in values.yaml. You can set it to empty for the Docker Hub public registry or specify any secret that is configured using kubectl create secret.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Version Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#version-configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Version Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#version-configuration",
    "content": "To configure which version of Determined will be installed by the Helm chart, change appVersion in Chart.yaml. You can specify a release version (e.g., 0.13.0) or specify any commit hash from the upstream Determined repo (e.g., b13461ed06f2fad339e179af8028d4575db71a81). You are strongly encouraged to use a released version.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Resource Configuration (GPU-based setups)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#resource-configuration-gpu-based-setups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Resource Configuration (GPU-based setups)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#resource-configuration-gpu-based-setups",
    "content": "For GPU-based configurations, you must specify the number of GPUs on each node (for GPU-enabled nodes only). This is done by setting maxSlotsPerPod in values.yaml. Determined uses this information when scheduling multi-GPU tasks. Each multi-GPU (distributed training) task will be scheduled as a set of slotsPerTask / maxSlotsPerPod separate pods, with each pod assigned up to maxSlotsPerPod GPUs. Distributed tasks with sizes that are not divisible by maxSlotsPerPod are never scheduled. If you have a cluster of different size nodes, set maxSlotsPerPod to the greatest common divisor of all the sizes. For example, if you have some nodes with 4 GPUs and other nodes with 8 GPUs, set maxSlotsPerPod to 4 so that all distributed experiments will launch with 4 GPUs per pod (with two pods on 8-GPU nodes).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Resource Configuration (CPU-based setups)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#resource-configuration-cpu-based-setups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Resource Configuration (CPU-based setups)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#resource-configuration-cpu-based-setups",
    "content": "For CPU-only configurations, you need to set slotType: cpu as well as slotResourceRequests.cpu: <number of CPUs per slot> in values.yaml. Please note that the number of CPUs allocatable by Kubernetes may be lower than the number of \u201chardware\u201d CPU cores. For example, an 8-core node may provide 7.91 CPUs, with the rest allocated for the Kubernetes system tasks. If slotResourceRequests.cpu was set to 8 in this example, the pods would fail to allocate, so it should be set to a lower number instead, such as 7.5. Then, similarly to GPU-based configuration, maxSlotsPerPod needs to be set to the greatest common divisor of all the node sizes. For example, if you have 16-core nodes with 15 allocatable CPUs, it\u2019s reasonable to set maxSlotsPerPod: 1 and slotResourceRequests.cpu: 15. If you have some 32-core nodes and some 64-core nodes, and you want to use finer-grained slotResourceRequests.cpu: 15, set maxSlotsPerPod: 2.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Checkpoint Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#checkpoint-storage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Checkpoint Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#checkpoint-storage",
    "content": "Checkpoints and TensorBoard events can be configured to be stored in shared_fs, AWS S3, Microsoft Azure Blob Storage, or GCS. By default, checkpoints and TensorBoard events are stored using shared_fs, which creates a hostPath Volume and saves to the host file system. This configuration is intended for initial testing only; you are strongly discouraged from using shared_fs for actual deployments of Determined on Kubernetes, because most Kubernetes cluster nodes do not have a shared file system. Instead of using shared_fs, configure either AWS S3, Microsoft Azure Blob Storage, or GCS: AWS S3: To configure Determined to use AWS S3 for checkpoint and TensorBoard storage, you need to set checkpointStorage.type in values.yaml to s3 and set checkpointStorage.bucket to the name of the bucket. The pods launched by the Determined master must have read, write, and delete access to the bucket. To enable this you can optionally configure checkpointStorage.accessKey and checkpointStorage.secretKey. You can optionally configure checkpointStorage.endpointUrl which specifies the endpoint to use for S3 clones (e.g., http://<minio-endpoint>:<minio-port|default=9000>). Microsoft Azure Blob Storage: To configure Determined to use Microsoft Azure Blob Storage for checkpoint and TensorBoard storage, you need to set checkpointStorage.type in values.yaml to azure and set checkpointStorage.container to the name of the container to store it in. You must also specify one of connection_string - the connection string associated with the Azure Blob Storage service account to use, or the tuple account_url and credential - where account_url is the URL for the service account to use, and credential is an optional credential. GCS: To configure Determined to use Google Cloud Storage for checkpoints and TensorBoard data, set checkpointStorage.type in values.yaml to gcs and set checkpointStorage.bucket to the name of the bucket. The pods launched by the Determined master must have read, write, and delete access to the bucket. For example, when launching GKE nodes you need to specify --scopes=storage-full to configure proper GCS access.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Pod Specs (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-pod-specs-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Pod Specs (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-pod-specs-optional",
    "content": "As described in the Deploy on Kubernetes guide, when tasks (e.g., experiments, notebooks) are started in a Determined cluster running on Kubernetes, the Determined master launches pods to execute these tasks. The Determined helm chart makes it possible to set default pod specs for all CPU and GPU tasks. The defaults can be defined in values.yaml under taskContainerDefaults.cpuPodSpec and taskContainerDefaults.gpuPodSpec. For examples of how to do this and a description of permissible fields, see the specifying custom pod specs guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Password (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-password-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Password (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-password-optional",
    "content": "Unless otherwise specified, the pre-existing users, admin and determined, do not have passwords associated with their accounts. You can set a default password for the determined and admin accounts if preferred or needed. This password will not affect any other user account. For additional information on managing users in determined, see the topic guide on users.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Database (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#database-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Database (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#database-optional",
    "content": "By default, the Helm chart deploys an instance of Postgres on the same Kubernetes cluster where Determined is deployed. If this is not what you want, you can configure the Helm chart to use an external Postgres database by setting db.hostAddress to the IP address of their database. If db.hostAddress is configured, the Determined Helm chart will not deploy a database.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "TLS (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#tls-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "TLS (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#tls-optional",
    "content": "By default, the Helm chart will deploy a load-balancer which makes the Determined master accessible over HTTP. To secure your cluster, Determined supports configuring TLS encryption which can be configured to terminate inside a load-balancer or inside the Determined master itself. To configure TLS, set useNodePortForMaster to true. This will instruct Determined to deploy a NodePort service for the master. You can then configure an Ingress that performs TLS termination in the load balancer and forwards plain text to the NodePort service, or forwards TLS encrypted data. Please note when configuring an Ingress that you need to have an Ingress controller running your cluster. TLS termination in a load-balancer (e.g., nginx). This option will provide TLS encryption between the client and the load-balancer, with all communication inside the cluster performed via HTTP. To configure this option set useNodePortForMaster to true and then configure an Ingress service to perform TLS termination and forward the plain text traffic to the Determined master. TLS termination in the Determined master. This option will provide TLS encryption inside the Kubernetes cluster. All communication with the master will be encrypted. Communication between task containers (distributed training) will not be encrypted. To configure this option create a Kubernetes TLS secret within the namespace where Determined is being installed and set tlsSecret to be the name of this secret. You also need to set useNodePortForMaster to true. After the NodePort service is created, you can configure an Ingress to forward TLS encrypted data to the NodePort service. An example of how to configure an Ingress, which will perform TLS termination in the load-balancer by default: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: determined-ingress annotations: kubernetes.io/ingress.class: \"nginx\" # Uncommenting this option instructs the created load-balancer # to forward TLS encrypted data to the NodePort service and # perform TLS termination in the Determined master. In order # to configure ssl-passthrough, your nginx ingress controller # must be running with the --enable-ssl-passthrough option enabled. # # nginx.ingress.kubernetes.io/ssl-passthrough: \"true\" spec: tls: - hosts: - your-hostname-for-determined.ai secretName: your-tls-secret-name rules: - host: your-hostname-for-determined.ai http: paths: - path: / backend: serviceName: determined-master-service-<name for your deployment> servicePort: masterPort configured in values.yaml To see information about using AWS Load Balancer instead of nginx visit Using AWS Load Balancer.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Scheduler (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-scheduler-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Default Scheduler (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#default-scheduler-optional",
    "content": "Determined includes support for the lightweight coscheduling plugin, which extends the default Kubernetes scheduler to provide gang scheduling. This feature is currently in beta and is not enabled by default. To activate the plugin, set the defaultScheduler field to coscheduler. If the field is empty or doesn\u2019t exist, Determined will use the default Kubernetes scheduler to schedule all experiments and tasks. defaultScheduler: coscheduler Determined also includes support for priority-based scheduling with preemption. This feature allows experiments to be preempted if higher priority ones are submitted. This feature is also in beta and is not enabled by default. To activate priority-based preemption scheduling, set defaultScheduler to preemption. defaultScheduler: preemption",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#node-taints",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#node-taints",
    "content": "Tainting nodes is optional, but you might want to taint nodes to restrict which nodes a pod may be scheduled onto. A taint consists of a taint type, tag, and effect. When using a managed kubernetes cluster (e.g. a GKE, AKS, or EKS cluster), it is possible to specify taints at cluster or nodepool creation using the specified CLIs. Please refer to the set up pages for each managed cluster service for instructions on how to do so. To add taints to an existing resource, it is necessary to use kubectl. Tolerations can be added to Pods by including the tolerations field in the Pod specification.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": "kubectl Taints",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#kubectl-taints",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": "kubectl Taints",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#kubectl-taints",
    "content": "To taint a node with kubectl, use kubectl taint nodes. kubectl taint nodes ${NODE_NAME} ${TAINT_TYPE}=${TAINT_TAG}:${TAINT_EFFECT} As an example, the following snippet taints nodes named node-1 to not be schedulable if the accelerator taint type has the gpu taint value. kubectl taint nodes node-1 accelerator=gpu:NoSchedule",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": "kubectl Tolerations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#kubectl-tolerations",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Node Taints",
      "lvl4": "kubectl Tolerations",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#kubectl-tolerations",
    "content": "To specify a toleration, use the toleration field in the PodSpec. tolerations: - key: \"${TAINT_TYPE}\" operator: \"Equal\" value: \"${TAINT_TAG}\" effect: \"${TAINT_EFFECT}\" The following example is a toleration for when a node has the accelerator taint type equal to the gpu taint value. tolerations: - key: \"accelerator\" operator: \"Equal\" value: \"gpu\" effect: \"NoSchedule\" The next example is a toleration for when a node has the gpu taint type. tolerations: - key: \"gpu\" operator: \"Exists\" effect: \"NoSchedule\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Setting Up Multiple Resource Pools",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#setting-up-multiple-resource-pools",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Configuration",
      "lvl3": "Setting Up Multiple Resource Pools",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#setting-up-multiple-resource-pools",
    "content": "To set up multiple resource pools for Determined on your Kubernetes cluster: Create a namespace for each resource pool. The default namespace can also be mapped to a resource pool. As Determined ensures that tasks in a given resource pool get launched in its linked namespace, the cluster admin needs to ensure that pods in a given namespace have the right nodeSelector or toleration automatically added to their pod spec so that they can be forced to be scheduled on the nodes that we want to be part of a given resource pool. This can be done using an admissions controller like a PodNodeSelector or PodTolerationRestriction. Alternatively, the cluster admin can also add a resource pool (and hence namespace) specific pod spec to the task_container_defaults sub-section of the resourcePools section of the Helm values.yaml: resourcePools: - pool_name: prod_pool kubernetes_namespace: default task_container_defaults: gpu_pod_spec: apiVersion: v1 kind: Pod spec: tolerations: - key: \"pool_taint\" operator: \"Equal\" value: \"prod\" effect: \"NoSchedule\" Label/taint the appropriate nodes you want to include as part of each resource pool. For instance you may add a taint like kubectl taint nodes prod_node_name pool_taint=prod:NoSchedule and the appropriate toleration to the PodTolerationRestriction admissions controller or in resourcePools.pool_name.task_container_defaults.gpu_pod_spec as above so it is automatically added to the pod spec based on which namespace (and hence resource pool) a task runs in. Add the appropriate resource pool name to namespace mappings in the resourcePools section of the values.yaml file in the Helm chart.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Install Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#install-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Install Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#install-determined",
    "content": "Once finished making configuration changes in values.yaml and Chart.yaml, Determined is ready to be installed. To install Determined, run: helm install <name for your deployment> determined-helm-chart determined-helm-chart is a relative path to where the Determined Helm Chart is located. It may take a few minutes for all resources to come up. If you encounter issues during installation, refer to the list of useful kubectl commands. Helm will install Determined within the default namespace. If you wish to install Determined into a non-default namespace, add -n <namespace name> to the command shown above. Once the installation has completed, instructions will be displayed for discovering the IP address assigned to the Determined master. The IP address can also be discovered by running kubectl get services.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Install Determined",
      "lvl3": "When installing Determined on Kubernetes, I get an ImagePullBackOff error",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#when-installing-determined-on-kubernetes-i-get-an-imagepullbackoff-error",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Install Determined",
      "lvl3": "When installing Determined on Kubernetes, I get an ImagePullBackOff error",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#when-installing-determined-on-kubernetes-i-get-an-imagepullbackoff-error",
    "content": "You may be trying to install a non-released version of Determined or a version in a private registry without the right secret. See the documentation on how to configure which version of Determined to install on Kubernetes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Upgrade Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#upgrade-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Upgrade Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#upgrade-determined",
    "content": "To upgrade Determined or to change a configuration setting, first make the appropriate changes in values.yaml and Chart.yaml, and then run: helm upgrade <name for your deployment> --wait determined-helm-chart Before upgrading Determined, consider pausing all active experiments. Any experiments that are active when the Determined master restarts will resume training after the upgrade, but will be rolled back to their most recent checkpoint.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Uninstall Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#uninstall-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Uninstall Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#uninstall-determined",
    "content": "To uninstall Determined run: # Please note that if the Postgres Database was deployed by Determined, it will # be deleted by this command, permanently removing all records of your experiments. helm delete <name for your deployment> # If there were any active tasks when uninstalling, this command will # delete all of the leftover Kubernetes resources. It is recommended to # pause all experiments prior to upgrading or uninstalling Determined. kubectl get pods --no-headers=true -l=determined | awk '{print $1}' | xargs kubectl delete pod",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined on Kubernetes",
      "lvl1": "Install Determined on Kubernetes",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/install-on-kubernetes.html#next-steps",
    "content": "Customize a Pod Development Guide Set up and Manage an Azure Kubernetes Service (AKS) Cluster Set up and Manage an AWS Kubernetes (EKS) Cluster Set up and Manage a Google Kubernetes Engine (GKE) Cluster",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#set-up-and-manage-an-aws-kubernetes-eks-cluster",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#set-up-and-manage-an-aws-kubernetes-eks-cluster",
    "content": "Determined can be installed on a cluster that is hosted on a managed Kubernetes service such as Amazon EKS. This document describes how to set up an EKS cluster with GPU-enabled nodes. The recommended setup includes deploying a cluster with a single non-GPU node that will host the Determined master and database, and an autoscaling group of GPU nodes. After creating a suitable EKS cluster, you can then proceed with the standard instructions for installing Determined on Kubernetes. Determined requires GPU-enabled nodes and the Kubernetes cluster to be running version >= 1.19 and <= 1.21, though later versions may work.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#prerequisites",
    "content": "Before setting up an EKS cluster, the user should have the latest versions of AWS CLI, kubectl, and eksctl installed on their local machine. Additionally, make sure to be subscribed to the EKS-optimized AMI with GPU support. Continuing without subscribing will cause node creation to fail.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create an S3 Bucket",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-an-s3-bucket",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create an S3 Bucket",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-an-s3-bucket",
    "content": "One resource that eksctl does not automatically create is an S3 bucket, which is necessary for Determined to store checkpoints. To quickly create an S3 bucket, use the command: aws s3 mb s3://<bucket-name> The bucket name needs to be specified in both the eksctl cluster config as well as the Determined Helm chart.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-the-cluster",
    "content": "The quickest and easiest way to deploy an EKS cluster is with eksctl. eksctl supports cluster creation with either command-line arguments or a cluster config file. Below is a template config that deploys a managed node group for Determined\u2019s master instance, as well as an autoscaling GPU node group for workers. To fill in the template, insert the cluster name and S3 bucket name. apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: <cluster-name> # Specify your cluster name here region: us-west-2 # The default region is us-west-2 version: \"1.19\" # 1.20 and 1.21 are also supported # Cluster availability zones must be explicitly named in order for single availability zone node groups to work. availabilityZones: - \"us-west-2b\" - \"us-west-2c\" - \"us-west-2d\" iam: withOIDC: true # Enables IAM IODC provider serviceAccounts: - metadata: name: checkpoint-storage-s3-bucket # If no namespace is set, \"default\" will be used. # Namespace will be created if it does not already exist. namespace: default labels: aws-usage: \"determined-checkpoint-storage\" attachPolicy: # Inline policy can be defined along with `attachPolicyARNs` Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"s3:ListBucket\" Resource: 'arn:aws:s3:::<bucket-name>' # Name of the previously created bucket - Effect: Allow Action: - \"s3:GetObject\" - \"s3:PutObject\" - \"s3:DeleteObject\" Resource: 'arn:aws:s3:::<bucket-name>/*' - metadata: name: cluster-autoscaler namespace: kube-system labels: aws-usage: \"determined-cluster-autoscaler\" attachPolicy: Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"autoscaling:DescribeAutoScalingGroups\" - \"autoscaling:DescribeAutoScalingInstances\" - \"autoscaling:DescribeLaunchConfigurations\" - \"autoscaling:DescribeTags\" - \"autoscaling:SetDesiredCapacity\" - \"autoscaling:TerminateInstanceInAutoScalingGroup\" - \"ec2:DescribeLaunchTemplateVersions\" Resource: '*' managedNodeGroups: - name: managed-m5-2xlarge instanceType: m5.2xlarge availabilityZones: - us-west-2b - us-west-2c - us-west-2d minSize: 1 maxSize: 2 volumeSize: 200 iam: withAddonPolicies: autoScaler: true cloudWatch: true ssh: allow: true # will use ~/.ssh/id_rsa.pub as the default ssh key labels: nodegroup-type: m5.2xlarge nodegroup-role: cpu-worker tags: k8s.io/cluster-autoscaler/enabled: \"true\" k8s.io/cluster-autoscaler/user-eks: \"owned\" k8s.io/cluster-autoscaler/node-template/label/nodegroup-type: m5.2xlarge k8s.io/cluster-autoscaler/node-template/label/nodegroup-role: cpu-worker nodeGroups: - name: g4dn-metal-us-west-2b instanceType: g4dn.metal # 8 GPUs per machine # Restrict to a single AZ to optimize data transfer between instances availabilityZones: - us-west-2b minSize: 0 maxSize: 2 volumeSize: 200 volumeType: gp2 iam: withAddonPolicies: autoScaler: true cloudWatch: true ssh: allow: true # This will use ~/.ssh/id_rsa.pub as the default ssh key. labels: nodegroup-type: g4dn.metal-us-west-2b nodegroup-role: gpu-worker # https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider/aws#special-note-on-gpu-instances k8s.amazonaws.com/accelerator: nvidia-tesla-t4 tags: k8s.io/cluster-autoscaler/enabled: \"true\" k8s.io/cluster-autoscaler/user-eks: \"owned\" k8s.io/cluster-autoscaler/node-template/label/nodegroup-type: g4dn.metal-us-west-2b k8s.io/cluster-autoscaler/node-template/label/nodegroup-role: gpu-worker The cluster specified above allows users to run experiments on an untainted g4dn.metal instances with minor additions to their experiment configs. To create a cluster with tainted instances, see the Tainting Nodes section below. To launch the cluster with eksctl, run: eksctl create cluster --config-file <cluster config yaml> For an experiment to run, its config must be modified to specify a service account for S3 access . An example of this is provided in the Configuring Per-Task Pod Specs section of the Customize a Pod guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create a kubeconfig for EKS",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-a-kubeconfig-for-eks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Create a kubeconfig for EKS",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#create-a-kubeconfig-for-eks",
    "content": "After creating the cluster, kubectl should be used to deploy apps. In order for kubectl to be used with EKS, users need to create or update the cluster kubeconfig. This can be done with the command: aws eks --region <region-code> update-kubeconfig --name <cluster_name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Enable GPU support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#enable-gpu-support",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Enable GPU support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#enable-gpu-support",
    "content": "To use GPU instances, the NVIDIA Kubernetes device plugin needs to be installed. Use the following command to install the plugin: # Deploy a DaemonSet that enables the GPUs. kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/master/nvidia-device-plugin.yml",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Enable Autoscaler",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#enable-autoscaler",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Enable Autoscaler",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#enable-autoscaler",
    "content": "Lastly, EKS requires manual deployment of an autoscaler. Save the following configuration in a new file such as determined-autoscaler.yaml: You will need to update the <cluster-autoscaler-image> to match the major and minor numbers of your Kubernetes version. For example, if you are using Kubernetes 1.20, use the cluster-autoscaler version 1.20 image found here: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.20.0 For a full list of cluster-autoscaler releases see here: https://github.com/kubernetes/autoscaler/releases After finding the particular release you want, click on the release and scroll to the bottom to see a list of image URLs. Example: https://github.com/kubernetes/autoscaler/releases/tag/cluster-autoscaler-1.20.0 apiVersion: apps/v1 kind: Deployment metadata: name: cluster-autoscaler namespace: kube-system labels: app: cluster-autoscaler spec: replicas: 1 selector: matchLabels: app: cluster-autoscaler template: metadata: labels: app: cluster-autoscaler annotations: prometheus.io/scrape: 'true' prometheus.io/port: '8085' spec: serviceAccountName: cluster-autoscaler tolerations: - key: node-role.kubernetes.io/master operator: \"Equal\" value: \"true\" effect: NoSchedule containers: - image: <cluster-autoscaler-image> # See, https://github.com/kubernetes/autoscaler/releases name: cluster-autoscaler resources: limits: cpu: 100m memory: 300Mi requests: cpu: 100m memory: 300Mi command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --scale-down-delay-after-add=5m - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/<cluster-name> volumeMounts: - name: ssl-certs mountPath: /etc/ssl/certs/ca-certificates.crt readOnly: true imagePullPolicy: \"Always\" volumes: - name: ssl-certs hostPath: path: \"/etc/ssl/certs/ca-bundle.crt\" To deploy an autoscaler that works with Determined, apply the official autoscaler configuration first, then apply the custom determined-autoscaler.yaml. # Apply the official autoscaler configuration kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-run-on-control-plane.yaml # Apply the custom deployment kubectl apply -f <cluster-autoscaler yaml, e.g. `determined-autoscaler.yaml`>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Change the Experiment Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#change-the-experiment-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Change the Experiment Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#change-the-experiment-configuration",
    "content": "To run an experiment with EKS, two additions must be made to the experiment config. A service account must be specified in order to allow Determined to save checkpoints to S3 and tolerances, if there are tainted nodes, must be listed for the experiment to be scheduled. An example of the necessary changes is shown here: environment: pod_spec: ... spec: ... serviceAccountName: checkpoint-storage-s3-bucket # Tolerations should only be included if nodes are tainted tolerations: - key: <tainted-group-key, e.g g4dn.metal-us-west-2b> operator: \"Equal\" value: \"true\" effect: \"NoSchedule\" Details about pod configuration can be found in Per-task Pod Specs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Make Changes to Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#make-changes-to-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Make Changes to Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#make-changes-to-determined",
    "content": "Following the deployment of EKS, make sure that the necessary changes to Determined have been applied in order to successfully run experiments. These changes include adding the created S3 bucket to Determined\u2019s Helm chart and specifying a service account in the default pod specs. When modifying the Helm chart to include S3, no keys or endpoint urls are needed. Additionally, if running on tainted nodes, be sure to add pod tolerations to the experiment spec to ensure they will get scheduled.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Use an AWS Load Balancer (optional)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#use-an-aws-load-balancer-optional",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Use an AWS Load Balancer (optional)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#use-an-aws-load-balancer-optional",
    "content": "It is possible to use ALB with the Determined EKS cluster instead of nginx. Determined expects the health check to be on /det/, so the config of alb.ingress.kubernetes.io/healthcheck-path must be set to /det/ in the master ingress yaml. An example of a master ingress yaml is shown here: apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: alb.ingress.kubernetes.io/inbound-cidrs: 0.0.0.0/0 alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}]' alb.ingress.kubernetes.io/scheme: internal alb.ingress.kubernetes.io/healthcheck-path: \"/det/\" kubernetes.io/ingress.class: alb name: determined-master-ingress spec: rules: - host: yourhost.com http: paths: - backend: serviceName: determined-master-service-determined servicePort: 8080 path: /* pathType: ImplementationSpecific In order for this ingress to work as expected the Helm parameter of useNodePortForMaster must be set to true and the AWS Load Balancer Controller must be installed in the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Manage an EKS Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#manage-an-eks-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Manage an EKS Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#manage-an-eks-cluster",
    "content": "For general instructions on adding taints and tolerations to nodes, see the Taints and Tolerations section in our Guide to Kubernetes. There, you can find an explanation of taints and tolerations, as well as instructions for using kubectl to add them to existing clusters. It is important to note that if you use EKS to create nodes with taints, you must also add tolerations using kubectl; otherwise, Kubernetes will be unable to schedule pods on the tainted node. To taint nodes, users will need to add a taint type and a tag to the node group specified in the cluster config from Create the Cluster. An example of the modifications is shown for a g4dn.metal node group: - name: g4dn-metal-us-west-2b ... taints: g4dn.metal-us-west-2b: \"true:NoSchedule\" ... tags: ... k8s.io/cluster-autoscaler/node-template/taint/g4dn.metal-us-west-2b: \"true:NoSchedule\" Furthermore, tainting requires changes to be made to the GPU enabling DaemonSet and more additions to the experiment config. First, to change the DaemonSet, save a copy of the official version and make the following additions to its tolerations: spec: tolerations: ... - key: g4dn.metal-us-west-2b operator: Exists effect: NoSchedule To modify the experiment config to run on tainted nodes, refer to the Change the Experiment Configuration section.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl1": "Set up and Manage an AWS Kubernetes (EKS) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-eks-cluster.html#next-steps",
    "content": "Install Determined on Kubernetes Development Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#set-up-and-manage-an-azure-kubernetes-service-aks-cluster",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#set-up-and-manage-an-azure-kubernetes-service-aks-cluster",
    "content": "Determined can be installed on a cluster that is hosted on a managed Kubernetes service such as AKS. This document describes how to set up an AKS cluster with GPU-enabled nodes. The recommended setup includes deploying a cluster with a single non-GPU node that will host the Determined master and database, and an autoscaling group of GPU nodes. After creating a suitable AKS cluster, you can then proceed with the standard instructions for installing Determined on Kubernetes. Determined requires GPU-enabled nodes and the Kubernetes cluster to be running version >= 1.19 and <= 1.21, though later versions may work.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#prerequisites",
    "content": "To deploy an AKS cluster, the user must have a resource group to manage the resources consumed by the cluster. To create one, follow the instructions found in the Azure Resource Groups Documentation. Additionally, users must have the Azure CLI and kubectl installed on their local machine. Finally, authenticate with the Azure CLI using az login in order to have access to your Azure subscription.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Set up the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#set-up-the-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Set up the Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#set-up-the-cluster",
    "content": "# Specify the Azure Resource Group you will be using to deploy the cluster. AKS_RESOURCE_GROUP=<resource group name, e.g. \"determined-resource-group\"> # Set a unique name for your cluster. AKS_CLUSTER_NAME=<any unique name, e.g. \"determined-cluster\"> # Set a unique name for your node pool. Azure requires node pool names to consist # solely of alphanumeric characters, start with a lowercase letter, and # be no longer than 12 characters. AKS_GPU_NODE_POOL_NAME=<any unique, conforming, name, e.g. \"determined-node-pool\"> # Set the GPU VM Size for your node pool. This VM size corresponds to a machine with 4 Tesla K80 GPUs. GPU_VM_SIZE=Standard_NC24 # Launch the AKS cluster that will contain a single non-GPU node. az aks create --resource-group ${AKS_RESOURCE_GROUP} --name ${AKS_CLUSTER_NAME} \\ --node-count 1 --generate-ssh-keys --vm-set-type VirtualMachineScaleSets \\ --load-balancer-sku standard --node-vm-size Standard_D8_v3 # Create a node pool. This will not launch any nodes immediately but will # scale up and down as needed. If you change the GPU type or the number of # GPUs per node, you may need to change the machine-type. az aks nodepool add --resource-group ${AKS_RESOURCE_GROUP} --cluster-name ${AKS_CLUSTER_NAME} \\ --name ${AKS_GPU_NODE_POOL_NAME} --node-count 0 --node-vm-size ${GPU_VM_SIZE} \\ --enable-cluster-autoscaler --min-count 0 --max-count 4",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Create a kubeconfig for AKS",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#create-a-kubeconfig-for-aks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Create a kubeconfig for AKS",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#create-a-kubeconfig-for-aks",
    "content": "After creating the cluster, kubectl should be used to deploy apps. In order for kubectl to be used with AKS, users need to create or update the cluster kubeconfig. This can be done with the command: az aks get-credentials --resource-group ${AKS_RESOURCE_GROUP} --name ${AKS_CLUSTER_NAME}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Enable GPU Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#enable-gpu-support",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Enable GPU Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#enable-gpu-support",
    "content": "To allow the AKS cluster to recognize GPU hardware resources, refer to the instructions provided by Azure on the Install NVIDIA Device Plugin tutorial. With this, the cluster is fully set up, and Determined can be deployed onto it.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#manage-an-aks-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Update the Autoscaler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#update-the-autoscaler",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Update the Autoscaler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#update-the-autoscaler",
    "content": "To update the cluster autoscaler, use the following Azure CLI command: az aks nodepool update --update-cluster-autoscaler --min-count <new_min_count> \\ --max-count <new_max_count> --resource-group ${AKS_RESOURCE_GROUP} \\ --cluster-name ${AKS_CLUSTER_NAME} --name ${AKS_GPU_NODE_POOL_NAME}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Add Taints and Tolerations to Nodes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#add-taints-and-tolerations-to-nodes",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Add Taints and Tolerations to Nodes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#add-taints-and-tolerations-to-nodes",
    "content": "For general instructions on adding taints and tolerations to nodes, see the Taints and Tolerations section in our Guide to Kubernetes. There, you can find an explanation of taints and tolerations, as well as instructions for using kubectl to add them to existing clusters. It is important to note that if you use the Azure CLI to create nodes with taints, you must also add tolerations using kubectl; otherwise, Kubernetes will be unable to schedule pods on the tainted node. To create a nodepool with a taint in AKS, use the --node-taints flag to specify the type, tag, and effect: az aks nodepool add \\ --resource-group ${AKS_RESOURCE_GROUP} \\ --cluster-name ${AKS_CLUSTER_NAME} \\ --name ${AKS_NODE_POOL_NAME} \\ --node-count 1 \\ --node-taints ${TAINT_TYPE}=${TAINT_TAG}:{TAINT_EFFECT} \\ --no-wait The following CLI command is an example of using the az CLI to make a node that is unschedulable unless a Pod has a toleration for a taint with type sku equal to gpu with the NoSchedule effect. az aks nodepool add \\ --resource-group ${AKS_RESOURCE_GROUP} \\ --cluster-name ${AKS_CLUSTER_NAME} \\ --name ${AKS_NODE_POOL_NAME} \\ --node-count 1 \\ --node-taints sku=gpu:NoSchedule \\ --no-wait",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Delete the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#delete-the-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Manage an AKS Cluster",
      "lvl3": "Delete the Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#delete-the-cluster",
    "content": "To delete the AKS cluster, use the following Azure CLI command: az aks delete --resource-group ${AKS_RESOURCE_GROUP} --name ${AKS_CLUSTER_NAME}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl1": "Set up and Manage an Azure Kubernetes Service (AKS) Cluster",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/setup-aks-cluster.html#next-steps",
    "content": "Install Determined on Kubernetes Development Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/troubleshooting.html#troubleshooting",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Troubleshooting",
      "lvl1": "Troubleshooting",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/troubleshooting.html#troubleshooting",
    "content": "If you cannot reach the Determined master after installing Determined on Kubernetes, follow these debugging steps: # Get the name of the Helm deployment. helm list # Double check the IP address and port assigned to the Determined master by looking up the master service. kubectl get service determined-master-service-development-<helm deployment name> # Check the status of master deployment. kubectl describe deployment determined-master-deployment-<helm deployment name> # Check the logs of master pod. kubectl logs <determined-master-pod-name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#helm-and-kubectl-command-examples",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#helm-and-kubectl-command-examples",
    "content": "Configuration Reference Helm Chart Configuration Reference kubectl is a command-line tool for interacting with a Kubernetes cluster. Helm is used to install and upgrade Determined on Kubernetes. This section covers some of the useful kubectl and helm commands when running Determined on Kubernetes. For all the commands listed below, include -n <kubernetes namespace name> if running Determined in a non-default namespace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "List Determined Installations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#list-determined-installations",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "List Determined Installations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#list-determined-installations",
    "content": "To list the current installation of Determined on the Kubernetes cluster: # To list in the current namespace. helm list # To list in all namespaces. helm list -A It is recommended to have just one instance of Determined per Kubernetes cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Get the Determined Master IP Address",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#get-the-determined-master-ip-address",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Get the Determined Master IP Address",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#get-the-determined-master-ip-address",
    "content": "To get the IP and port address of the Determined master: # Get all services. kubectl get services # Get the master service. The exact name of the master service depends on # the name given to your helm deployment, which can be looked up by running # ``helm list``. kubectl get service determined-master-service-<helm deployment name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Check the Determined Master Status",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#check-the-determined-master-status",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Check the Determined Master Status",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#check-the-determined-master-status",
    "content": "Logs for the Determined master are available via the CLI and WebUI. Kubectl commands are useful for diagnosing any issues that arise during installation. # Get all deployments. kubectl get deployments # Describe the current state of Determined master deployment. The exact name # of the master deployment depends on the name given to your helm deploy # which can be looked up by running `helm list`. kubectl describe deployment determined-master-deployment-<helm deployment name> # Get all pods associated with the Determined master deployment. Note this # will only include pods that are running the Determined master, not pods # that are running tasks associated with Determined workloads. kubectl get pods -l=app=determined-master-<helm deployment name> # Get logs for the pod running the Determined master. kubectl logs <determined-master-pod-name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Get All Running Task Pods",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#get-all-running-task-pods",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Get All Running Task Pods",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#get-all-running-task-pods",
    "content": "These kubectl commands list and delete pods which are running Determined tasks: # Get all pods that are running Determined tasks. kubectl get pods -l=determined # Delete all Determined task pods. Users should never have to run this, # unless they are removing a deployment of Determined. kubectl get pods --no-headers=true -l=determined | awk '{print $1}' | xargs kubectl delete pod",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Useful Debugging Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#useful-debugging-commands",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm and Kubectl Command Examples",
      "lvl1": "Helm and Kubectl Command Examples",
      "lvl2": "Useful Debugging Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/helm-commands.html#useful-debugging-commands",
    "content": "# Get the name of the Helm deployment. helm list # Double check the IP address and port assigned to the Determined master by looking up the master service. kubectl get service determined-master-service-development-<helm deployment name> # Check the status of master deployment. kubectl describe deployment determined-master-deployment-<helm deployment name> # Check the logs of master pod. kubectl logs <determined-master-pod-name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#customize-a-pod",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#customize-a-pod",
    "content": "In a Determined cluster running on Kubernetes, tasks (e.g., experiments, notebooks) are executed by launching one or more Kubernetes pods. You can customize these pods by providing custom pod specs. Common use cases include assigning pods to specific nodes, specifying additional volume mounts, and attaching permissions. Configuring pod specs is not required to use Determined on Kubernetes. In this topic guide, we will cover: How Determined uses pod specs. The different ways to configure custom pod specs. Supported pod spec fields. How to configure default pod specs. How to configure per-task pods specs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "How Determined Uses Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#how-determined-uses-pod-specs",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "How Determined Uses Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#how-determined-uses-pod-specs",
    "content": "All Determined tasks are launched as pods. Determined pods consists of an initContainer named determined-init-container and a container named determined-container which executes the workload. When you provide a pod spec, Determined inserts the determined-init-container and determined-container into the provided pod spec. You may also configure some of the fields for the determined-container, as described below.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Ways to Configure Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#ways-to-configure-pod-specs",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Ways to Configure Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#ways-to-configure-pod-specs",
    "content": "Determined provides two ways to configure pod specs. When Determined is installed, the system administrator can configure pod specs that are used by default for all GPU and CPU tasks. In addition, you can specify a custom pod spec for individual tasks (e.g., for an experiment by specifying environment.pod_spec in the experiment configuration). If a custom pod spec is specified for a task, it overrides the default pod spec (if any).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#supported-pod-spec-fields",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#supported-pod-spec-fields",
    "content": "This section describes which fields can and cannot be configured when specifying custom pod specs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": "Not Supported",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#not-supported",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": "Not Supported",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#not-supported",
    "content": "Determined does not support configuring the following fields: Pod Name - Determined automatically assigns a name for every pod that is created. Pod Namespace - Determined automatically sets the pod namespace based on the resource pool the task belongs to. The mapping between resource pools and namespaces can be configured in the resourcePools section of the Helm values.yaml. Host Networking - This must be configured via the master configuration. Restart Policy - This is always set to Never.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": "Supported",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#supported",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Supported Pod Spec Fields",
      "lvl3": "Supported",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#supported",
    "content": "As part of your pod spec, you can specify initContainers and containers. Additionally you can configure the determined-container that executes the task (e.g., training), by setting the container name in the pod spec to determined-container. For the determined-container, Determined supports configuring the following fields: Resource requests and limits (except GPU resources). Volume mounts and volumes. All securityContext fields within the pod spec of the determined-container container except for RunAsUser and RunAsGroup. For those fields, use det user link-with-agent-user instead. Example of configuring a Pachyderm notebook plugin to run in det notebook: environment: pod_spec: apiVersion: v1 kind: Pod spec: containers: - name: determined-container securityContext: privileged: true",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Default Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#default-pod-specs",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Default Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#default-pod-specs",
    "content": "Default pod specs must be configured when installing or upgrading Determined. The default pod specs are configured in values.yaml of the Helm Chart Configuration Reference under taskContainerDefaults.cpuPodSpec and taskContainerDefaults.gpuPodSpec. The gpuPodSpec is applied to all tasks that use GPUs (e.g., experiments, notebooks). cpuPodSpec is applied to all tasks that only use CPUs (e.g., TensorBoards, CPU-only notebooks). Fields that are not specified will remain at their default Determined values. Example of configuring default pod specs in values.yaml: taskContainerDefaults: cpuPodSpec: apiVersion: v1 kind: Pod metadata: labels: customLabel: cpu-label spec: containers: # Will be applied to the container executing the task. - name: determined-container volumeMounts: - name: example-volume mountPath: /example-data # Custom sidecar container. - name: sidecar-container image: alpine:latest volumes: - name: example-volume hostPath: path: /data gpuPodSpec: apiVersion: v1 kind: Pod metadata: labels: customLabel: gpu-label spec: containers: - name: determined-container volumeMounts: - name: example-volume mountPath: /example-data volumes: - name: example-volume hostPath: path: /data The default pod specs can also be configured on a resource pool level. GPU jobs submitted in the resource pool will have the task spec applied. If a job is submitted in a resource pool with a matching CPU / GPU pod spec then the top level taskContainerDefaults.gpuPodSpec or taskContainerDefaults.cpuPodSpec will not be applied. Example of configuring resource pool default pod spec in values.yaml. resourcePools: - pool_name: prod_pool kubernetes_namespace: default task_container_defaults: gpu_pod_spec: apiVersion: v1 kind: Pod spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: topology.kubernetes.io/zone operator: In values: - antarctica-west1",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Per-task Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#per-task-pod-specs",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customize a Pod",
      "lvl1": "Customize a Pod",
      "lvl2": "Per-task Pod Specs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/k8s/custom-pod-specs.html#per-task-pod-specs",
    "content": "In addition to default pod specs, it is also possible to configure custom pod specs for individual tasks. Pod specs for individual tasks can be configured under the environment field in the experiment config (for experiments) or the task configuration (for other tasks). Example of configuring a pod spec for an individual task: environment: pod_spec: apiVersion: v1 kind: Pod metadata: labels: customLabel: task-specific-label spec: # Specify a pull secret for task container image. imagePullSecrets: - name: regcred # Specify a service account that allows writing checkpoints to S3 (for EKS). serviceAccountName: <checkpoint-storage-s3-bucket> # Specify tolerations for scheduling on tainted nodes. tolerations: - key: \"tained-nodegroup-name\" operator: \"Equal\" value: \"true\" effect: \"NoSchedule\" When a custom pod spec is provided for a task, it will merge with the default pod spec (either resourcePools.task_container_defaults or top level task_container_defaults if resourcePools.task_container_defaults is not specified) according to Kubernetes strategic merge patch. Determined does not support setting the strategic merge patch strategy, so the section titled \u201cUse strategic merge patch to update a Deployment using the retainKeys strategy\u201d in the linked Kubernetes docs will not work. Some fields in pod specs are merged by values of items in lists. Volumes for example are merged by volume name. If for some reason you would want to remove a volume mount specific in the default task container you would need to override it with an empty volume of the same path. Example values.yaml resourcePools: - pool_name: prod_pool kubernetes_namespace: default task_container_defaults: gpu_pod_spec: apiVersion: v1 kind: Pod spec: volumes: - name: secret-volume secret: secretName: prod-test-secret containers: - name: determined-container volumeMounts: - name: secret-volume mountPath: /etc/secret-volume Example expconf.yaml environment: pod_spec: apiVersion: v1 kind: Pod spec: volumes: - name: empty-dir-override emptyDir: sizeLimit: 100Mi containers: - name: determined-container volumeMounts: - name: empty-dir-override mountPath: /etc/secret-volume resources: resource_pool: prod_pool",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#install-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#install-determined",
    "content": "This user guide describes how to deploy a Determined cluster on Google Cloud Platform (GCP). The det deploy tool makes it easy to create and deploy these resources in GCP. The det deploy tool uses Terraform to automatically deploy and configure a Determined cluster in GCP. Alternatively, if you already have a process for setting up infrastructure with Terraform, you can use our Terraform modules rather than det deploy. Store your installation commands and flags in a shell script for future use, particularly for upgrading. For more information about using Determined on GCP, see the Deploy on GCP topic guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#project",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#project",
    "content": "To get started on GCP, you will need to create a project. The following GCP APIs must be enabled on your GCP project: Cloud Filestore API Cloud Resource Manager API Cloud SQL Admin API IAM API Service Networking API Cloud Logging API",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Credentials",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#credentials",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Credentials",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#credentials",
    "content": "The det deploy tool requires credentials in order to create resources in GCP. There are two ways to provide these credentials: Use gcloud to authenticate your user account: gcloud auth application-default login This command will open a sign-in page in your browser where you can sign in to the Google account that has access to your project. Ensure your user account has Owner access to the project you want to deploy your cluster in. Use service account credentials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Resource Quotas",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#resource-quotas",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Requirements",
      "lvl3": "Resource Quotas",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#resource-quotas",
    "content": "The default GCP Resource Quotas for GPUs are relatively low; you may wish to request a quota increase.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Install",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#install",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Install",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#install",
    "content": "Install Terraform. Install determined using pip: pip install determined The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#deploy-a-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#deploy-a-cluster",
    "content": "We recommend creating a new directory and running the commands below inside that directory. The deployment process will create Terraform state and variables files in the directory where it is run. The state file keeps track of deployed resources and their state and is used to update or delete the cluster in the future. The variables files includes all Terraform variables used for deployment (e.g., service account keypath, cluster ID, GCP region and zone). Any future update or deletion commands should be run inside the same directory so det deploy can read the state and variables files. If either of these files is deleted, it will be difficult to manage the deployment afterward. Storing these files in a safe location is strongly recommended. To deploy the cluster, run: det deploy gcp up --cluster-id CLUSTER_ID --project-id PROJECT_ID CLUSTER_ID is an arbitrary unique ID for the new cluster. We recommend choosing a cluster ID that is memorable and helps identify what the cluster is being used for. The deployment process may take 5-10 minutes. When it completes, summary information about the newly deployed cluster will be printed, including the URL of the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": "Required Arguments:",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#required-arguments",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": "Required Arguments:",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#required-arguments",
    "content": "Argument Description Default Value --cluster-id A string appended to resources to uniquely identify the cluster. required --project-id The project to deploy the cluster in. required",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": "Optional Arguments:",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#optional-arguments",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Deploy a Cluster",
      "lvl3": "Optional Arguments:",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#optional-arguments",
    "content": "Argument Description Default Value --keypath The path to the service account JSON key file if using a service account. Including this flag will supersede default Google Cloud user credentials. Not set --preemptible Whether to use preemptible dynamic agent instances. False --gpu-type The type of GPU to use for the agent instances. Ensure gpu_type is available in your selected region and zone by referring to the GPUs on Compute Engine page. nvidia-tesla-t4 --gpu-num The number of GPUs on each agent instance. Between 0 and 8 (more GPUs require a more powerful agent-instance-type). Refer to the GPUs on Compute Engine page for specific GCP requirements. Can be set to 0 for CPU-based training. 4 --max-dynamic-agents Maximum number of dynamic agent instances at one time. 5 --max-aux-containers-per-agent The maximum number of containers running for agents in the auxiliary resource pool. 100 --max-idle-agent-period The length of time to wait before idle dynamic agents will be automatically terminated. 10m --network The network to create (ensure there isn\u2019t a network with the same name already in the project, otherwise the deployment will fail). det-default-cluster-id --region The region to deploy the cluster in. us-west1 --zone The zone to deploy the cluster in. region-b --master-instance-type Instance type to use for the master instance. n1-standard-2 --aux-agent-instance-type Instance type to use for the agent instances in the auxiliary resource pool. n1-standard-4 --compute-agent-instance-type Instance type to use for the agent instances in the compute resource pool. n1-standard-32 --min-cpu-platform-master Minimum CPU platform for the master instance. Intel Skylake --min-cpu-platform-agent Minimum CPU platform for the agent instances. Ensure the platform is compatible with your selected gpu-type and available in your selected region and zone by referring to the GPUs on Compute Engine page. Intel Broadwell --local-state-path Directory used to store cluster metadata. The same directory cannot be used for multiple clusters at the same time. Current working directory --master-config-template-path Path to the custom master.yaml template. Default template can be obtained using det deploy gcp dump-master-config-template. Not set The following gcloud commands will help to validate your configuration, including resource availability in your desired region and zone: # Validate that the GCP Project ID exists. gcloud projects list # Verify that the environment_image is listed. gcloud compute images list --filter=name:<environment_image> # Check that a zone is available in the configured region. gcloud compute zones list --filter=region:<region> # List the available machine types (for master_machine_type and agent_machine_type) in the configured zone. gcloud compute machine-types list --filter=zone:<zone> # List the valid gpu_type values for the configured zone. gcloud compute accelerator-types list --filter=zone:<zone>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Update a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#update-a-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Update a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#update-a-cluster",
    "content": "If you need to make changes to your cluster, you can rerun det deploy gcp up [args] in the same directory and your cluster will be updated. The det deploy tool will only replace resources that need to be replaced based on the changes you\u2019ve made in the updated execution. If you\u2019d like to change the region of a deployment after it has already been deployed, we recommend deleting the cluster first, then redeploying the cluster with the new region.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Destroy a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#destroy-a-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Destroy a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#destroy-a-cluster",
    "content": "To bring down the cluster, run the following in the same directory where you ran det deploy gcp up: det deploy gcp down det deploy will use the .tfstate and terraform.tfvars.json files in the current directory to determine which resources to destroy. If you deployed with a service account JSON key file, the same credentials file will be used for deprovisioning. Otherwise, default Google Cloud credentials are used.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Custom master.yaml templates",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#custom-master-yaml-templates",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Custom master.yaml templates",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#custom-master-yaml-templates",
    "content": "Similarly to a corresponding AWS feature, advanced users who require a deep customization of master settings (i.e., the master.yaml config file) can use the master.yaml templating feature. Since det deploy gcp fills in plenty of infrastructure-related values such as subnetwork ids or boot disk images, we provide a simplified templating solution, similar to helm charts in kubernetes. Template language is based on golang templates, and includes sprig helper library and toYaml serialization helper. Example workflow: Get the default template using det deploy gcp dump-master-config-template > /path/to/master.yaml.tmpl Customize the template as you see fit by editing it in any text editor. For example, let\u2019s say a user wants to utilize (default) 4-GPU instances for the default compute pool, but they also often run single-GPU notebook jobs, for which a single-GPU instance would be perfect. So, you want to add a third pool compute-pool-solo with a customized instance type. Start with the default template, and find the resource_pools section: resource_pools: - pool_name: aux-pool max_aux_containers_per_agent: {{ .resource_pools.pools.aux_pool.max_aux_containers_per_agent }} provider: instance_type: {{- toYaml .resource_pools.pools.aux_pool.instance_type | nindent 8 }} {{- toYaml .resource_pools.gcp | nindent 6}} - pool_name: compute-pool max_aux_containers_per_agent: 0 provider: instance_type: {{- toYaml .resource_pools.pools.compute_pool.instance_type | nindent 8 }} cpu_slots_allowed: true {{- toYaml .resource_pools.gcp | nindent 6}}: Then, append a new section: - pool_name: compute-pool-solo max_aux_containers_per_agent: 0 provider: instance_type: machine_type: n1-standard-4 gpu_type: nvidia-tesla-t4 gpu_num: 1 preemptible: false {{- toYaml .resource_pools.gcp | nindent 6}} Use the new template: det deploy gcp <ALL PREVIOUSLY USED FLAGS> --master-config-template-path /path/to/edited/master.yaml.tmpl All set! Check the Cluster page in WebUI to ensure your cluster has 3 resource pools. In case of errors, ssh to the master instance as instructed by det deploy gcp output, and check sudo journalctl -u google-startup-scripts.service, /var/log/cloud-init-output.log, or sudo docker logs determined-master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Service Account Credentials",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#service-account-credentials",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Service Account Credentials",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#service-account-credentials",
    "content": "For more security controls, you can create a service account or select an existing service account from the service account key page in the Google Cloud Console and ensure it has the following IAM roles: Cloud Filestore Editor Cloud SQL Admin Compute Admin Compute Network Admin Security Admin Service Account Admin Service Account User Service Networking Admin Storage Admin Roles provide the service account permissions to create specific resources in your project. You can add roles to service accounts following this guide. Once you have a service account with the appropriate roles, go to the service account key page in the Google Cloud Console and create a JSON key file. Save it to a location you\u2019ll remember; we\u2019ll refer to the path to this key file as the keypath, which is an optional argument you can supply when using det deploy. Once you have the keypath you can use it to deploy a GCP cluster by continuing the installation section.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Run Determined on NVIDIA A100 GPUs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#run-determined-on-nvidia-a100-gpus",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Run Determined on NVIDIA A100 GPUs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/install-gcp.html#run-determined-on-nvidia-a100-gpus",
    "content": "Determined makes it possible to try out your models on latest NVIDIA A100 GPUs; however, there are a few considerations: A100s may not be available in your default GCP region and zone, and you may need to specify a different one explicitly. See more on GPU availablity. Make sure you have sufficient resource quota for A100s in your target region and zone. See more on quotas. Adjust maximum number of instances and to be within your quota using --max-dynamic-agents NUMBER. This command line will spin up a cluster of up to 2 A100s in the us-central1-c zone: det deploy gcp up --cluster-id CLUSTER_ID --project-id PROJECT_ID \\ --max-dynamic-agents 2 \\ --compute-agent-instance-type a2-highgpu-1g --gpu-num 1 \\ --gpu-type nvidia-tesla-a100 \\ --region us-central1 --zone us-central1-c \\ --gpu-env-image determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 \\ --cpu-env-image determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#deploy-determined-with-dynamic-agents",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#deploy-determined-with-dynamic-agents",
    "content": "This document describes how to install, configure, and upgrade a deployment of Determined with dynamic agents on GCP. For an overview of the elastic infrastructure in Determined, visit Elastic Infrastructure.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#system-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-project",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-project",
    "content": "The Determined master and the Determined agents are intended to run in the same project.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Instance Labels",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#instance-labels",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Instance Labels",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#instance-labels",
    "content": "When using dynamic agents on GCP, Determined identifies the Compute Engine instances that it is managing using a configurable instance label (see Cluster Configuration for details). Administrators should be careful to ensure that this label is not used by other Compute Engine instances that are launched outside of Determined; if that assumption is violated, unexpected behavior may occur.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-images",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-images",
    "content": "The Determined master node will run on a custom image that will be shared with you by Determined AI. Determined agent nodes will run on a custom image that will be shared with you by Determined AI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Machine Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-machine-types",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Compute Engine Machine Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#compute-engine-machine-types",
    "content": "The Determined master node should be deployed on a Compute Engine instance with >= 2 CPUs (Intel Broadwell or later), 4GB of RAM, and 100GB of disk storage. This would be a Compute Engine n1-standard-2 or more powerful.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "GCP API Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#gcp-api-access",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "GCP API Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#gcp-api-access",
    "content": "The Determined master needs to run as a service account that has the permissions to manage Compute Engine instances. There are two options: Create a particular service account with the Compute Admin role. Then set the Determined master to use this account. See Compute Engine IAM roles for more details on how to configure the service account. In order for the Determined agent to be associated with a service account, the Determined master needs to have access to service accounts. Please ensure the service account of the Determined master has the Service Account User role. In order for the Determined agent to use a shared VPC, the service account that the master runs with needs to have the Compute Network User role. Use the default service account and add the Compute Engine: Read Write scope. Optionally, the Determined agent may be associated with a service account. Access scopes are the legacy method of specifying permissions for your instance. A best practice is to set the full cloud-platform access scope on the instance, then securely limit the service account\u2019s API access with Cloud IAM roles. See Access Scopes for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Internet Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#set-up-internet-access",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Internet Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#set-up-internet-access",
    "content": "The Determined Docker images are hosted on Docker Hub. Determined agents need access to Docker Hub for such tasks as building new images for user workloads. If packages, data, or other resources needed by user workloads are hosted on the public Internet, Determined agents need to be able to access them. Note that agents can be configured to use proxies when accessing network resources. For best performance, it is recommended that the Determined master and agents use the same physical network or VPC. When using VPCs on a public cloud provider, additional steps might need to be taken to ensure that instances in the VPC can access the Internet: On GCP, the instances need to have an external IP address, or a GCP Cloud NAT should be configured for the VPC. On AWS, the instances need to have a public IP address, and a VPC Internet Gateway should be configured for the VPC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#set-up-firewall-rules",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#set-up-firewall-rules",
    "content": "The firewall rules must satisfy the following network access requirements for the master and agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#master",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#master",
    "content": "Inbound TCP to the master\u2019s network port from the Determined agent instances, as well as all machines where developers want to use the Determined CLI or WebUI. The default port is 8443 if TLS is enabled and 8080 if not. Outbound TCP to all ports on the Determined agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Agents",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#agents",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Agents",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#agents",
    "content": "Inbound TCP from all ports on the master to all ports on the agent. Outbound TCP from all ports on the agent to the master\u2019s network port. Outbound TCP to the services that host the Docker images, packages, data, and other resources that need to be accessed by user workloads. For example, if your data is stored on Amazon S3, ensure the firewall rules allow access to this data. Inbound and outbound TCP on all ports to and from each Determined agent. The details are as follows: Inbound and outbound TCP ports 1734 and 1750 are used for synchronization between trial containers. Inbound and outbound TCP port 12350 is used for internal SSH-based communication between trial containers. Inbound and outbound TCP port 12355 is used for GLOO rendezvous between trial containers. Inbound and outbound ephemeral TCP ports in the range 1024-65536 are used for communication between trials via GLOO. This range is configured by the configuration parameter task_container_defaults.gloo_port_range inside master.yaml as described in the Configuring the Cluster guide. For every GPU on each agent machine, an inbound and outbound ephemeral TCP port in the range 1024-65536 is used for communication between trials via NCCL. This range is configured by the configuration parameter task_container_defaults.nccl_port_range inside master.yaml as described in the Configuring the Cluster guide. Two additional ephemeral TCP ports in the range 1024-65536 are used for additional intra-trial communication between trial containers. For TensorBoards, an inbound and outbound TCP port between 2600-2900 is used to connect the master and the tensorboard container. The following GPU types are supported by Determined: nvidia-tesla-t4 nvidia-tesla-p100 nvidia-tesla-p4 nvidia-tesla-v100 nvidia-tesla-a100",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Cluster Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#cluster-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Cluster Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#cluster-configuration",
    "content": "The Determined Cluster is configured with master.yaml file located at /usr/local/determined/etc on the Determined master instance. You need to configure GPU dynamic agents in each resource pool. See Configuring the Cluster for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Attach a Disk To Each Dynamic Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#attach-a-disk-to-each-dynamic-agent",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Attach a Disk To Each Dynamic Agent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#attach-a-disk-to-each-dynamic-agent",
    "content": "If your input data set is on a persistent disk, you can attach that disk to each dynamic agent by using the base instance configuration and preparing commands. The following is an example configuration. See REST Resource: instances for the full list of configuration options supported by GCP. See Formatting and mounting a zonal persistent disk for more examples of formatting or mounting disks in GCP. Here is an example master configuration to attach and mount a second disk to each dynamic agent. provider: startup_script: | lsblk mkdir -p /mnt/disks/second mount -o discard,defaults /dev/sdb1 /mnt/disks/second lsblk type: gcp base_config: disks: - mode: READ_ONLY boot: false source: zones/<zone>/disks/<the name of the existing disk> autoDelete: false boot_disk_size: 200 boot_disk_source_image: projects/<project>/global/images/<image name> If a specific non-root user needs to access the disk, please run the tasks linked with the POSIX UID/GID of the user (See Run Tasks as Specific Agent Users for details.) and grant access to the corresponding UID/GID. You can use the following command to validate if Determined tasks can read from the attached disk. cat > command.yaml << EOF bind_mounts: - host_path: /mnt/disks/second container_path: /second EOF # Test attached read-only disk. det command run --config-file command.yaml ls -l /second",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Securely Pull Images from GCR",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#securely-pull-images-from-gcr",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Securely Pull Images from GCR",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#securely-pull-images-from-gcr",
    "content": "If you have expensive operations to perform at startup, it can be useful to add custom layers to the task images Determined provides. If you have store these images in a secure registry, such as GCR, you can pull these images securely by using existing tooling like docker-credential-gcr. Here is an example master configuration of how to allow the agent to inherit the permissions of the service account associated with a GCE instance, for accessing GCR. provider: container_startup_script: | export HOME=/root apt-get update && apt-get install -y curl docker.io curl -fsSL \"https://github.com/GoogleCloudPlatform/docker-credential-gcr/releases/download/v1.5.0/docker-credential-gcr_linux_amd64-1.5.0.tar.gz\" \\ | tar xz --to-stdout > /usr/bin/docker-credential-gcr && chmod +x /usr/bin/docker-credential-gcr docker-credential-gcr configure-docker This is an example of an operation that requires use of container_startup_script. Because Docker credential helpers alter the Docker client configuration to depend on the helper binary by name, it must be installed and configured in the container.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#installation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#installation",
    "content": "These instructions describe how to install Determined for the first time; for directions on how to upgrade an existing Determined installation, see the Upgrades section below. Ensure that you are using the most up-to-date Determined images. Keep the image IDs handy as we will need them later.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#id2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#id2",
    "content": "To install the master, we will launch an instance from the Determined master image. Let\u2019s start by navigating to the Compute Engine Dashboard of the GCP Console. Click \u201cCreate Instance\u201d and follow the instructions below: Choose Machine Type: we recommend a n1-standard-2 or more powerful. Configure Boot Disk: Choose Boot Disk Image: find the Determined master image in \u201cImages\u201d and click \u201cSelect\u201d. Set Boot Disk Size: set Size to be at least 100GB. If you have a previous Determined installation that you are upgrading, you want to use the snapshot or existing disk. This disk will be used to store all your experiment metadata and checkpoints. Configure Identity and API access: choose the service account according to GCP API Access. Configure Firewalls: choose or create a security group according to these Set up Internet Access. Check off Allow HTTP traffic. Review and launch the instance. SSH into the Determined master and edit the config at /usr/local/determined/etc/master.yaml according to the guide on Configuring the Cluster. Start the Determined master by entering make -C /usr/local/determined enable-master into the terminal.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#agent",
    "content": "There is no installation needed for the agent. The Determined master will dynamically launch Determined agent instances based on the Configuring the Cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Upgrades",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#upgrades",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Upgrades",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/dynamic-agents-gcp.html#upgrades",
    "content": "Upgrading an existing Determined installation with dynamic agents on GCP requires the same steps as an installation without dynamic agents. See Upgrade.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#deploy-on-gcp",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#deploy-on-gcp",
    "content": "This document describes how Determined runs on Google Cloud Platform (GCP). For installation, see Install Determined. At a high level, Determined uses Google Compute Engine (GCE) instances as the base unit. The cluster is managed by a master node (a single, non-GPU instance), which in turn provisions and deprovisions other agent nodes (GPU instances) depending on the current volume of experiments being run on the cluster. As an example, if only a master node is running, then you are only being charged for the master. When an experiment is started, the master creates GPU instances as agents, and when the experiment is done the master will turn off the agents so you are not charged for them when no experiments are using them. The master also keeps all experiment metadata in a separate database, which can be queried by the user via the Determined WebUI or CLI. All nodes in the cluster communicate with each other internally within the Virtual Private Cloud (VPC) and the user interacts with the master via a designated port configured during installation. The diagram below outlines the high level architecture of a Determined cluster in GCP. Following the diagram, a standard execution would be: User submits experiment to master Master creates one or more agents (depending on experiment) if they don\u2019t exist Agent accesses required data, images, etc. Agent completes experiment and communicates completion to master Master shuts down agents that are no longer needed There are two types of resources used to run Determined: core resources that enable the Determined platform, and periphery resources that add optional functionality. The section below provides additional detail on these resources. You can deploy these resources in GCP by following the Install Determined guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": "Core Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#core-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": "Core Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#core-resources",
    "content": "Master Node: A single Google Compute Engine (GCE) instance is designated as the master. The master\u2019s primary function is to: host the cluster\u2019s WebUI (browser) where users will monitor their experiments respond to commands from the Determined CLI installed by users locally schedule experiments manage other GCE instances (agents) which run experiments Agent Node(s): For most Determined clusters in GCP, the volume of active experiments dictate the number of agents. All agents are managed by the master and users need not interact with the agents directly. Database: Determined uses a CloudSQL (Postgres) database for storing all experiment metadata. Service Account: A service account is used to manage the creation of compute (GCE) resources and access to Google Cloud Storage (GCS) buckets for checkpoints, TensorBoards, and other data storage as needed. Firewall Rules: Firewall rules are set to ensure each node in the cluster can communicate with each other.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": "Periphery Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#periphery-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on GCP",
      "lvl1": "Deploy on GCP",
      "lvl2": "Periphery Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/gcp/overview.html#periphery-resources",
    "content": "Network/Subnetwork: The Determined cluster can be configured inside an existing VPC or be set to create a new VPC. Static IP: For production clusters, a static IP is recommended for the master; otherwise an ephemeral IP is automatically generated by GCP. Google Filestore: The Determined cluster can leverage an existing GCS Filestore (assuming it has the correct associated permissions), or the Terraform script can create a Filestore instance with the cluster. Google Cloud Storage (GCS) bucket: The Determined cluster can leverage an existing GCS bucket (assuming it has the correct associated permissions), or the Terraform script can create a bucket with the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#install-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#install-determined",
    "content": "This user guide describes how to deploy a Determined cluster on Amazon Web Services (AWS). The det deploy tool makes it easy to create and install these resources. If you would rather create the cluster manually, see the Manual Deployment section below. Store your installation commands and flags in a shell script for future use, particularly for upgrading. For more information about using Determined on AWS, see the Deploy on AWS topic guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#det-deploy-tool",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#det-deploy-tool",
    "content": "The det deploy tool is provided by the determined Python package. It uses AWS CloudFormation to automatically deploy and configure a Determined cluster. CloudFormation builds the necessary components for Determined into a single CloudFormation stack.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Requirements",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#requirements",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Requirements",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#requirements",
    "content": "Either AWS credentials or an IAM role with permissions to access AWS CloudFormation APIs. See the AWS Documentation for information on how to use AWS credentials. An AWS EC2 Keypair. You may also want to increase the EC2 instance limits on your account \u2014 the default instance limits on GPU instances are zero. The default configuration for det deploy can result in launching up to 5 g4dn.metal instances (which have 94 vCPUs each), which would exceed the default quota. AWS instance limits can be increased by submitting a request to the AWS Support Center.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Installation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#installation",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Installation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#installation",
    "content": "det command line tool can be installed using pip: pip install determined The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Deploying",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#deploying",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Deploying",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#deploying",
    "content": "The basic command to deploy a cluster is as follows: det deploy aws up --cluster-id CLUSTER_ID --keypair KEYPAIR_NAME CLUSTER_ID is an arbitrary unique ID for the new cluster. We recommend choosing a cluster ID that is memorable and helps identify what the cluster is being used for. The cluster ID will be used as the AWS CloudFormation stack name. KEYPAIR_NAME is the name of the AWS EC2 key pair to use when provisioning the cluster. If the AWS CLI is installed on your machine, you can get a list of the available keypair names by running aws ec2 describe-key-pairs. The deployment process may take 5\u201310 minutes. When it completes, summary information about the newly deployed cluster will be printed, including the URL of the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Deployment Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#deployment-types",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Deployment Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#deployment-types",
    "content": "det deploy supports multiple deployment types to work with different security needs. The deployment type can be specified using the --deployment-type argument (e.g., det deploy aws --deployment-type secure). simple: The simple deployment provides an easy way to deploy a Determined cluster in AWS. This creates the master instance in the default subnet for the account. efs: The EFS deployment creates an EFS file system and a Determined cluster into a separate VPC. The EFS drive attaches to agent instances at /mnt/efs. This path is automatically bind-mounted into the task containers. fsx: The FSX deployment creates a Lustre FSx file system and a Determined cluster into a separate VPC. The FSx drive attaches to agent instances at /mnt/fsx. This path is automatically bind-mounted into the task containers. secure: The secure deployment creates resources to lock down the Determined cluster. These resources are: A VPC with a public and private subnet A NAT gateway for the private subnet to make outbound connections An S3 VPC gateway so the private subnet can access S3 A bastion instance in the public subnet A master instance in the private subnet",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#cli-arguments",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Spinning up or updating the Cluster",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#spinning-up-or-updating-the-cluster",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Spinning up or updating the Cluster",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#spinning-up-or-updating-the-cluster",
    "content": "det deploy aws up --cluster-id CLUSTER_ID --keypair KEYPAIR_NAME Argument Description Default Value --cluster-id Unique ID for the cluster (used as the CloudFormation stack name). required --keypair The name of the AWS EC2 key pair to use for both master and agent instances. required --region AWS region to deploy into. The default region for the AWS user --profile AWS profile to use for deploying cluster resources. default --master-instance-type AWS instance type to use for the master. m5.large --aux-agent-instance-type AWS instance type to use for the agents in the auxiliary resource pool. Must be one of the following instance types: g4dn.xlarge, g4dn.2xlarge, g4dn.4xlarge, g4dn.8xlarge, g4dn.16xlarge, g4dn.12xlarge, g4dn.metal, g5.xlarge, g5.2xlarge, g5.4xlarge, g5.8xlarge, g5.12xlarge, g5.16xlarge, g5.24xlarge, g5.48large, p3.2xlarge, p3.8xlarge, p3.16xlarge, p3dn.24xlarge, p4d.24xlarge, or any general purpose instance types (t2, t3, c4, c5, m4, m5 and variants). t2.xlarge --compute-agent-instance-type AWS instance type to use for the agents in the compute resource pool. For GPU-based training, must be one of the following instance types: g4dn.xlarge, g4dn.2xlarge, g4dn.4xlarge, g4dn.8xlarge, g4dn.16xlarge, g4dn.12xlarge, g4dn.metal, g5.xlarge, g5.2xlarge, g5.4xlarge, g5.8xlarge, g5.12xlarge, g5.16xlarge, g5.24xlarge, g5.48large, p3.2xlarge, p3.8xlarge, p3.16xlarge, p3dn.24xlarge, or p4d.24xlarge. For CPU-based training or testing, any general purpose instance type may be used (t2, t3, c4, c5, m4, m5 and variants). g4dn.metal --deployment-type The deployment type to use. simple --inbound-cidr CIDR range for inbound traffic. 0.0.0.0/0 --db-password The password for postgres user for database. postgres --max-aux-containers-per-agent The maximum number of containers to launch on each agent in the default auxiliary resource pool. 100 --max-idle-agent-period The length of time to wait before idle dynamic agents will be automatically terminated. 10m (10 minutes) --max-dynamic-agents Maximum number of dynamic agent instances in the default compute resource pool. 5 --spot Use spot instances for the default auxiliary and compute resource pools. False --spot-max-price The maximum price to use when launching spot instances. If the current spot market price exceeds this value, Determined will not create new instances. If no maximum price is configured, the maximum price will be the on-demand price for the configured instance type and region. Not set --dry-run Print the template but do not execute it. False --master-config-template-path Path to the custom master.yaml template. Default template can be obtained using det deploy aws dump-master-config-template. Not set --efs-id Preexisting EFS file system that will be mounted into the task containers; if not provided, a new EFS instance will be created. The agents must be able to connect to the EFS instance. This option can only be used together with the efs deployment type. Not set --fsx-id Preexisting FSx file system that will be mounted into the task containers; if not provided, a new FSx instance will be created. The agents must be able to connect to the FSx instance. This option can only be used together with the fsx deployment type. Not set --shut-down-on-connection-loss, --no-shut-down-on-connection-loss Whether or not agent instances should automatically shut down when they lose connection to the master. Shut down automatically",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Tearing Down the Cluster",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#tearing-down-the-cluster",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Tearing Down the Cluster",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#tearing-down-the-cluster",
    "content": "det deploy aws down --cluster-id CLUSTER_ID Argument Description Default Value --cluster-id Unique ID for the cluster (used as the CloudFormation stack name). required --region AWS region deployed into. The default region for the AWS user --profile AWS profile used for deploying cluster resources. default",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Listing Clusters",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#listing-clusters",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Listing Clusters",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#listing-clusters",
    "content": "det deploy aws list Argument Description Default Value --region AWS region to deploy into. The default region for the AWS user --profile AWS profile used for deploying cluster resources. default",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Printing the default master.yaml template",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#printing-the-default-master-yaml-template",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "CLI Arguments",
      "lvl4": "Printing the default master.yaml template",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#printing-the-default-master-yaml-template",
    "content": "det deploy aws dump-master-config-template",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Custom master.yaml templates",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#custom-master-yaml-templates",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Custom master.yaml templates",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#custom-master-yaml-templates",
    "content": "Advanced users who require a deep customization of master settings (i.e., the master.yaml config file) can use the master.yaml templating feature. Since det deploy aws fills in plenty of infrastructure-related values such as VPC subnet ids or IAM instance profile roles, we provide a simplified templating solution, similar to helm charts in kubernetes. Template language is based on golang templates, and includes sprig helper library and toYaml serialization helper. Example workflow: Get the default template using det deploy aws dump-master-config-template > /path/to/master.yaml.tmpl Customize the template as you see fit by editing it in any text editor. For example, let\u2019s say a user wants to utilize (default) g4dn.metal 8-GPU instances for the default compute pool, but they also often run single-GPU notebook jobs, for which a single g4dn.xlarge instance would be perfect. So, you want to add a third pool compute-pool-solo with a customized instance type. Start with the default template, and find the resource_pools section: resource_pools: - pool_name: aux-pool max_aux_containers_per_agent: {{ .resource_pools.pools.aux_pool.max_aux_containers_per_agent }} provider: instance_type: {{ .resource_pools.pools.aux_pool.instance_type }} {{- toYaml .resource_pools.aws | nindent 6}} - pool_name: compute-pool max_aux_containers_per_agent: 0 provider: instance_type: {{ .resource_pools.pools.compute_pool.instance_type }} cpu_slots_allowed: true {{- toYaml .resource_pools.aws | nindent 6}} Then, append a new section: - pool_name: compute-pool-solo max_aux_containers_per_agent: 0 provider: instance_type: g4dn.xlarge {{- toYaml .resource_pools.aws | nindent 6}} Use the new template: det deploy aws <ALL PREVIOUSLY USED FLAGS> --master-config-template-path /path/to/edited/master.yaml.tmpl All set! Check the Cluster page in WebUI to ensure your cluster has 3 resource pools. In case of errors, ssh to the master instance as instructed by det deploy aws output, and check /var/log/cloud-init-output.log or sudo docker logs determined-master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Modifying a Deployment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#modifying-a-deployment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "det deploy tool",
      "lvl3": "Modifying a Deployment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#modifying-a-deployment",
    "content": "To modify an already deployed cluster you have a few options: If what you\u2019d like to change is provided as a det deploy CLI option, you can re-deploy the cluster using det deploy. Use the same full det deploy command as on cluster creation, but update the options as necessary, while keeping the cluster-id the same. det deploy will then find the existing cluster, take it down, and spin up a new one with the updated options. If you want more control over the master configuration while minimizing downtime, you can SSH into the master instance using the private key from the keypair that was used to provision the cluster. Once you\u2019re successfully connected, you can modify master.yaml under /usr/local/determined/etc and restart the master Docker container for your changes to take effect: sudo docker container restart determined-master For example, if you want to add or modify resource pools you can edit the master configuration file at /usr/local/determined/etc/master.yaml and add a new resource pool entry.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#manual-deployment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Database",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#database",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Database",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#database",
    "content": "Determined requires a PostgreSQL-compatible database, such as AWS Aurora. Configure the cluster to use the database by including the database information in master.yaml. Make sure to create a database before running the Determined cluster (e.g., CREATE DATABASE <database-name>). Example master.yaml snippet: db: user: \"${database-user}\" password: \"${database-password}\" host: \"${database-hostname}\" port: 5432 name: \"${database-name}\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#security-groups",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#security-groups",
    "content": "VPC Security Groups provide a set of rules for inbound and outbound network traffic. The requirements for a Determined cluster are:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#master",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#master",
    "content": "Egress on all ports to agent security group Egress on all ports to the Internet Ingress on port 8080 for access the Determined WebUI and REST APIs Ingress on port 22 for SSH (recommended but not required) Ingress on all ports from agent security group Example: MasterSecurityGroupEgress: Type: AWS::EC2::SecurityGroupEgress Properties: GroupId: !GetAtt MasterSecurityGroup.GroupId DestinationSecurityGroupId: !GetAtt AgentSecurityGroup.GroupId FromPort: 0 ToPort: 65535 IpProtocol: tcp MasterSecurityGroupInternet: Type: AWS::EC2::SecurityGroupEgress Properties: GroupId: !GetAtt MasterSecurityGroup.GroupId CidrIp: 0.0.0.0/0 FromPort: 0 ToPort: 65535 IpProtocol: tcp MasterSecurityGroupIngress: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt MasterSecurityGroup.GroupId FromPort: 8080 ToPort: 8080 IpProtocol: tcp SourceSecurityGroupId: !GetAtt AgentSecurityGroup.GroupId MasterSecurityGroupIngressUI: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt MasterSecurityGroup.GroupId FromPort: 8080 ToPort: 8080 IpProtocol: tcp CidrIp: !Ref InboundCIDRRange MasterSSHIngress: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt MasterSecurityGroup.GroupId IpProtocol: tcp FromPort: 22 ToPort: 22 CidrIp: !Ref InboundCIDRRange",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": "Agent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#agent",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Security Groups",
      "lvl4": "Agent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#agent",
    "content": "Egress on all ports to the Internet Ingress on all ports from master security group Ingress on all ports from agent security group Ingress on port 22 for SSH (recommended but not required) Example: AgentSecurityGroupEgress: Type: AWS::EC2::SecurityGroupEgress Properties: GroupId: !GetAtt AgentSecurityGroup.GroupId CidrIp: 0.0.0.0/0 FromPort: 0 ToPort: 65535 IpProtocol: tcp AgentSecurityGroupIngressMaster: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt AgentSecurityGroup.GroupId FromPort: 0 ToPort: 65535 IpProtocol: tcp SourceSecurityGroupId: !GetAtt MasterSecurityGroup.GroupId AgentSecurityGroupIngressAgent: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt AgentSecurityGroup.GroupId FromPort: 0 ToPort: 65535 IpProtocol: tcp SourceSecurityGroupId: !GetAtt AgentSecurityGroup.GroupId AgentSSHIngress: Type: AWS::EC2::SecurityGroupIngress Properties: GroupId: !GetAtt AgentSecurityGroup.GroupId IpProtocol: tcp FromPort: 22 ToPort: 22 CidrIp: !Ref InboundCIDRRange",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#iam-roles",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#iam-roles",
    "content": "IAM roles comprise IAM policies, which provide access to AWS APIs such as the EC2 or S3 API. The IAM policies needed for the Determined cluster are:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#id1",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#id1",
    "content": "Allow EC2 to assume role Allow EC2 to describe, create, and terminate instances with agent role Allow EC2 to describe, create, and terminate spot instance requests (only required if using spot instances) MasterRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: Service: - ec2.amazonaws.com Action: - sts:AssumeRole Policies: - PolicyName: determined-agent-policy PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - ec2:DescribeInstances - ec2:TerminateInstances - ec2:CreateTags - ec2:RunInstances - ec2:CancelSpotInstanceRequests # Only required if using spot instances - ec2:RequestSpotInstances # Only required if using spot instances - ec2:DescribeSpotInstanceRequests # Only required if using spot instances Resource: \"*\" - PolicyName: pass-role PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: iam:PassRole Resource: !GetAtt AgentRole.Arn",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": "Agent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#id2",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "IAM Roles",
      "lvl4": "Agent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#id2",
    "content": "Allow EC2 to assume role Allow S3 access for checkpoint storage Allow agent instance to describe instances AgentRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: Service: - ec2.amazonaws.com Action: - sts:AssumeRole Policies: - PolicyName: agent-s3-policy PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: \"s3:*\" Resource: \"*\" - PolicyName: determined-ec2 PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - ec2:DescribeInstances Resource: \"*\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Master Node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#master-node",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Install Determined",
      "lvl1": "Install Determined",
      "lvl2": "Manual Deployment",
      "lvl3": "Master Node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/install-on-aws.html#master-node",
    "content": "The master node should be deployed on an EC2 instance with at least 4 CPUs (Intel Broadwell or later), 8GB of RAM, and 200GB of disk storage. This roughly corresponds to an EC2 t2.large instance or better. The AMI should be the default Ubuntu 18.04 AMI. To run Determined: Install Docker and create the determined Docker network. apt-get remove docker docker-engine docker.io containerd runc apt-get update apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" apt-get update apt-get install -y docker-ce docker-ce-cli containerd.io docker network create determined Configure the cluster with master.yaml. See Configuring the Cluster for more information. Notes: image_id should be the latest Determined agent AMI. instance_type should be any p2 or p3 EC2 instance type. For more information about resource pools, see Resource Pools An important assumption of Determined with dynamic agents is that any EC2 instances with the configured tag_key:tag_value pair are managed by the Determined master. This pair should be unique to your Determined installation. If it is not, Determined may inadvertently manage your non-Determined EC2 instances. If using spot instances, Determined also assumes that any EC2 spot instance requests with the configured tag_key:tag_value pair are managed by the Determined master. checkpoint_storage: type: s3 bucket: ${CheckpointBucket} db: user: postgres password: \"${DBPassword}\" host: \"${Database.Endpoint.Address}\" port: 5432 name: determined resource_pools: - pool_name: default description: The default resource pool provider: iam_instance_profile_arn: ${AgentInstanceProfile.Arn} image_id: ${AgentAmiId} agent_docker_image: determinedai/determined-agent:${Version} instance_name: determined-agent-${UserName} instance_type: ${AgentInstanceType} master_url: http://local-ipv4:8080 max_idle_agent_period: ${MaxIdleAgentPeriod} max_instances: ${MaxInstances} network_interface: public_ip: true security_group_id: ${AgentSecurityGroup.GroupId} type: aws ssh_key_name: ${Keypair} tag_key: determined-${UserName} tag_value: determined-${UserName}-agent Start the Determined master. docker run \\ --rm \\ --network determined \\ -p 8080:8080 \\ -v master.yaml:/etc/determined/master.yaml \\ determinedai/determined-master:${Version}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#deploy-determined-with-dynamic-agents",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#deploy-determined-with-dynamic-agents",
    "content": "This document describes how to install, configure, and upgrade a deployment of Determined with dynamic agents on AWS. See Elastic Infrastructure for an overview of using elastic infrastructure in Determined. Determined is able to launch dynamic agents as spot instances, which can be much less costly than using standard on-demand instances. For more details on spot instances, see Use Spot Instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#system-requirements",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 Instance Tags",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-instance-tags",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 Instance Tags",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-instance-tags",
    "content": "An important assumption of Determined with dynamic agents is that any EC2 instances with the configured tag_key:tag_value pair are managed by the Determined master (See Cluster Configuration). This pair should be unique to your Determined installation. If it is not, Determined may inadvertently manage your non-Determined EC2 instances. If using spot instances, Determined also assumes that any EC2 spot instance requests with the configured tag_key:tag_value pair are managed by the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 AMIs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-amis",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 AMIs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-amis",
    "content": "The Determined master node will run on a custom AMI that will be shared with you by Determined AI. Determined agent nodes will run on a custom AMI that will be shared with you by Determined AI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 Instance Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-instance-types",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "EC2 Instance Types",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#ec2-instance-types",
    "content": "The Determined master node should be deployed on an EC2 instance supporting >= 2 CPUs (Intel Broadwell or later), 4GB of RAM, and 100GB of disk storage. This corresponds to an EC2 t2.medium instance or better. All Determined agent nodes must be the same AWS instance type; any G4, P2, or P3 instance type is supported. This can be configured in the Cluster Configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Master IAM Role",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#master-iam-role",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Master IAM Role",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#master-iam-role",
    "content": "The Determined master needs to have an IAM role with the following permissions: ec2:CreateTags: used to tag the Determined agent instances that the Determined master provisions. These tags are configured by the aws-cluster-configuration. ec2:DescribeInstances: used to find active Determined agent instances based on tags. ec2:RunInstances: used to provision Determined agent instances. ec2:TerminateInstances: used to terminate idle Determined agent instances. If using spot instances, the master also needs the following permissions: ec2:RequestSpotInstances: used to provision Determined agent instances as spot instances. ec2:CancelSpotInstanceRequests: used to adjust the number of spot instance requests to match the number of instances needed for the current workloads. ec2:DescribeSpotInstanceRequests: used to find open spot instance requests that, once fulfilled, will create Determined agent spot instances. An example IAM policy with the appropriate permissions is below: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"ec2:DescribeInstances\", \"ec2:TerminateInstances\", \"ec2:CreateTags\", \"ec2:RunInstances\", \"ec2:CancelSpotInstanceRequests\", \"ec2:RequestSpotInstances\", \"ec2:DescribeSpotInstanceRequests\", ], \"Resource\": \"*\" } ] } If you need to attach an instance profile to the agent (e.g., iam_instance_profile_arn is set in the Cluster Configuration), make sure to add PassRole policy to the master role with Resource set to the desired agent role. For example: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"iam:PassRole\", \"Resource\": \"<arn::agent-role>\" } ] } See Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Internet Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#set-up-internet-access",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Internet Access",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#set-up-internet-access",
    "content": "The Determined Docker images are hosted on Docker Hub. Determined agents need access to Docker Hub for such tasks as building new images for user workloads. If packages, data, or other resources needed by user workloads are hosted on the public Internet, Determined agents need to be able to access them. Note that agents can be configured to use proxies when accessing network resources. For best performance, it is recommended that the Determined master and agents use the same physical network or VPC. When using VPCs on a public cloud provider, you may need to take additional steps to ensure instances in the VPC can access the Internet: On GCP, either the instances must have an external IP address or a GCP Cloud NAT should be configured for the VPC. On AWS, the instances must have a public IP address and a VPC Internet Gateway should be configured for the VPC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#set-up-firewall-rules",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#set-up-firewall-rules",
    "content": "The firewall rules must satisfy the following network access requirements for the master and agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#master",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Master",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#master",
    "content": "Inbound TCP to the master\u2019s network port from the Determined agent instances, as well as all machines where developers want to use the Determined CLI or WebUI. The default port is 8443 if TLS is enabled and 8080 if not. Outbound TCP to all ports on the Determined agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Agents",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#agents",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "System Requirements",
      "lvl3": "Set up Firewall Rules",
      "lvl4": "Agents",
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#agents",
    "content": "Inbound TCP from all ports on the master to all ports on the agent. Outbound TCP from all ports on the agent to the master\u2019s network port. Outbound TCP to the services that host the Docker images, packages, data, and other resources that need to be accessed by user workloads. For example, if your data is stored on Amazon S3, ensure the firewall rules allow access to this data. Inbound and outbound TCP on all ports to and from each Determined agent. The details are as follows: Inbound and outbound TCP ports 1734 and 1750 are used for synchronization between trial containers. Inbound and outbound TCP port 12350 is used for internal SSH-based communication between trial containers. Inbound and outbound TCP port 12355 is used for GLOO rendezvous between trial containers. Inbound and outbound ephemeral TCP ports in the range 1024-65536 are used for communication between trials via GLOO. This range is configured by the configuration parameter task_container_defaults.gloo_port_range inside master.yaml as described in the Configuring the Cluster guide. For every GPU on each agent machine, an inbound and outbound ephemeral TCP port in the range 1024-65536 is used for communication between trials via NCCL. This range is configured by the configuration parameter task_container_defaults.nccl_port_range inside master.yaml as described in the Configuring the Cluster guide. Two additional ephemeral TCP ports in the range 1024-65536 are used for additional intra-trial communication between trial containers. For TensorBoards, an inbound and outbound TCP port between 2600-2900 is used to connect the master and the tensorboard container.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Cluster Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cluster-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Cluster Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cluster-configuration",
    "content": "The Determined Cluster is configured with master.yaml file located at /usr/local/determined/etc/ on the Determined master instance. You need to configure AWS dynamic agents in each resource pool. See Configuring the Cluster for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#installation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#installation",
    "content": "These instructions describe how to install Determined for the first time. For directions on how to upgrade an existing Determined installation, see the Upgrades section below. Ensure that you are using the most up-to-date Determined AMIs. Keep the AMI IDs handy; you will need them later (e.g., ami-0f4677bfc3161edc8).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#id2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Master",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#id2",
    "content": "To install the master, we will launch an instance from the Determined master AMI. Let\u2019s start by navigating to the EC2 Dashboard of the AWS Console. Click \u201cLaunch Instance\u201d and follow the instructions below: Choose AMI: find the Determined master AMI in \u201cMy AMIs\u201d and click \u201cSelect\u201d. Choose Instance Type: we recommend a t2.medium or more powerful. Configure Instance: choose the IAM role according to Master IAM Role. Add Storage: click Add New Volume and add an EBS volume of at least 100GB. If you have a previous Determined installation that you are upgrading, you want to attach the same EBS volume as the previous installation. This volume will be used to store all your experiment metadata and checkpoints. Configure Security Group: choose or create a security group according to Set up Internet Access. Review and launch the instance. SSH into the Determined master and edit the config at /usr/local/determined/etc/master.yaml according to the guide on Cluster Configuration. Start the Determined master by entering make -C /usr/local/determined enable-master into the terminal.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Installation",
      "lvl3": "Agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#agent",
    "content": "There is no installation needed for the agent. The Determined master will dynamically launch Determined agent instances based on the Cluster Configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Upgrades",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#upgrades",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Upgrades",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#upgrades",
    "content": "Upgrading an existing Determined installation with dynamic agents on AWS requires the same steps as an installation without dynamic agents. See Upgrade.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#monitoring",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#monitoring",
    "content": "Both the Determined master and agent AMIs are configured to forward system journald logs and basic GPU metrics to AWS CloudWatch when their instances have the appropriate IAM permissions. These logs and metrics can be helpful for diagnosing infrastructure issues when using dynamic agents on AWS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": "CloudWatch Logging",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cloudwatch-logging",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": "CloudWatch Logging",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cloudwatch-logging",
    "content": "An instance needs the following permissions to upload logs to CloudWatch: logs:CreateLogStream logs:PutLogEvents logs:DescribeLogStreams Instances will upload their logs to the log group /determined/determined/journald. This log group must be created in advance before any logs can be stored. An example IAM policy with the appropriate permissions is below: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\", \"logs:DescribeLogStreams\" ], \"Resource\": [ \"arn:aws:logs:*:*:log-group:/determined/determined/journald\", \"arn:aws:logs:*:*:log-group:/determined/determined/journald:log-stream:*\" ] } ] }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": "CloudWatch Metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cloudwatch-metrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy Determined with Dynamic Agents",
      "lvl1": "Deploy Determined with Dynamic Agents",
      "lvl2": "Monitoring",
      "lvl3": "CloudWatch Metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/dynamic-agents-aws.html#cloudwatch-metrics",
    "content": "An instance needs the following permissions to upload logs to CloudWatch: cloudwatch:PutMetricData Instances will upload their metrics to namespace Determined. An example IAM policy with the appropriate permissions is below. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"cloudwatch:PutMetricData\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" } ] }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#deploy-on-aws",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#deploy-on-aws",
    "content": "This section describes how Determined runs on Amazon Web Services (AWS). For installation, see Install Determined. A master node (a single, non-GPU instance) manages the cluster, provisioning and terminating agent nodes dynamically as new workloads are started by users. The master stores metadata in an external database; using AWS Aurora or RDS is recommended. Users interact with the cluster by using a CLI or visiting the WebUI hosted on the master. Nodes in the cluster communicate with one another over a Virtual Private Cloud (VPC); users interact with the master via a designated external port configured during installation. Following the diagram, a standard execution would be: User submits experiment to master Master creates one or more agents (depending on experiment) if they don\u2019t exist Agent accesses required data, images, etc. Agent completes experiment and communicates completion to master Master shuts down agents that are no longer needed This section provides details on the core resources, which are required to run Determined, and peripheral resources, which are optionally configurable based on user requirements.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": "Core Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#core-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": "Core Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#core-resources",
    "content": "Master Node: A single EC2 instance that: hosts the Determined WebUI where users monitor their experiments responds to commands from the Determined CLI schedules workloads manages other EC2 instances (agents) that run experiments Agent Node(s): For most Determined clusters in AWS, the number of agents varies with the volume and type of workloads currently running. All agents are managed by the master and users do not have to interact with them directly. For more information on scaling clusters, or dynamic agents, see Elastic Infrastructure. Database: Determined uses an Amazon Relational Database Service (Postgres) database to store metadata. AWS Identity and Access Management (IAM): IAM roles are attached to the instances to manage the creation of compute (EC2) resources and access to Amazon Simple Storage Service (S3) buckets for checkpoints, TensorBoards, and other data storage as needed. Security Groups: VPC Security Groups ensure that each node in the cluster can communicate with each other.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": "Periphery Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#periphery-resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deploy on AWS",
      "lvl1": "Deploy on AWS",
      "lvl2": "Periphery Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/overview.html#periphery-resources",
    "content": "Network/Subnetwork: The Determined cluster runs in an existing or newly created VPC. Elastic IP: For production clusters, the master should have an associated elastic IP; otherwise, AWS automatically assigns an ephemeral IP. Amazon Simple Storage Service (S3) Bucket: The Determined cluster can leverage an existing S3 bucket (assuming it has the correct associated permissions), or the CloudFormation script can create a bucket with the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#use-spot-instances",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#use-spot-instances",
    "content": "This document describes how to use AWS spot instances with Determined. Spot instances can be much cheaper than on-demand instances (up to 90% cheaper, but more often 70-80%) but they are unreliable, so software that runs on spot instances must be fault tolerant. Unfortunately, deep learning code is often not written with fault tolerance in mind, preventing many practitioners from using spot instances easily. Because Determined was built with fault tolerance as a core feature, it works seamlessly when run on top of spot instances, allowing users to reduce their training costs by setting a single flag in the Configuring the Cluster. Determined handles most details of working with spot instances, but knowing how spot instances work at a high level is helpful for understanding the behavior of Determined when provisioning spot instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "On-Demand vs Spot",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#on-demand-vs-spot",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "On-Demand vs Spot",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#on-demand-vs-spot",
    "content": "The standard way to create an EC2 instance is to create an on-demand instance. On-demand instances always have the same price and once you have created one, you will keep that instance indefinitely. The number of EC2 instances desired by customers varies over time. AWS wants to have enough hardware so that during peak usage periods, all customers are able to get as many on-demand instances as they need. This means that during non-peak periods (which is most of the time), AWS has extra hardware capacity sitting around unused. AWS makes these extra instances available to customers via the spot market as spot instances. They can be rented at a much reduced cost, but the trade-off is that, if AWS needs instances to satisfy on-demand users, they can reclaim your spot instance and give it to the on-demand user. If all available instances are in use by on-demand customers, you will not be able to launch any spot instances. Because spot capacity depends on supply and demand, your ability to launch spot instances will vary by region/availability zone, as well as instance type. GPU instances, particularly those with the most modern GPUs, are often in high demand and they may sometimes be difficult to get as spot instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Using Spot Instances with Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#using-spot-instances-with-determined",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Using Spot Instances with Determined",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#using-spot-instances-with-determined",
    "content": "Because they can be reclaimed, using spot instances requires you to have good fault tolerance built into your software. Determined was built with fault-tolerance as a core feature, so using spot instances is usually as easy as configuring a resource pool with spot: true in the master configuration. Here is a fragment of a master configuration file that defines a resource pool with up to 10 g4dn.metal spot instances: resource_pools: - pool_name: aws-spot-g4dn-metal provider: type: aws max_instances: 10 instance_type: g4dn.metal spot: true # ... When using det deploy to install Determined on AWS, you can also specify --spot when running det deploy aws up to cause the default CPU and GPU resource pools to use spot instances. AWS might not always have the capacity to fulfill spot requests. When AWS is out of capacity, the Determined cluster will wait until AWS has capacity and can fulfill the requests. This will be visible in the master logs. A useful approach is to configure the master with two resource pools, one that uses spot instances and another that uses on-demand instances. This allows users to easily select whether to use spot or on-demand instances for a given job by setting resources.resource_pool appropriately in their experiment configuration file.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Spot Pricing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#spot-pricing",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Spot Pricing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#spot-pricing",
    "content": "Unlike on-demand instances, the market price of a spot instance varies. Once the spot instance has been created, the hourly cost to run that instance is constant, but if you try to create another spot instance, the price may have changed. The spot price is typically around 70% less than the on-demand price (see AWS\u2019s spot advisor for up-to-date information), but it can technically rise as high as the on-demand price. AWS and Determined allow you to specify the maximum price that you are willing to pay for a spot instance. If the market price is above that number, the spot instance will not be created until the price falls under your maximum price. You can set this value via the spot_max_price field in the master configuration. The market price being above your spot_max_price is another reason why Determined may not be creating spot instances when you expect it to. If this is preventing Determined from creating spot instances, this will be visible in the master logs. Many users want to reduce costs by using spot instances, but have deadlines and are not willing to delay their experiments. In this case, it may be best to not set spot_max_price and pay whatever the market price is. Your mileage may vary, but at Determined, we have regularly seen 70% cost reductions when using V100s, without specifying a spot_max_price.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Troubleshooting",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#troubleshooting",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Use Spot Instances",
      "lvl1": "Use Spot Instances",
      "lvl2": "Troubleshooting",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "setup-cluster/deploy-cluster/aws/aws-spot.html#troubleshooting",
    "content": "Some users may encounter the following error in the Determined master logs the first time they try to use spot instances: AWS error while launching spot instances, AuthFailure.ServiceLinkedRoleCreationNotPermitted, The provided credentials do not have permission to create the service-linked role for EC2 Spot Instances. When this error occurs, please check the AWS documentation. Most likely, you will need to use the AWS CLI to create the AWSServiceRoleForEC2Spot role: aws iam create-service-linked-role --aws-service-name spot.amazonaws.com",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reference",
      "lvl1": "Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/index.html#reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reference",
      "lvl1": "Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/index.html#reference",
    "content": "<div class=\"landing\"> <div class=\"tiles-flex\"> <div class=\"tile-container\"> <a class=\"tile\" href=\"python-sdk.html\"> <h2 class=\"tile-title\">Python SDK</h2> <p class=\"tile-description\">You can interact with a Determined cluster with the Python SDK.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"rest-api.html\"> <h2 class=\"tile-title\">REST API</h2> <p class=\"tile-description\">The Determined REST API allows you to interact with a Determined cluster programmatically.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"training/index.html\"> <h2 class=\"tile-title\">Training API Reference</h2> <p class=\"tile-description\">Reference documentation for the Training APIs and Experiment Configuration File.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"model-hub/index.html\"> <h2 class=\"tile-title\">Model Hub Reference</h2> <p class=\"tile-description\">Reference documentation for the Model Hub APIs.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"deploy/index.html\"> <h2 class=\"tile-title\">Deployment Reference</h2> <p class=\"tile-description\">Reference documentation for configuring Determined deployment.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"interface/job-config-reference.html\"> <h2 class=\"tile-title\">Job Configuration Reference</h2> <p class=\"tile-description\">Configuration reference information for interactive jobs such as TensorBoards, notebooks, commands, and shells.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"searcher/custom-searcher-reference.html\"> <h2 class=\"tile-title\">Custom Searcher Reference</h2> <p class=\"tile-description\">Reference documentation for custom search methods.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"cli-reference.html\"> <h2 class=\"tile-title\">CLI Reference</h2> <p class=\"tile-description\">Reference documentation for the Determined CLI.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../interfaces/index.html\"> <h2 class=\"tile-title\">Tools</h2> <p class=\"tile-description\">Get help for using tools and interfaces including how to install the Determined CLI.</p> </a> </div> </div> </div>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI Reference",
      "lvl1": "Determined CLI Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/cli-reference.html#determined-cli-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI Reference",
      "lvl1": "Determined CLI Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/cli-reference.html#determined-cli-reference",
    "content": "User Guide Determined CLI User Guide The Determined CLI has built-in documentation that you can access by using the help command or -h and --help flags. To see a comprehensive list of nouns and abbreviations, simply call det help or det -h. Each noun has its own set of associated verbs, which are detailed in the help documentation. For example, to learn more about individual experiment commands, you can type det experiment help. usage: det [-h] [-u username] [-m address] [-v] command ... Determined command-line client positional arguments: command help show help for this command auth manage auth agent (a) manage agents command (cmd) manage commands checkpoint (c) manage checkpoints deploy (d) manage deployments experiment (e) manage experiments job (j) manage job master (m) manage master model (m) manage models notebook manage notebooks oauth manage OAuth preview-search preview search resources (res) query historical resource allocation shell manage shells slot (s) manage slots task manage tasks (commands, experiments, notebooks, shells, tensorboards) template (tpl) manage config templates tensorboard manage TensorBoard instances trial (t) manage trials user (u) manage users version show version information optional arguments: -h, --help show this help message and exit -u username, --user username run as the given user (default: None) -m address, --master address master address (default: localhost:8080) -v, --version print CLI version and exit",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI Reference",
      "lvl1": "Determined CLI Reference",
      "lvl2": "Syntax",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/cli-reference.html#syntax",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI Reference",
      "lvl1": "Determined CLI Reference",
      "lvl2": "Syntax",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/cli-reference.html#syntax",
    "content": "det [-h] [-u username] [-m address] [-v] command ... det: This is the main command you\u2019ll use for interacting with the Determined AI CLI. [-h]: The square brackets indicate that this is an optional argument. -h``or ``--help can be used to display a help message and exit. If you need information about a specific command, add the -h flag after the det command. [-u username]: Another optional argument, -u or --user allows you to run the command as a specific user. Replace username with the desired username. For example, to run a command as user \u201cabbie\u201d, you would use det -u abbie command. [-m address]: This optional argument, -m or --master, lets you specify the master address for the Determined cluster. Replace address with the actual address of the master, e.g., localhost:8080. [-v]: The -v or --version flag is another optional argument that you can use to print the CLI version and exit. command: This represents the specific subcommand you want to execute such as list, pause, logs, or kill. You\u2019ll replace command with the actual command you want to run. \u2026: The ellipsis signifies that you can provide additional arguments, options, or values, depending on the subcommand you choose.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#rest-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#rest-api-reference",
    "content": "The Determined REST API provides a way to interact with a Determined cluster programmatically. The API reference documentation includes detailed information about the REST API endpoints and a playground for interacting with the API. The protobuf mechanism is used to define language-agnostic message structures. These type definitions are used with gRPC-gateway to provide consistent REST endpoints that serve various needs. These tools are used to autogenerate an OpenAPI v2 specification, which inlines documentation for each endpoint and response message. The specification can be served to different tools to generate code for different languages and to provide web-based explorers, such as the Swagger UI, for the API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#reference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#reference",
    "content": "REST API Reference Determined REST API The REST API reference documentation lists available endpoints grouped by workflow. Click an endpoint method to see the expected input parameters and response. You can also use Try it out button to make an HTTP request against the endpoint. You need to have the appropriate cookie set and a running cluster for an interactive request. If you have access to a running Determined cluster you can try the live-interact version by clicking the API icon from the Determined WebUI or by navigating to /docs/rest-api/ on your Determined cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Authentication",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#authentication",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Authentication",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#authentication",
    "content": "Most of the API calls to a Determined cluster require authentication. On each API call, the server expects a Bearer token. To receive a token, POST a valid username and password combination to the login endpoint, /api/v1/auth/login using the following format: { \"username\": \"string\", \"password\": \"string\" } Example request: curl -s \"${DET_MASTER}/api/v1/auth/login\" \\ -H 'Content-Type: application/json' \\ --data-binary '{\"username\":\"determined\",\"password\":\"\"}' Example response: { \"token\": \"string\", \"user\": { \"username\": \"string\", \"admin\": true, \"active\": true, \"agent_user_group\": { \"agent_uid\": 0, \"agent_gid\": 0 } } } When you receive the token, store it and attach it to future API calls under the Authorization header in the Bearer $TOKEN format.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#example",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "REST API",
      "lvl1": "REST API",
      "lvl2": "Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/rest-api.html#example",
    "content": "This example shows how to use the REST API to unarchive a previously archived experiment. To find an archived experiment, look up the experiment endpoint to find which filtering options are provided. They are archived and limit. Including a bearer token to authenticate the request, use the archived and limit query parameters to limit the result set to only show a single archived experiment: curl -H \"Authorization: Bearer ${token}\" \"${DET_MASTER}/api/v1/experiments?archived=true&limit=1\" JSON response: { \"experiments\": [ { \"id\": 16, \"description\": \"mnist_pytorch_const\", \"labels\": [], \"startTime\": \"2020-08-26T20:12:35.337160Z\", \"endTime\": \"2020-08-26T20:12:51.951720Z\", \"state\": \"STATE_COMPLETED\", \"archived\": true, \"numTrials\": 1, \"progress\": 0, \"username\": \"determined\" } ], \"pagination\": { \"offset\": 0, \"limit\": 1, \"startIndex\": 0, \"endIndex\": 1, \"total\": 1 } } In the archive endpoint entry, you can see that all that you need is an experiment ID. With the experiment ID you want, you can now unarchive the experiment using the unarchive endpoint in a POST request: curl -H \"Authorization: Bearer ${token}\" -X POST \"${DET_MASTER}/api/v1/experiments/16/unarchive\"",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#python-sdk",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#python-sdk",
    "content": "You can interact with a Determined cluster with the Python SDK. The client module exposes many of the same capabilities as the det CLI tool directly to Python code with an object-oriented interface.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Experiment Workflow Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#experiment-workflow-example",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Experiment Workflow Example",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#experiment-workflow-example",
    "content": "As a simple example, let\u2019s walk through the most basic workflow for creating an experiment, waiting for it to complete, and finding the top-performing checkpoint. The first step is to import the client module and possibly to call login(): from determined.experimental import client # We will assume that you have called `det user login`, so this is unnecessary: # client.login(master=..., user=..., password=...) The next step is to call create_experiment(): # Config can be a path to a config file or a Python dict of the config. exp = client.create_experiment(config=\"my_config.yaml\", model_dir=\".\") print(f\"started experiment {exp.id}\") The returned object will be an ExperimentReference object, which has methods for controlling the lifetime of the experiment running on the cluster. In this example, we will just wait for the experiment to complete. exit_status = exp.wait() print(f\"experiment completed with status {exit_status}\") Now that the experiment has completed, you can grab the top-performing checkpoint from training: best_checkpoint = exp.top_checkpoint() print(f\"best checkpoint was {best_checkpoint.uuid}\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#python-sdk-reference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Client",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#module-determined.experimental.client",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Client",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#module-determined.experimental.client",
    "content": "The client module exposes many of the same capabilities as the det CLI tool directly to Python code with an object-oriented interface. As a simple example, let\u2019s walk through the most basic workflow for creating an experiment, waiting for it to complete, and finding the top-performing checkpoint. The first step is to import the client module and possibly to call login(): from determined.experimental import client # We will assume that you have called `det user login`, so this is unnecessary: # client.login(master=..., user=..., password=...) The next step is to call create_experiment(): # config can be a path to a config file or a python dict of the config. exp = client.create_experiment(config=\"my_config.yaml\", model_dir=\".\") print(f\"started experiment {exp.id}\") The returned object will be an ExperimentReference which has methods for controlling the lifetime of the experiment running on the cluster. In this example, we will just wait for the experiment to complete. exit_status = exp.wait() print(f\"experiment completed with status {exit_status}\") Now that the experiment has completed, you can grab the top-performing checkpoint from training: best_checkpoint = exp.top_checkpoint() print(f\"best checkpoint was {best_checkpoint.uuid}\") See Checkpoints for more ideas on what to do next. determined.experimental.client.loginmaster: Optional[str] = Noneuser: Optional[str] = Nonepassword: Optional[str] = Nonecert_path: Optional[str] = Nonecert_name: Optional[str] = Nonenoverify: bool = FalseNone login() will configure the default Determined() singleton used by all of the other functions in the client module. It is often unnecessary to call login(). If you have configured your environment so that the Determined CLI works without any extra arguments or environment variables, you should not have to call login() at all. If you do need to call login(), it must be called before any calling any other functions from this module, otherwise it will fail. If you have reason to connect to multiple masters, you should use explicit Determined objects instead. Each explicit Determined object accepts the same parameters as login(), and offers the same functions as what are offered in this module. Try to avoid having your password in your python code. If you are running on your local machine, you should always be able to use det user login on the CLI, and login() will not need either a user or a password. If you have ran det user login with multiple users (and you have not ran det user logout), then you should be able to run login(user=...) for any of those users without putting your password in your code. Parameters master (string, optional) \u2013 The URL of the Determined master. If this argument is not specified, the environment variables DET_MASTER and DET_MASTER_ADDR will be checked for the master URL in that order. user (string, optional) \u2013 The Determined username used for authentication. (default: determined) password (string, optional) \u2013 The password associated with the user. cert_path (string, optional) \u2013 A path to a custom PEM-encoded certificate, against which to validate the master. (default: None) cert_name (string, optional) \u2013 The name of the master hostname to use during certificate validation. Normally this is taken from the master URL, but there may be cases where the master is exposed on multiple networks that this value might need to be overridden. (default: None) noverify (boolean, optional) \u2013 disable all TLS verification entirely. (default: False) determined.experimental.client.create_experimentconfig: Union[str, pathlib.Path, Dict]model_dir: strincludes: Optional[Iterable[Union[str, pathlib.Path]]] = Nonedetermined.common.experimental.experiment.ExperimentReference Creates an experiment with config parameters and model directory. The function returns an ExperimentReference of the experiment. Parameters config (str, pathlib.Path, dictionary) \u2013 Experiment config filename (.yaml) or a dict. model_dir (str) \u2013 Directory containing model definition. iterables (Iterable[Union[str, pathlib.Path]], optional) \u2013 Additional files or directories to include in the model definition. (default: None) determined.experimental.client.get_experimentexperiment_id: intdetermined.common.experimental.experiment.ExperimentReference Get the ExperimentReference representing the experiment with the provided experiment ID. Parameters experiment_id (int) \u2013 The experiment ID. determined.experimental.client.get_trialtrial_id: intdetermined.common.experimental.trial.TrialReference Get the TrialReference representing the trial with the provided trial ID. Parameters trial_id (int) \u2013 The trial ID. determined.experimental.client.get_checkpointuuid: strdetermined.common.experimental.checkpoint._checkpoint.Checkpoint Get the Checkpoint representing the checkpoint with the provided UUID. Parameters uuid (string) \u2013 The checkpoint UUID. determined.experimental.client.create_modelname: strdescription: Optional[str] = ''metadata: Optional[Dict[str, Any]] = Nonedetermined.common.experimental.model.Model Add a Model to the model registry. This function returns a Model. Parameters name (string) \u2013 The name of the model. This name must be unique. description (string, optional) \u2013 A description of the model. metadata (dict, optional) \u2013 Dictionary of metadata to add to the model. determined.experimental.client.get_modelidentifier: Union[str, int]determined.common.experimental.model.Model Get the Model from the model registry with the provided identifier, which is either a string-type name or an integer-type model ID. If no model with that name is found in the registry, an exception is raised. Parameters identifier (string, int) \u2013 The unique name or ID of the model. determined.experimental.client.get_modelssort_by: determined.common.experimental.model.ModelSortBy = ModelSortBy.NAMEorder_by: determined.common.experimental.model.ModelOrderBy = ModelOrderBy.ASCENDINGname: str = ''description: str = ''List[determined.common.experimental.model.Model] Get a list of all models in the model registry. Parameters sort_by \u2013 Which field to sort by. See ModelSortBy. order_by \u2013 Whether to sort in ascending or descending order. See ModelOrderBy. name \u2013 If this parameter is set, models will be filtered to only include models with names matching this parameter. description \u2013 If this parameter is set, models will be filtered to only include models with descriptions matching this parameter. determined.experimental.client.stream_trials_metricstrial_ids: List[int]group: strIterable[determined.common.experimental.metrics.TrialMetrics] Streams trial metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for. determined.experimental.client.stream_trials_training_metricstrial_ids: List[int]Iterable[determined.common.experimental.metrics.TrainingMetrics] @deprecated: Use stream_trials_metrics instead with group set to \u201ctraining\u201d Streams training metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for. determined.experimental.client.stream_trials_validation_metricstrial_ids: List[int]Iterable[determined.common.experimental.metrics.ValidationMetrics] @deprecated: Use stream_trials_metrics instead with group set to \u201cvalidation\u201d Streams validation metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Checkpoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#checkpoint",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Checkpoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#checkpoint",
    "content": "class determined.experimental.client.Checkpointsession: determined.common.api._session.Sessiontask_id: Optional[str]allocation_id: Optional[str]uuid: strreport_time: Optional[str]resources: Dict[str, Any]metadata: Dict[str, Any]state: determined.common.experimental.checkpoint._checkpoint.CheckpointStatetraining: Optional[determined.common.experimental.checkpoint._checkpoint.CheckpointTrainingMetadata] = None A Checkpoint object is usually obtained from determined.experimental.client.get_checkpoint(). A Checkpoint represents a trained model. This class provides helper functionality for downloading checkpoints to local storage and loading checkpoints into memory. The TrialReference class contains methods that return instances of this class. downloadpath: Optional[str] = Nonemode: determined.common.experimental.checkpoint._checkpoint.DownloadMode = DownloadMode.AUTOstr Download checkpoint to local storage. determined.pytorch.load_trial_from_checkpoint_path() determined.keras.load_model_from_checkpoint_path() determined.estimator.load_estimator_from_checkpoint_path() Parameters path (string, optional) \u2013 Top level directory to place the checkpoint under. If this parameter is not set, the checkpoint will be downloaded to checkpoints/<checkpoint_uuid> relative to the current working directory. mode (DownloadMode, optional) \u2013 Governs how a checkpoint is downloaded. Defaults to AUTO. write_metadata_filepath: strNone Write a file with this Checkpoint\u2019s metadata inside of it. This is normally executed as part of Checkpoint.download(). However, in the special case where you are accessing the checkpoint files directly (not via Checkpoint.download) you may use this method directly to obtain the latest metadata. add_metadatametadata: Dict[str, Any]None Adds user-defined metadata to the checkpoint. The metadata argument must be a JSON-serializable dictionary. If any keys from this dictionary already appear in the checkpoint metadata, the corresponding dictionary entries in the checkpoint are replaced by the passed-in dictionary values. Warning: this metadata change is not propagated to the checkpoint storage. Parameters metadata (dict) \u2013 Dictionary of metadata to add to the checkpoint. remove_metadatakeys: List[str]None Removes user-defined metadata from the checkpoint. Any top-level keys that appear in the keys list are removed from the checkpoint. Warning: this metadata change is not propagated to the checkpoint storage. Parameters keys (List[string]) \u2013 Top-level keys to remove from the checkpoint metadata. deleteNone Notifies the master of a checkpoint deletion request, which will be handled asynchronously. Master will delete checkpoint and all associated data in the checkpoint storage. remove_filesglobs: List[str]None Removes any files from the checkpoint in checkpoint storage that match one or more of the provided globs. The checkpoint resources and state will be updated in master asynchronously to reflect checkpoint storage. If globs is the empty list then no files will be deleted and the resources and state will only be refreshed in master. Parameters globs (List[string]) \u2013 Globs to match checkpoint files against. get_metricsgroup: Optional[str] = NoneIterable[determined.common.experimental.metrics.TrialMetrics] Gets all metrics for a given metric group associated with this checkpoint. The checkpoint can be originally associated by calling core_context.experimental.report_task_using_checkpoint(<CHECKPOINT>) from within a task. Parameters group (str, optional) \u2013 Group name for the metrics (example: \u201ctraining\u201d, \u201cvalidation\u201d). All metrics will be returned when querying by \u201c\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Determined",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#determined",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Determined",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#determined",
    "content": "class determined.experimental.client.Determinedmaster: Optional[str] = Noneuser: Optional[str] = Nonepassword: Optional[str] = Nonecert_path: Optional[str] = Nonecert_name: Optional[str] = Nonenoverify: bool = False Determined gives access to Determined API objects. Parameters master (string, optional) \u2013 The URL of the Determined master. If this argument is not specified, the environment variables DET_MASTER and DET_MASTER_ADDR will be checked for the master URL in that order. user (string, optional) \u2013 The Determined username used for authentication. (default: determined) create_experimentconfig: Union[str, pathlib.Path, Dict]model_dir: Union[str, pathlib.Path]includes: Optional[Iterable[Union[str, pathlib.Path]]] = Nonedetermined.common.experimental.experiment.ExperimentReference Create an experiment with config parameters and model directory. The function returns ExperimentReference of the experiment. Parameters config (string, pathlib.Path, dictionary) \u2013 experiment config filename (.yaml) or a dict. model_dir (string) \u2013 directory containing model definition. includes (Iterable[Union[str, pathlib.Path]], optional) \u2013 Additional files or (default (directories to include in the model definition.) \u2013 None) get_experimentexperiment_id: intdetermined.common.experimental.experiment.ExperimentReference Get the ExperimentReference representing the experiment with the provided experiment ID. get_trialtrial_id: intdetermined.common.experimental.trial.TrialReference Get the TrialReference representing the trial with the provided trial ID. get_checkpointuuid: strdetermined.common.experimental.checkpoint._checkpoint.Checkpoint Get the Checkpoint representing the checkpoint with the provided UUID. create_modelname: strdescription: Optional[str] = ''metadata: Optional[Dict[str, Any]] = Nonelabels: Optional[List[str]] = Noneworkspace_name: Optional[str] = Nonedetermined.common.experimental.model.Model Add a model to the model registry. Parameters name (string) \u2013 The name of the model. This name must be unique. description (string, optional) \u2013 A description of the model. metadata (dict, optional) \u2013 Dictionary of metadata to add to the model. get_modelidentifier: Union[str, int]determined.common.experimental.model.Model Get the Model from the model registry with the provided identifer, which is either a string-type name or an integer-type model ID. If no corresponding model is found in the registry, an exception is raised. Parameters identifier (string, int) \u2013 The unique name or ID of the model. get_model_by_idmodel_id: intdetermined.common.experimental.model.Model Get the Model from the model registry with the provided id. If no model with that id is found in the registry, an exception is raised. Determined.get_model_by_id() has been deprecated and will be removed in a future version. Please call Determined.get_model() with either a string-type name or an integer-type model ID. get_modelssort_by: determined.common.experimental.model.ModelSortBy = ModelSortBy.NAMEorder_by: determined.common.experimental.model.ModelOrderBy = ModelOrderBy.ASCENDINGname: Optional[str] = Nonedescription: Optional[str] = Nonemodel_id: Optional[int] = Noneworkspace_names: Optional[List[str]] = Noneworkspace_ids: Optional[List[int]] = NoneList[determined.common.experimental.model.Model] Get a list of all models in the model registry. Parameters sort_by \u2013 Which field to sort by. See ModelSortBy. order_by \u2013 Whether to sort in ascending or descending order. See ModelOrderBy. name \u2013 If this parameter is set, models will be filtered to only include models with names matching this parameter. description \u2013 If this parameter is set, models will be filtered to only include models with descriptions matching this parameter. model_id \u2013 If this paramter is set, models will be filtered to only include the model with this unique numeric id. get_model_labelsList[str] Get a list of labels used on any models, sorted from most-popular to least-popular. stream_trials_metricstrial_ids: List[int]group: strIterable[determined.common.experimental.metrics.TrialMetrics] Streams metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for. stream_trials_training_metricstrial_ids: List[int]Iterable[determined.common.experimental.metrics.TrainingMetrics] @deprecated: Use stream_trials_metrics instead with group set to \u201ctraining\u201d Streams training metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for. stream_trials_validation_metricstrial_ids: List[int]Iterable[determined.common.experimental.metrics.ValidationMetrics] @deprecated: Use stream_trials_metrics instead with group set to \u201cvalidation\u201d Streams validation metrics for one or more trials sorted by trial_id, trial_run_id and steps_completed. Parameters trial_ids \u2013 List of trial IDs to get metrics for.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ExperimentReference",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#experimentreference",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ExperimentReference",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#experimentreference",
    "content": "class determined.experimental.client.ExperimentReferenceexperiment_id: intsession: determined.common.api._session.Session An ExperimentReference object is usually obtained from determined.experimental.client.create_experiment() or determined.experimental.client.get_experiment(). Helper class that supports querying the set of checkpoints associated with an experiment. deleteNone Delete an experiment and all its artifacts from persistent storage. You must be authenticated as admin to delete an experiment. get_trialssort_by: determined.common.experimental.trial.TrialSortBy = TrialSortBy.IDorder_by: determined.common.experimental.trial.TrialOrderBy = TrialOrderBy.ASCENDINGList[determined.common.experimental.trial.TrialReference] Get the list of TrialReference instances representing trials for an experiment. Parameters sort_by \u2013 Which field to sort by. See TrialSortBy. order_by \u2013 Whether to sort in ascending or descending order. See TrialOrderBy. await_first_trialinterval: float = 0.1determined.common.experimental.trial.TrialReference Wait for the first trial to be started for this experiment. waitinterval: float = 5.0determined.common.experimental.experiment.ExperimentState Wait for the experiment to reach a complete or terminal state. Parameters interval (int, optional) \u2013 An interval time in seconds before checking next experiement state. top_checkpointsort_by: Optional[str] = Nonesmaller_is_better: Optional[bool] = Nonedetermined.common.experimental.checkpoint._checkpoint.Checkpoint Return the Checkpoint for this experiment that has the best validation metric, as defined by the sort_by and smaller_is_better arguments. Parameters sort_by (string, optional) \u2013 The name of the validation metric to order checkpoints by. If this parameter is not specified, the metric defined in the experiment configuration searcher field will be used. smaller_is_better (bool, optional) \u2013 Specifies whether to sort the metric above in ascending or descending order. If sort_by is unset, this parameter is ignored. By default, the value of smaller_is_better from the experiment\u2019s configuration is used. top_n_checkpointslimit: intsort_by: Optional[str] = Nonesmaller_is_better: Optional[bool] = NoneList[determined.common.experimental.checkpoint._checkpoint.Checkpoint] Return the N Checkpoint instances with the best validation metrics, as defined by the sort_by and smaller_is_better arguments. This method will return the best checkpoint from the top N best-performing distinct trials of the experiment. Only checkpoints in a COMPLETED state with a matching COMPLETED validation are considered. Parameters limit (int) \u2013 The maximum number of checkpoints to return. sort_by (string, optional) \u2013 The name of the validation metric to use for sorting checkpoints. If this parameter is unset, the metric defined in the experiment configuration searcher field will be used. smaller_is_better (bool, optional) \u2013 Specifies whether to sort the metric above in ascending or descending order. If sort_by is unset, this parameter is ignored. By default, the value of smaller_is_better from the experiment\u2019s configuration is used.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "DownloadMode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#downloadmode",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "DownloadMode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#downloadmode",
    "content": "class determined.experimental.client.DownloadModevalue A list of supported checkpoint download modes. DIRECT Download directly from checkpoint storage. MASTER Proxy download through the master. AUTO Attempt DIRECT and fall back to MASTER.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#model",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "Model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#model",
    "content": "class determined.experimental.client.Modelsession: determined.common.api._session.Sessionmodel_id: intname: strdescription: strcreation_time: datetime.datetimelast_updated_time: datetime.datetimemetadata: Dict[str, Any]labels: List[str]username: strarchived: boolworkspace_id: Optional[int] = None A Model object is usually obtained from determined.experimental.client.create_model() or determined.experimental.client.get_model(). Class representing a model in the model registry. It contains methods for model versions and metadata. Parameters model_id (int) \u2013 The unique id of this model. name (string) \u2013 The name of the model. description (string, optional) \u2013 The description of the model. creation_time (datetime) \u2013 The time the model was created. last_updated_time (datetime) \u2013 The time the model was most recently updated. metadata (dict, optional) \u2013 User-defined metadata associated with the checkpoint. labels ([string]) \u2013 User-defined text labels associated with the checkpoint. username (string) \u2013 The user who initially created this model. archived (boolean) \u2013 The status (archived or not) for this model. get_versionversion: int = - 1Optional[determined.common.experimental.model.ModelVersion] Retrieve the checkpoint corresponding to the specified id of the model version. If the specified version of the model does not exist, an exception is raised. If no version is specified, the latest version of the model is returned. In this case, if there are no registered versions of the model, None is returned. Parameters version (int, optional) \u2013 The model version ID requested. get_versionsorder_by: determined.common.experimental.model.ModelOrderBy = ModelOrderBy.DESCENDINGList[determined.common.experimental.model.ModelVersion] Get a list of ModelVersions with checkpoints of this model. The model versions are sorted by model version ID and are returned in descending order by default. Parameters order_by (enum) \u2013 A member of the ModelOrderBy enum. register_versioncheckpoint_uuid: strdetermined.common.experimental.model.ModelVersion Creates a new model version and returns the ModelVersion corresponding to the version. Parameters checkpoint_uuid \u2013 The UUID of the checkpoint to register. add_metadatametadata: Dict[str, Any]None Adds user-defined metadata to the model. The metadata argument must be a JSON-serializable dictionary. If any keys from this dictionary already appear in the model\u2019s metadata, the previous dictionary entries are replaced. Parameters metadata (dict) \u2013 Dictionary of metadata to add to the model. remove_metadatakeys: List[str]None Removes user-defined metadata from the model. Any top-level keys that appear in the keys list are removed from the model. Parameters keys (List[str]) \u2013 Top-level keys to remove from the model metadata. set_labelslabels: List[str]None Sets user-defined labels for the model. The labels argument must be an array of strings. If the model previously had labels, they are replaced. Parameters labels (List[str]) \u2013 All labels to set on the model. archiveNone Sets the model\u2019s state to archived unarchiveNone Removes the model\u2019s archived state deleteNone Deletes the model in the registry",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelOrderBy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelorderby",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelOrderBy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelorderby",
    "content": "class determined.experimental.client.ModelOrderByvalue Specifies whether a sorted list of models should be in ascending or descending order.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelSortBy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelsortby",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelSortBy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelsortby",
    "content": "class determined.experimental.client.ModelSortByvalue Specifies the field to sort a list of models on. UNSPECIFIED NAME DESCRIPTION CREATION_TIME LAST_UPDATED_TIME WORKSPACE",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelVersion",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelversion",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ModelVersion",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#modelversion",
    "content": "class determined.experimental.model.ModelVersionsession: determined.common.api._session.Sessionmodel_version_id: intcheckpoint: determined.common.experimental.checkpoint._checkpoint.Checkpointmetadata: Dict[str, Any]name: strcomment: strnotes: strmodel_id: intmodel_name: strmodel_version: int A ModelVersion object includes a Checkpoint, and can be fetched using model.get_version(). set_namename: strNone Sets the human-friendly name for this model version Parameters name (string) \u2013 New name for model version set_notesnotes: strNone Sets the human-friendly notes / readme for this model version Parameters notes (string) \u2013 Replaces notes for model version in registry deleteNone Deletes the model version in the registry get_metricsgroup: Optional[str] = NoneIterable[determined.common.experimental.metrics.TrialMetrics] Gets all metrics for a given metric group associated with this model version. The checkpoint can be originally associated by calling core_context.experimental.report_task_using_model_version(<MODEL_VERSION>) from within a task. Parameters group (str, optional) \u2013 Group name for the metrics (example: \u201ctraining\u201d, \u201cvalidation\u201d). All metrics will be returned when querying by None.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "TrialReference",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#trialreference",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "TrialReference",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#trialreference",
    "content": "class determined.experimental.client.TrialReferencetrial_id: intsession: determined.common.api._session.Session A TrialReference object is usually obtained from determined.experimental.client.get_trial(). Trial reference class used for querying relevant Checkpoint instances. logsfollow: bool = False*head: Optional[int] = Nonetail: Optional[int] = Nonecontainer_ids: Optional[List[str]] = Nonerank_ids: Optional[List[int]] = Nonestdtypes: Optional[List[str]] = Nonemin_level: Optional[determined.common.experimental.trial.LogLevel] = NoneIterable[str] Return an iterable of log lines from this trial meeting the specified criteria. Parameters follow (bool, optional) \u2013 If the iterable should block waiting for new logs to arrive. Mutually exclusive with head and tail. Defaults to False. head (int, optional) \u2013 When set, only fetches the first head lines. Mutually exclusive with follow and tail. Defaults to None. tail (int, optional) \u2013 When set, only fetches the first head lines. Mutually exclusive with follow and head. Defaults to None. container_ids (List[str], optional) \u2013 When set, only fetch logs from lines from specific containers. Defaults to None. rank_ids (List[int], optional) \u2013 When set, only fetch logs from lines from specific ranks. Defaults to None. stdtypes (List[int], optional) \u2013 When set, only fetch logs from lines from the given stdio outputs. Defaults to None (same as [\"stdout\", \"stderr\"]). min_level \u2013 (LogLevel, optional): When set, defines the minimum log priority for lines that will be returned. Defaults to None (all logs returned). top_checkpointsort_by: Optional[str] = Nonesmaller_is_better: Optional[bool] = Nonedetermined.common.experimental.checkpoint._checkpoint.Checkpoint Return the Checkpoint instance with the best validation metric as defined by the sort_by and smaller_is_better arguments. Parameters sort_by (string, optional) \u2013 The name of the validation metric to order checkpoints by. If this parameter is unset the metric defined in the related experiment configuration searcher field will be used. smaller_is_better (bool, optional) \u2013 Whether to sort the metric above in ascending or descending order. If sort_by is unset, this parameter is ignored. By default, the value of smaller_is_better from the experiment\u2019s configuration is used. select_checkpointlatest: bool = Falsebest: bool = Falseuuid: Optional[str] = Nonesort_by: Optional[str] = Nonesmaller_is_better: Optional[bool] = Nonedetermined.common.experimental.checkpoint._checkpoint.Checkpoint Return the Checkpoint instance with the best validation metric as defined by the sort_by and smaller_is_better arguments. Exactly one of the best, latest, or uuid parameters must be set. Parameters latest (bool, optional) \u2013 Return the most recent checkpoint. best (bool, optional) \u2013 Return the checkpoint with the best validation metric as defined by the sort_by and smaller_is_better arguments. If sort_by and smaller_is_better are not specified, the values from the associated experiment configuration will be used. uuid (string, optional) \u2013 Return the checkpoint for the specified UUID. sort_by (string, optional) \u2013 The name of the validation metric to order checkpoints by. If this parameter is unset the metric defined in the related experiment configuration searcher field will be used. smaller_is_better (bool, optional) \u2013 Whether to sort the metric above in ascending or descending order. If sort_by is unset, this parameter is ignored. By default, the value of smaller_is_better from the experiment\u2019s configuration is used. get_checkpointssort_by: Optional[Union[str, determined.common.experimental.trial.CheckpointSortBy]] = Noneorder_by: Optional[determined.common.experimental.trial.CheckpointOrderBy] = NoneList[determined.common.experimental.checkpoint._checkpoint.Checkpoint] Return a list of Checkpoint instances for the current trial. Either sort_by and order_by are both specified or neither are. Parameters sort_by (string, CheckpointSortBy) \u2013 Which field to sort by. Strings are assumed to be validation metric names. order_by (CheckpointOrderBy) \u2013 Whether to sort in ascending or descending order. stream_metricsgroup: strIterable[determined.common.experimental.metrics.TrialMetrics] Streams metrics for this trial sorted by trial_id, trial_run_id and steps_completed. stream_training_metricsIterable[determined.common.experimental.metrics.TrainingMetrics] @deprecated: Use stream_metrics instead with group set to \u201ctraining\u201d Streams training metrics for this trial sorted by trial_id, trial_run_id and steps_completed. stream_validation_metricsIterable[determined.common.experimental.metrics.ValidationMetrics] @deprecated: Use stream_metrics instead with group set to \u201cvalidation\u201d Streams validation metrics for this trial sorted by trial_id, trial_run_id and steps_completed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "TrainingMetrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#trainingmetrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "TrainingMetrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#trainingmetrics",
    "content": "class determined.experimental.client.TrainingMetricstotal_batches: Optional[int] = None**kwargs: Any @deprecated: Use TrialMetrics instead. Specifies a training metric report that the trial reported.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ValidationMetrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#validationmetrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Python SDK",
      "lvl1": "Python SDK",
      "lvl2": "Python SDK Reference",
      "lvl3": "ValidationMetrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/python-sdk.html#validationmetrics",
    "content": "class determined.experimental.client.ValidationMetricstotal_batches: Optional[int] = None**kwargs: Any @deprecated: Use TrialMetrics instead. Specifies a validation metric report that the trial reported.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#custom-searcher-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.LocalSearchRunner",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-localsearchrunner",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.LocalSearchRunner",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-localsearchrunner",
    "content": "class determined.searcher.LocalSearchRunnersearch_method: determined.searcher._search_method.SearchMethodsearcher_dir: Optional[pathlib.Path] = None LocalSearchRunner performs a search for optimal hyperparameter values, applying the provided SearchMethod. It is executed locally and interacts with a Determined cluster where it starts a multi-trial experiment. It then reacts to event notifications coming from the running experiments by forwarding them to event handler methods in your SearchMethod implementation and sending the returned operations back to the experiment. runexp_config: Union[Dict[str, Any], str]model_dir: Optional[str] = Noneincludes: Optional[Iterable[Union[str, pathlib.Path]]] = Noneint Run custom search. Parameters exp_config (dictionary, string) \u2013 experiment config filename (.yaml) or a dict. model_dir (string) \u2013 directory containing model definition. includes (Iterable[Union[str, pathlib.Path]], optional) \u2013 Additional files or directories to include in the model definition. (default: None)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.RemoteSearchRunner",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-remotesearchrunner",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.RemoteSearchRunner",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-remotesearchrunner",
    "content": "class determined.searcher.RemoteSearchRunnersearch_method: determined.searcher._search_method.SearchMethodcontext: determined.core._context.Context RemoteSearchRunner performs a search for optimal hyperparameter values, applying the provided SearchMethod (you will subclass SearchMethod and provide an instance of the derived class). RemoteSearchRunner executes on-cluster: it runs a meta-experiment using Core API. runexp_config: Union[Dict[str, Any], str]model_dir: Optional[str] = Noneincludes: Optional[Iterable[Union[str, pathlib.Path]]] = Noneint Run custom search as a Core API experiment (on-cluster). Parameters exp_config (dictionary, string) \u2013 experiment config filename (.yaml) or a dict. model_dir (string) \u2013 directory containing model definition. includes (Iterable[Union[str, pathlib.Path]], optional) \u2013 Additional files or directories to include in the model definition. (default: None)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.SearchMethod",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-searchmethod",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.SearchMethod",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-searchmethod",
    "content": "class determined.searcher.SearchMethod The implementation of a custom hyperparameter tuning algorithm. To implement your specific hyperparameter tuning approach, subclass SearchMethod overriding the event handler methods. Each event handler, except progress() returns a list of operations (List[Operation]) that will be submitted to master for processing. Currently, we support the following Operation: Create - starts a new trial with a unique trial id and a set of hyperparameter values. ValidateAfter - sets number of steps (i.e., batches or epochs) after which a validation is run for a trial with a given id. Progress - updates the progress of the multi-trial experiment to the master. Close - closes a trial with a given id. Shutdown - closes the experiment. Do not modify searcher_state passed into event handlers. abstract initial_operationssearcher_state: determined.searcher._search_method.SearcherStateList[determined.searcher._search_method.Operation] Returns a list of initial operations that the custom hyperparameter search should perform. This is called by the Custom Searcher SearchRunner to initialize the trials Example: def initial_operations(self, _: searcher.SearcherState) -> List[searcher.Operation]: ops: List[searcher.Operation] = [] N = 100 hparams = { # ... } for _ in range(0, N): create = searcher.Create( request_id=uuid.uuid4(), hparams=hparams, checkpoint=None, ) ops.append(create) return ops Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state Returns Initial list of Operation to start the Hyperparameter search Return type List[Operation] loadpath: pathlib.PathTuple[determined.searcher._search_method.SearcherState, int] Loads searcher state and method-specific state. load_method_statepath: pathlib.PathNone Loads method-specific search state. abstract on_trial_closedsearcher_state: determined.searcher._search_method.SearcherStaterequest_id: uuid.UUIDList[determined.searcher._search_method.Operation] Informs the searcher that a trial has been closed as a result of a Close Example: def on_trial_closed( self, searcher_state: SearcherState, request_id: uuid.UUID ) -> List[Operation]: if searcher_state.trials_created < self.max_num_trials: hparams = { # ... } return [ searcher.Create( request_id=uuid.uuid4(), hparams=hparams, checkpoint=None, ) ] if searcher_state.trials_closed >= self.max_num_trials: return [searcher.Shutdown()] return [] Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state request_id (uuid.UUID) \u2013 Request UUID of the Trial that was closed Returns List of Operation to run after closing the given trial Return type List[Operation] abstract on_trial_createdsearcher_state: determined.searcher._search_method.SearcherStaterequest_id: uuid.UUIDList[determined.searcher._search_method.Operation] Informs the searcher that a trial has been created as a result of Create operation. Example: def on_trial_created( self, _: SearcherState, request_id: uuid.UUID ) -> List[Operation]: return [ searcher.ValidateAfter( request_id=request_id, length=1, # Run for one unit of time (epoch, etc.) ) ] In this example, we are choosing to deterministically train for one unit of time Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state request_id (uuid.UUID) \u2013 Request UUID of the Trial that was created Returns List of Operation to run upon creation of the given trial Return type List[Operation] abstract on_trial_exited_earlysearcher_state: determined.searcher._search_method.SearcherStaterequest_id: uuid.UUIDexited_reason: determined.searcher._search_method.ExitedReasonList[determined.searcher._search_method.Operation] Informs the searcher that a trial has exited earlier than expected. Example: def on_trial_exited_early( self, searcher_state: SearcherState, request_id: uuid.UUID, exited_reason: ExitedReason, ) -> List[Operation]: if exited_reason == searcher.ExitedReason.USER_CANCELED: return [searcher.Shutdown(cancel=True)] if exited_reason == searcher.ExitedReason.INVALID_HP: return [searcher.Shutdown(failure=True)] if searcher_state.failures >= self.max_failures: return [searcher.Shutdown(failure=True)] return [] The trial has already been internally closed when this callback is run. You do not need to explicitly issue a Close operation Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state request_id (uuid.UUID) \u2013 Request UUID of the Trial that exited early exited_reason (ExitedReason) \u2013 The reason that the trial exited early Returns List of Operation to run in response to the given trial exiting early Return type List[Operation] abstract on_validation_completedsearcher_state: determined.searcher._search_method.SearcherStaterequest_id: uuid.UUIDmetric: Anytrain_length: intList[determined.searcher._search_method.Operation] Informs the searcher that the validation workload has completed after training for train_length units. It returns any new operations as a result of this workload completing Example: def on_validation_completed( self, searcher_state: SearcherState, request_id: uuid.UUID, metric: Any, train_length: int ) -> List[Operation]: if train_length < self.max_train_length: return [ searcher.ValidateAfter( request_id=request_id, length=train_length + 1, # Run an additional unit of time ) ] return [searcher.Close(request_id=request_id)] Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state request_id (uuid.UUID) \u2013 Request UUID of the Trial that was trained metric (Any) \u2013 Metric data returned by the trial train_length (int) \u2013 The cumulative units of time that that trial has finished training for (epochs, etc.) Returns List of Operation to run upon completion of training for the given trial Return type List[Operation] abstract progresssearcher_state: determined.searcher._search_method.SearcherStatefloat Returns experiment progress as a float between 0 and 1. Example: def progress(self, searcher_state: SearcherState) -> float: return searcher_state.trials_closed / float(self.max_num_trials) Parameters searcher_state (SearcherState) \u2013 Read-only current searcher state Returns Experiment progress as a float between 0 and 1. Return type float savesearcher_state: determined.searcher._search_method.SearcherStatepath: pathlib.Path*experiment_id: intNone Saves the searcher state and the search method state. It will be called by the SearchRunner after receiving operations from the SearchMethod save_method_statepath: pathlib.PathNone Saves method-specific state",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.SearcherState",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-searcherstate",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.SearcherState",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-searcherstate",
    "content": "class determined.searcher.SearcherState Custom Searcher State. Search runners maintain this state that can be used by a SearchMethod to inform event handling. In other words, this state can be taken into account when deciding which operations to return from your event handler. Do not modify SearcherState in your SearchMethod. If your hyperparameter tuning algorithm needs additional state variables, add those variable to your SearchMethod implementation. failures number of failed trials Type Set[uuid.UUID] trial_progress progress of each trial as a number between 0.0 and 1.0 Type Dict[uuid.UUID, float] trials_closed set of completed trials Type Set[uuid.UUID] trials_created set of created trials Type Set[uuid.UUID]",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Operation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-operation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Operation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-operation",
    "content": "class determined.searcher.Operation Abstract base class for all Operations",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Close",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-close",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Close",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-close",
    "content": "class determined.searcher.Closerequest_id: uuid.UUID Operation for closing the specified trial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Progress",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-progress",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Progress",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-progress",
    "content": "class determined.searcher.Progressprogress: float Operation for signalling the relative progress of the hyperparameter search between 0 and 1",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Create",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-create",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Create",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-create",
    "content": "class determined.searcher.Createrequest_id: uuid.UUIDhparams: Dict[str, Any]checkpoint: Optional[determined.common.experimental.checkpoint._checkpoint.Checkpoint] Operation for creating a trial with a specified combination of hyperparameter values",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.ValidateAfter",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-validateafter",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.ValidateAfter",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-validateafter",
    "content": "class determined.searcher.ValidateAfterrequest_id: uuid.UUIDlength: int Operation signaling the trial to train until its total units trained equals the specified length, where the units (batches, epochs, etc.) are specified in the searcher section of the experiment configuration",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Shutdown",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-shutdown",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.Shutdown",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-shutdown",
    "content": "class determined.searcher.Shutdowncancel: bool = Falsefailure: bool = False Operation for shutting the experiment down",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.ExitedReason",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-exitedreason",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Searcher Reference",
      "lvl1": "Custom Searcher Reference",
      "lvl2": "determined.searcher.ExitedReason",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/searcher/custom-searcher-reference.html#determined-searcher-exitedreason",
    "content": "class determined.searcher.ExitedReasonvalue The reason why a trial exited early The following reasons are supported: ERRORED: The Trial encountered an exception USER_CANCELLED: The Trial was manually closed by the user INVALID_HP: The hyperparameters the trial was created with were invalid",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Job Configuration Reference",
      "lvl1": "Job Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/interface/job-config-reference.html#job-configuration-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Job Configuration Reference",
      "lvl1": "Job Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/interface/job-config-reference.html#job-configuration-reference",
    "content": "The behavior of interactive jobs, such as TensorBoards, notebooks, commands, and shells, can be influenced by setting a variety of configuration variables. These configuration variables are similar but not identical to the configuration options supported by experiments. Configuration settings can be specified by passing a YAML configuration file when launching the workload via the Determined CLI: $ det tensorboard start experiment_id --config-file=my_config.yaml $ det notebook start --config-file=my_config.yaml $ det cmd run --config-file=my_config.yaml ... $ det shell start --config-file=my_config.yaml Configuration variables can also be set directly on the command line when any Determined task, except a TensorBoard, is launched: $ det notebook start --config resources.slots=2 $ det cmd run --config description=\"determined_command\" ... $ det shell start --config resources.priority=1 Options set via --config take precedence over values specified in the configuration file. Configuration settings are compatible with any Determined task unless otherwise specified. The following configuration settings are supported: description: A human-readable description of the task. This does not need to be unique. The default description consists of a timestamp and the entrypoint of the command. environment: Specifies the environment of the container that is used to execute the task. image: The Docker image to use when executing the workload. This image must be accessible via docker pull to every Determined agent machine in the cluster. Users can configure different container images for NVIDIA GPU tasks using cuda key (gpu prior to 0.17.6), CPU tasks using cpu key, and ROCm (AMD GPU) tasks using rocm key. Default values: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 for NVIDIA GPUs. determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-0.24.0 for ROCm. determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 for CPUs. force_pull_image: Forcibly pull the image from the Docker registry and bypass the Docker cache. Defaults to false. environment_variables: A list of environment variables that will be set in every trial container. Each element of the list should be a string of the form NAME=VALUE. See Environment Variables for more details. Users can customize environment variables for GPU, CPU, and ROCm tasks differently by specifying a dict with cuda (gpu prior to 0.17.6), cpu, and rocm keys. pod_spec: Only applicable when running Determined on Kubernetes. Applies a pod spec to the pods that are launched by Determined for this task. See Customize a Pod for details. registry_auth: Specifies the Docker registry credentials to use when pulling a Docker image, if needed. username (required) password (required) server (optional) email (optional) add_capabilities: A list of Linux capabilities to grant to task containers. Each entry in the list is equivalent to a --cap-add CAP command-line argument to docker run. add_capabilities is honored by resource managers of type agent but is ignored by resource managers of type kubernetes. See master configuration for details about resource managers. drop_capabilities: Just like add_capabilities but corresponding to the --cap-drop argument of docker run rather than --cap-add. proxy_ports: Expose configured network ports on the chief task container. See Exposing Custom Ports for details. resources: The resources Determined allows a task to use. slots: Specifies the number of slots to use for the task. The default value is 1. The maximum value is the number of slots on the agent in the cluster with the most slots. For example, Determined will be unable to schedule a task that requests 4 slots if the Determined cluster is composed of agents with 2 slots each. The number of slots for TensorBoard is fixed at 0 and may not be changed. shm_size: The size of /dev/shm for task containers. The value can be a number in bytes or a number with a suffix (e.g., 128M for 128MiB or 1.5G for 1.5GiB). Defaults to 4294967296 (4GiB). If set, this value overrides the value specified in the master configuration. priority: The priority assigned to this task. Tasks with smaller priority values are scheduled before tasks with higher priority values. Only applicable when using the priority scheduler. Refer to Scheduling for more information. resource_pool: The resource pool where this task will be scheduled. If no resource pool is specified, CPU-only tasks will be scheduled in the default CPU pool, while GPU-using tasks will be scheduled in the default GPU tool. Refer to Resource Pools for more information. devices: A list of device strings to pass to the Docker daemon. Each entry in the list is equivalent to a --device DEVICE command-line argument to docker run. devices is honored by resource managers of type agent but is ignored by resource managers of type kubernetes. See master configuration for details about resource managers. agent_label: This field has been deprecated and will be ignored. Use resource_pool instead. bind_mounts: Specifies a collection of directories that are bind-mounted into the Docker containers for execution. This can be used to allow commands to access additional data that is not contained in the command context. This field should consist of an array of entries. Note that users should ensure that the specified host paths are accessible on all agent hosts (e.g., by configuring a network file system appropriately). Defaults to an empty list. host_path: (required) The file system path on each agent to use. Must be an absolute filepath. container_path: (required) The file system path in the container to use. May be a relative filepath, in which case it will be mounted relative to the working directory inside the container. It is not allowed to mount directly into the working directory (container_path == \".\") to reduce the risk of cluttering the host filesystem. read_only: Whether the bind-mount should be a read-only mount. Defaults to false. propagation: (Advanced users only) Optional propagation behavior for replicas of the bind-mount. Defaults to rprivate. work_dir: Working directory. This can include $AGENT_USER or $DET_USER, which will be replaced with the actual agent user id or determined user id. This cannot be set if submitting a context directory. Defaults to null. tensorboard_args: Lists optional arguments for launching TensorBoard. Each element of the list should be a string of the form NAME=VALUE. idle_timeout: Specifies the duration before idle instances are automatically terminated. This string is a sequence of decimal numbers, each with optional fraction and a unit suffix, such as \u201c30s\u201d, \u201c1h\u201d, or \u201c1m30s\u201d. Valid time units are \u201cs\u201d, \u201cm\u201d, \u201ch\u201d. The default value is 20m. This is only used by TensorBoard and notebook instances. A TensorBoard instance is considered to be idle if it does not receive any HTTP traffic. A notebook instance is considered to be idle if it is not receiving any HTTP traffic and it is not otherwise active (as defined by the notebook_idle_type option). The default timeout for TensorBoard is 5m (5 minutes). notebook_idle_type: Specifies how to decide whether a notebook is idle or active. Valid values are: kernels_or_terminals (default): The notebook is considered active if any kernels or terminals are running. kernel_connections: The notebook is considered active if there are any open connections from any web connections to any kernels. (JupyterLab does not report connections to terminals, so they cannot be counted.) activity: The notebook is considered active if any kernel is executing a command or any terminal that is currently being viewed in JupyterLab is inputting or outputting any data. (A terminal that is running a command but not being viewed or running a command with no output is treated as idle, since JupyterLab does not provide activity information for those case.) slurm: Slurm cluster details may optionally be specified in the same fashion as for experiments. pbs: PBS cluster details may optionally be specified in the same fashion as for experiments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Hub APIs",
      "lvl1": "Model Hub APIs",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/index.html#model-hub-apis",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Hub APIs",
      "lvl1": "Model Hub APIs",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/index.html#model-hub-apis",
    "content": "This section includes reference documentation for the model hub APIs: Title Description MMDetection API The MMDetection API reference, which makes it easy to use the popular MMDetection library with Determined. Transformers API The Transformers API reference for using the Huggingface transformers library with Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#transformers-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#model-hub-huggingface",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#model-hub-huggingface",
    "content": "class model_hub.huggingface.BaseTransformerTrialcontext: determined.pytorch._pytorch_context.PyTorchTrialContext This is the base PyTorchTrial for transformers that implements the __init__ and train_batch methods. You can subclass BaseTransformerTrial to customize a trial for your own usage by filing in the expected methods for data loading and evaluation. The __init__ method replicated below makes heavy use of the helper functions in the next section. def __init__(self, context: det_torch.PyTorchTrialContext) -> None: self.context = context # A subclass of BaseTransformerTrial may have already set hparams and data_config # attributes so we only reset them if they do not exist. if not hasattr(self, \"hparams\"): self.hparams = attrdict.AttrDict(context.get_hparams()) if not hasattr(self, \"data_config\"): self.data_config = attrdict.AttrDict(context.get_data_config()) if not hasattr(self, \"exp_config\"): self.exp_config = attrdict.AttrDict(context.get_experiment_config()) # Check to make sure all expected hyperparameters are set. self.check_hparams() # Parse hparams and data_config. ( self.config_kwargs, self.tokenizer_kwargs, self.model_kwargs, ) = hf_parse.default_parse_config_tokenizer_model_kwargs(self.hparams) optimizer_kwargs, scheduler_kwargs = hf_parse.default_parse_optimizer_lr_scheduler_kwargs( self.hparams ) self.config, self.tokenizer, self.model = build_using_auto( self.config_kwargs, self.tokenizer_kwargs, self.hparams.model_mode, self.model_kwargs, use_pretrained_weights=self.hparams.use_pretrained_weights, ) self.model = self.context.wrap_model(self.model) self.optimizer = self.context.wrap_optimizer( build_default_optimizer(self.model, optimizer_kwargs) ) if self.hparams.use_apex_amp: self.model, self.optimizer = self.context.configure_apex_amp( models=self.model, optimizers=self.optimizer, ) self.lr_scheduler = self.context.wrap_lr_scheduler( build_default_lr_scheduler(self.optimizer, scheduler_kwargs), det_torch.LRScheduler.StepMode.STEP_EVERY_BATCH, ) self.grad_clip_fn = None if optimizer_kwargs.max_grad_norm > 0: # type: ignore self.grad_clip_fn = lambda x: torch.nn.utils.clip_grad_norm_( x, optimizer_kwargs.max_grad_norm ) The evaluate_batch method replicated below should work for most models and tasks but can be overwritten for more custom behavior in a subclass. def train_batch(self, batch: Any, epoch_idx: int, batch_idx: int) -> Any: # By default, all HF models return the loss in the first element. # We do not automatically apply a label smoother for the user. # If this is something you want to use, please see how it's # applied by transformers.Trainer: # https://github.com/huggingface/transformers/blob/v4.3.3/src/transformers/trainer.py#L1324 outputs = self.model(**batch) loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0] self.context.backward(loss) self.context.step_optimizer(self.optimizer, self.grad_clip_fn) return loss",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": "Helper Functions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#helper-functions",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": "Helper Functions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#helper-functions",
    "content": "The BaseTransformerTrial calls many helper functions below that are also useful when subclassing BaseTransformerTrial or writing custom transformers trials for use with Determined. model_hub.huggingface.build_default_lr_scheduleroptimizer: torch.optim.optimizer.Optimizerscheduler_kwargs: model_hub.huggingface._config_parser.LRSchedulerKwargsAny This follows the function in transformer\u2019s Trainer to construct the lr_scheduler. Parameters optimizer \u2013 optimizer to apply lr_scheduler to scheduler_kwargs \u2013 see LRSchedulerKwargs in _config_parser.py for expected fields. Returns lr_scheduler configured accordingly model_hub.huggingface.build_default_optimizermodel: torch.nn.modules.module.Moduleoptimizer_kwargs: model_hub.huggingface._config_parser.OptimizerKwargsUnion[transformers.optimization.Adafactor, transformers.optimization.AdamW] This follows the function in transformer\u2019s Trainer to construct the optimizer. Parameters model \u2013 model whose parameters will be updated by the optimizer weight_decay \u2013 weight_decay factor to apply to weights optimizer_kwargs \u2013 see OptimizerKwargs in _config_parser.py for expected fields Returns optimizer configured accordingly model_hub.huggingface.build_using_autoconfig_kwargs: Union[Dict, attrdict.dictionary.AttrDict]tokenizer_kwargs: Union[Dict, attrdict.dictionary.AttrDict]model_mode: strmodel_kwargs: Union[Dict, attrdict.dictionary.AttrDict]use_pretrained_weights: bool = TrueTuple[transformers.PretrainedConfig, transformers.PreTrainedTokenizer, transformers.PreTrainedModel] Build the config, tokenizer, and model using tranformer\u2019s Auto classes. Parameters config_kwargs \u2013 arguments for transformers configuration classes tokenizer_kwargs \u2013 arguments for transformers tokenizer classes model_mode \u2013 one of (pretraining, causal-lm, masked-lm, seq2seq-lm, sequence-classification, multiple-choice, next-sentence, token-classification, question-answering) model_kwargs \u2013 arguments for transformers model classes Returns transformer config, tokenizer, and model model_hub.huggingface.default_load_datasetdata_config: Union[Dict, attrdict.dictionary.AttrDict]Union[datasets.Dataset, datasets.IterableDataset, datasets.DatasetDict, datasets.IterableDatasetDict] Creates the dataset using HuggingFace datasets\u2019 load_dataset method. If a dataset_name is provided, we will use that long with the dataset_config_name. Otherwise, we will create the dataset using provided train_file and validation_file. Parameters data_config \u2013 arguments for load_dataset. See DatasetKwargs for expected fields. Returns Dataset returned from hf_datasets.load_dataset. model_hub.huggingface.default_parse_config_tokenizer_model_kwargshparams: Union[Dict, attrdict.dictionary.AttrDict]Tuple[Dict, Dict, Dict] This function will provided hparams into fields for the transformers config, tokenizer, and model. See the defined dataclasses ConfigKwargs, TokenizerKwargs, and ModelKwargs for expected fields and defaults. Parameters hparams \u2013 hyperparameters to parse. Returns One dictionary each for the config, tokenizer, and model. model_hub.huggingface.default_parse_optimizer_lr_scheduler_kwargshparams: Union[Dict, attrdict.dictionary.AttrDict]Tuple[model_hub.huggingface._config_parser.OptimizerKwargs, model_hub.huggingface._config_parser.LRSchedulerKwargs] Parse hparams relevant for the optimizer and lr_scheduler and fills in with the same defaults as those used by the transformers Trainer. See the defined dataclasses OptimizerKwargs and LRSchedulerKwargs for expected fields and defaults. Parameters hparams \u2013 hparams to parse. Returns Configuration for the optimizer and lr scheduler.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": "Structured Dataclasses",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#structured-dataclasses",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers API",
      "lvl1": "Transformers API",
      "lvl2": "model_hub.huggingface",
      "lvl3": "Structured Dataclasses",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/transformers-api.html#structured-dataclasses",
    "content": "Structured dataclasses are used to ensure that Determined parses the experiment config correctly. See the below classes for details on what fields can be used in the experiment config to configure the dataset; transformers config, model, and tokenizer; as well as optimizer and learning rate scheduler for use with the functions above. class model_hub.huggingface.DatasetKwargs**kwargs: Dict[str, Any] Config parser for dataset fields. Either dataset_name needs to be provided or train_file and validation_file need to be provided. Parameters dataset_name (optional, defaults to None) \u2013 Path argument to pass to HuggingFace datasets.load_dataset. Can be a dataset identifier in HuggingFace Datasets Hub or a local path to processing script. dataset_config_name (optional, defaults to None) \u2013 The name of the dataset configuration to pass to HuggingFace datasets.load_dataset. validation_split_percentage (optional, defaults to None) \u2013 This is used to create a validation split from the training data when a dataset does not have a predefined validation split. train_file (optional, defaults to None) \u2013 Path to training data. This will be used if a dataset_name is not provided. validation_file (optional, defaults to None) \u2013 Path to validation data. This will be used if a dataset_name is not provided. Returns dataclass with the above fields populated according to provided config. class model_hub.huggingface.ConfigKwargs**kwargs: Dict[str, Any] Config parser for transformers config fields. Parameters pretrained_model_name_or_path \u2013 Path to pretrained model or model identifier from huggingface.co/models. cache_dir (optional, defaults to None) \u2013 Where do you want to store the pretrained models downloaded from huggingface.co. revision (optional, defaults to None) \u2013 The specific model version to use (can be a branch name, tag name or commit id). use_auth_token (optional, defaults to None) \u2013 Will use the token generated when running transformers-cli login (necessary to use this script with private models). num_labels (optional, excluded if not provided) \u2013 Number of labels to use in the last layer added to the model, typically for a classification task. finetuning_task (optional, excluded if not provided) \u2013 Name of the task used to fine-tune the model. This can be used when converting from an original PyTorch checkpoint. Returns dataclass with the above fields populated according to provided config. class model_hub.huggingface.ModelKwargspretrained_model_name_or_path: strcache_dir: Optional[str] = Nonerevision: Optional[str] = 'main'use_auth_token: Optional[bool] = False Config parser for transformers model fields. Parameters pretrained_model_name_or_path \u2013 Path to pretrained model or model identifier from huggingface.co/models. cache_dir (optional, defaults to None) \u2013 Where do you want to store the pretrained models downloaded from huggingface.co. revision (optional, defaults to None) \u2013 The specific model version to use (can be a branch name, tag name or commit id). use_auth_token (optional, defaults to None) \u2013 Will use the token generated when running transformers-cli login (necessary to use this script with private models). Returns dataclass with the above fields populated according to provided config. class model_hub.huggingface.OptimizerKwargsweight_decay: Optional[float] = 0adafactor: Optional[bool] = Falselearning_rate: Optional[float] = 5e-05max_grad_norm: Optional[float] = 1.0adam_beta1: Optional[float] = 0.9adam_beta2: Optional[float] = 0.999adam_epsilon: Optional[float] = 1e-08scale_parameter: Optional[bool] = Falserelative_step: Optional[bool] = False Config parser for transformers optimizer fields. class model_hub.huggingface.LRSchedulerKwargsnum_training_steps: intlr_scheduler_type: Optional[str] = 'linear'num_warmup_steps: Optional[int] = 0 Config parser for transformers lr scheduler fields.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection API",
      "lvl1": "MMDetection API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/mmdetection-api.html#mmdetection-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection API",
      "lvl1": "MMDetection API",
      "lvl2": "model_hub.mmdetection",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/mmdetection-api.html#model-hub-mmdetection",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection API",
      "lvl1": "MMDetection API",
      "lvl2": "model_hub.mmdetection",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/mmdetection-api.html#model-hub-mmdetection",
    "content": "class model_hub.mmdetection.MMDetTrialcontext: determined.pytorch._pytorch_context.PyTorchTrialContext This trial serves as the trainer for MMDetection models. It replaces the mmcv runner used by MMDetection. For nearly all use cases, you can just use this trial definition and control behavior by changing the MMDetection config. If you want to customize the trial further, you can use this trial as the starting point. Simlar to using the MMDetection library directly, the main way users customize an experiment is by modifying the MMDetection config. We detail how to configure MMDetection through the Determined experiment configuration in the readme.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection API",
      "lvl1": "MMDetection API",
      "lvl2": "model_hub.mmdetection",
      "lvl3": "Helper Functions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/mmdetection-api.html#module-model_hub.mmdetection",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection API",
      "lvl1": "MMDetection API",
      "lvl2": "model_hub.mmdetection",
      "lvl3": "Helper Functions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/model-hub/modelhub/mmdetection-api.html#module-model_hub.mmdetection",
    "content": "class model_hub.mmdetection.GCSBackend*args: Any**kwargs: Any To use a Google Storage bucket as the storage backend, set data.file_client_args field of the experiment config as follows: data: file_client_args: backend: gcs bucket_name: <FILL IN> get_local_pathfilepath: strIterator[str] Download a file from filepath. get_local_path is decorated by contxtlib.contextmanager(). It can be called with with statement, and when exists from the with statement, the temporary path will be released. :param filepath: Download a file from filepath. :type filepath: str class model_hub.mmdetection.S3Backend*args: Any**kwargs: Any To use a S3 bucket as the storage backend, set data.file_client_args field of the experiment config as follows: data: file_client_args: backend: s3 bucket_name: <FILL IN> get_local_pathfilepath: strIterator[str] Download a file from filepath. get_local_path is decorated by contxtlib.contextmanager(). It can be called with with statement, and when exists from the with statement, the temporary path will be released. :param filepath: Download a file from filepath. :type filepath: str model_hub.mmdetection.get_pretrained_ckpt_pathdownload_directory: strconfig_file: strTuple[Any, Any] If the config_file has an associated pretrained checkpoint, return path to downloaded checkpoint and preloaded checkpoint Parameters download_directory \u2013 path to download checkpoints to config_file \u2013 mmdet config file path for which to find and load pretrained weights Returns checkpoint path, loaded checkpoint",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deployment Reference",
      "lvl1": "Deployment Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/index.html#deployment-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Deployment Reference",
      "lvl1": "Deployment Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/index.html#deployment-reference",
    "content": "Deloyment Reference includes reference documentation for configuring Determined deployment. Title Description Common Configuration Options Common configuration option reference for security, networking, checkpointing, and telemetry options. Master Configuration Reference Master node configuration option reference. Agent Configuration Reference Agent node configuration option reference. Helm Chart Configuration Reference Helm chart configuration option reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#common-configuration-options",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Master Port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#master-port",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Master Port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#master-port",
    "content": "By default, the master listens on TCP port 8080. This can be configured via the port option.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#security",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#security",
    "content": "The master can secure all incoming connections using TLS. That ability requires a TLS private key and certificate to be provided; set the options security.tls.cert and security.tls.key to paths to a PEM-encoded TLS certificate and private key, respectively, to do so. If TLS is enabled, the default port becomes 8443 rather than 8080. See Transport Layer Security for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Configuring Trial Runner Networking",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#configuring-trial-runner-networking",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Configuring Trial Runner Networking",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#configuring-trial-runner-networking",
    "content": "The master is capable of selecting the network interface that trial runners will use to communicate when performing distributed (multi-machine) training. The network interface can be configured by editing task_container_defaults.dtrain_network_interface. If left unspecified, which is the default setting, Determined will auto-discover a common network interface shared by the trial runners. For Distributed Training with Determined, Determined automatically detects a common network interface shared by the agent machines. If your cluster has multiple common network interfaces, please specify the fastest one. Additionally, the ports used by the GLOO and NCCL libraries, which are used during distributed (multi-machine) training can be configured to fall within user-defined ranges. If left unspecified, ports will be chosen randomly from the unprivileged port range (1024-65535).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Default Checkpoint Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#default-checkpoint-storage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Default Checkpoint Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#default-checkpoint-storage",
    "content": "See Checkpoint Storage for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#telemetry",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#telemetry",
    "content": "By default, the master and WebUI collect anonymous information about how Determined is being used. This usage information is collected so that we can improve the design of the product. Determined does not report information that can be used to identify individual users of the product, nor does it include model source code, model architecture/checkpoints, training datasets, training and validation metrics, logs, or hyperparameter values. The information we collect from the master periodically includes: a unique, randomly generated ID for the current database and for the current instance of the master the version of Determined the version of Go that was used to compile the master the number of registered users the number of experiments that have been created the total number of trials across all experiments the number of active, paused, completed, and canceled experiments whether tasks are scheduled using Kubernetes or the built-in Determined scheduler the total number of slots (e.g., GPUs) the number of slots currently being utilized the type of each configured resource pool We also record when the following events happen: an experiment is created an experiment changes state an agent connects or disconnects a user is created (the username is not transmitted) When an experiment is created, we report: the name of the hyperparameter search method the total number of hyperparameters the number of slots (e.g., GPUs) used by each trial in the experiment the name of the container image used When a task terminates, we report: the start and end time of the task the number of slots (e.g., GPUs) used for experiments, we also report: the number of trials in the experiment the total number of training workloads across all trials in the experiment the total elapsed time for all workloads across all trials in the experiment The information we collect from the WebUI includes: pages that are visited errors that occur (both network errors and uncaught exceptions) user-triggered actions To disable telemetry reporting in both the master and the WebUI, start the master with the --telemetry-enabled=false flag (this can also be done by editing the master config file or setting an environment variable, as with any other configuration option). Disabling telemetry reporting will not affect the functionality of Determined in any way.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Telemetry",
      "lvl3": "OpenTelemetry",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#opentelemetry",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Common Configuration Options",
      "lvl1": "Common Configuration Options",
      "lvl2": "Telemetry",
      "lvl3": "OpenTelemetry",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/common-config-options.html#opentelemetry",
    "content": "Separate from the telemetry reporting mentioned above, Determined also supports OpenTelemetry to collect traces. This is disabled by default; to enable it, use the master configuration setting telemetry.otel-enabled. When enabled, the master will send OpenTelemetry traces to a collector running at localhost:4317. A different endpoint can be set via the telemetry.otel-endpoint configuration setting.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-configuration-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "config_file",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#config-file",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "config_file",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#config-file",
    "content": "Path to the agent configuration file. Normally this should only be set via an environment variable or command-line option. Defaults to /etc/determined/agent.yaml.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "master_host",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#master-host",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "master_host",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#master-host",
    "content": "Required. The hostname or IP address of the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "master_port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#master-port",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "master_port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#master-port",
    "content": "The port of the Determined master. Defaults to 443 if TLS is enabled and 80 otherwise.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_id",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-id",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_id",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-id",
    "content": "The ID of this agent; defaults to the hostname of the current machine. Agent IDs must be unique within a cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_master_host",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-master-host",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_master_host",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-master-host",
    "content": "Master hostname that containers started by this agent will connect to. Defaults to the value of master_host.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_master_port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-master-port",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_master_port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-master-port",
    "content": "Master port that containers started by this agent will connect to. Defaults to the value of master_port.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "resource_pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#resource-pool",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "resource_pool",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#resource-pool",
    "content": "Which resource pool the agent should join. Defaults to the value of default, which will work if and only if there is a resource pool named default. For more information please see Resource Pools.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "visible_gpus",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#visible-gpus",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "visible_gpus",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#visible-gpus",
    "content": "The GPUs that should be exposed as slots by the agent. A comma-separated list of GPUs, each specified by a 0-based index, UUID, PCI bus ID, or board serial number. The 0-based index of NVIDIA GPUs or AMD GPUs can be obtained via the nvidia-smi or rocm-smi commands.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "slot_type",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#slot-type",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "slot_type",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#slot-type",
    "content": "The slot type that should be exposed. Dynamic agents having GPUs will be configured to cuda, agents without GPUs with cpu_slots_allowed: true provisioner option will be configured to cpu, and none otherwise. For static agents this field defaults to auto. auto: Automatically detects the slot type. The agent will detect if there are NVIDIA GPUs or AMD GPUs. If there are GPUs, it maps each GPU to one slot. Otherwise, it maps all the CPUs to a slot. none: The agent will not create any slots for detected devices. cuda: The agent will map each detected NVIDIA GPU to a slot. Prior to Determined 0.17.6, this option was called gpu. cpu: Map all the CPUs to a slot, even when GPUs are present. rocm: The agent will map each detected ROCm AMD GPU to a slot.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "http_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#http-proxy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "http_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#http-proxy",
    "content": "The HTTP proxy address for the agent\u2019s containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "https_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#https-proxy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "https_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#https-proxy",
    "content": "The HTTPS proxy address for the agent\u2019s containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "ftp_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#ftp-proxy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "ftp_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#ftp-proxy",
    "content": "The FTP proxy address for the agent\u2019s containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "no_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#no-proxy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "no_proxy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#no-proxy",
    "content": "The addresses that the agent\u2019s containers should not proxy.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#security",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#security",
    "content": "Security-related configuration settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "security",
      "lvl3": "tls",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#tls",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "security",
      "lvl3": "tls",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#tls",
    "content": "Configuration settings for TLS. enabled: Whether to use TLS to connect to the master. Defaults to false. skip_verify: Skip verifying the master certificate when using TLS. Defaults to false. Enabling this setting will reduce the security of your Determined cluster. master_cert: CA cert file for the master when using TLS. master_cert_name: A hostname for which the master\u2019s TLS certificate is valid, if the value of the master_host option is an IP address or is not contained in the certificate. client_cert/client_key: Paths to files containing the client TLS certificate and key to use when connecting to the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#fluent",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#fluent",
    "content": "fluentd settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#image",
    "content": "Docker image to use for the managed Fluent Bit daemon. Defaults to fluent/fluent-bit:1.9.3.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "port",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#port",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "port",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#port",
    "content": "TCP port for the Fluent Bit daemon to listen on. Defaults to port 24224. Should be unique when running multiple agents on the same node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "container_name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-name",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "fluent",
      "lvl3": "container_name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-name",
    "content": "Name for the Fluent Bit container. Defaults to determined-fluent. Should be unique when running multiple agents on the same node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_reconnect_attempts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-reconnect-attempts",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_reconnect_attempts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-reconnect-attempts",
    "content": "Maximum number of times the agent will attempt to reconnect to master on connection failure. Defaults to 5.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_reconnect_backoff",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-reconnect-backoff",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "agent_reconnect_backoff",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#agent-reconnect-backoff",
    "content": "Time interval between reconnection attempts, in seconds. Defaults to 5 seconds.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_auto_remove_disabled (debug)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-auto-remove-disabled-debug",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "container_auto_remove_disabled (debug)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#container-auto-remove-disabled-debug",
    "content": "Whether to disable setting AutoRemove flag on task containers. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "hooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#hooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "hooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#hooks",
    "content": "Configuration for commands to run when certain events occur. The value of each option in this section is an array of strings specifying the command and its arguments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "hooks",
      "lvl3": "on_connection_lost",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#on-connection-lost",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "hooks",
      "lvl3": "on_connection_lost",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#on-connection-lost",
    "content": "A command to run when the agent fails to either connect to the master on startup or reconnect after a loss of connection. When reconnecting, the agent will make several attempts as specified by the agent_reconnect_attempts and agent_reconnect_backoff configuration options. In order to shut down the machine on which the agent is running, set this to [\"sudo\", \"shutdown\", \"now\"], or just [\"shutdown\", \"now\"] if the agent is running as root. Additional system configuration may be required in order to allow the agent to execute the command from inside a Docker container or without the need to enter a password.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "label",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#label",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "label",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#label",
    "content": "Deprecated. This field has been deprecated and will be ignored. Use resource_pool instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "debug",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#debug",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "debug",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#debug",
    "content": "If true, enables a more verbose form of logging that may be helpful in diagnosing issues. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "image_root",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#image-root",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Agent Configuration Reference",
      "lvl1": "Agent Configuration Reference",
      "lvl2": "image_root",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/agent-config-reference.html#image-root",
    "content": "If set then specifies the path to a shared directory of previously downloaded Determined environment images. If not defined, then Determined environments will be downloaded automatically. For more information on setting up an image cache see Configuring an Apptainer/Singularity Image Cache Directory. Defaults to undefined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#helm-chart-configuration-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#helm-chart-configuration-reference",
    "content": "Installation Guide Install Determined on Kubernetes",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": "Chart.yaml Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#chart-yaml-settings",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": "Chart.yaml Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#chart-yaml-settings",
    "content": "appVersion: Configures which version of Determined to install. Users can specify a release version (e.g., 0.13.0) or specify any commit hash from the upstream Determined repo (e.g., b13461ed06f2fad339e179af8028d4575db71a81). Users are encouraged to use a released version. If using a non-release branch of the Determined repository, appVersion is going to be set to X.Y.Z.dev0. This is not an official release version and deploying this version result in a ImagePullBackOff error. Users should remove .dev0 to get the latest released version, or they can specify a specific commit hash instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": "values.yaml Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#values-yaml-settings",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Helm Chart Configuration Reference",
      "lvl1": "Helm Chart Configuration Reference",
      "lvl2": "values.yaml Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/helm-config-reference.html#values-yaml-settings",
    "content": "masterPort: The port at which the Determined master listens for connections on. (Required) useNodePortForMaster: When set to false (default), a LoadBalancer service is deployed to make the Determined master reachable from outside the cluster. When set to true, the master will instead be exposed behind a NodePort service. When using a NodePort service users will typically have to configure an Ingress to make the Determined master reachable from outside the cluster. NodePort service is recommended when configuring TLS termination in a load-balancer. tlsSecret: enables TLS encryption for all communication with the Determined master (TLS termination is performed in the Determined master). This includes communication between the Determined master and the task containers it launches, but does not include communication between the task containers (distributed training). The specified Secret of type tls must already exist in the same namespace in which Determined is being installed. db: Specifies the configuration of the database. name: The database name to use. (Required) user: The database user to use when logging in the database. (Required) password: The password to use when logging in the database. (Required) port: The database port to use. (Required) hostAddress: Optional configuration to indicate the address of a user provisioned database If configured, the Determined helm chart will not deploy a database. storageSize: Only used when hostAddress is left blank. Configures the size of the PersistentVolumeClaim for the Determined deployed database. cpuRequest: The CPU requirements for the Determined database. memRequest: The memory requirements for the Determined database. cpuLimit: Optional configuration. The CPU limits for the Determined database. memLimit: Optional configuration. The memory limits for the Determined database. useNodePortForDB: Optional configuration that configures whether ClusterIP or NodePort service type is used for the Determined database. By default ClusterIP is used. storageClassName: Optional configuration to indicate StorageClass that should be used by the PersistentVolumeClaim for the Determined deployed database. This can be left blank if a default storage class is specified in the cluster. If dynamic provisioning of PersistentVolumes is disabled, users must manually create a PersistentVolume that will match the PersistentVolumeClaim. checkpointStorage: Specifies where model checkpoints will be stored. This can be overridden on a per-experiment basis in the Experiment Configuration Reference. A checkpoint contains the architecture and weights of the model being trained. Determined currently supports several kinds of checkpoint storage, gcs, s3, azure and shared_fs, identified by the type subfield. type: gcs: Checkpoints are stored on Google Cloud Storage (GCS). Authentication is done using GCP\u2019s \u201cApplication Default Credentials\u201d approach. When using Determined inside Google Kubernetes Engine (GCE), the simplest approach is to ensure that the nodes used by Determined are running in a service account that has the \u201cStorage Object Admin\u201d role on the GCS bucket being used for checkpoints. As an alternative (or when running outside of GKE), you can add the appropriate service account credentials to your container (e.g., via a bind-mount), and then set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the container path where the credentials are located. See Environment Variables for more information on how to set environment variables in trial environments. bucket: The GCS bucket name to use. prefix: The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix type: s3: Checkpoints are stored in Amazon S3. bucket: The S3 bucket name to use. accessKey: The AWS access key to use. secretKey: The AWS secret key to use. prefix: The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix endpointUrl: The optional endpoint to use for S3 clones, e.g., http://127.0.0.1:8080/. type: azure: Checkpoints are stored in Microsoft\u2019s Azure Blob Storage. Authentication is performed by providing either a connection string, or an account URL and an optional credential. container: The Azure Blob Storage container name to use. connection_string: The connection string for the service account to use. account_url: The account URL for the service account to use. credential: The optional credential to use in conjunction with the account URL. Please only specify either connection_string or the account_url and credential pair. type: shared_fs: Checkpoints are written to a hostPath Volume. Users are strongly discouraged from using shared_fs for storage beyond initial testing as most Kubernetes cluster nodes do not have a shared file system. hostPath: The file system path on each node to use. This directory will be mounted to /determined_shared_fs inside the trial pod. When an experiment finishes, the system will optionally delete some checkpoints to reclaim space. The saveExperimentBest, saveTrialBest and saveTrialLatest parameters specify which checkpoints to save. See Checkpoint Garbage Collection for more details. maxSlotsPerPod: Specifies number of GPUs there are per machine. Determined uses this information when scheduling multi-GPU tasks. Each multi-GPU (distributed training) task will be scheduled as a set of slotsPerTask / maxSlotsPerPod separate pods, with each pod assigned up to maxSlotsPerPod GPUs. Distributed tasks with sizes that are not divisible by maxSlotsPerPod are never scheduled. If you have a cluster of different size nodes, set the maxSlotsPerPod to greatest common divisor of all the sizes. For example, if you have some nodes with 4 GPUs and other nodes with 8 GPUs, set maxSlotsPerPod to 4 so that all distributed experiments will launch with 4 GPUs per pod (with two pods on 8-GPU nodes). (Required) masterCpuRequest: The CPU requirements for the Determined master. masterMemRequest: The memory requirements for the Determined master. masterCpuLimit: Optional configuration. The CPU limits for the Determined master. masterMemLimit: Optional configuration. The memory limits for the Determined master. taskContainerDefaults: Specifies Docker defaults for all task containers. A task represents a single schedulable unit, such as a trial, command, or tensorboard. networkMode: The Docker network to use for the Determined task containers. If this is set to \u201chost\u201d, Docker host-mode networking will be used instead. Defaults to \u201cbridge\u201d. dtrainNetworkInterface: The network interface to use during distributed training. If not set, Determined automatically determines the network interface. When training a model with multiple machines, the host network interface used by each machine must have the same interface name across machines. This is usually determined automatically, but there may be issues if there is an interface name common to all machines but it is not routable between machines. Determined already filters out common interfaces like lo and docker0, but agent machines may have others. If interface detection is not finding the appropriate interface, the dtrainNetworkInterface option can be used to set it explicitly (e.g., eth11). forcePullImage: Defines the default policy for forcibly pulling images from the Docker registry and bypassing the Docker cache. If a pull policy is specified in the experiment config this default is overriden. Please note that as of November 1st, 2020 unauthenticated users will be capped at 100 pulls from Docker per 6 hours. Defaults to false. cpuPodSpec: Sets the default pod spec for all non-GPU tasks. See Customize a Pod for details. gpuPodSpec: Sets the default pod spec for all GPU tasks. See Customize a Pod for details. cpuImage: Sets the default Docker image for all non-GPU tasks. If a Docker image is specified in the experiment config this default is overriden. Defaults to: determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0. gpuImage: Sets the default Docker image for all GPU tasks. If a Docker image is specified in the experiment config this default is overriden. Defaults to: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0. enterpriseEdition: Specifies whether to use Determined enterprise edition. imagePullSecretName: Specifies the image pull secret for pulling the Determined master image. Required when using the enterprise edition. telemetry: Specifies whether we collect anonymous information about the usage of Determined. enabled: Whether collection is enabled. Defaults to true. observability: Specifies whether Determined enables Prometheus monitoring routes. See Prometheus for details. enable_prometheus: Whether Prometheus is enabled. Defaults to false. tensorboardTimeout: Specifies the duration in seconds before idle TensorBoard instances are automatically terminated. A TensorBoard instance is considered to be idle if it does not receive any HTTP traffic. The default timeout is 300 (5 minutes). defaultPassword: Specifies a string containing the default password for the admin and determined user accounts. logging: Configures where trial logs are stored. This section takes the same shape as the logging configuration in the cluster configuration, except that names are changed to camel case to match Helm conventions (e.g., skip_verify would be skipVerify here). logging.security.tls.certificate: Contains the contents of an expected TLS certificate for the Elasticsearch cluster, rather than a path as it does in the cluster configuration. This can be conveniently set at the command line using helm install --set-file logging.security.tls.certificate=<path>. defaultScheduler: Configures the default scheduler that Determined will use. Currently supports the coscheduler option, which enables the lightweight coscheduling plugin, and the preemption option, which enables a priority-based preemption scheduler. Unless specified as coscheduler, Determined will use the default Kubernetes scheduler. resourcePools: This section contains the names of the resource pools and their linked namespaces. Maps to the resource_pools section from the master configuration. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-configuration-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-configuration-reference",
    "content": "The Determined master supports various configuration settings that can be set via a YAML configuration file, environment variables, or command-line options. The configuration file is typically located at /etc/determined/master.yaml on the master and it is read when the master starts up. To inspect the configuration of an active master, use the Determined CLI and execute the command det master config. The master supports the following configuration settings:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "config_file",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#config-file",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "config_file",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#config-file",
    "content": "Path to the master configuration file. Normally this should only be set via an environment variable or command-line option. Defaults to /etc/determined/master.yaml.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#port",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "port",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#port",
    "content": "The TCP port on which the master accepts incoming connections. If TLS has been enabled, defaults to 8443; otherwise defaults to 8080.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#task-container-defaults",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#task-container-defaults",
    "content": "Specifies defaults for all task containers. A task represents a single schedulable unit, such as a trial, command, or TensorBoard.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "shm_size_bytes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#shm-size-bytes",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "shm_size_bytes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#shm-size-bytes",
    "content": "The size (in bytes) of /dev/shm for Determined task containers. Defaults to 4294967296.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "network_mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-mode",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "network_mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-mode",
    "content": "The Docker network to use for the Determined task containers. If this is set to host, Docker host-mode networking will be used instead. Defaults to bridge.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "dtrain_network_interface",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#dtrain-network-interface",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "dtrain_network_interface",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#dtrain-network-interface",
    "content": "The network interface to use during distributed training. If not set, Determined automatically determines the network interface to use. When training a model with multiple machines, the host network interface used by each machine must have the same interface name across machines. The network interface to use can be determined automatically, but there may be issues if there is an interface name common to all machines but it is not routable between machines. Determined already filters out common interfaces like lo and docker0, but agent machines may have others. If interface detection is not finding the appropriate interface, the dtrain_network_interface option can be used to set it explicitly (e.g., eth11). To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "cpu_pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu-pod-spec",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "cpu_pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu-pod-spec",
    "content": "Defines the default pod spec which will be applied to all CPU-only tasks when running on Kubernetes. See Customize a Pod for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "gpu_pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#gpu-pod-spec",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "gpu_pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#gpu-pod-spec",
    "content": "Defines the default pod spec which will be applied to all GPU tasks when running on Kubernetes. See Customize a Pod for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#image",
    "content": "Defines the default Docker image to use when executing the workload. If a Docker image is specified in the experiment config this default is overridden. This image must be accessible via docker pull to every Determined agent machine in the cluster. Users can configure different container images for NVIDIA GPU tasks using the cuda key (gpu prior to Determined 0.17.6), CPU tasks using cpu key, and ROCm (AMD GPU) tasks using the rocm key. Default values: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 for NVIDIA GPUs. determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-0.24.0 for ROCm. determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 for CPUs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "environment_variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#environment-variables",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "environment_variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#environment-variables",
    "content": "A list of environment variables that will be set in every task container. Each element of the list should be a string of the form NAME=VALUE. See Environment Variables for more details. Environment variables specified in the experiment configuration will override default values specified here. You can customize environment variables for CUDA (NVIDIA GPU), CPU, and ROCm (AMD GPU) tasks differently by specifying a dict with cuda (gpu prior to Determined 0.17.6), cpu, and rocm keys.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "force_pull_image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#force-pull-image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "force_pull_image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#force-pull-image",
    "content": "Defines the default policy for forcibly pulling images from the Docker registry and bypassing the Docker cache. If a pull policy is specified in the experiment configuration this default value is overridden. Please note that as of November 1st, 2020, unauthenticated users will be capped at 100 pulls from Docker Hub per 6 hours. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "registry_auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#registry-auth",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "registry_auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#registry-auth",
    "content": "Defines the default Docker registry credentials to use when pulling a custom base Docker image, if needed. If credentials are specified in the experiment config this default value is overridden. Credentials are specified as the following nested fields: username (required) password (required) serveraddress (required) email (optional)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "add_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#add-capabilities",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "add_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#add-capabilities",
    "content": "The default list of Linux capabilities to grant to task containers. Ignored by resource managers of type kubernetes. See environment.add_capabilities for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "drop_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#drop-capabilities",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "drop_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#drop-capabilities",
    "content": "Just like add_capabilities but for dropping capabilities.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "devices",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#devices",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "devices",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#devices",
    "content": "The default list of devices to pass to the Docker daemon. Ignored by resource managers of type kubernetes. See resources.devices for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "bind_mounts",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#bind-mounts",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "bind_mounts",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#bind-mounts",
    "content": "The default bind mounts to pass to the Docker container. Ignored by resource managers of type kubernetes. See resources.devices for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "kubernetes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#kubernetes",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "kubernetes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#kubernetes",
    "content": "max_slots_per_pod See resource_manager.max_slots for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "slurm",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slurm",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "slurm",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slurm",
    "content": "Additional Slurm options when launching trials with sbatch. See environment.slurm for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "pbs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#pbs",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "task_container_defaults",
      "lvl3": "pbs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#pbs",
    "content": "Additional PBS options when launching trials with qsub. See environment.pbs for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "root",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#root",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "root",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#root",
    "content": "Specifies the root directory of the state files. Defaults to /usr/share/determined/master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cache",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cache",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cache",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cache",
    "content": "Configuration for file cache.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cache",
      "lvl3": "cache_dir",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cache-dir",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cache",
      "lvl3": "cache_dir",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cache-dir",
    "content": "Specifies the root directory for file cache. Defaults to /var/cache/determined. Note that the master would break on startup if it does not have access to create this default directory.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "launch_error",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "launch_error",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error",
    "content": "Optional. Specifies whether to refuse an experiment or task if the slots requested exceeds the cluster capacity. This option has no effect for Kubernetes or Slurm clusters. If false, only a warning is returned. The default value is true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cluster_name",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cluster-name",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "cluster_name",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cluster-name",
    "content": "Optional. Specify a human-readable name for this cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "tensorboard_timeout",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tensorboard-timeout",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "tensorboard_timeout",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tensorboard-timeout",
    "content": "Specifies the duration in seconds before idle TensorBoard instances are automatically terminated. A TensorBoard instance is considered to be idle if it does not receive any HTTP traffic. The default timeout is 300 (5 minutes).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "notebook_timeout",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#notebook-timeout",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "notebook_timeout",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#notebook-timeout",
    "content": "Specifies the duration in seconds before idle Notebook instances are automatically terminated. A Notebook instance is considered to be idle if it is not receiving any HTTP traffic and it is not otherwise active (as defined by the notebook_idle_type option in the task configuration). Defaults to null, i.e. disabled.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#resource-manager",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#resource-manager",
    "content": "The resource manager used to acquire resources. Defaults to agent.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 56
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 57
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-agent",
    "content": "The agent resource manager includes static and dynamic agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 58
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#scheduler",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 59
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#scheduler",
    "content": "Specifies how Determined schedules tasks to agents on resource pools. If a resource pool is specified with an individual scheduler configuration, that will override the default scheduling behavior specified here. For more on scheduling behavior in Determined, see Scheduling.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 60
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 61
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type",
    "content": "The scheduling policy to use when allocating resources between different tasks (experiments, Notebooks, etc.). Defaults to fair_share. fair_share: Tasks receive a proportional amount of the available resources depending on the resource they require and their weight. round_robin: Tasks are scheduled in the order in which they arrive at the cluster. priority: Tasks are scheduled based on their priority, which can range from the values 1 to 99 inclusive. Lower priority numbers indicate higher-priority tasks. A lower-priority task will never be scheduled while a higher-priority task is pending. Zero-slot tasks (e.g., CPU-only Notebooks, TensorBoards) are prioritized separately from tasks requiring slots (e.g., experiments running on GPUs). Task priority can be assigned using the resources.priority field. If a task does not specify a priority it is assigned the default_priority. preemption: Specifies whether lower-priority tasks should be preempted to schedule higher priority tasks. Tasks are preempted in order of lowest priority first. default_priority: The priority that is assigned to tasks that do not specify a priority. Can be configured to 1 to 99 inclusively. Defaults to 42.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 62
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "fitting_policy",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fitting-policy",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 63
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "fitting_policy",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fitting-policy",
    "content": "The scheduling policy to use when assigning tasks to agents in the cluster. Defaults to best. best: The best-fit policy ensures that tasks will be preferentially \u201cpacked\u201d together on the smallest number of agents. worst: The worst-fit policy ensures that tasks will be placed on under-utilized agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 64
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "allow_heterogeneous_fits",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#allow-heterogeneous-fits",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 65
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "scheduler",
      "lvl5": "allow_heterogeneous_fits",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#allow-heterogeneous-fits",
    "content": "Fit distributed jobs onto agents of different sizes. When enabled, we still prefer to fit jobs on same sized nodes but will fallback to allow heterogeneous fits. Sizes should be powers of two for the fitting algorithm to work.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 66
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "default_aux_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#default-aux-resource-pool",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 67
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "default_aux_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#default-aux-resource-pool",
    "content": "The default resource pool to use for tasks that do not need dedicated compute resources, auxiliary, or systems tasks. Defaults to default if no resource pool is specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 68
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "default_compute_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#default-compute-resource-pool",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 69
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "default_compute_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#default-compute-resource-pool",
    "content": "The default resource pool to use for tasks that require compute resources, e.g. GPUs or dedicated CPUs. Defaults to default if no resource pool is specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 70
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "require_authentication",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#require-authentication",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 71
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "require_authentication",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#require-authentication",
    "content": "Whether to require that agent connections be verified using mutual TLS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 72
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "client_ca",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#client-ca",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 73
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: agent",
      "lvl4": "client_ca",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#client-ca",
    "content": "Certificate authority file to use for verifying agent certificates.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 74
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-kubernetes",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 75
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-kubernetes",
    "content": "The kubernetes resource manager launches tasks on a Kubernetes cluster. The Determined master must be running within the Kubernetes cluster. When using the kubernetes resource manager, we recommend deploying Determined using the Determined Helm Chart. When installed via Helm, the configuration settings below will be set automatically. For more information on using Determined with Kubernetes, see the documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 76
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "namespace",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#namespace",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 77
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "namespace",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#namespace",
    "content": "The namespace where Determined will deploy Pods and ConfigMaps.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 78
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "max_slots_per_pod",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-slots-per-pod",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 79
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "max_slots_per_pod",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-slots-per-pod",
    "content": "Each multi-slot (distributed training) task will be scheduled as a set of slots_per_task / max_slots_per_pod separate pods, with each pod assigned up to max_slots_per_pod slots. Distributed tasks with sizes that are not divisible by max_slots_per_pod are never scheduled. If you have a cluster of different size nodes, set max_slots_per_pod to the greatest common divisor of all the sizes. For example, if you have some nodes with 4 GPUs and other nodes with 8 GPUs, set maxSlotsPerPod to 4 so that all distributed experiments will launch with 4 GPUs per pod (with two pods on 8-GPU nodes). This field can also be set in task_container_defaults.kubernetes.max_slots_per_pod to allow per resource pool max_slots_per_pod.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 80
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 81
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type",
    "content": "Resource type used for compute tasks. Defaults to cuda.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 82
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cuda",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-cuda",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 83
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cuda",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-cuda",
    "content": "One NVIDIA GPU will be requested per compute slot. Prior to Determined 0.17.6, this option was called gpu.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 84
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-cpu",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 85
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-cpu",
    "content": "CPU resources will be requested for each compute slot. slot_resource_requests.cpu option is required to specify the specific amount of the resources.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 86
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_resource_requests",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-resource-requests",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 87
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_resource_requests",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-resource-requests",
    "content": "Supports customizing the resource requests made when scheduling Kubernetes pods.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 88
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_resource_requests",
      "lvl5": "cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 89
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "slot_resource_requests",
      "lvl5": "cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu",
    "content": "The number of Kubernetes CPUs to request per compute slot.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 90
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "master_service_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-service-name",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 91
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "master_service_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-service-name",
    "content": "The service account Determined uses to interact with the Kubernetes API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 92
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fluent",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 93
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fluent",
    "content": "Options for configuring how Fluent Bit sidecars are run.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 94
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": "image",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id1",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 95
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": "image",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id1",
    "content": "The Fluent Bit image to use. Defaults to fluent/fluent-bit:1.9.3.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 96
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": "uid/gid",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#uid-gid",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 97
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: kubernetes",
      "lvl4": "fluent",
      "lvl5": "uid/gid",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#uid-gid",
    "content": "The UID and GID to run the Fluent Bit sidecar as. If these are not specified, the container will run as root when the associated task container is running as root and as a default non-root user otherwise.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 98
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-slurm-or-pbs",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 99
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-slurm-or-pbs",
    "content": "The HPC launcher submits tasks to a Slurm/PBS cluster. For more information, see Configure and Verify Determined Master on HPC Cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 100
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "master_host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-host",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 101
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "master_host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-host",
    "content": "The hostname for the Determined master by which tasks will communicate with its API server.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 102
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "master_port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-port",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 103
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "master_port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-port",
    "content": "The port for the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 104
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#host",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 105
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#host",
    "content": "The hostname for the Launcher, which Determined communicates with to launch and monitor jobs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 106
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id2",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 107
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id2",
    "content": "The port for the Launcher.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 108
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "protocol",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#protocol",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 109
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "protocol",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#protocol",
    "content": "The protocol for communicating with the Launcher.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 110
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "security",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#security",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 111
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "security",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#security",
    "content": "Security-related configuration settings for communicating with the Launcher.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 112
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "security",
      "lvl5": "tls",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tls",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 113
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "security",
      "lvl5": "tls",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tls",
    "content": "TLS-related configuration settings. enabled: Enable TLS. skip_verify: Skip server certificate verification. certificate: Path to a file containing the cluster\u2019s TLS certificate. Only needed if the certificate is not signed by a well-known CA; cannot be specified if skip_verify is enabled.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 114
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "container_run_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container-run-type",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 115
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "container_run_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container-run-type",
    "content": "The type of the container runtime to be used when launching tasks. The value may be apptainer, singularity, enroot, or podman. The default value is singularity. The value singularity is also used when using Apptainer.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 116
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "auth_file",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#auth-file",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 117
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "auth_file",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#auth-file",
    "content": "The location of a file that contains an authorization token to communicate with the launcher. It is automatically updated by the launcher as needed when the launcher is started. The specified path must be writable by the launcher, and readable by the Determined master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 118
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id3",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 119
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id3",
    "content": "The default slot type assumed when users request resources from Determined in terms of slots. Available values are cuda, rocm, and cpu, where 1 cuda or rocm slot is 1 GPU. Otherwise, CPU slots are requested. The number of CPUs allocated per node is 1, unless overridden by slots_per_node in the experiment configuration. Defaults per-partition to cuda if GPU resources are found within the partition, else cpu. If GPUs cannot be detected automatically, for example when operating with gres_supported: false, then this result may be overridden using partition_overrides.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 120
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cuda",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id4",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 121
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cuda",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id4",
    "content": "One NVIDIA GPU will be requested per compute slot. Partitions will be represented as a resource pool with slot type cuda which can be overridden using partition_overrides.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 122
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: rocm",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-rocm",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 123
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: rocm",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#slot-type-rocm",
    "content": "One AMD GPU will be requested per compute slot. Partitions will be represented as a resource pool with slot type rocm which can be overridden using partition_overrides.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 124
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id5",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 125
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "slot_type",
      "lvl5": "slot_type: cpu",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id5",
    "content": "CPU resources will be requested for each compute slot. Partitions will be represented as a resource pool with slot type cpu. One node will be allocated per slot.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 126
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "rendezvous_network_interface",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rendezvous-network-interface",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 127
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "rendezvous_network_interface",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rendezvous-network-interface",
    "content": "The interface used to bootstrap communication between distributed jobs. For example, when using horovod the IP address for the host on this interface is passed in the host list to horovodrun. Defaults to any interface beginning with eth if one exists, otherwise the IPv4 resolution of the hostname.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 128
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "proxy_network_interface",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#proxy-network-interface",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 129
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "proxy_network_interface",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#proxy-network-interface",
    "content": "The interface used to proxy the master for services running on compute nodes. The interface Defaults to the IPv4 resolution of the hostname.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 130
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "user_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#user-name",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 131
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "user_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#user-name",
    "content": "The username that the Launcher will run as. It is recommended to set this to something other than root. The user must have a home directory with read permissions for all users to enable access to generated sbatch scripts and job log files. It must have access to the Slurm/PBS queue and node status commands (squeue, sinfo, pbsnodes, qstat ) to discover partitions and to display cluster usage. When changing this value, ownership of the job_storage_root directory tree must be updated accordingly, and the determined-master service must be restarted. See job_storage_root for an example command to update the directory tree ownership.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 132
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "group_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#group-name",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 133
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "group_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#group-name",
    "content": "The group that the Launcher will belong to. It should be a group that is not shared with other non-privileged users.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 134
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "sudo_authorized",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#sudo-authorized",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 135
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "sudo_authorized",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#sudo-authorized",
    "content": "A comma-separated list of user/group specifications identifying users for which the launcher can submit/control Slurm/PBS jobs using sudo. This value will be added to the sudo configuration created by the launcher. The default is ALL. The specification !root is automatically appended to this list to prevent privilege elevation. See the sudoers(5) definition of Runas_List for the full syntax of this value. See Configuration of sudo for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 136
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "apptainer_image_root or singularity_image_root",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#apptainer-image-root-or-singularity-image-root",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 137
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "apptainer_image_root or singularity_image_root",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#apptainer-image-root-or-singularity-image-root",
    "content": "The shared directory where Apptainer/Singularity images should be located. Only one of these two can be specified. This directory must be visible to the launcher and from the compute nodes. See Provide a Container Image Cache for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 138
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_storage_root",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#job-storage-root",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 139
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_storage_root",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#job-storage-root",
    "content": "The shared directory where temporary job-related files will be stored for each active HPC job. It hosts the necessary Determined executables for the job, any model and configuration files, space for per-rank /tmp and working directories, generated Slurm/PBS scripts, and any log files. This directory must be writable by the launcher and the compute nodes. It must be owned by the configured user_name and readable by all users that may launch jobs. If user_name is configured as root, a directory must be specified, otherwise, the default is $HOME/.launcher. The content for an HPC job under this directory is normally removed automatically when the job terminates. Content may be manually purged when there are no active HPC jobs. If user_name is changed, you can adjust the ownership of this directory using the command of the form: chown -R --from={prior_user_name} {user_name}:{group_name} {job_storage_root}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 140
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 141
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#path",
    "content": "The PATH for the launcher service so that it is able to find the Slurm, PBS, Singularity, NVIDIA binaries, etc., in case they are not in a standard location on the compute node. For example, PATH=/opt/singularity/3.8.5/bin:${PATH}.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 142
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "ld_library_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ld-library-path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 143
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "ld_library_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ld-library-path",
    "content": "The LD_LIBRARY_PATH for the launcher service so that it is able to find the Slurm, PBS, Singularity, NVIDIA libraries, etc., in case they are not in a standard location on the compute node. For example, LD_LIBRARY_PATH=/cm/shared/apps/slurm/21.08.6/lib:/cm/shared/apps/slurm/21.08.6/lib/slurm:${LD_LIBRARY_PATH}.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 144
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "launcher_jvm_args",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launcher-jvm-args",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 145
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "launcher_jvm_args",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launcher-jvm-args",
    "content": "Provides an override of the default HPC launcher JVM heap configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 146
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "tres_supported",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tres-supported",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 147
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "tres_supported",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tres-supported",
    "content": "Indicates if SelectType=select/cons_tres is set in the Slurm configuration. Affects how Determined requests GPUs from Slurm. The default is true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 148
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "gres_supported",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#gres-supported",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 149
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "gres_supported",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#gres-supported",
    "content": "Indicates if GPU resources are properly configured in the HPC workload manager. For PBS, the ngpus option can be used to identify the number of GPUs available on a node. For Slurm, GresTypes=gpu is set in the Slurm configuration, and nodes with GPUs have properly configured GRES to indicate the presence of any GPUs. The default is true. When false, Determined will request slots_per_trial nodes and utilize only GPU 0 on each node. It is the user\u2019s responsibility to ensure that GPUs will be available on nodes selected for the job using other configurations, such as targeting a specific resource pool with only GPU nodes or specifying a Slurm constraint in the experiment configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 150
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#partition-overrides",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 151
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#partition-overrides",
    "content": "A map of partition/queue names to partition-level overrides. For each configuration, if it is set for a given partition, it overrides the setting at the root level and applies to the resource pool resulting from this partition. Partition names are treated as case-insensitive.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 152
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "description",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#description",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 153
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "description",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#description",
    "content": "Description of the resource pool",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 154
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "rendezvous_network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id6",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 155
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "rendezvous_network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id6",
    "content": "Interface used to bootstrap communication between distributed jobs",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 156
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "proxy_network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id7",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 157
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "proxy_network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id7",
    "content": "Interface used to proxy the master for services running on compute nodes",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 158
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "slot_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id8",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 159
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "slot_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id8",
    "content": "The resource type used for tasks",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 160
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "task_container_defaults",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id9",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 161
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "partition_overrides",
      "lvl5": "task_container_defaults",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id9",
    "content": "See top-level setting. Each partition_overrides entry may specify a task_container_defaults that applies additional defaults on top of the top-level task_container_defaults for all tasks launched on that partition. When applying the defaults, individual fields override prior values, and list fields are appended. If the partition is referenced in a custom HPC resource pool, an additional task_container_defaults may be applied by the resource pool. partition_overrides: mlde_cuda: description: Partition for CUDA jobs (tesla cards only) slot_type: cuda task_container_defaults: dtrain_network_interface: hsn0,hsn1,hsn2,hsn3 slurm: sbatch_args: - --cpus-per-gpu=16 - --mem-per-gpu=65536 gpu_type: tesla mlde_cpu: description: Generic CPU job partition (limited to node001) slot_type: cpu task_container_defaults: slurm: sbatch_args: --nodelist=node001",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 162
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "default_aux_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id10",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 163
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "default_aux_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id10",
    "content": "The default resource pool to use for tasks that do not need dedicated compute resources, auxiliary, or systems tasks. Defaults to the Slurm/PBS default partition if no resource pool is specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 164
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "default_compute_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id11",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 165
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "default_compute_resource_pool",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id11",
    "content": "The default resource pool to use for tasks that require compute resources, e.g. GPUs or dedicated CPUs. Defaults to the Slurm/PBS default partition if it has GPU resources and if no resource pool is specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 166
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#job-project-source",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 167
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#job-project-source",
    "content": "Configures labeling of jobs on the HPC cluster (via Slurm --wckey or PBS -P). Allowed values are:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 168
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "project",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#project",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 169
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "project",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#project",
    "content": "Use the project name of the experiment (this is the default, if no project nothing is passed to workload manager).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 170
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "workspace",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#workspace",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 171
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "workspace",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#workspace",
    "content": "Use the workspace name of the project (if no workspace, nothing is passed to workload manager).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 172
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "label [:prefix]",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-prefix",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 173
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_manager",
      "lvl3": "type: slurm or pbs",
      "lvl4": "job_project_source",
      "lvl5": "label [:prefix]",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-prefix",
    "content": "Use the value from the experiment configuration tags list (if no matching tags, nothing is passed to workload manager). If a tag in the list begins with the specified prefix, remove the prefix and use the remainder as the value for the WCKey/Project. If multiple tag values begin with prefix, the remainders are concatenated with a comma (,) separator for Slurm or underscore (_) for PBS. If a prefix is not specified or empty, all tags will be matched (and therefore concatenated). Workload managers do not generally support multiple WCKey/Project values so it is recommended that prefix is configured to match a single label to enable use of the workload manager reporting tools that summarize usage by each WCKey/Project value.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 174
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#resource-pools",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 175
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#resource-pools",
    "content": "A list of resource pools. A resource pool is a collection of identical computational resources. You can specify which resource pool a job should be assigned to when the job is submitted. Refer to the documentation on Resource Pools for more information. Defaults to a resource pool with a name default.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 176
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "pool_name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#pool-name",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 177
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "pool_name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#pool-name",
    "content": "The name of the resource pool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 178
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "description",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id12",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 179
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "description",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id12",
    "content": "The description of the resource pool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 180
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "max_aux_containers_per_agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-aux-containers-per-agent",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 181
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "max_aux_containers_per_agent",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-aux-containers-per-agent",
    "content": "The maximum number of auxiliary or system containers that can be scheduled on each agent in this pool.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 182
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "agent_reconnect_wait",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-reconnect-wait",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 183
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "agent_reconnect_wait",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-reconnect-wait",
    "content": "Maximum time the master should wait for a disconnected agent before considering it dead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 184
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "agent_reattach_enabled (experimental)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-reattach-enabled-experimental",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 185
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "agent_reattach_enabled (experimental)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-reattach-enabled-experimental",
    "content": "Whether master & agent try to recover running containers after a restart. On master or agent process restart, the agent must reconnect within agent_reconnect_wait period.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 186
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "task_container_defaults",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id13",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 187
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "task_container_defaults",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id13",
    "content": "Each resource pool may specify a task_container_defaults that applies additional defaults on top of the top-level setting (and partition_overrides for Slurm/PBS) for all tasks launched in that resource pool. When applying the defaults, individual fields override prior values, and list fields are appended.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 188
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "kubernetes_namespace",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#kubernetes-namespace",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 189
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "kubernetes_namespace",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#kubernetes-namespace",
    "content": "When the Kubernetes resource manager is in use, this specifies a namespace that tasks in this resource pool will be launched into.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 190
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id14",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 191
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id14",
    "content": "Specifies how Determined schedules tasks to agents. The scheduler configuration on each resource pool will override the global one. For more on scheduling behavior in Determined, see Scheduling.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 192
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id15",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 193
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id15",
    "content": "The scheduling policy to use when allocating resources between different tasks (experiments, Notebooks, etc.). Defaults to fair_share.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 194
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "fair_share",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fair-share",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 195
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "fair_share",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#fair-share",
    "content": "Tasks receive a proportional amount of the available resources depending on the resource they require and their weight.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 196
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "round_robin",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#round-robin",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 197
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "round_robin",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#round-robin",
    "content": "Tasks are scheduled in the order in which they arrive at the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 198
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "priority",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#priority",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 199
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "type",
      "lvl5": "priority",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#priority",
    "content": "Tasks are scheduled based on their priority, which can range from the values 1 to 99 inclusive. Lower priority numbers indicate higher-priority tasks. A lower-priority task will never be scheduled while a higher-priority task is pending. Zero-slot tasks (e.g., CPU-only Notebooks, TensorBoards) are prioritized separately from tasks requiring slots (e.g., experiments running on GPUs). Task priority can be assigned using the resources.priority field. If a task does not specify a priority it is assigned the default_priority. preemption: Specifies whether lower-priority tasks should be preempted to schedule higher priority tasks. Tasks are preempted in order of lowest priority first. default_priority: The priority that is assigned to tasks that do not specify a priority. Can be configured to 1 to 99 inclusively. Defaults to 42.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 200
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id16",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 201
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id16",
    "content": "The scheduling policy to use when assigning tasks to agents in the cluster. Defaults to best.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 202
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": "best",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#best",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 203
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": "best",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#best",
    "content": "The best-fit policy ensures that tasks will be preferentially \u201cpacked\u201d together on the smallest number of agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 204
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": "worst",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#worst",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 205
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "scheduler",
      "lvl4": "fitting_policy",
      "lvl5": "worst",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#worst",
    "content": "The worst-fit policy ensures that tasks will be placed on under-utilized agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 206
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#provider",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 207
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#provider",
    "content": "Specifies the configuration of dynamic agents.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 208
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "master_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-url",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 209
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "master_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-url",
    "content": "The full URL of the master. A valid URL is in the format of scheme://host:port. The scheme must be either http or https. If the master is deployed on EC2, rather than hardcoding the IP address, you should use one of the following to set the host as an alias: local-ipv4, public-ipv4, local-hostname, or public-hostname. If the master is deployed on GCP, rather than hardcoding the IP address, you should use one of the following to set the host as an alias: internal-ip or external-ip. Which one you should select is based on your network configuration. On master startup, we will replace the above alias host with its real value. Defaults to http as scheme, local IP address as host, and 8080 as port.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 210
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "master_cert_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-cert-name",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 211
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "master_cert_name",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#master-cert-name",
    "content": "A hostname for which the master\u2019s TLS certificate is valid, if the host specified by the master_url option is an IP address or is not contained in the certificate. See Transport Layer Security for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 212
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "startup_script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#startup-script",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 213
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "startup_script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#startup-script",
    "content": "One or more shell commands that will be run during agent instance start up. These commands are executed as root as soon as the agent cloud instance has started and before the Determined agent container on the instance is launched. For example, this feature can be used to mount a distributed file system or make changes to the agent instance\u2019s configuration. The default value is the empty string. It may be helpful to use the YAML | syntax to specify a multi-line string. For example, startup_script: | mkdir -p /mnt/disks/second mount /dev/sdb1 /mnt/disks/second",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 214
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "container_startup_script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container-startup-script",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 215
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "container_startup_script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container-startup-script",
    "content": "One or more shell commands that will be run when the Determined agent container is started. These commands are executed inside the agent container but before the Determined agent itself is launched. For example, this feature can be used to configure Docker so that the agent can pull task images from GCR securely (see this example for more details). The default value is the empty string.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 216
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_image",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-image",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 217
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_image",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-image",
    "content": "The Docker image to use for the Determined agents. A valid form is <repository>:<tag>. Defaults to determinedai/determined-agent:<master version>.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 218
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_network",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-network",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 219
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_network",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-network",
    "content": "The Docker network to use for the Determined agent and task containers. If this is set to host, Docker host-mode networking will be used instead. The default value is determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 220
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_runtime",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-runtime",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 221
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "agent_docker_runtime",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#agent-docker-runtime",
    "content": "The Docker runtime to use for the Determined agent and task containers. Defaults to runc.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 222
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_idle_agent_period",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-idle-agent-period",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 223
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_idle_agent_period",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-idle-agent-period",
    "content": "How long to wait before terminating idle dynamic agents. This string is a sequence of decimal numbers, each with optional fraction and a unit suffix, such as \u201c30s\u201d, \u201c1h\u201d, or \u201c1m30s\u201d. Valid time units are \u201cs\u201d, \u201cm\u201d, \u201ch\u201d. The default value is 20m.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 224
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_agent_starting_period",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-agent-starting-period",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 225
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_agent_starting_period",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-agent-starting-period",
    "content": "How long to wait for agents to start up before retrying. This string is a sequence of decimal numbers, each with optional fraction and a unit suffix, such as \u201c30s\u201d, \u201c1h\u201d, or \u201c1m30s\u201d. Valid time units are \u201cs\u201d, \u201cm\u201d, \u201ch\u201d. The default value is 20m.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 226
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "min_instances",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#min-instances",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 227
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "min_instances",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#min-instances",
    "content": "Min number of Determined agent instances. Defaults to 0.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 228
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_instances",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-instances",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 229
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "max_instances",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#max-instances",
    "content": "Max number of Determined agent instances. Defaults to 5.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 230
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "launch_error_timeout",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error-timeout",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 231
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "launch_error_timeout",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error-timeout",
    "content": "Duration for which a provisioning error is valid. Tasks that are unschedulable in the existing cluster may be canceled. After the timeout period, the error state is reset. Defaults to 0s.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 232
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "launch_error_retries",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error-retries",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 233
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "launch_error_retries",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#launch-error-retries",
    "content": "Number of retries to allow before registering a provider provisioning error with launch_error_timeout duration. Defaults to 0.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 234
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-aws",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 235
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-aws",
    "content": "Required. Specifies running dynamic agents on AWS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 236
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "region",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#region",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 237
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "region",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#region",
    "content": "The region of the AWS resources used by Determined. We advise setting this region to be the same region as the Determined master for better network performance. Defaults to the same region as the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 238
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "root_volume_size",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#root-volume-size",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 239
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "root_volume_size",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#root-volume-size",
    "content": "Size of the root volume of the Determined agent in GB. We recommend at least 100GB. Defaults to 200.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 240
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "image_id",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#image-id",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 241
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "image_id",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#image-id",
    "content": "Optional. The AMI ID of the Determined agent. Defaults to the latest GCP agent image.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 242
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "tag_key",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tag-key",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 243
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "tag_key",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tag-key",
    "content": "Key for tagging the Determined agent instances. Defaults to managed-by.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 244
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "tag_value",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tag-value",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 245
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "tag_value",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#tag-value",
    "content": "Value for tagging the Determined agent instances. Defaults to the master instance ID if the master is on EC2, otherwise determined-ai-determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 246
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "custom_tags",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#custom-tags",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 247
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "custom_tags",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#custom-tags",
    "content": "List of arbitrary user-defined tags that are added to the Determined agent instances and do not affect how Determined works. Each tag must specify key and value fields. Defaults to the empty list. key: Key of custom tag. value: value of custom tag.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 248
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_name",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-name",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 249
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_name",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-name",
    "content": "Name to set for the Determined agent instances. Defaults to determined-ai-agent.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 250
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "ssh_key_name",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssh-key-name",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 251
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "ssh_key_name",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssh-key-name",
    "content": "Required. The name of the SSH key registered with AWS for SSH key access to the agent instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 252
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "iam_instance_profile_arn",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#iam-instance-profile-arn",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 253
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "iam_instance_profile_arn",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#iam-instance-profile-arn",
    "content": "The Amazon Resource Name (ARN) of the IAM instance profile to attach to the agent instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 254
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-interface",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 255
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-interface",
    "content": "Network interface to set for the Determined agent instances. public_ip: Whether to use public IP addresses for the Determined agents. See Set up Internet Access for instructions on whether a public IP should be used. Defaults to true. security_group_id: The ID of the security group that will be used to run the Determined agents. This should be the security group you identified or created in Set up Internet Access. Defaults to the default security group of the specified VPC. subnet_id: The ID of the subnet to run the Determined agents in. Defaults to the default subnet of the default VPC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 256
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-type",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 257
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-type",
    "content": "AWS instance type to use for dynamic agents. If instance_slots is not specified, for GPU instances this must be one of the following: g4dn.xlarge, g4dn.2xlarge, g4dn.4xlarge, g4dn.8xlarge, g4dn.16xlarge, g4dn.12xlarge, g4dn.metal, g5.xlarge, g5.2xlarge, g5.4xlarge, g5.8xlarge, g5.12xlarge, g5.16xlarge, g5.24xlarge, g5.48large, p3.2xlarge, p3.8xlarge, p3.16xlarge, p3dn.24xlarge, or p4d.24xlarge. For CPU instances, most general purpose instance types are allowed (t2, t3, c4, c5, m4, m5 and variants). Defaults to g4dn.metal.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 258
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_slots",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-slots",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 259
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "instance_slots",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#instance-slots",
    "content": "The optional number of GPUs for the AWS instance type. This is used in conjunction with the instance_type in order to specify types that are not listed in the instance_type list above. Note that some GPUs may not be supported. WARNING: be sure to specify the correct number of GPUs to ensure that provisioner launches the correct number of instances.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 260
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "cpu_slots_allowed",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu-slots-allowed",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 261
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "cpu_slots_allowed",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cpu-slots-allowed",
    "content": "Whether to allow slots on the CPU instance types. When true, and if the instance type doesn\u2019t have any GPUs, each instance will provide a single CPU-based compute slot; if it has any GPUs, they\u2019ll be used for compute slots instead. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 262
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "spot",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#spot",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 263
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "spot",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#spot",
    "content": "Whether to use spot instances. Defaults to false. See Use Spot Instances for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 264
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "spot_max_price",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#spot-max-price",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 265
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: aws",
      "lvl5": "spot_max_price",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#spot-max-price",
    "content": "Optional. Indicates the maximum price per hour that you are willing to pay for a spot instance. The market price for a spot instance varies based on supply and demand. If the market price exceeds the spot_max_price, Determined will not launch instances. This field must be a string and must not include a currency sign. For example, $2.50 should be represented as \"2.50\". Defaults to the on-demand price for the given instance type.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 266
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-gcp",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 267
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-gcp",
    "content": "Required. Specifies running dynamic agents on GCP.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 268
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "base_config",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#base-config",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 269
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "base_config",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#base-config",
    "content": "Instance resource base configuration that will be merged with the fields below to construct GCP inserting instance request. See REST Resource: instances for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 270
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "project",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id17",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 271
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "project",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id17",
    "content": "The project ID of the GCP resources used by Determined. Defaults to the project of the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 272
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "zone",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#zone",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 273
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "zone",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#zone",
    "content": "The zone of the GCP resources used by Determined. Defaults to the zone of the master.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 274
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "boot_disk_size",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#boot-disk-size",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 275
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "boot_disk_size",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#boot-disk-size",
    "content": "Size of the root volume of the Determined agent in GB. We recommend at least 100GB. Defaults to 200.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 276
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "boot_disk_source_image",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#boot-disk-source-image",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 277
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "boot_disk_source_image",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#boot-disk-source-image",
    "content": "Optional. The boot disk source image of the Determined agent that was shared with you. To use a specific version of the Determined agent image from a specific project, it should be set in the format: projects/<project-id>/global/images/<image-id>. Defaults to the latest GCP agent image.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 278
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "label_key",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-key",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 279
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "label_key",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-key",
    "content": "Key for labeling the Determined agent instances. Defaults to managed-by.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 280
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "label_value",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-value",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 281
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "label_value",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#label-value",
    "content": "Value for labeling the Determined agent instances. Defaults to the master instance name if the master is on GCP, otherwise determined-ai-determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 282
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "name_prefix",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#name-prefix",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 283
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "name_prefix",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#name-prefix",
    "content": "Name prefix to set for the Determined agent instances. The names of the Determined agent instances are a concatenation of the name prefix and a pet name. Defaults to the master instance name if the master is on GCP otherwise determined-ai-determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 284
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id18",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 285
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "network_interface",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id18",
    "content": "Required. Network configuration for the Determined agent instances. See the GCP API Access section for the suggested configuration. network: Required. Network resource for the Determined agent instances. The network configuration should specify the project ID of the network. It should be set in the format: projects/<project>/global/networks/<network>. subnetwork: Required. Subnetwork resource for the Determined agent instances. The subnet configuration should specify the project ID and the region of the subnetwork. It should be set in the format: projects/<project>/regions/<region>/subnetworks/<subnetwork>. external_ip: Whether to use external IP addresses for the Determined agent instances. See Set up Internet Access for instructions on whether an external IP should be set. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 286
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "network_tags",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-tags",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 287
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "network_tags",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#network-tags",
    "content": "An array of network tags to set firewalls for the Determined agent instances. This is the one you identified or created in Firewall Rules. Defaults to be an empty array.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 288
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "service_account",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#service-account",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 289
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "service_account",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#service-account",
    "content": "Service account for the Determined agent instances. See the GCP API Access section for suggested configuration. email: Email of the service account for the Determined agent instances. Defaults to the empty string. scopes: List of scopes authorized for the Determined agent instances. As suggested in GCP API Access, we recommend you set the scopes to [\"https://www.googleapis.com/auth/cloud-platform\"]. Defaults to [\"https://www.googleapis.com/auth/cloud-platform\"].",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 290
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "instance_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id19",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 291
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "instance_type",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id19",
    "content": "Type of instance for the Determined agents. machine_type: Type of machine for the Determined agents. Defaults to n1-standard-32. gpu_type: Type of GPU for the Determined agents. Set it to be an empty string to not use any GPUs. Defaults to nvidia-tesla-t4. gpu_num: Number of GPUs for the Determined agents. Defaults to 4. preemptible: Whether to use preemptible dynamic agent instances. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 292
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "cpu_slots_allowed",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id20",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 293
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "cpu_slots_allowed",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id20",
    "content": "Whether to allow slots on the CPU instance types. When true, and if the instance type doesn\u2019t have any GPUs, each instance will provide a single CPU-based compute slot; if it has any GPUs, they\u2019ll be used for compute slots instead. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 294
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "operation_timeout_period",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#operation-timeout-period",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 295
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: gcp",
      "lvl5": "operation_timeout_period",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#operation-timeout-period",
    "content": "Default value is 5m. The amount of time that a GCP operation can be tracked before timing out. The timeout period is specified using a string that consists of a sequence of decimal numbers, each with optional fraction, followed by a unit suffix. Valid time units are \u201cs\u201d for seconds, \u201cm\u201d for minutes, and \u201ch\u201d for hours. For example, you could set the timeout period to 30 seconds by using \u201c30s\u201d, or to 1 minute and 30 seconds by using \u201c1m30s\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 296
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: hpc",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-hpc",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 297
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: hpc",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-hpc",
    "content": "Required. Specifies a custom resource pool that submits work to an underlying Slurm/PBS partition on an HPC cluster. One resource pool is automatically created for each Slurm partition or PBS queue on an HPC cluster. This provider enables the creation of additional resource pools with different submission options to those partitions/queues.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 298
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: hpc",
      "lvl5": "partition",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#partition",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 299
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "resource_pools",
      "lvl3": "provider",
      "lvl4": "type: hpc",
      "lvl5": "partition",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#partition",
    "content": "The target HPC partition where jobs will be launched when using this resource pool. Add task_container_defaults to provide a resource pool with additional default options. The task_container_defaults from the resource pool are applied after any task_container_defaults from partition_overrides. When applying the defaults, individual fields override prior values, and list fields are appended. This can be used to create a resource pool with homogeneous resources when the underlying partition or queue does not. Consider the following: resource_pools: - pool_name: defq_GPU_tesla description: Lands jobs on defq_GPU with tesla GPU selected, XL675d systems task_container_defaults: slurm: gpu_type: tesla sbatch_options: - -CXL675d provider: type: hpc partition: defq_GPU In this example, jobs submitted to the resource pool named defq_GPU_tesla will be executed in the HPC partition named defq_GPU with the gpu_type property set, and Slurm constraint associated with the feature XL675d used to identify the model type of the compute node.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 300
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#checkpoint-storage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 301
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#checkpoint-storage",
    "content": "Specifies where model checkpoints will be stored. This can be overridden on a per-experiment basis in the Experiment Configuration Reference. A checkpoint contains the architecture and weights of the model being trained. Determined currently supports several kinds of checkpoint storage, gcs, s3, azure, and shared_fs, identified by the type subfield.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 302
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-gcs",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 303
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-gcs",
    "content": "Checkpoints are stored on Google Cloud Storage (GCS). Authentication is done using GCP\u2019s \u201cApplication Default Credentials\u201d approach. When using Determined inside Google Compute Engine (GCE), the simplest approach is to ensure that the VMs used by Determined are running in a service account that has the \u201cStorage Object Admin\u201d role on the GCS bucket being used for checkpoints. As an alternative (or when running outside of GCE), you can add the appropriate service account credentials to your container (e.g., via a bind-mount), and then set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the container path where the credentials are located. See Environment Variables for more information on how to set environment variables in trial environments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 304
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#bucket",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 305
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#bucket",
    "content": "The GCS bucket name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 306
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#prefix",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 307
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: gcs",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#prefix",
    "content": "The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 308
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-s3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 309
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-s3",
    "content": "Checkpoints are stored in Amazon S3.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 310
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id21",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 311
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id21",
    "content": "The S3 bucket name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 312
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "access_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#access-key",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 313
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "access_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#access-key",
    "content": "The AWS access key to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 314
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "secret_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#secret-key",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 315
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "secret_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#secret-key",
    "content": "The AWS secret key to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 316
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id22",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 317
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id22",
    "content": "The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 318
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "endpoint_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#endpoint-url",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 319
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: s3",
      "lvl4": "endpoint_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#endpoint-url",
    "content": "The optional endpoint to use for S3 clones, e.g., http://127.0.0.1:8080/.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 320
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-azure",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 321
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-azure",
    "content": "Checkpoints are stored in Microsoft\u2019s Azure Blob Storage. Authentication is performed by providing either a connection string or an account URL and an optional credential.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 322
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "container",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 323
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "container",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#container",
    "content": "The Azure Blob Storage container name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 324
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "connection_string",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#connection-string",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 325
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "connection_string",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#connection-string",
    "content": "The connection string for the service account to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 326
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "account_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#account-url",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 327
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "account_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#account-url",
    "content": "The account URL for the service account to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 328
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "credential",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#credential",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 329
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: azure",
      "lvl4": "credential",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#credential",
    "content": "The optional credential to use in conjunction with the account URL. Please only specify either connection_string or the account_url and credential pair.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 330
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-shared-fs",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 331
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-shared-fs",
    "content": "Checkpoints are written to a directory on the agent\u2019s file system. The assumption is that the system administrator has arranged for the same directory to be mounted at every agent host, and for the content of this directory to be the same on all agent hosts (e.g., by using a distributed or network file system such as GlusterFS or NFS).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 332
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "host_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#host-path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 333
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "host_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#host-path",
    "content": "The file system path on each agent to use. This directory will be mounted to /determined_shared_fs inside the trial container.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 334
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "storage_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#storage-path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 335
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "storage_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#storage-path",
    "content": "The optional path where checkpoints will be written to and read from. Must be a subdirectory of the host_path or an absolute path containing the host_path. If unset, checkpoints are written to and read from the host_path.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 336
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "propagation",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#propagation",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 337
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "checkpoint_storage",
      "lvl3": "type: shared_fs",
      "lvl4": "propagation",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#propagation",
    "content": "(Advanced users only) Optional propagation behavior for replicas of the bind-mount. Defaults to rprivate. When an experiment finishes, the system will optionally delete some checkpoints to reclaim space. The save_experiment_best, save_trial_best and save_trial_latest parameters specify which checkpoints to save. See Checkpoint Garbage Collection for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 338
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#db",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 339
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#db",
    "content": "Specifies the configuration of the database.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 340
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "user",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#user",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 341
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "user",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#user",
    "content": "Required. The database user to use when logging into the database.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 342
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "password",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#password",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 343
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "password",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#password",
    "content": "Required. The password to use when logging into the database.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 344
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "host",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id23",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 345
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "host",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id23",
    "content": "Required. The database host to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 346
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "port",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id24",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 347
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "port",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id24",
    "content": "Required. The database port to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 348
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#name",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 349
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#name",
    "content": "Required. The database name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 350
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "ssl_mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssl-mode",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 351
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "ssl_mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssl-mode",
    "content": "The SSL mode to use. See the PostgreSQL documentation for the list of possible values and their meanings. Defaults to disable. In order to ensure that SSL is used, this should be set to require, verify-ca, or verify-full.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 352
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "ssl_root_cert",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssl-root-cert",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 353
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "db",
      "lvl3": "ssl_root_cert",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssl-root-cert",
    "content": "The location of the root certificate file to use for verifying the server\u2019s certificate. See the PostgreSQL documentation for more information about certificate verification. Defaults to ~/.postgresql/root.crt.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 354
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id25",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 355
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id25",
    "content": "Specifies security-related configuration settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 356
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "tls",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id26",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 357
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "tls",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id26",
    "content": "Specifies configuration settings for TLS. TLS is enabled if certificate and key files are both specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 358
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "cert",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cert",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 359
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "cert",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#cert",
    "content": "Certificate file to use for serving TLS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 360
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#key",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 361
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "key",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#key",
    "content": "Key file to use for serving TLS.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 362
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "ssh",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssh",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 363
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "ssh",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#ssh",
    "content": "Specifies configuration settings for SSH.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 364
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "rsa_key_size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rsa-key-size",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 365
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "rsa_key_size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rsa-key-size",
    "content": "Number of bits to use when generating RSA keys for SSH for tasks. Maximum size is 16384.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 366
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "authz",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#authz",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 367
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "authz",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#authz",
    "content": "Authorization settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 368
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "type",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id27",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 369
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "type",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id27",
    "content": "Authorization system to use. Defaults to basic. See RBAC docs for further info.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 370
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "rbac_ui_enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rbac-ui-enabled",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 371
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "rbac_ui_enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#rbac-ui-enabled",
    "content": "Whether to enable RBAC in WebUI and CLI. When type is rbac, defaults true, otherwise false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 372
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "workspace_creator_assign_role",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#workspace-creator-assign-role",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 373
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "workspace_creator_assign_role",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#workspace-creator-assign-role",
    "content": "Assign a role to the user on workspace creation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 374
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "strict_job_queue_control",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#strict-job-queue-control",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 375
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "strict_job_queue_control",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#strict-job-queue-control",
    "content": "Restrict reordering of existing jobs through job queue to users with PERMISSION_TYPE_CONTROL_STRICT_JOB_QUEUE. Requires Determined Enterprise Edition. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 376
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#enabled",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 377
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#enabled",
    "content": "Whether this feature is enabled. Defaults to true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 378
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "role_id",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#role-id",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 379
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "security",
      "lvl3": "role_id",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#role-id",
    "content": "Integer identifier of a role to be assigned. Defaults to 2, which is the role id of WorkspaceAdmin role.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 380
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#webhooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 381
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "webhooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#webhooks",
    "content": "Specifies configuration settings related to webhooks. signing_key: The key used to sign outgoing webhooks. base_url: The URL users use to access Determined, for generating hyperlinks.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 382
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#telemetry",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 383
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#telemetry",
    "content": "Specifies configuration settings related to telemetry collection and tracing.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 384
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id28",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 385
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id28",
    "content": "Whether to collect and report anonymous information about the usage of this Determined cluster. See Telemetry for details on what kinds of information are reported. Defaults to true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 386
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "otel_enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#otel-enabled",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 387
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "otel_enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#otel-enabled",
    "content": "Whether OpenTelemetry is enabled. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 388
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "otel_endpoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#otel-endpoint",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 389
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "telemetry",
      "lvl3": "otel_endpoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#otel-endpoint",
    "content": "OpenTelemetry endpoint to use. Defaults to localhost:4317.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 390
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "observability",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#observability",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 391
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "observability",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#observability",
    "content": "Specifies whether Determined enables Prometheus monitoring routes. See Prometheus for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 392
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "observability",
      "lvl3": "enable_prometheus",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#enable-prometheus",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 393
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "observability",
      "lvl3": "enable_prometheus",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#enable-prometheus",
    "content": "Whether Prometheus is enabled. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 394
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#logging",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 395
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#logging",
    "content": "Specifies configuration settings for the logging backend for trial logs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 396
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: default",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-default",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 397
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: default",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-default",
    "content": "Trial logs are shipped to the master and stored in Postgres. If nothing is set, this is the default.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 398
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-elastic",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 399
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#type-elastic",
    "content": "Trial logs are shipped to the Elasticsearch cluster described by the configuration settings in the section. See the topic guide for a more detailed explanation of how and when to use Elasticsearch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 400
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id29",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 401
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "host",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id29",
    "content": "Hostname or IP address for the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 402
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id30",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 403
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "port",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id30",
    "content": "Port for the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 404
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id31",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 405
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id31",
    "content": "Security-related configuration settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 406
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "username",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#username",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 407
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "username",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#username",
    "content": "Username to use when accessing the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 408
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "password",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id32",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 409
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "password",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id32",
    "content": "Password to use when accessing the cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 410
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "tls",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id33",
    "content": null,
    "type": "lvl5",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 50,
      "position": 411
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "logging",
      "lvl3": "type: elastic",
      "lvl4": "security",
      "lvl5": "tls",
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id33",
    "content": "TLS-related configuration settings. enabled: Enable TLS. skip_verify: Skip server certificate verification. certificate: Path to a file containing the cluster\u2019s TLS certificate. Only needed if the certificate is not signed by a well-known CA; cannot be specified if skip_verify is enabled. additional_fluent_outputs: An optional configuration string containing additional Fluent Bit outputs for advanced users to specify logging integrations. See the Fluent Bit documentation for the format and supported logging outputs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 412
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#scim",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 413
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#scim",
    "content": "Applies only to Determined Enterprise Edition. Specifies whether the SCIM service is enabled and the credentials for clients to use it.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 414
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id34",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 415
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id34",
    "content": "Whether to enable SCIM. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 416
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#auth",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 417
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#auth",
    "content": "The configuration for authenticating SCIM requests.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 418
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id35",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 419
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "type",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id35",
    "content": "The authentication type to use. Either \"basic\" (for HTTP basic authentication) or \"oauth\" (for OAuth 2.0).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 420
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "username",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id36",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 421
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "username",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id36",
    "content": "The username for HTTP basic authentication (only allowed with type: basic).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 422
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "password",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id37",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 423
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "scim",
      "lvl3": "auth",
      "lvl4": "password",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id37",
    "content": "The password for HTTP basic authentication (only allowed with type: basic).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 424
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#saml",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 425
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#saml",
    "content": "Applies only to Determined Enterprise Edition. Specifies whether SAML SSO is enabled and the configuration to use it.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 426
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id38",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 427
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "enabled",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id38",
    "content": "Whether to enable SAML SSO. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 428
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "provider",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id39",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 429
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "provider",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#id39",
    "content": "The name of the IdP. Currently (officially) supported: \u201cokta\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 430
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_recipient_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-recipient-url",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 431
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_recipient_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-recipient-url",
    "content": "The URL your IdP will send SAML assertions to.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 432
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_sso_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-sso-url",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 433
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_sso_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-sso-url",
    "content": "An IdP-provided URL to redirect SAML requests to.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 434
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_sso_descriptor_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-sso-descriptor-url",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 435
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_sso_descriptor_url",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-sso-descriptor-url",
    "content": "An IdP-provided URL, also known as IdP issuer. It is an identifier for the IdP that issues the SAML requests and responses.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 436
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_cert_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-cert-path",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 437
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Master Configuration Reference",
      "lvl1": "Master Configuration Reference",
      "lvl2": "saml",
      "lvl3": "idp_cert_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/deploy/config/master-config-reference.html#idp-cert-path",
    "content": "The path to the IdP\u2019s certificate, used to validate assertions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 438
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#det-core-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#det-core-api-reference",
    "content": "User Guide Core API User Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.init",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#module-determined.core",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.init",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#module-determined.core",
    "content": "determined.core.init*distributed: Optional[determined.core._distributed.DistributedContext] = Nonecheckpoint_storage: Optional[Union[str, Dict[str, Any]]] = Nonepreempt_mode: determined.core._preempt.PreemptMode = PreemptMode.WorkersAskChieftensorboard_mode: determined.core._tensorboard_mode.TensorboardMode = TensorboardMode.AUTOdetermined.core._context.Context core.init() builds a core.Context for use with the Core API. Always use with core.init() as context instead of instantiating a core.Context directly. Certain components of the Core API may be configured by passing arguments to core.init(). The only arg that is required is a DistributedContext, and even that is only required for multi-slot tasks. All of your training must occur within the scope of the with core.init() as core_context, as there are resources necessary for training which start in the core.Context\u2019s __enter__ method and must be cleaned up in its __exit__() method. Parameters distributed (core.DistributedContext, optional) \u2013 Passing a DistributedContext is required for multi-slot training, but unnecessary for single-slot training. Defaults to None. preempt_mode (core.PreemptMode, optional) \u2013 Configure the calling pattern for the core_context.preempt.should_preempt() method. See PreemptMode for more detail. Defaults to WorkersAskChief. checkpoint_storage (Union[str, dict], optional) \u2013 A directory path or a cloud storage URI of the form s3://<bucket>[/<prefix>] (AWS) or gs://<bucket>[/<prefix>] (GCP). This should only be used when IAM permissions can be assumed. You may also pass a dictionary matching the checkpoint_storage field of the experiment config, with the exception that type: shared_fs configs are not allowed. tensorboard_mode (core.TensorboardMode, optional) \u2013 Define how Tensorboard metrics and profiling data are retained. See TensorboardMode` for more detail. Defaults to AUTO.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.Context",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-context",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.Context",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-context",
    "content": "class determined.core.Contextcheckpoint: determined.core._checkpoint.CheckpointContextdistributed: Optional[determined.core._distributed.DistributedContext] = Nonepreempt: Optional[determined.core._preempt.PreemptContext] = Nonetrain: Optional[determined.core._train.TrainContext] = Nonesearcher: Optional[determined.core._searcher.SearcherContext] = Noneinfo: Optional[determined._info.ClusterInfo] = Noneexperimental: Optional[determined.core._experimental.ExperimentalCoreContext] = None_tensorboard_manager: Optional[determined.tensorboard.base.TensorboardManager] = None_heartbeat: Optional[determined.core._heartbeat._Heartbeat] = None_log_shipper: Optional[determined.core._log_shipper._LogShipper] = None core.Context is a simple composition of several component APIs, with the following public members: .checkpoint, a CheckpointContext .distributed, a DistributedContext .preempt, a PreemptContext .searcher, a SearcherContext .train, a TrainContext core.Context is a tool for integrating arbitrary distributed tasks into a Determined cluster. You should always use core.init() instead of creating a core.Context manually.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.DistributedContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-distributedcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.DistributedContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-distributedcontext",
    "content": "class determined.core.DistributedContext*rank: intsize: intlocal_rank: intlocal_size: intcross_rank: intcross_size: intchief_ip: Optional[str] = Nonepub_port: int = 12360pull_port: int = 12376port_offset: int = 0force_tcp: bool = False DistributedContext provides useful methods for effective distributed training. A DistributedContext has the following required args: rank: the index of this worker in the entire job size: the number of workers in the entire job local_rank: the index of this worker on this machine local_size: the number of workers on this machine cross_rank: the index of this machine in the entire job cross_size: the number of machines in the entire job Additionally, any time that cross_size > 1, you must also provide: chief_ip: the ip address to reach the chief worker (where rank==0) DistributedContext has .allgather(), .gather(), and .broadcast() methods, which are easy to use and which can be useful for coordinating work across workers, but it is not a replacement for the allgather/gather/broadcast operations in your particular distributed training framework. classmethod from_horovodhvd: Anychief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the provided hvd module to determine rank information. Example: import horovod.torch as hvd hvd.init() distributed = DistributedContext.from_horovod(hvd) The IP address for the chief worker is required whenever hvd.cross_size() > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_deepspeedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard deepspeed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_torch_distributedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard torch distributed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided via the chief_ip argument or the DET_CHIEF_IP environment variable. get_rankint Return the rank of the process in the trial. The rank of a process is a unique ID within the trial. That is, no two processes in the same trial are assigned the same rank. get_local_rankint Return the rank of the process on the agent. The local rank of a process is a unique ID within a given agent and trial; that is, no two processes in the same trial that are executing on the same agent are assigned the same rank. get_sizeint Return the number of slots this trial is running on. get_num_agentsint Return the number of agents this trial is running on. gatherstuff: AnyOptional[List] Gather stuff to the chief. The chief returns a list of all stuff, and workers return None. gather() is not a replacement for the gather functionality of your distributed training framework. gather_localstuff: AnyOptional[List] Gather stuff to the local chief. The local chief returns a list of all stuff, and local workers return None. gather_local() is not a replacement for the gather functionality of your distributed training framework. allgatherstuff: AnyList Gather stuff to the chief and broadcast all of it back to the workers. allgather() is not a replacement for the allgather functionality of your distributed training framework. allgather_localstuff: AnyList Gather stuff to the local chief and broadcast all of it back to the local workers. allgather_local() is not a replacement for the allgather functionality of your distributed training framework. broadcaststuff: AnyAny Every worker gets the stuff sent by the chief. broadcast() is not a replacement for the broadcast functionality of your distributed training framework. broadcast_localstuff: Optional[Any] = NoneAny Every worker gets the stuff sent by the local chief. broadcast_local() is not a replacement for the broadcast functionality of your distributed training framework.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.CheckpointContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-checkpointcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.CheckpointContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-checkpointcontext",
    "content": "class determined.core.CheckpointContextdist: determined.core._distributed.DistributedContextstorage_manager: determined.common.storage.base.StorageManagersession: determined.common.api._session.Sessiontask_id: strallocation_id: Optional[str]tbd_sync_mode: determined.core._tensorboard_mode.TensorboardModetensorboard_manager: Optional[determined.tensorboard.base.TensorboardManager] CheckpointContext gives access to checkpoint-related features of a Determined cluster. uploadckpt_dir: Optional[Union[str, os.PathLike]]metadata: Optional[Dict[str, Any]] = None*shard: bool = Falseselector: Optional[Callable[[str], bool]] = Nonestr upload() chooses a random storage_id, then uploads the contents of ckpt_dir to checkpoint storage into a directory by the name of the storage_id. The name of the ckpt_dir is not preserved. When shard=False, only the chief worker (distributed.rank==0) may call upload(). When shard=True, upload() becomes a synchronization point between workers, so all workers must call upload(). Those workers with nothing to upload may pass ckpt_dir=None. The final checkpoint stored in checkpoint storage will contain a union of the contents from each ckpt_dir. Each worker may optionally provide a selector that accepts a path relative to the checkpoint root, and returns True for paths that should be uploaded. Returns: The storage_id for this checkpoint. Example: if core_context.distributed.rank == 0: storage_id = core_context.checkpoint.upload(ckpt_dir, shard=False) print(f\"done uploading checkpoint {storage_id}\") downloadstorage_id: strckpt_dir: Union[str, os.PathLike]download_mode: determined.core._checkpoint.DownloadMode = DownloadMode.LocalWorkersShareDownload*selector: Optional[Callable[[str], bool]] = NoneNone Download the contents of a checkpoint from checkpoint storage into a directory specified by ckpt_dir, which is created if it does not exist. This .download() method is similar to but less flexible than the .download() method of the Checkpoint class in the Determined Python SDK. This .download() is here as a convenience. get_metadatastorage_id: strDict[str, Any] Returns the current metadata associated with the checkpoint. store_pathmetadata: Optional[Dict[str, Any]] = None*shard: bool = FalseIterator[Tuple[pathlib.Path, str]] store_path() is a context manager which chooses a random path and prepares a directory you should save your model to. When the context manager exits, the model is automatically uploaded (at least, for cloud-backed checkpoint storage backends). metadata must include a \u2018steps_completed\u2019 key in the current implementation. Raises ValueError if the \u2018steps_completed\u2019 key is not present in the metadata dictionary. When shard=False, only the chief worker (distributed.rank==0) may call store_path(). When shard=True, store_path() becomes a synchronization point between workers, so all workers must call store_path(), even workers which will not write any checkpoint files. Example: if core_context.distributed.rank == 0: with core_context.checkpoint.store_path(shard=False) as (path, storage_id): my_save_model(my_model, path) print(f\"done saving checkpoint {storage_id}\") print(f\"done uploading checkpoint {storage_id}\") restore_pathstorage_id: strdownload_mode: determined.core._checkpoint.DownloadMode = DownloadMode.LocalWorkersShareDownload*selector: Optional[Callable[[str], bool]] = NoneIterator[pathlib.Path] restore_path() is a context manager which downloads a checkpoint (if required by the storage backend) and cleans up the temporary files afterwards (if applicable). In multi-worker scenarios, with the default download_mode (LocalWorkersShareDownload), all workers must call restore_path() but only the local chief worker on each node (distributed.local_rank==0) actually downloads data. Example: with core_context.checkpoint.restore_path(my_checkpoint_uuid) as path: my_model = my_load_model(path) deletestorage_id: strNone Delete a checkpoint from the storage backend.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.PreemptContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-preemptcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.PreemptContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-preemptcontext",
    "content": "class determined.core.PreemptContextsession: determined.common.api._session.Sessionallocation_id: strdist: determined.core._distributed.DistributedContextpreempt_mode: determined.core._preempt.PreemptMode = PreemptMode.WorkersAskChief PreemptContext gives access to preemption signals that originate from a user action, such as pausing an experiment using the WebUI or the CLI, from in the Determined scheduler. should_preemptauto_ack: bool = Truebool should_preempt() returns True if the task should shut itself down, or False otherwise. The requirements on the the caller and the synchronization between workers during a call to should_preempt() are defined by the preempt_mode argument passed to the PreemptContext constructor. Parameters auto_ack (bool, optional) \u2013 In order for the task to be restarted by the Determined master after shutting down due to preemption, the task must acknowledge the preemption signal to the Determined master. When auto_ack is True this acknowledgement is automatically sent the first time that should_preempt() returns True. If you might choose not to exit after receiving the preemption signal (but you still want to check the signal for some purpose), then you should set auto_ack to False. Then if you later do decide to comply with the preemption signal, it is your responsibility to call acknowledge_preemption_signal() manually any time before exiting. Defaults to True. Currently, only blocking behavior is supported when checking should_preempt(), so it is not performant enough to call every batch. acknowledge_preemption_signalNone acknowledge_preemption_signal() tells the Determined master that you are shutting down, but you have not finished your work and you expect to be restarted later to complete it. This is important to tell the master explicitly because otherwise if the python process exits with a zero exit code, the master interprets that as a completed task, and the task does not get rescheduled. By default, acknowledge_preemption_signal() is called automatically the first time that should_preempt() returns True, unless should_preempt() is called with auto_ack=False.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.TrainContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-traincontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.TrainContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-traincontext",
    "content": "class determined.core.TrainContextsession: determined.common.api._session.Sessiontrial_id: intrun_id: intexp_id: intdistributed: determined.core._distributed.DistributedContexttensorboard_mode: determined.core._tensorboard_mode.TensorboardModetensorboard_manager: Optional[determined.tensorboard.base.TensorboardManager]tbd_writer: Optional[determined.tensorboard.metric_writers.callback.BatchMetricWriter] TrainContext gives access to report training and validation metrics to the Determined master during trial tasks. set_statusstatus: strNone Report a short user-facing string that the WebUI can render to indicate what a trial is working on. report_training_metricssteps_completed: intmetrics: Dict[str, Any]batch_metrics: Optional[List[Dict[str, Any]]] = NoneNone Report training metrics to the master. You can include a list of batch_metrics. Batch metrics are not be shown in the WebUI but may be accessed from the master using the CLI for post-processing. report_validation_metricssteps_completed: intmetrics: Dict[str, Any]None Report validation metrics to the master. Note that for hyperparameter search, this is independent of the need to report the searcher metric using SearcherOperation.report_completed() in the Searcher API. report_metricsgroup: strsteps_completed: intmetrics: Dict[str, Any]None Report metrics data to the master. Parameters group (string) \u2013 metrics group name. Can be used to partition metrics into different logical groups or time series. \u201ctraining\u201d and \u201cvalidation\u201d group names map to built-in training and validation time series. Note: Group cannot contain . character. steps_completed (int) \u2013 global step number, e.g. the number of batches processed. metrics (Dict[str, Any]) \u2013 metrics data dictionary. Must be JSON-serializable. When reporting metrics with the same group and steps_completed values, the dictionary keys must not overlap. get_tensorboard_pathpathlib.Path Get TensorBoard log directory path. upload_tensorboard_filesselector: Callable[[pathlib.Path], bool] = <function TrainContext.<lambda>>, mangler: Callable[[pathlib.Path, int], pathlib.Path] = <function TrainContext.<lambda>>None Upload files generated for consumption by Tensorboard to checkpoint storage. Parameters selector \u2013 optional function returning True for a file that should be included. If not provided, all files are uploaded. mangler \u2013 optional function modifying the destination file names based on rank. report_early_exitreason: determined.core._train.EarlyExitReasonNone Report an early exit reason to the Determined master. Currenlty, the only meaningful value to report is EarlyExitReason.INVALID_HP, which is reported automatically in core.Context.__exit__() detects an exception of type det.InvalidHP. get_experiment_best_validationOptional[float] Get the best reported validation metric reported so far, across the whole experiment. The returned value is the highest or lowest reported validation metric value, using the searcher.metric field of the experiment config as the key and searcher.smaller_is_better for the comparison.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searchercontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searchercontext",
    "content": "class determined.core.SearcherContextsession: determined.common.api._session.Sessiondist: determined.core._distributed.DistributedContexttrial_id: intrun_id: intallocation_id: strunits: Optional[determined.core._searcher.Unit] = None SearcherContext gives direct access to operations emitted by the search algorithm in the master. Each SearcherOperation emitted has a (unitless) length that you should train for, then you complete the op by reporting the validation metric you are searching over. It is the user\u2019s responsibility to execute the required training. Because the user configured the length of the searcher in the experiment configuration, the user should know if the unitless length represents epochs, batches, records, etc. It is also the user\u2019s responsibility to evaluate the model after training and report the correct metric; if you intend to search over a metric called val_accuracy, you should report val_accuracy. Lastly, it is recommended (not required) to report progress periodically, so that the webui can accurately reflect current progress. Progress is another unitless length. Example: # Assuming you configured the searcher in terms of batches, # the op.length is also interpeted as a batch count. # Note that you'll have to load your starting point from a # checkpoint if you want to support pausing/continuing training. batches_trained = 0 for op in core_context.searcher.operations(): # Train for however long the op requires you to. # Note that op.length is an absolute length, not an # incremental length: while batches_trained < op.length: my_train_batch() batches_trained += 1 # Reporting progress every batch would be expensive: if batches_trained % 1000: op.report_progress(batches_trained) # After training the required amount, pass your searcher # metric to op.report_completed(): val_metrics = my_validate() op.report_completed(val_metrics[\"my_searcher_metric\"]) Note that reporting metrics is completely independent of the SearcherContext API, using core_context.train.report_training_metrics() or core_context.train.report_validation_metrics(). operationssearcher_mode: determined.core._searcher.SearcherMode = SearcherMode.WorkersAskChiefauto_ack: bool = TrueIterator[determined.core._searcher.SearcherOperation] Iterate through all the operations this searcher has to offer. See SearcherMode for details about calling requirements in distributed training scenarios. After training to the point specified by each SearcherOperation, the chief, and only the chief, must call op.report_completed() on each operation. This is true regardless of the searcher_mode setting because the Determined master needs a clear, unambiguous report of when an operation is completed. acknowledge_out_of_opsNone acknowledge_out_of_ops() tells the Determined master that you are shutting down because you have recognized the searcher has no more operations for you to complete at this time. This is important for the Determined master to know that it is safe to restart this process should new operations be assigned to this trial. acknowledge_out_of_ops() is normally called automatically just before operations() raises a StopIteration, unless operations() is called with auto_ack=False. get_configured_unitsOptional[determined.core._searcher.Unit] get_configured_units() reports what units were used in the searcher field of the experiment config. If no units were configured, None is returned. An experiment configured like this causes get_configured_units() to return EPOCHS: searcher: name: single max_length: epochs: 50 An experiment configured like this causes get_configured_units() to return None: searcher: name: single max_length: 50",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherOperation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searcheroperation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherOperation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searcheroperation",
    "content": "class determined.core.SearcherOperationsession: determined.common.api._session.Sessiontrial_id: intlength: intis_chief: bool A SearcherOperation is a request from the hyperparameter-search logic for the training script to execute one train-validate-report cycle. Some searchers, such as single, random, or grid, pass only a single SearcherOperation to each trial, while others may pass many SearcherOperations. Each SearcherOperation has a length attribute representing the cumulative training that should be completed before the validate-report steps of the cycle. The length attribute is absolute, not incremental, meaning that if the searcher wants you to train for 10 units and validate, then train for 10 more units and validate, it emits one SearcherOperation with .length=10 followed by a second SearcherOperation with .length=20. Using absolute lengths instead of incremental lengths makes restarting after crashes simple and robust.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.PreemptMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-preemptmode",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.PreemptMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-preemptmode",
    "content": "class determined.core.PreemptModevalue PreemptMode defines the calling behavior of the PreemptContext.should_preempt() call. When mode is WorkersAskChief (the default), all workers must call should_preempt() in step. Only the chief actually communicates with the master, then the chief broadcasts its decision to all workers. This guarantees that all workers decide to preempt at the exact same time. When mode is ChiefOnly, only the chief is allowed to call PreemptContext.should_preempt(). Usually this implies you must manually inform the workers if they should preempt or not. When mode is WorkersAskMaster, each worker contacts the master independently in order to decide to preempt or not. Each worker receives the preemption signal at roughly the same time, but it becomes your responsibility to tolerate situations where some workers have exited due to preemption and others have not.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searchermode",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.SearcherMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-searchermode",
    "content": "class determined.core.SearcherModevalue SearcherMode defines the calling behavior of the SearcherContext.operations() call. When mode is WorkersAskChief (the default), all workers must call SearcherContext.operations() in step with each other. The chief iterates through searcher operations from the master and then propagates the operations to each worker, introducing a synchronization point between workers. When mode is ChiefOnly, only the chief may call SearcherContext.operations(). Usually this implies you must manually inform the workers of what work to do next.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.TensorboardMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-tensorboardmode",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.core.TensorboardMode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-core-tensorboardmode",
    "content": "class determined.core.TensorboardModevalue TensorboardMode defines how Tensorboard artifacts are handled. In AUTO mode the chief automatically writes any reported training or validation metrics to the Tensorboard path (see TrainContext.get_tensorboard_path()), and automatically uploads all of its own tensorboard artifacts to checkpoint storage. Tensorboard artifacts written by non-chief workers will not be uploaded at all. This is the same behavior that existed prior to 0.18.3. In MANUAL mode no Tensorboard artifacts are written or uploaded at all. It is entirely up to the user to write their desired metrics and upload them with calls to TrainContext.upload_tensorboard_files().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.TrialInfo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-trialinfo",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.core API Reference",
      "lvl1": "det.core API Reference",
      "lvl2": "determined.TrialInfo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-core-reference.html#determined-trialinfo",
    "content": "class determined.TrialInfotrial_id: intexperiment_id: inttrial_seed: inthparams: Dict[str, Any]config: Dict[str, Any]steps_completed: inttrial_run_id: intdebug: boolinter_node_network_interface: Optional[str] experiment_id The Experiment ID for the current task. hparams The hyperparameter values selected for the current Trial. trial_id The Trial ID for the current task. trial_seed The random seed for the current Trial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training Reference",
      "lvl1": "Training Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/index.html#training-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training Reference",
      "lvl1": "Training Reference",
      "lvl2": "Python Modules APIs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/index.html#python-modules-apis",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training Reference",
      "lvl1": "Training Reference",
      "lvl2": "Python Modules APIs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/index.html#python-modules-apis",
    "content": "det det.core det.pytorch det.pytorch.samplers det.pytorch.deepspeed det.keras",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training Reference",
      "lvl1": "Training Reference",
      "lvl2": "Experiment Configuration File",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/index.html#experiment-configuration-file",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training Reference",
      "lvl1": "Training Reference",
      "lvl2": "Experiment Configuration File",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/index.html#experiment-configuration-file",
    "content": "Experiment Configuration Reference",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#det-keras-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#det-keras-api-reference",
    "content": "User Guide Keras API",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrial",
    "content": "class determined.keras.TFKerasTrialcontext: determined.keras._tf_keras_context.TFKerasTrialContext To implement a new tf.keras trial, subclass this class and implement the abstract methods described below (build_model(), build_training_data_loader(), and build_validation_data_loader()). In most cases you should provide a custom __init__() method as well. By default, experiments use TensorFlow 2.x. To configure your trial to use legacy TensorFlow 1.x, specify a TensorFlow 1.x image in the environment.image field of the experiment configuration (e.g., determinedai/environments:cuda-10.2-pytorch-1.7-tf-1.15-gpu-0.21.2). Trials default to using eager execution with TensorFlow 2.x but not with TensorFlow 1.x. To override the default behavior, call the appropriate function at the top of your code. For example, if you want to disable eager execution while using TensorFlow 2.x, call tf.compat.v1.disable_eager_execution after your import statements. If you are using TensorFlow 1.x in eager mode, please add experimental_run_tf_function=False to your model compile function. __init__context: determined.keras._tf_keras_context.TFKerasTrialContextNone Initializes a trial using the provided context. This method should typically be overridden by trial definitions: at minimum, it is important to store context as an instance variable so that it can be accessed by other methods of the trial class. This can also be a convenient place to initialize other state that is shared between methods. abstract build_modelkeras.engine.training.Model Returns the deep learning architecture associated with a trial. The architecture might depend on the current values of the model\u2019s hyperparameters, which can be accessed via context.get_hparam(). This function returns a tf.keras.Model object. After constructing the tf.keras.Model object, users must do two things before returning it: Wrap the model using context.wrap_model(). Compile the model using model.compile(). abstract build_training_data_loaderUnion[keras.utils.data_utils.Sequence, tensorflow.python.data.ops.dataset_ops.DatasetV2, SequenceAdapter, tuple] Defines the data loader to use during training. Should return one of the following: 1) A tuple (x_train, y_train), where x_train is a NumPy array (or array-like), a list of arrays (in case the model has multiple inputs), or a dict mapping input names to the corresponding array, if the model has named inputs. y_train should be a NumPy array. 2) A tuple (x_train, y_train, sample_weights) of NumPy arrays. 3) A tf.data.Dataset returning a tuple of either (inputs, targets) or (inputs, targets, sample_weights). 4) A keras.utils.Sequence returning a tuple of either (inputs, targets) or (inputs, targets, sample weights). When using tf.data.Dataset, you must wrap the dataset using determined.keras.TFKerasTrialContext.wrap_dataset(). This wrapper is used to shard the dataset for distributed training. For optimal performance, users should wrap a dataset immediately after creating it. If you are using tf.data.Dataset, Determined\u2019s support for automatically checkpointing the dataset does not currently work correctly. This means that resuming workloads will start from the beginning of the dataset if using tf.data.Dataset. abstract build_validation_data_loaderUnion[keras.utils.data_utils.Sequence, tensorflow.python.data.ops.dataset_ops.DatasetV2, SequenceAdapter, tuple] Defines the data loader to use during validation. Should return one of the following: 1) A tuple (x_val, y_val), where x_val is a NumPy array (or array-like), a list of arrays (in case the model has multiple inputs), or a dict mapping input names to the corresponding array, if the model has named inputs. y_val should be a NumPy array. 2) A tuple (x_val, y_val, sample_weights) of NumPy arrays. 3) A tf.data.Dataset returning a tuple of either (inputs, targets) or (inputs, targets, sample_weights). 4) A keras.utils.Sequence returning a tuple of either (inputs, targets) or (inputs, targets, sample weights). When using tf.data.Dataset, you must wrap the dataset using determined.keras.TFKerasTrialContext.wrap_dataset(). This wrapper is used to shard the dataset for distributed training. For optimal performance, users should wrap a dataset immediately after creating it. session_configtensorflow.core.protobuf.config_pb2.ConfigProto Specifies the tf.ConfigProto to be used by the TensorFlow session. By default, tf.ConfigProto(allow_soft_placement=True) is used. keras_callbacksList[keras.callbacks.Callback] Specifies a list of determined.keras.callbacks.Callback objects to be used during training. note: Note that :class:`determined.keras.callbacks.Callback` is a subclass of `tf.keras.callback.Callback <https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback>`__ objects which supports stateful callbacks that can be checkpointed an restored mid-training. Please see :class:`determined.keras.callbacks.Callback` for a summary of differences between normal Keras callbacks and Determined Keras callbacks. warning: For legacy callbacks which do not subclass :class:`determined.keras.callbacks.Callback`, if ``records_per_epoch`` is not set in the experiement config for an experiment, ``on_epoch_end`` will never be called.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrialcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrialcontext",
    "content": "class determined.keras.TFKerasTrialContext*arg: Any**kwarg: Any Base context class that contains runtime information for any Determined workflow that uses the tf.keras API. TFKerasTrialContext always has a DistributedContext accessible via context.distributed for information related to distributed training. TFKerasTrialContext always has a TFKerasExperimentalContext accessible via context.experimental for information related to experimental features. get_global_batch_sizeint Return the global batch size. get_per_slot_batch_sizeint Return the per-slot batch size. When a model is trained with a single GPU, this is equal to the global batch size. When multi-GPU training is used, this is equal to the global batch size divided by the number of GPUs used to train the model. configure_fitverbose: Optional[bool] = Noneclass_weight: Any = <determined.keras._tf_keras_context._ArgNotProvided object>workers: Optional[int] = Noneuse_multiprocessing: Optional[bool] = Nonemax_queue_size: Optional[bool] = Noneshuffle: Optional[bool] = Nonevalidation_steps: Any = <determined.keras._tf_keras_context._ArgNotProvided object>None Configure parameters of model.fit(). See the Keras documentation for the meaning of each parameter. Note that the output of verbose=True will be visually different in Determined than with Keras, for better rendering in trial logs. Note that if configure_fit() is called multiple times, any keyword arguments which are not provided in the second call will not overwrite any settings configured by the first call. Usage Example class MyTFKerasTrial(det.keras.TFKerasTrial): def __init__(self, context): ... self.context.configure_fit(verbose=False, workers=5) # It is safe to call configure_fit() multiple times. self.context.configure_fit(use_multiprocessing=True) wrap_datasetdataset: Anyshard_dataset: bool = TrueAny This should be used to wrap tf.data.Dataset objects immediately after they have been created. Users should use the output of this wrapper as the new instance of their dataset. If users create multiple datasets (e.g., one for training and one for validation), users should wrap each dataset independently. Parameters dataset \u2013 tf.data.Dataset shard_dataset \u2013 When performing multi-slot (distributed) training, this controls whether the dataset is sharded so that each training process (one per slot) sees unique data. If set to False, users must manually configure each process to use unique data. wrap_optimizeroptimizer: keras.optimizers.optimizer_experimental.optimizer.Optimizerkeras.optimizers.optimizer_experimental.optimizer.Optimizer This should be user to wrap tf.keras.optimizers.Optimizer objects. Users should use the output use the output of this wrapper as the new instance of their optimizer. If users create multiple optimizers, users should wrap each optimizer independently. Parameters optimizer \u2013 tf.keras.optimizers.Optimizer wrap_modelmodel: AnyAny This should be used to wrap tf.keras.Model objects immediately after they have been created but before they have been compiled. This function takes a tf.keras.Model and returns a wrapped version of the model; the return value should be used in place of the original model. Parameters model \u2013 tf.keras.Model classmethod from_configconfig: Dict[str, Any]determined._trial_context.TrialContext Create a context object suitable for debugging outside of Determined. An example for a subclass of PyTorchTrial: config = { ... } context = det.pytorch.PyTorchTrialContext.from_config(config) my_trial = MyPyTorchTrial(context) train_ds = my_trial.build_training_data_loader() for epoch_idx in range(3): for batch_idx, batch in enumerate(train_ds): metrics = my_trial.train_batch(batch, epoch_idx, batch_idx) ... An example for a subclass of TFKerasTrial: config = { ... } context = det.keras.TFKerasTrialContext.from_config(config) my_trial = tf_keras_one_var_model.OneVarTrial(context) model = my_trial.build_model() model.fit(my_trial.build_training_data_loader()) eval_metrics = model.evaluate(my_trial.build_validation_data_loader()) Parameters config \u2013 An experiment config file, in dictionary form. get_data_configDict[str, Any] Return the data configuration. get_experiment_configDict[str, Any] Return the experiment configuration. get_experiment_idint Return the experiment ID of the current trial. get_hparamname: strAny Return the current value of the hyperparameter with the given name. get_hparamsDict[str, Any] Return a dictionary of hyperparameter names to values. get_stop_requestedbool Return whether a trial stoppage has been requested. get_tensorboard_pathpathlib.Path Get the path where files for consumption by TensorBoard should be written get_trial_idint Return the trial ID of the current trial. set_stop_requestedstop_requested: boolNone Set a flag to request a trial stoppage. When this flag is set to True, we finish the step, checkpoint, then exit.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrialContext.distributed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrialcontext-distributed",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasTrialContext.distributed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerastrialcontext-distributed",
    "content": "class determined.core._distributed.DistributedContext*rank: intsize: intlocal_rank: intlocal_size: intcross_rank: intcross_size: intchief_ip: Optional[str] = Nonepub_port: int = 12360pull_port: int = 12376port_offset: int = 0force_tcp: bool = False DistributedContext provides useful methods for effective distributed training. A DistributedContext has the following required args: rank: the index of this worker in the entire job size: the number of workers in the entire job local_rank: the index of this worker on this machine local_size: the number of workers on this machine cross_rank: the index of this machine in the entire job cross_size: the number of machines in the entire job Additionally, any time that cross_size > 1, you must also provide: chief_ip: the ip address to reach the chief worker (where rank==0) DistributedContext has .allgather(), .gather(), and .broadcast() methods, which are easy to use and which can be useful for coordinating work across workers, but it is not a replacement for the allgather/gather/broadcast operations in your particular distributed training framework. classmethod from_horovodhvd: Anychief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the provided hvd module to determine rank information. Example: import horovod.torch as hvd hvd.init() distributed = DistributedContext.from_horovod(hvd) The IP address for the chief worker is required whenever hvd.cross_size() > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_deepspeedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard deepspeed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_torch_distributedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard torch distributed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided via the chief_ip argument or the DET_CHIEF_IP environment variable. get_rankint Return the rank of the process in the trial. The rank of a process is a unique ID within the trial. That is, no two processes in the same trial are assigned the same rank. get_local_rankint Return the rank of the process on the agent. The local rank of a process is a unique ID within a given agent and trial; that is, no two processes in the same trial that are executing on the same agent are assigned the same rank. get_sizeint Return the number of slots this trial is running on. get_num_agentsint Return the number of agents this trial is running on. gatherstuff: AnyOptional[List] Gather stuff to the chief. The chief returns a list of all stuff, and workers return None. gather() is not a replacement for the gather functionality of your distributed training framework. gather_localstuff: AnyOptional[List] Gather stuff to the local chief. The local chief returns a list of all stuff, and local workers return None. gather_local() is not a replacement for the gather functionality of your distributed training framework. allgatherstuff: AnyList Gather stuff to the chief and broadcast all of it back to the workers. allgather() is not a replacement for the allgather functionality of your distributed training framework. allgather_localstuff: AnyList Gather stuff to the local chief and broadcast all of it back to the local workers. allgather_local() is not a replacement for the allgather functionality of your distributed training framework. broadcaststuff: AnyAny Every worker gets the stuff sent by the chief. broadcast() is not a replacement for the broadcast functionality of your distributed training framework. broadcast_localstuff: Optional[Any] = NoneAny Every worker gets the stuff sent by the local chief. broadcast_local() is not a replacement for the broadcast functionality of your distributed training framework.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasExperimentalContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerasexperimentalcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.TFKerasExperimentalContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-tfkerasexperimentalcontext",
    "content": "class determined.keras.TFKerasExperimentalContext Bases: object Context class that contains experimental runtime information and features for any Determined workflow that uses the tf.keras API. TFKerasExperimentalContext extends TFKerasTrialContext under the context.experimental namespace.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.callbacks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-callbacks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.callbacks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-callbacks",
    "content": "class determined.keras.callbacks.Callback A Determined subclass of the tf.keras.callbacks.Callback interface which supports additional new callbacks. The following behaviors differ between normal Keras operation and Keras operation within Determined: Keras calls on_epoch_end at the end of the training dataset, but Determined calls it based on the records_per_epoch setting in the experiment config. Keras calls on_epoch_end with training and validation logs, but Determined does not schedule training or validation around epochs in general, so Determined cannot guarantee that those values are available for on_epoch_end calls. As a result, on_epoch_end will be called with an empty dictionary for its logs. Keras does not support stateful callbacks, but Determined does. Therefore: The tf.keras version of EarlyStopping will not work right in Determined. You should use you should use determined.keras.callbacks.EarlyStopping instead. The tf.keras version of ReduceLROnPlateau will not work right in Determined. You should use you should use determined.keras.callbacks.ReduceLRScheduler instead. The Determined versions are based around on_test_end rather than on_epoch_end, which can be influenced by setting min_validation_period in the experiment configuration. get_stateAny get_state should return a pickleable object that represents the state of this callback. When training is continued from a checkpoint, the value returned from get_state() will be passed back to the Callback object via load_state(). load_statestate: AnyNone load_state should accept the exact pickleable object returned by get_state to restore the internal state of a stateful Callback as it was when load_state was called. on_checkpoint_endcheckpoint_dir: strNone on_checkpoint_end is called after a checkpoint is finished, and allows users to save arbitrary files alongside the checkpoint. Parameters checkpoint_dir \u2013 The path to the checkpoint_dir where new files may be added. on_train_workload_begintotal_batches_trained: intbatches_requested: Optional[int]logs: DictNone on_train_workload_begin is called before a chunk of model training. The number of batches in the workload may vary, but will not exceed the scheduling_unit setting for the experiment. Parameters total_batches_trained \u2013 The number of batches trained at the start of the workload. batches_requested \u2013 The number of batches expected to train during the workload. logs \u2013 a dictionary (presently always an empty dictionary) on_train_workload_endtotal_batches_trained: intlogs: DictNone on_train_workload_end is called after a chunk of model training. Parameters total_batches_trained \u2013 The number of batches trained at the end of the workload. logs \u2013 a dictionary of training metrics aggregated during this workload. class determined.keras.callbacks.EarlyStopping*arg: Any**kwarg: Any EarlyStopping behaves exactly like the tf.keras.callbacks.EarlyStopping except that it checks after every on_test_end() rather than every on_epoch_end() and it can save and restore its state after pauses in training. Therefore, part of configuring the Determined implementation of EarlyStopping is to configure min_validation_period for the experiment appropriately (likely it should be configured to validate every epoch). In Determined, on_test_end may be called slightly more often than min_validation_period during some types of hyperparameter searches, but it is unlikely for that to occur often enough have a meaningful impact on this callback\u2019s operation. class determined.keras.callbacks.ReduceLROnPlateau*arg: Any**kwarg: Any ReduceLROnPlateau behaves exactly like the tf.keras.callbacks.ReduceLROnPlateau except that it checks after every on_test_end() rather than every on_epoch_end() and it can save and restore its state after pauses in training. Therefore, part of configuring the Determined implementation of ReduceLROnPlateau is to configure min_validation_period for the experiment appropriately (likely it should be configured to validate every epoch). In Determined, on_test_end may be called slightly more often than min_validation_period during some types of hyperparameter searches, but it is unlikely for that to occur often enough have a meaningful impact on this callback\u2019s operation. class determined.keras.callbacks.TensorBoard*args**kwargs This is a thin wrapper over the TensorBoard callback that ships with tf.keras. For more information, see the TensorBoard Guide or the upstream docs for tf.keras.callbacks.TensorBoard. Note that if a log_dir argument is passed to the constructor, it will be ignored.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.load_model_from_checkpoint_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-load-model-from-checkpoint-path",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.keras API Reference",
      "lvl1": "det.keras API Reference",
      "lvl2": "determined.keras.load_model_from_checkpoint_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-keras-reference.html#determined-keras-load-model-from-checkpoint-path",
    "content": "class determined.keras.load_model_from_checkpoint_pathpath: strtags: Optional[List[str]] = None Loads a checkpoint written by a TFKerasTrial. You should have already downloaded the checkpoint files, likely with Checkpoint.download(). The return type is a TensorFlow AutoTrackable object. Parameters path (string) \u2013 Top level directory to load the checkpoint from. tags (list string, optional) \u2013 Specifies which tags are loaded from the TensorFlow SavedModel. See documentation for tf.compat.v1.saved_model.load_v2.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-configuration-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-configuration-reference",
    "content": "The behavior of an experiment is configured via a YAML file. A configuration file is typically passed as a command-line argument when an experiment is created with the Determined CLI. For example: det experiment create config-file.yaml model-directory",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Training Units",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#training-units",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Training Units",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#training-units",
    "content": "Some configuration settings, such as searcher training lengths and budgets, min_validation_period, and min_checkpoint_period, can be expressed in terms of a few training units: records, batches, or epochs. records: A record is a single labeled example (sometimes called a sample). batches: A batch is a group of records. The number of records in a batch is configured via the global_batch_size hyperparameter. epoch: An epoch is a single copy of the entire training data set; the number of records in an epoch is configured via the records_per_epoch configuration field. For example, to specify the max_length for a searcher in terms of batches, the configuration would read as shown below. max_length: batches: 900 To express it in terms of records or epochs, records or epochs would be specified in place of batches. In the case of epochs, records_per_epoch must also be specified. Below is an example that configures a single searcher to train a model for 64 epochs. records_per_epoch: 50000 searcher: name: single metric: validation_error max_length: epochs: 64 smaller_is_better: true The configured records_per_epoch is only used for interpreting configuration fields that are expressed in epochs. Actual epoch boundaries are still determined by the dataset itself (specifically, the end of an epoch occurs when the training data loader runs out of records). When the amount of training data for a model is specified using records or epochs, and the batch size does not evenly divide the configured number of inputs, the remaining \u201cpartial batch\u201d of data will be dropped (ignored). For example, if an experiment is configured to train a single model on 10 records with a batch size of 3, the model will be trained on only 9 records of data. In the special case where a trial is configured to train on less than a single batch of data, a single complete batch will be used instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Training Units",
      "lvl3": "Training Unit Conversion Limitations (Caveats)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#training-unit-conversion-limitations-caveats",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Training Units",
      "lvl3": "Training Unit Conversion Limitations (Caveats)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#training-unit-conversion-limitations-caveats",
    "content": "In most cases, values expressed in one type of training unit can be converted to another type while maintaining the same behavior. However, there are some limitations to consider: Since training units must be positive integers, it is not always possible to convert between different types of units. For example, converting 50 records into batches is not possible if the batch size is 64. When performing a hyperparameter search over a range of values for global_batch_size, the specified batches cannot be converted to a fixed number of records or epochs and hence cause different behaviors in different trials of the search. When using adaptive_asha, a single training unit is treated as atomic (unable to be divided into fractional parts) when dividing max_length into the series of rounds (or rungs) by which we early-stop underperforming trials. This rounding may result in unexpected behavior when configuring max_length with a small number of large epochs or batches. To verify your search is working as intended before committing to a full run, you can use the CLI\u2019s \u201cpreview search\u201d feature: det preview-search <configuration.yaml>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#metadata",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#name",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "name",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#name",
    "content": "Optional. A short human-readable name for the experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "description",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#description",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "description",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#description",
    "content": "Optional. A human-readable description of the experiment. This does not need to be unique but should be limited to less than 255 characters for the best experience.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "labels",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#labels",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "labels",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#labels",
    "content": "Optional. A list of label names (strings). Assigning labels to experiments allows you to identify experiments that share the same property or should be grouped together. You can add and remove labels using either the CLI (det experiment label) or the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#data",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#data",
    "content": "Optional. This field can be used to specify information about how the experiment accesses and loads training data. The content and format of this field is user-defined: it should be used to specify whatever configuration is needed for loading data for use by the experiment\u2019s model definition. For example, if your experiment loads data from Amazon S3, the data field might contain the S3 bucket name, object prefix, and AWS authentication credentials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "workspace",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#workspace",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "workspace",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#workspace",
    "content": "Optional. The name of the pre-existing workspace where you want to create the experiment. The workspace and project fields must either both be present or both be absent. If they are absent, the experiment is placed in the Uncategorized project in the Uncategorized workspace. You can manage workspaces using the CLI det workspace help command or the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#project",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Metadata",
      "lvl3": "project",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#project",
    "content": "Optional. The name of the pre-existing project inside workspace where you want to create the experiment. The workspace and project fields must either both be present or both be absent. If they are absent, the experiment is placed in the Uncategorized project in the Uncategorized workspace. You can manage projects using the CLI det project help command or the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#entrypoint",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-config-entrypoint",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-config-entrypoint",
    "content": "Required. A model definition trial class specification or Python launcher script, which is the model processing entrypoint. This field can have the following formats. Formats that specify a trial class have the form <module>:<object_reference>. The <module> field specifies the module containing the trial class in the model definition, relative to root. The <object_reference> specifies the trial class name in the module, which can be a nested object delimited by a period (.). Examples: MnistTrial expects an MnistTrial class exposed in a __init__.py file at the top level of the context directory. model_def:CIFAR10Trial expects a CIFAR10Trial class defined in the model_def.py file at the top level of the context directory. determined_lib.trial:trial_classes.NestedTrial expects a NestedTrial class, which is an attribute of trial_classes defined in the determined_lib/trial.py file. These formats follow Python Entry points specification except that the context directory name is prefixed by <module> or used as the module if the <module> field is empty.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Arbitrary Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#arbitrary-script",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Arbitrary Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#arbitrary-script",
    "content": "Required. An arbitrary entrypoint script name. Example: entrypoint: ./hello.sh",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Preconfigured Launch Module with Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#preconfigured-launch-module-with-script",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Preconfigured Launch Module with Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#preconfigured-launch-module-with-script",
    "content": "Required. The name of a preconfigured launch module and script name. Example: entrypoint: python3 -m (LAUNCH_MODULE) train.py LAUNCH_MODULE options: Horovod (determined.launch.horovod) PyTorch (determined.launch.torch_distributed) Deepspeed (determined.launch.deepspeed)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Preconfigured Launch Module with Legacy Trial Definition",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#preconfigured-launch-module-with-legacy-trial-definition",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Preconfigured Launch Module with Legacy Trial Definition",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#preconfigured-launch-module-with-legacy-trial-definition",
    "content": "Required. The name of a preconfigured launch module and legacy trial class specification. Example: entrypoint: python3 -m (LAUNCH_MODULE) --trial model_def:Trial LAUNCH_MODULE options: [need literals for these] Horovod (determined.launch.horovod) PyTorch (determined.launch.torch_distributed) Deepspeed (determined.launch.deepspeed)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Legacy Trial Definition",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#legacy-trial-definition",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Entrypoint",
      "lvl3": "entrypoint",
      "lvl4": "Legacy Trial Definition",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#legacy-trial-definition",
    "content": "Required. A legacy trial class specification. Example: entrypoint: model_def:Trial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#basic-behaviors",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "scheduling_unit",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#scheduling-unit",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "scheduling_unit",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#scheduling-unit",
    "content": "Optional. Instructs how frequent to perform system operations, such as periodic checkpointing and preemption, in the unit of batches. The number of records in a batch is controlled by the global_batch_size hyperparameter. Defaults to 100. Setting this value too small can increase the overhead of system operations and decrease training throughput. Setting this value too large might prevent the system from reallocating resources from this workload to another, potentially more important, workload. As a rule of thumb, it should be set to the number of batches that can be trained in roughly 60\u2013180 seconds.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "records_per_epoch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#records-per-epoch",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "records_per_epoch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#records-per-epoch",
    "content": "Optional. The number of records in the training data set. It must be configured if you want to specify min_validation_period, min_checkpoint_period, and searcher.max_length in units of epochs. The system does not attempt to determine the size of an epoch automatically, because the size of the training set might vary based on data augmentation, changes to external storage, or other factors.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "max_restarts",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-restarts",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Basic Behaviors",
      "lvl3": "max_restarts",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-restarts",
    "content": "Optional. The max_restarts parameter parameter sets a limit on the number of times the Determined master can try restarting a trial, preventing an infinite loop if the same error repeatedly occurs. After reach the max_restarts limit for an experiment, any subsequent failed trials will not be restarted and will be marked as errored. An experiment is considered successful if at least one of its trials completes without errors. The default value for max_restarts is 5.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Validation Policy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#validation-policy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Validation Policy",
      "lvl3": "min_validation_period",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#min-validation-period",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Validation Policy",
      "lvl3": "min_validation_period",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#min-validation-period",
    "content": "Optional. Specifies the minimum frequency at which validation should be run for each trial. The frequency should be defined using a nested dictionary indicating the unit as records, batches, or epochs. For example: min_validation_period: epochs: 2 If this is in the unit of epochs, records_per_epoch must be specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Validation Policy",
      "lvl3": "perform_initial_validation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#perform-initial-validation",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Validation Policy",
      "lvl3": "perform_initial_validation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#perform-initial-validation",
    "content": "Optional. Instructs Determined to perform an initial validation before any training begins, for each trial. This can be useful to determine a baseline when fine-tuning a model on a new dataset.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-policy",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-policy",
    "content": "Determined checkpoints in the following situations: Periodically during training, to keep a record of the training progress. During training, to enable recovery of the trial\u2019s execution in case of resumption or errors. Upon completion of the trial. Prior to the searcher making a decision based on the validation of trials, ensuring consistency in case of a failure.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": "min_checkpoint_period",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#min-checkpoint-period",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": "min_checkpoint_period",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#min-checkpoint-period",
    "content": "Optional. Specifies the minimum frequency for running checkpointing for each trial. This value should be set using a nested dictionary in the form of records, batches, or epochs. For example: min_checkpoint_period: epochs: 2 If the unit is in epochs, you must also specify records_per_epoch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": "checkpoint_policy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id4",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Policy",
      "lvl3": "checkpoint_policy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id4",
    "content": "Optional. Controls how Determined performs checkpoints after validation operations, if at all. Should be set to one of the following values: best (default): A checkpoint will be taken after every validation operation that performs better than all previous validations for this experiment. Validation metrics are compared according to the metric and smaller_is_better options in the searcher configuration. all: A checkpoint will be taken after every validation, no matter the validation performance. none: A checkpoint will never be taken due to a validation. However, even with this policy selected, checkpoints are still expected to be taken after the trial is finished training, due to cluster scheduling decisions, before search method decisions, or due to min_checkpoint_period.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-storage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-storage",
    "content": "The checkpoint_storage section defines how model checkpoints will be stored. A checkpoint contains the architecture and weights of the model being trained. Each checkpoint has a UUID, which is used as the name of the checkpoint directory on the external storage system. If this field is not specified, the experiment will default to the checkpoint storage configured in the master configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-garbage-collection",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-garbage-collection",
    "content": "When an experiment finishes, the system will optionally delete some checkpoints to reclaim space. The save_experiment_best, save_trial_best and save_trial_latest parameters specify which checkpoints to save. If multiple save_* parameters are specified, the union of the specified checkpoints are saved.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_experiment_best",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-experiment-best",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_experiment_best",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-experiment-best",
    "content": "The number of the best checkpoints with validations over all trials to save (where best is measured by the validation metric specified in the searcher configuration).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_trial_best",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-trial-best",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_trial_best",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-trial-best",
    "content": "The number of the best checkpoints with validations of each trial to save.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 56
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_trial_latest",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-trial-latest",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 57
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Garbage Collection",
      "lvl4": "save_trial_latest",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#save-trial-latest",
    "content": "The number of the latest checkpoints of each trial to save.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 58
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Saving Policy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-saving-policy",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 59
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Saving Policy",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#checkpoint-saving-policy",
    "content": "The checkpoint garbage collection fields default to the following values: save_experiment_best: 0 save_trial_best: 1 save_trial_latest: 1 This policy will save the most recent and the best checkpoint per trial. In other words, if the most recent checkpoint is also the best checkpoint for a given trial, only one checkpoint will be saved for that trial. Otherwise, two checkpoints will be saved.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 60
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Saving Policy",
      "lvl4": "Examples",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#examples",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 61
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Checkpoint Storage",
      "lvl3": "Checkpoint Saving Policy",
      "lvl4": "Examples",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#examples",
    "content": "Suppose an experiment has the following trials, checkpoints and validation metrics (where smaller_is_better is true): Trial ID Checkpoint ID Validation Metric 1 1 null 1 2 null 1 3 0.6 1 4 0.5 1 5 0.4 2 6 null 2 7 0.2 2 8 0.3 2 9 null 2 10 null The effect of various policies is enumerated in the following table: save_experiment_best save_trial_best save_trial_latest Saved Checkpoint IDs 0 0 0 none 2 0 0 8,7 >= 5 0 0 8,7,5,4,3 0 1 0 7,5 0 >= 3 0 8,7,5,4,3 0 0 1 10,5 0 0 3 10,9,8,5,4,3 2 1 0 8,7,5 2 0 1 10,8,7,5 0 1 1 10,7,5 2 1 1 10,8,7,5 If aggressive reclamation is desired, set save_experiment_best to a 1 or 2 and leave the other parameters zero. For more conservative reclamation, set save_trial_best to 1 or 2; optionally set save_trial_latest as well. Checkpoints of an existing experiment can be garbage collected by changing the GC policy using the det experiment set gc-policy subcommand of the Determined CLI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 62
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#storage-type",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 63
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#storage-type",
    "content": "Determined currently supports several kinds of checkpoint storage, gcs, s3, azure, and shared_fs, identified by the type subfield. Additional fields may also be required, depending on the type of checkpoint storage in use. For example, to store checkpoints on Google Cloud Storage: checkpoint_storage: type: gcs bucket: <your-bucket-name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 64
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#google-cloud-storage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 65
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#google-cloud-storage",
    "content": "If type: gcs is specified, checkpoints will be stored on Google Cloud Storage (GCS). Authentication is done using GCP\u2019s \u201cApplication Default Credentials\u201d approach. When using Determined inside Google Compute Engine (GCE), the simplest approach is to ensure that the VMs used by Determined are running in a service account that has the \u201cStorage Object Admin\u201d role on the GCS bucket being used for checkpoints. As an alternative (or when running outside of GCE), you can add the appropriate service account credentials to your container (e.g., via a bind-mount), and then set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the container path where the credentials are located. See Environment Variables for more details on how to set environment variables in containers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 66
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#bucket",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 67
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#bucket",
    "content": "Required. The GCS bucket name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 68
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#prefix",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 69
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Google Cloud Storage",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#prefix",
    "content": "Optional. The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 70
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#amazon-s3",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 71
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#amazon-s3",
    "content": "If type: s3 is specified, checkpoints will be stored in Amazon S3 or an S3-compatible object store such as MinIO.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 72
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id7",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 73
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "bucket",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id7",
    "content": "Required. The S3 bucket name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 74
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "access_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#access-key",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 75
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "access_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#access-key",
    "content": "Required. The AWS access key to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 76
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "secret_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#secret-key",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 77
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "secret_key",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#secret-key",
    "content": "Required. The AWS secret key to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 78
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id8",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 79
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "prefix",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id8",
    "content": "Optional. The optional path prefix to use. Must not contain ... Note: Prefix is normalized, e.g., /pre/.//fix -> /pre/fix",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 80
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "endpoint_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#endpoint-url",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 81
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Amazon S3",
      "lvl4": "endpoint_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#endpoint-url",
    "content": "Optional. The endpoint to use for S3 clones, e.g., http://127.0.0.1:8080/. If not specified, Amazon S3 will be used.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 82
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#azure-blob-storage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 83
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#azure-blob-storage",
    "content": "If type: azure is specified, checkpoints will be stored in Microsoft\u2019s Azure Blob Storage. Please only specify one of connection_string or the account_url, credential tuple.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 84
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "container",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#container",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 85
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "container",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#container",
    "content": "Required. The Azure Blob Storage container name to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 86
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "connection_string",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#connection-string",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 87
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "connection_string",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#connection-string",
    "content": "Required. The connection string for the Azure Blob Storage service account to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 88
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "account_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#account-url",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 89
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "account_url",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#account-url",
    "content": "Required. The account URL for the Azure Blob Storage service account to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 90
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "credential",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#credential",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 91
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Azure Blob Storage",
      "lvl4": "credential",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#credential",
    "content": "Optional. The credential to use with the account_url.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 92
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#shared-file-system",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 93
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#shared-file-system",
    "content": "If type: shared_fs is specified, checkpoints will be written to a directory on the agent\u2019s file system. The assumption is that the system administrator has arranged for the same directory to be mounted at every agent machine, and for the content of this directory to be the same on all agent hosts (e.g., by using a distributed or network file system such as GlusterFS or NFS). When downloading checkpoints from a shared file system (e.g., using det checkpoint download), we assume the same shared file system is mounted locally at the same host_path.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 94
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "host_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#host-path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 95
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "host_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#host-path",
    "content": "Required. The file system path on each agent to use. This directory will be mounted to /determined_shared_fs inside the trial container. Optional Fields",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 96
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "storage_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#storage-path",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 97
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "storage_path",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#storage-path",
    "content": "Optional. The path where checkpoints will be written to and read from. Must be a subdirectory of the host_path or an absolute path containing the host_path. If not specified, checkpoints are written to and read from the host_path.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 98
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "propagation",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#propagation",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 99
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Storage Type",
      "lvl3": "Shared File System",
      "lvl4": "propagation",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#propagation",
    "content": "Optional. Propagation behavior for replicas of the bind-mount. Defaults to rprivate.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 100
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#hyperparameters",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 101
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#hyperparameters",
    "content": "The hyperparameters section defines the hyperparameter space for the experiment. The appropriate hyperparameters for a specific model depend on the nature of the model being trained. In Determined, it is common to specify hyperparameters that influence various aspects of the model\u2019s behavior, such as data augmentation, neural network architecture, and the choice of optimizer, as well as its configuration. To access the value of a hyperparameter in a particular trial, use the trial context with context.get_hparam(). For example, you can access the current value of a hyperparameter named learning_rate by calling context.get_hparam(\"learning_rate\"). Every experiment must specify a hyperparameter called global_batch_size. This hyperparameter is required for distributed training to calculate the appropriate per-worker batch size. The batch size per slot is computed at runtime, based on the number of slots used to train a single trial of the experiment (see resources.slots_per_trial). To access the updated values, use the trial context with context.get_per_slot_batch_size() and context.get_global_batch_size(). To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. The hyperparameter space is defined by a dictionary. Each key in the dictionary is the name of a hyperparameter; the associated value defines the range of the hyperparameter. If the value is a scalar, the hyperparameter is a constant; otherwise, the value should be a nested map. Here is an example: hyperparameters: global_batch_size: 64 optimizer_config: optimizer: type: categorical vals: - SGD - Adam - RMSprop learning_rate: type: log minval: -5.0 maxval: 1.0 base: 10.0 num_layers: type: int minval: 1 maxval: 3 layer1_dropout: type: double minval: 0.2 maxval: 0.5 This configuration defines the following hyperparameters: global_batch_size: a constant value optimizer_config: a top level nested hyperparameter with two child hyperparameters: optimizer: a categorical hyperparameter learning_rate: a log scale hyperparameter num_layers: an integer hyperparameter layer1_dropout: a double hyperparameter The field optimizer_config demonstrates how nesting can be used to organize hyperparameters. Arbitrary levels of nesting are supported with all types of hyperparameters. Aside from hyperparameters with constant values, the four types of hyperparameters \u2013 categorical, double, int, and log \u2013 can take on a range of possible values. The following sections cover how to configure the hyperparameter range for each type of hyperparameter.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 102
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Categorical",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#categorical",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 103
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Categorical",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#categorical",
    "content": "A categorical hyperparameter ranges over a set of specified values. The possible values are defined by the vals key. vals is a list; each element of the list can be of any valid YAML type, such as a boolean, a string, a number, or a collection.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 104
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Double",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#double",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 105
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Double",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#double",
    "content": "A double hyperparameter is a floating point variable. The minimum and maximum values of the variable are defined by the minval and maxval keys, respectively (inclusive of endpoints). When doing a grid search, the count key must also be specified; this defines the number of points in the grid for this hyperparameter. Grid points are evenly spaced between minval and maxval. See Grid Method for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 106
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Integer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#integer",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 107
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Integer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#integer",
    "content": "An int hyperparameter is an integer variable. The minimum and maximum values of the variable are defined by the minval and maxval keys, respectively (inclusive of endpoints). When doing a grid search, the count key must also be specified; this defines the number of points in the grid for this hyperparameter. Grid points are evenly spaced between minval and maxval. See Grid Method for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 108
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Log",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#log",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 109
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Hyperparameters",
      "lvl3": "Log",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#log",
    "content": "A log hyperparameter is a floating point variable that is searched on a logarithmic scale. The base of the logarithm is specified by the base field; the minimum and maximum exponent values of the hyperparameter are given by the minval and maxval fields, respectively (inclusive of endpoints). When doing a grid search, the count key must also be specified; this defines the number of points in the grid for this hyperparameter. Grid points are evenly spaced between minval and maxval. See Grid Method for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 110
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#searcher",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 111
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#searcher",
    "content": "The searcher section defines how the experiment\u2019s hyperparameter space will be explored. To run an experiment that trains a single trial with fixed hyperparameters, specify the single searcher and specify constant values for the model\u2019s hyperparameters. Otherwise, Determined supports three different hyperparameter search algorithms: adaptive_asha, random, and grid. To define your own hyperparameter search algorithm, specify the custom searcher. For more information about custom search algorithms, see Custom Search Methods. The name of the hyperparameter search algorithm to use is configured via the name field; the remaining fields configure the behavior of the searcher and depend on the searcher being used. For example, to configure a random hyperparameter search that trains 5 trials for 1000 batches each: searcher: name: random metric: accuracy max_trials: 5 max_length: batches: 1000 For details on using Determined to perform hyperparameter search, refer to Hyperparameter Tuning. For more information on the search methods supported by Determined, refer to Hyperparameter Tuning.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 112
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#single",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 113
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#single",
    "content": "The single search method does not perform a hyperparameter search at all; rather, it trains a single trial for a fixed length. When using this search method, all of the hyperparameters specified in the hyperparameters section must be constants. By default, validation metrics are only computed once, after the specified length of training has been completed; min_validation_period can be used to specify that validation metrics should be computed more frequently.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 114
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#metric",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 115
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#metric",
    "content": "Required. The name of the validation metric used to evaluate the performance of a hyperparameter configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 116
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-length",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 117
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-length",
    "content": "Required. The length of the trial. This needs to be set in the unit of records, batches, or epochs using a nested dictionary. For example: max_length: epochs: 2 If this is in the unit of epochs, records_per_epoch must be specified. Optional Fields",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 118
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#smaller-is-better",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 119
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#smaller-is-better",
    "content": "Optional. Whether to minimize or maximize the metric defined above. The default value is true (minimize).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 120
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#source-trial-id",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 121
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#source-trial-id",
    "content": "Optional. If specified, the weights of this trial will be initialized to the most recent checkpoint of the given trial ID. This will fail if the source trial\u2019s model architecture is inconsistent with the model architecture of this experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 122
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#source-checkpoint-uuid",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 123
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Single",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#source-checkpoint-uuid",
    "content": "Optional. Like source_trial_id, but specifies an arbitrary checkpoint from which to initialize weights. At most one of source_trial_id or source_checkpoint_uuid should be set.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 124
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#random",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 125
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#random",
    "content": "The random search method implements a simple random search. The user specifies how many hyperparameter configurations should be trained and how long each configuration should be trained for; the configurations are sampled randomly from the hyperparameter space. Each trial is trained for the specified length and then validation metrics are computed. min_validation_period can be used to specify that validation metrics should be computed more frequently.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 126
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id9",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 127
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id9",
    "content": "Required. The name of the validation metric used to evaluate the performance of a hyperparameter configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 128
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-trials",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 129
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-trials",
    "content": "Required. The number of trials, i.e., hyperparameter configurations, to evaluate.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 130
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id10",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 131
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id10",
    "content": "Required. The length of each trial. This needs to be set in the unit of records, batches, or epochs using a nested dictionary. For example: max_length: epochs: 2 If this is in the unit of epochs, records_per_epoch must be specified. Optional Fields",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 132
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id11",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 133
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id11",
    "content": "Optional. Whether to minimize or maximize the metric defined above. The default value is true (minimize).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 134
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-concurrent-trials",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 135
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-concurrent-trials",
    "content": "Optional. The maximum number of trials that can be worked on simultaneously. The default value is 16. When the value is 0 we will work on as many trials as possible.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 136
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id12",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 137
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id12",
    "content": "Optional. If specified, the weights of every trial in the search will be initialized to the most recent checkpoint of the given trial ID. This will fail if the source trial\u2019s model architecture is incompatible with the model architecture of any of the trials in this experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 138
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id13",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 139
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Random",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id13",
    "content": "Optional. Like source_trial_id but specifies an arbitrary checkpoint from which to initialize weights. At most one of source_trial_id or source_checkpoint_uuid should be set.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 140
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#grid",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 141
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#grid",
    "content": "The grid search method performs a grid search. The coordinates of the hyperparameter grid are specified via the hyperparameters field. For more details see the Grid Method.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 142
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id14",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 143
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id14",
    "content": "Required. The name of the validation metric used to evaluate the performance of a hyperparameter configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 144
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id15",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 145
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id15",
    "content": "Required. The length of each trial. This needs to be set in the unit of records, batches, or epochs using a nested dictionary. For example: max_length: epochs: 2 If this is in the unit of epochs, records_per_epoch must be specified. Optional Fields",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 146
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id16",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 147
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id16",
    "content": "Optional. Whether to minimize or maximize the metric defined above. The default value is true (minimize).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 148
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id17",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 149
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id17",
    "content": "Optional. The maximum number of trials that can be worked on simultaneously. The default value is 16. When the value is 0 we will work on as many trials as possible.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 150
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id18",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 151
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id18",
    "content": "Optional. If specified, the weights of this trial will be initialized to the most recent checkpoint of the given trial ID. This will fail if the source trial\u2019s model architecture is inconsistent with the model architecture of this experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 152
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id19",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 153
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Grid",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id19",
    "content": "Optional. Like source_trial_id, but specifies an arbitrary checkpoint from which to initialize weights. At most one of source_trial_id or source_checkpoint_uuid should be set.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 154
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#adaptive-asha",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 155
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#adaptive-asha",
    "content": "The adaptive_asha search method employs multiple calls to the asynchronous successive halving algorithm (ASHA) which is suitable for large-scale experiments with hundreds or thousands of trials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 156
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id20",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 157
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "metric",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id20",
    "content": "Required. The name of the validation metric used to evaluate the performance of a hyperparameter configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 158
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id21",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 159
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_length",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id21",
    "content": "Required. The maximum training length of any one trial. The vast majority of trials will be stopped early, and thus only a small fraction of trials will actually be trained for this long. This quantity is domain-specific and should roughly reflect the length of training needed for the model to converge on the data set. This needs to be set in the unit of records, batches, or epochs using a nested dictionary. For example: max_length: epochs: 2 If this is in the unit of epochs, records_per_epoch must be specified.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 160
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id22",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 161
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id22",
    "content": "Required. The number of trials, i.e., hyperparameter configurations, to evaluate.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 162
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id23",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 163
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "smaller_is_better",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id23",
    "content": "Optional. Whether to minimize or maximize the metric defined above. The default value is true (minimize).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 164
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "mode",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#mode",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 165
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "mode",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#mode",
    "content": "Optional. How aggressively to perform early stopping. There are three modes: aggressive, standard, and conservative; the default is standard. These modes differ in the degree to which early-stopping is used. In aggressive mode, the searcher quickly stops underperforming trials, which enables the searcher to explore more hyperparameter configurations, but at the risk of discarding a configuration too soon. On the other end of the spectrum, conservative mode performs significantly less downsampling, but as a consequence does not explore as many configurations given the same budget. We recommend using either aggressive or standard mode.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 166
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "stop_once",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#stop-once",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 167
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "stop_once",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#stop-once",
    "content": "Optional. If stop_once is set to true, we will use a variant of ASHA that will not resume trials once stopped. This variant defaults to continuing training and will only stop trials if there is enough evidence to terminate training. We recommend using this version of ASHA when training a trial for the max length as fast as possible is important or when fault tolerance is too expensive.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 168
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "divisor",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#divisor",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 169
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "divisor",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#divisor",
    "content": "Optional. The fraction of trials to keep at each rung, and also determines the training length for each rung. The default setting is 4; only advanced users should consider changing this value.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 170
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_rungs",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-rungs",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 171
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_rungs",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-rungs",
    "content": "Optional. The maximum number of times we evaluate intermediate results for a trial and terminate poorly performing trials. The default value is 5; only advanced users should consider changing this value.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 172
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id24",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 173
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "max_concurrent_trials",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id24",
    "content": "Optional. The maximum number of trials that can be worked on simultaneously. The default value is 16, and we set reasonable values depending on max_trials and the number of rungs in the brackets. This is akin to controlling the degree of parallelism of the experiment. If this value is less than the number of brackets produced by the adaptive algorithm, it will be rounded up.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 174
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id25",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 175
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "source_trial_id",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id25",
    "content": "Optional. If specified, the weights of every trial in the search will be initialized to the most recent checkpoint of the given trial ID. This will fail if the source trial\u2019s model architecture is inconsistent with the model architecture of any of the trials in this experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 176
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id26",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 177
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Searcher",
      "lvl3": "Adaptive ASHA",
      "lvl4": "source_checkpoint_uuid",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id26",
    "content": "Optional. Like source_trial_id, but specifies an arbitrary checkpoint from which to initialize weights. At most one of source_trial_id or source_checkpoint_uuid should be set.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 178
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#resources",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 179
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#resources",
    "content": "The resources section defines the resources that an experiment is allowed to use.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 180
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "slots_per_trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slots-per-trial",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 181
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "slots_per_trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slots-per-trial",
    "content": "Optional. The number of slots to use for each trial of this experiment. The default value is 1; specifying a value greater than 1 means that multiple GPUs will be used in parallel. Training on multiple GPUs is done using data parallelism. Configuring slots_per_trial to be greater than max_slots is not sensible and will result in an error. Using slots_per_trial to enable data parallel training for PyTorch can alter the behavior of certain models, as described in the PyTorch documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 182
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "max_slots",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-slots",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 183
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "max_slots",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#max-slots",
    "content": "Optional. The maximum number of scheduler slots that this experiment is allowed to use at any one time. The slot limit of an active experiment can be changed using det experiment set max-slots <id> <slots>. By default, there is no limit on the number of slots an experiment can use. When the cluster is deployed with an HPC workload manager, this value is ignored and instead managed by the configured workload manager. max_slots is only considered when scheduling jobs; it is not currently used when provisioning dynamic agents. This means that we may provision more instances than the experiment can schedule.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 184
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "weight",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#weight",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 185
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "weight",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#weight",
    "content": "Optional. The weight of this experiment in the scheduler. When multiple experiments are running at the same time, the number of slots assigned to each experiment will be approximately proportional to its weight. The weight of an active experiment can be changed using det experiment set weight <id> <weight>. The default weight is 1. When the cluster is deployed with an HPC workload manager, this value is ignored and instead managed by the configured workload manager.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 186
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "shm_size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#shm-size",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 187
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "shm_size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#shm-size",
    "content": "Optional. The size of /dev/shm for task containers. The value can be a number in bytes or a number with a suffix (e.g., 128M for 128MiB or 1.5G for 1.5GiB). Defaults to 4294967296 (4GiB). If set, this value overrides the value specified in the master configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 188
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "priority",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#priority",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 189
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "priority",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#priority",
    "content": "Optional. The priority assigned to this experiment. Only applicable when using the priority scheduler. Experiments with smaller priority values are scheduled before experiments with higher priority values. If using Kubernetes, the opposite is true; experiments with higher priorities are scheduled before those with lower priorities. Refer to Scheduling for more information. When the cluster is deployed with an HPC workload manager, this value is ignored and instead managed by the configured workload manager.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 190
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "resource_pool",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#resource-pool",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 191
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "resource_pool",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#resource-pool",
    "content": "Optional. The resource pool where this experiment will be scheduled. If no resource pool is specified, experiments will run in the default GPU pool. Refer to Resource Pools for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 192
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "devices",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#devices",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 193
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "devices",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#devices",
    "content": "Optional. A list of device strings to pass to the Docker daemon. Each entry in the list is equivalent to a --device DEVICE command-line argument to docker run. devices is honored by resource managers of type agent but is ignored by resource managers of type kubernetes. See master configuration for details about resource managers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 194
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "agent_label",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#agent-label",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 195
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Resources",
      "lvl3": "agent_label",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#agent-label",
    "content": "Optional. This field has been deprecated and will be ignored. Use resource_pool instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 196
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#bind-mounts",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 197
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#bind-mounts",
    "content": "The bind_mounts section specifies directories that are bind-mounted into every container launched for this experiment. Bind mounts are often used to enable trial containers to access additional data that is not part of the model definition directory. This field should consist of an array of entries; each entry has the form described below. Users must ensure that the specified host paths are accessible on all agent hosts (e.g., by configuring a network file system appropriately).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 198
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "host_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id27",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 199
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "host_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id27",
    "content": "Required. The file system path on each agent to use. Must be an absolute filepath.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 200
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "container_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#container-path",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 201
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "container_path",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#container-path",
    "content": "Required. The file system path in the container to use. May be a relative filepath, in which case it will be mounted relative to the working directory inside the container. It is not allowed to mount directly into the working directory (i.e., container_path == \".\") to reduce the risk of cluttering the host filesystem. For each bind mount, the following optional fields may also be specified:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 202
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "read_only",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#read-only",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 203
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "read_only",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#read-only",
    "content": "Required. Whether the bind-mount should be a read-only mount. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 204
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "propagation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id28",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 205
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Bind Mounts",
      "lvl3": "propagation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id28",
    "content": "Required. Propagation behavior for replicas of the bind-mount. Defaults to rprivate. For example, to mount /data on the host to the same path in the container, use: bind_mounts: - host_path: /data container_path: /data It is also possible to mount multiple paths: bind_mounts: - host_path: /data container_path: /data - host_path: /shared/read-only-data container_path: /shared/read-only-data read_only: true",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 206
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#environment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 207
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#environment",
    "content": "The environment section defines properties of the container environment that is used to execute workloads for this experiment. For more information on customizing the trial environment, refer to Customizing Your Environment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 208
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 209
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#image",
    "content": "Optional. The Docker image to use when executing the workload. This image must be accessible via docker pull to every Determined agent machine in the cluster. Users can configure different container images for NVIDIA GPU tasks using cuda key (gpu prior to 0.17.6), CPU tasks using cpu key, and ROCm (AMD GPU) tasks using rocm key. Default values: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 for NVIDIA GPUs. determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 for CPUs. determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-0.24.0 for ROCm. When the cluster is configured with resource_manager.type: slurm and container_run_type: singularity, images are executed using the Singularity container runtime which provides additional options for specifying the container image. The image can be: A full path to a local Singularity image (beginning with a / character). Any of the other supported Singularity container formats identified by prefix (e.g. instance://, library://, shub://, oras://, docker-archive:// or docker://). See the Singularity run command documentation for a full description of the capabilities. A Singularity image provided via the singularity_image_root configured for the cluster as described in Provide a Container Image Cache. If none of the above applies, Determined will apply the docker:// prefix to the image. When the cluster is configured with resource_manager.type: slurm and container_run_type: podman, images are executed using the Podman container runtime. The image can be any of the supported PodMan container formats identified by transport (e.g. docker: (the default), docker-archive:, docker-daemon:, or oci-archive:). See the Podman run command documentation for a full description of the capabilities. When the cluster is configured with resource_manager.type: slurm and container_run_type: enroot, images are executed using the Enroot container runtime. The image name must resolve to an Enroot container name created by the user before launching the Determined task. To enable the default docker image references used by Determined to be found in the Enroot container list the following transformations are applied to the image name (this is the same transformation performed by the enroot import command): Any forward slash character in the image name (/) is replaced with a plus sign (+) Any colon (:) is replaced with a plus sign (+) See Enroot Requirements for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 210
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "force_pull_image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#force-pull-image",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 211
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "force_pull_image",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#force-pull-image",
    "content": "Optional. Forcibly pull the image from the Docker registry, bypassing the Docker or Singularity built-in cache. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 212
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "registry_auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#registry-auth",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 213
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "registry_auth",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#registry-auth",
    "content": "Optional. The Docker registry credentials to use when pulling a custom base Docker image, if needed. Credentials are specified as the following nested fields: username (required) password (required) serveraddress (required) email (optional)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 214
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "environment_variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#environment-variables",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 215
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "environment_variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#environment-variables",
    "content": "Optional. A list of environment variables that will be set in every trial container. Each element of the list should be a string of the form NAME=VALUE. See Environment Variables for more details. You can customize environment variables for CUDA (NVIDIA GPU), CPU, and ROCm (AMD GPU) tasks differently by specifying a dict with cuda (gpu prior to 0.17.6), cpu, and rocm keys.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 216
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pod-spec",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 217
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "pod_spec",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pod-spec",
    "content": "Optional. Only applicable when running Determined on Kubernetes. Applies a pod spec to the pods that are launched by Determined for this task. See Customize a Pod for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 218
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "add_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#add-capabilities",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 219
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "add_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#add-capabilities",
    "content": "Optional. A list of Linux capabilities to grant to task containers. Each entry in the list is equivalent to a --cap-add CAP command-line argument to docker run. add_capabilities is honored by resource managers of type agent but is ignored by resource managers of type kubernetes. See master configuration for details about resource managers.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 220
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "drop_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#drop-capabilities",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 221
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "drop_capabilities",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#drop-capabilities",
    "content": "Optional. Just like add_capabilities but corresponding to the --cap-drop argument of docker run rather than --cap-add.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 222
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "proxy_ports",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#proxy-ports",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 223
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Environment",
      "lvl3": "proxy_ports",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#proxy-ports",
    "content": "Optional. Expose configured network ports on the chief task container. See Exposing Custom Ports for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 224
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#optimizations",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 225
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#optimizations",
    "content": "The optimizations section contains configuration options that influence the performance of the experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 226
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "aggregation_frequency",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#aggregation-frequency",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 227
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "aggregation_frequency",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#aggregation-frequency",
    "content": "Optional. Specifies after how many batches gradients are exchanged during distributed training. Defaults to 1.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 228
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "average_aggregated_gradients",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#average-aggregated-gradients",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 229
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "average_aggregated_gradients",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#average-aggregated-gradients",
    "content": "Optional. Whether gradients accumulated across batches (when aggregation_frequency > 1) should be divided by the aggregation_frequency. Defaults to true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 230
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "average_training_metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#average-training-metrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 231
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "average_training_metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#average-training-metrics",
    "content": "Optional. For multi-GPU training, whether to average the training metrics across GPUs instead of only using metrics from the chief GPU. This impacts the metrics shown in the Determined UI and TensorBoard, but does not impact the outcome of training or hyperparameter search. This option is currently supported for PyTorchTrial and TFKerasTrial instances. Defaults to true.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 232
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "gradient_compression",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#gradient-compression",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 233
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "gradient_compression",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#gradient-compression",
    "content": "Optional. Whether to compress gradients when they are exchanged during distributed training. Compression may alter gradient values to achieve better space reduction. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 234
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "mixed_precision",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#mixed-precision",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 235
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "mixed_precision",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#mixed-precision",
    "content": "Optional. Whether to use mixed precision training with PyTorch during distributed training. Setting O1 enables mixed precision and loss scaling. Defaults to O0 which disables mixed precision training. This configuration setting is deprecated; users are advised to call context.configure_apex_amp in the constructor of their trial class instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 236
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "tensor_fusion_threshold",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#tensor-fusion-threshold",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 237
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "tensor_fusion_threshold",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#tensor-fusion-threshold",
    "content": "Optional. The threshold in MB for batching together gradients that are exchanged during distributed training. Defaults to 64.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 238
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "tensor_fusion_cycle_time",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#tensor-fusion-cycle-time",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 239
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "tensor_fusion_cycle_time",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#tensor-fusion-cycle-time",
    "content": "Optional. The delay (in milliseconds) between each tensor fusion during distributed training. Defaults to 5.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 240
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "auto_tune_tensor_fusion",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#auto-tune-tensor-fusion",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 241
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Optimizations",
      "lvl3": "auto_tune_tensor_fusion",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#auto-tune-tensor-fusion",
    "content": "Optional. When enabled, configures tensor_fusion_threshold and tensor_fusion_cycle_time automatically. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 242
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Reproducibility",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#reproducibility",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 243
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Reproducibility",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#reproducibility",
    "content": "The reproducibility section specifies configuration options related to reproducible experiments. See Reproducibility for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 244
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Reproducibility",
      "lvl3": "experiment_seed",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-seed",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 245
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Reproducibility",
      "lvl3": "experiment_seed",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#experiment-seed",
    "content": "Optional. The random seed to use to initialize random number generators for all trials in this experiment. Must be an integer between 0 and 231\u20131. If an experiment_seed is not explicitly specified, the master will automatically generate an experiment seed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 246
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#profiling",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 247
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#profiling",
    "content": "The profiling section specifies configuration options related to profiling experiments. See System Metrics for a more detailed walkthrough.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 248
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id29",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 249
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id29",
    "content": "Optional. Profiling is supported for all frameworks, though timings are only collected for PyTorchTrial. Profiles are collected for a maximum of 5 minutes, regardless of the settings below.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 250
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "enabled",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#enabled",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 251
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "enabled",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#enabled",
    "content": "Optional. Defines whether profiles should be collected or not. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 252
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "begin_on_batch",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#begin-on-batch",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 253
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "begin_on_batch",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#begin-on-batch",
    "content": "Optional. Specifies the batch on which profiling should begin.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 254
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "end_after_batch",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#end-after-batch",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 255
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "end_after_batch",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#end-after-batch",
    "content": "Optional. Specifies the batch after which profiling should end.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 256
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "sync_timings",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#sync-timings",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 257
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Profiling",
      "lvl3": "profiling",
      "lvl4": "sync_timings",
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#sync-timings",
    "content": "Optional. Specifies whether Determined should wait for all GPU kernel streams before considering a timing as ended. Defaults to \u2018true\u2019. Applies only for frameworks that collect timing metrics (currently just PyTorch).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 258
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slurm-options",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 259
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slurm-options",
    "content": "The slurm section specifies configuration options applicable when the cluster is configured with resource_manager.type: slurm.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 260
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "gpu_type",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#gpu-type",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 261
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "gpu_type",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#gpu-type",
    "content": "Optional. An optional GPU type name to be included in the generated Slurm --gpus or --gres option if you have configured GPU types within your Slurm gres configuration. Specify this option to select that specific GPU type when there are multiple GPU types within the Slurm partition. The default is to select GPUs without regard to their type. For example, you can request the tesla GPU type with: slurm: gpu_type: tesla",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 262
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "sbatch_args",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#sbatch-args",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 263
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "sbatch_args",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#sbatch-args",
    "content": "Optional. Additional Slurm options to be passed when launching trials with sbatch. These options enable control of Slurm options not otherwise managed by Determined. For example, to specify required memory per CPU and exclusive access to an entire node when scheduled, you could specify: slurm: sbatch_args: - --mem-per-cpu=10 - --exclusive",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 264
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "slots_per_node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slots-per-node",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 265
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "Slurm Options",
      "lvl3": "slots_per_node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#slots-per-node",
    "content": "Optional. The minimum number of slots required for a node to be scheduled during a trial. If gres_supported is false, specify slots_per_node in order to utilize more than one GPU per node. It is the user\u2019s responsibility to ensure that slots_per_node GPUs will be available on nodes selected for the job using other configurations such as targeting a specific resource pool with only GPU nodes or specifying a Slurm constraint in the experiment configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 266
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pbs-options",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 267
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pbs-options",
    "content": "The pbs section specifies configuration options applicable when the cluster is configured with resource_manager.type: pbs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 268
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": "pbsbatch_args",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pbsbatch-args",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 269
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": "pbsbatch_args",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#pbsbatch-args",
    "content": "Optional. Additional PBS options to be passed when launching trials with qsub. These options enable control of PBS options not otherwise managed by Determined. For example, to specify that the job should have a priority of 1000 and a project name of MyProjectName, you could specify: pbs: pbsbatch_args: - -p1000 - -PMyProjectName Requesting of resources and job placement may be influenced through use of -l, however chunk count, chunk arrangement, and GPU or CPU counts per chunk (depending on the value of slot_type) are controlled by Determined; any values specified for these quantities will be ignored. Consider if the following were specified for a CUDA experiment: pbs: pbsbatch_args: - -l select=2:ngpus=4:mem=4gb - -l place=scatter:shared - -l walltime=1:00:00 The chunk count (two), the GPU count per chunk (four), and the chunk arrangement (scatter) will all be ignored in favor of values calculated by Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 270
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": "slots_per_node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id33",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 271
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Experiment Configuration Reference",
      "lvl1": "Experiment Configuration Reference",
      "lvl2": "PBS Options",
      "lvl3": "slots_per_node",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/experiment-config-reference.html#id33",
    "content": "Optional. Specifies the minimum number of slots required for a node to be scheduled during a trial. If gres_supported is set to false, specify slots_per_node in order to utilize more than one GPU per node. It is the user\u2019s responsibility to ensure that slots_per_node GPUs will be available on the nodes selected for the job using other configurations such as targeting a specific resource pool with only slots_per_node GPU nodes or specifying a PBS constraint in the experiment configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 272
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#det-pytorch-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#det-pytorch-api-reference",
    "content": "User Guide PyTorch Trial Determined offers a PyTorch-based training loop that is fully integrated with the Determined platform which includes: PyTorchTrial, which you must subclass to define things like model architecture, optimizer, data loaders, and how to train or validate a single batch. PyTorchTrialContext, which can be accessed from within PyTorchTrial and contains runtime methods used for training with the PyTorch API. Trainer, which is used for customizing and executing the training loop around a PyTorchTrial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrial",
    "content": "class determined.pytorch.PyTorchTrialcontext: determined.pytorch._pytorch_context.PyTorchTrialContext PyTorch trials are created by subclassing this abstract class. We can do the following things in this trial class: Define models, optimizers, and LR schedulers. In the __init__() method, initialize models, optimizers, and LR schedulers and wrap them with wrap_model, wrap_optimizer, wrap_lr_scheduler provided by PyTorchTrialContext. Run forward and backward passes. In train_batch(), call backward and step_optimizer provided by PyTorchTrialContext. We support arbitrary numbers of models, optimizers, and LR schedulers and arbitrary orders of running forward and backward passes. Configure automatic mixed precision. In the __init__() method, call configure_apex_amp provided by PyTorchTrialContext. Clip gradients. In train_batch(), pass a function into step_optimizer(optimizer, clip_grads=...) provided by PyTorchTrialContext. trial_context_class alias of determined.pytorch._pytorch_context.PyTorchTrialContext abstract __init__context: determined.pytorch._pytorch_context.PyTorchTrialContextNone Initializes a trial using the provided context. The general steps are: Initialize model(s) and wrap them with context.wrap_model. Initialize optimizer(s) and wrap them with context.wrap_optimizer. Initialize learning rate schedulers and wrap them with context.wrap_lr_scheduler. If desired, wrap models and optimizer with context.configure_apex_amp to use apex.amp for automatic mixed precision. Define custom loss function and metric functions. You may see metrics for trials that are paused and later continued that are significantly different from trials that are not paused if some of your models, optimizers, and learning rate schedulers are not wrapped. The reason is that the model\u2019s state may not be restored accurately or completely from the checkpoint, which is saved to a checkpoint and then later loaded into the trial during resumed training. When using PyTorch, this can sometimes happen if the PyTorch API is not used correctly. Here is a code example. self.context = context self.a = self.context.wrap_model(MyModelA()) self.b = self.context.wrap_model(MyModelB()) self.opt1 = self.context.wrap_optimizer(torch.optm.Adam(self.a)) self.opt2 = self.context.wrap_optimizer(torch.optm.Adam(self.b)) (self.a, self.b), (self.opt1, self.opt2) = self.context.configure_apex_amp( models=[self.a, self.b], optimizers=[self.opt1, self.opt2], num_losses=2, ) self.lrs1 = self.context.wrap_lr_scheduler( lr_scheduler=LambdaLR(self.opt1, lr_lambda=lambda epoch: 0.95 ** epoch), step_mode=LRScheduler.StepMode.STEP_EVERY_EPOCH, )) abstract train_batchbatch: Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]epoch_idx: intbatch_idx: intUnion[torch.Tensor, Dict[str, Any]] Train on one batch. Users should implement this function by doing the following things: Run forward passes on the models. Calculate the gradients with the losses with context.backward. Call an optimization step for the optimizers with context.step_optimizer. You can clip gradients by specifying the argument clip_grads. Step LR schedulers if using manual step mode. Return training metrics in a dictionary. Here is a code example. # Assume two models, two optimizers, and two LR schedulers were initialized # in ``__init__``. # Calculate the losses using the models. loss1 = self.model1(batch) loss2 = self.model2(batch) # Run backward passes on losses and step optimizers. These can happen # in arbitrary orders. self.context.backward(loss1) self.context.backward(loss2) self.context.step_optimizer( self.opt1, clip_grads=lambda params: torch.nn.utils.clip_grad_norm_(params, 0.0001), ) self.context.step_optimizer(self.opt2) # Step the learning rate. self.lrs1.step() self.lrs2.step() return {\"loss1\": loss1, \"loss2\": loss2} Parameters batch (Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor) \u2013 batch of data for training. epoch_idx (integer) \u2013 index of the current epoch among all the batches processed per device (slot) since the start of training. batch_idx (integer) \u2013 index of the current batch among all the epochs processed per device (slot) since the start of training. Returns training metrics to return. Return type torch.Tensor or Dict[str, Any] abstract build_training_data_loaderdetermined.pytorch._data.DataLoader Defines the data loader to use during training. Must return an instance of determined.pytorch.DataLoader. abstract build_validation_data_loaderdetermined.pytorch._data.DataLoader Defines the data loader to use during validation. Must return an instance of determined.pytorch.DataLoader. build_callbacksDict[str, determined.pytorch._callback.PyTorchCallback] Defines a dictionary of string names to callbacks to be used during training and/or validation. The string name will be used as the key to save and restore callback state for any callback that defines load_state_dict() and state_dict(). evaluate_batchbatch: Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]batch_idx: intDict[str, Any] Calculate validation metrics for a batch and return them as a dictionary mapping metric names to metric values. Per-batch validation metrics are reduced (aggregated) to produce a single set of validation metrics for the entire validation set (see evaluation_reducer()). There are two ways to specify evaluation metrics. Either override evaluate_batch() or evaluate_full_dataset(). While evaluate_full_dataset() is more flexible, evaluate_batch() should be preferred, since it can be parallelized in distributed environments, whereas evaluate_full_dataset() cannot. Only one of evaluate_full_dataset() and evaluate_batch() should be overridden by a trial. The metrics returned from this function must be JSON-serializable. Parameters batch (Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor) \u2013 batch of data for evaluating. batch_idx (integer) \u2013 index of the current batch among all the epochs processed per device (slot) since the start of training. evaluation_reducerUnion[determined.pytorch._reducer.Reducer, Dict[str, determined.pytorch._reducer.Reducer]] Return a reducer for all evaluation metrics, or a dict mapping metric names to individual reducers. Defaults to determined.pytorch.Reducer.AVG. evaluate_full_datasetdata_loader: torch.utils.data.dataloader.DataLoaderDict[str, Any] Calculate validation metrics on the entire validation dataset and return them as a dictionary mapping metric names to reduced metric values (i.e., each returned metric is the average or sum of that metric across the entire validation set). This validation cannot be distributed and is performed on a single device, even when multiple devices (slots) are used for training. Only one of evaluate_full_dataset() and evaluate_batch() should be overridden by a trial. The metrics returned from this function must be JSON-serializable. Parameters data_loader (torch.utils.data.DataLoader) \u2013 data loader for evaluating. get_batch_lengthbatch: Anyint Count the number of records in a given batch. Override this method when you are using custom batch types, as produced when iterating over the determined.pytorch.DataLoader. For example, when using pytorch_geometric: # Extra imports: from determined.pytorch import DataLoader from torch_geometric.data.dataloader import Collater # Trial methods: def build_training_data_loader(self): return DataLoader( self.train_subset, batch_size=self.context.get_per_slot_batch_size(), collate_fn=Collater([], []), ) def get_batch_length(self, batch): # `batch` is `torch_geometric.data.batch.Batch`. return batch.num_graphs Parameters batch (Any) \u2013 input training or validation data batch object.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrialcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrialcontext",
    "content": "class determined.pytorch.PyTorchTrialContextcore_context: determined.core._context.Contexttrial_seed: Optional[int]hparams: Optional[Dict]slots_per_trial: intnum_gpus: intexp_conf: Optional[Dict[str, Any]]aggregation_frequency: intsteps_completed: intmanaged_training: booldebug_enabled: boolenable_tensorboard_logging: bool = True Contains runtime information for any Determined workflow that uses the PyTorch API. With this class, users can do the following things: Wrap PyTorch models, optimizers, and LR schedulers with their Determined-compatible counterparts using wrap_model(), wrap_optimizer(), wrap_lr_scheduler(), respectively. The Determined-compatible objects are capable of transparent distributed training, checkpointing and exporting, mixed-precision training, and gradient aggregation. Configure apex amp by calling configure_apex_amp() (optional). Calculate the gradients with backward() on a specified loss. Run an optimization step with step_optimizer(). Functionalities inherited from determined.TrialContext, including getting the runtime information and properly handling training data in distributed training. backwardloss: torch.Tensorgradient: Optional[torch.Tensor] = Noneretain_graph: bool = Falsecreate_graph: bool = FalseNone Compute the gradient of current tensor w.r.t. graph leaves. The arguments are used in the same way as torch.Tensor.backward. See https://pytorch.org/docs/1.4.0/_modules/torch/tensor.html#Tensor.backward for details. When using distributed training, we don\u2019t support manual gradient accumulation. That means the gradient on each parameter can only be calculated once on each batch. If a parameter is associated with multiple losses, you can either choose to call backward'' on only one of those losses, or you can set the ``require_grads flag of a parameter or module to False to avoid manual gradient accumulation on that parameter. However, you can do gradient accumulation across batches by setting optimizations.aggregation_frequency in the experiment configuration to be greater than 1. Parameters gradient (Tensor or None) \u2013 Gradient w.r.t. the tensor. If it is a tensor, it will be automatically converted to a Tensor that does not require grad unless create_graph is True. None values can be specified for scalar Tensors or ones that don\u2019t require grad. If a None value would be acceptable then this argument is optional. retain_graph (bool, optional) \u2013 If False, the graph used to compute the grads will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph. create_graph (bool, optional) \u2013 If True, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to False. configure_apex_ampmodels: Union[torch.nn.modules.module.Module, List[torch.nn.modules.module.Module]]optimizers: Union[torch.optim.optimizer.Optimizer, List[torch.optim.optimizer.Optimizer]]enabled: Optional[bool] = Trueopt_level: Optional[str] = 'O1'cast_model_type: Optional[torch.dtype] = Nonepatch_torch_functions: Optional[bool] = Nonekeep_batchnorm_fp32: Optional[Union[bool, str]] = Nonemaster_weights: Optional[bool] = Noneloss_scale: Optional[Union[float, str]] = Nonecast_model_outputs: Optional[torch.dtype] = Nonenum_losses: Optional[int] = 1verbosity: Optional[int] = 1min_loss_scale: Optional[float] = Nonemax_loss_scale: Optional[float] = 16777216.0Tuple Configure automatic mixed precision for your models and optimizers using NVIDIA\u2019s Apex PyTorch extension. Note that details for apex.amp are handled automatically within Determined after this call. This function must be called after you have finished constructing your models and optimizers with wrap_model() and wrap_optimizer(). This function has the same arguments as apex.amp.initialize. When using distributed training and automatic mixed precision, we only support num_losses=1 and calling backward on the loss once. Parameters models (torch.nn.Module or list of torch.nn.Module s) \u2013 Model(s) to modify/cast. optimizers (torch.optim.Optimizer or list of torch.optim.Optimizer s) \u2013 Optimizers to modify/cast. REQUIRED for training. enabled (bool, optional, default=True) \u2013 If False, renders all Amp calls no-ops, so your script should run as if Amp were not present. opt_level (str, optional, default=\"O1\") \u2013 Pure or mixed precision optimization level. Accepted values are \u201cO0\u201d, \u201cO1\u201d, \u201cO2\u201d, and \u201cO3\u201d, explained in detail above. cast_model_type (torch.dtype, optional, default=None) \u2013 Optional property override, see above. patch_torch_functions (bool, optional, default=None) \u2013 Optional property override. keep_batchnorm_fp32 (bool or str, optional, default=None) \u2013 Optional property override. If passed as a string, must be the string \u201cTrue\u201d or \u201cFalse\u201d. master_weights (bool, optional, default=None) \u2013 Optional property override. loss_scale (float or str, optional, default=None) \u2013 Optional property override. If passed as a string, must be a string representing a number, e.g., \u201c128.0\u201d, or the string \u201cdynamic\u201d. cast_model_outputs (torch.dtype, optional, default=None) \u2013 Option to ensure that the outputs of your model is always cast to a particular type regardless of opt_level. num_losses (int, optional, default=1) \u2013 Option to tell Amp in advance how many losses/backward passes you plan to use. When used in conjunction with the loss_id argument to amp.scale_loss, enables Amp to use a different loss scale per loss/backward pass, which can improve stability. If num_losses is left to 1, Amp will still support multiple losses/backward passes, but use a single global loss scale for all of them. verbosity (int, default=1) \u2013 Set to 0 to suppress Amp-related output. min_loss_scale (float, default=None) \u2013 Sets a floor for the loss scale values that can be chosen by dynamic loss scaling. The default value of None means that no floor is imposed. If dynamic loss scaling is not used, min_loss_scale is ignored. max_loss_scale (float, default=2.**24) \u2013 Sets a ceiling for the loss scale values that can be chosen by dynamic loss scaling. If dynamic loss scaling is not used, max_loss_scale is ignored. Returns Model(s) and optimizer(s) modified according to the opt_level. If optimizers args were lists, the corresponding return value will also be a list. current_train_batchint Current global batch index get_data_configDict[str, Any] Return the data configuration. get_enable_tensorboard_loggingbool Return whether automatic tensorboard logging is enabled get_experiment_idint Return the experiment ID of the current trial. get_global_batch_sizeint Return the global batch size. get_hparamname: strAny Return the current value of the hyperparameter with the given name. get_per_slot_batch_sizeint Return the per-slot batch size. When a model is trained with a single GPU, this is equal to the global batch size. When multi-GPU training is used, this is equal to the global batch size divided by the number of GPUs used to train the model. get_stop_requestedbool Return whether a trial stoppage has been requested. get_tensorboard_pathpathlib.Path Get the path where files for consumption by TensorBoard should be written get_tensorboard_writerAny This function returns an instance of torch.utils.tensorboard.SummaryWriter Trials users who wish to log to TensorBoard can use this writer object. We provide and manage a writer in order to save and upload TensorBoard files automatically on behalf of the user. Usage example: class MyModel(PyTorchTrial): def __init__(self, context): ... self.writer = context.get_tensorboard_writer() def train_batch(self, batch, epoch_idx, batch_idx): self.writer.add_scalar('my_metric', np.random.random(), batch_idx) self.writer.add_image('my_image', torch.ones((3,32,32)), batch_idx) get_trial_idint Return the trial ID of the current trial. is_epoch_endbool Returns true if the current batch is the last batch of the epoch. Not accurate for variable size epochs. is_epoch_startbool Returns true if the current batch is the first batch of the epoch. Not accurate for variable size epochs. set_enable_tensorboard_loggingenable_tensorboard_logging: boolNone Set a flag to indicate whether automatic upload to tensorboard is enabled. set_profiler*args: List[str]**kwargs: AnyNone set_profiler() is a thin wrapper around the native PyTorch profiler, torch-tb-profiler. It overrides the on_trace_ready parameter to the determined tensorboard path, while all other arguments are passed directly into torch.profiler.profile. Stepping the profiler will be handled automatically during the training loop. See the PyTorch profiler plugin for details. Examples: Profiling GPU and CPU activities, skipping batch 1, warming up on batch 2, and profiling batches 3 and 4. self.context.set_profiler( activities=[ torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA, ], schedule=torch.profiler.schedule( wait=1, warmup=1, active=2 ), ) set_stop_requestedstop_requested: boolNone Set a flag to request a trial stoppage. When this flag is set to True, we finish the step, checkpoint, then exit. step_optimizeroptimizer: torch.optim.optimizer.Optimizerclip_grads: Optional[Callable[[Iterator], None]] = Noneauto_zero_grads: bool = Truescaler: Optional[Any] = NoneNone Perform a single optimization step. This function must be called once for each optimizer. However, the order of different optimizers\u2019 steps can be specified by calling this function in different orders. Also, gradient accumulation across iterations is performed by the Determined training loop by setting the experiment configuration field optimizations.aggregation_frequency. Here is a code example: def clip_grads(params): torch.nn.utils.clip_grad_norm_(params, 0.0001), self.context.step_optimizer(self.opt1, clip_grads) Parameters optimizer (torch.optim.Optimizer) \u2013 Which optimizer should be stepped. clip_grads (a function, optional) \u2013 This function should have one argument for parameters in order to clip the gradients. auto_zero_grads (bool, optional) \u2013 Automatically zero out gradients automatically after stepping the optimizer. If false, you need to call optimizer.zero_grad() manually. Note that if optimizations.aggregation_frequency is greater than 1, auto_zero_grads must be true. scaler (torch.cuda.amp.GradScaler, optional) \u2013 The scaler to use for stepping the optimizer. This should be unset if not using AMP, and is necessary if wrap_scaler() was called directly. to_devicedata: Union[Dict[str, Union[numpy.ndarray, torch.Tensor]], Sequence[Union[numpy.ndarray, torch.Tensor]], numpy.ndarray, torch.Tensor]Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor] Map generated data to the device allocated by the Determined cluster. All the data in the data loader and the models are automatically moved to the allocated device. This method aims at providing a function for the data generated on the fly. wrap_lr_schedulerlr_scheduler: torch.optim.lr_scheduler._LRSchedulerstep_mode: determined.pytorch._lr_scheduler.LRScheduler.StepModefrequency: int = 1torch.optim.lr_scheduler._LRScheduler Returns a wrapped LR scheduler. The LR scheduler must use an optimizer wrapped by wrap_optimizer(). If apex.amp is in use, the optimizer must also have been configured with configure_apex_amp(). wrap_modelmodel: torch.nn.modules.module.Moduletorch.nn.modules.module.Module Returns a wrapped model. wrap_optimizeroptimizer: torch.optim.optimizer.Optimizerbackward_passes_per_step: int = 1fp16_compression: Optional[bool] = Noneaverage_aggregated_gradients: Optional[bool] = Nonetorch.optim.optimizer.Optimizer Returns a wrapped optimizer. The optimizer must use the models wrapped by wrap_model(). This function creates a horovod.DistributedOptimizer if using parallel/distributed training. backward_passes_per_step can be used to specify how many gradient aggregation steps will be performed in a single train_batch call per optimizer step. In most cases, this will just be the default value 1. However, this advanced functionality can be used to support training loops like the one shown below: def train_batch( self, batch: TorchData, epoch_idx: int, batch_idx: int ) -> Dict[str, torch.Tensor]: data, labels = batch output = self.model(data) loss1 = output['loss1'] loss2 = output['loss2'] self.context.backward(loss1) self.context.backward(loss2) self.context.step_optimizer(self.optimizer, backward_passes_per_step=2) return {\"loss1\": loss1, \"loss2\": loss2} wrap_scalerscaler: AnyAny Prepares to use automatic mixed precision through PyTorch\u2019s native AMP API. The returned scaler should be passed to step_optimizer, but usage does not otherwise differ from vanilla PyTorch APIs. Loss should be scaled before calling backward, unscale_ should be called before clipping gradients, update should be called after stepping all optimizers, etc. PyTorch 1.6 or greater is required for this feature. Parameters scaler (torch.cuda.amp.GradScaler) \u2013 Scaler to wrap and track. Returns The scaler. It may be wrapped to add additional functionality for use in Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrialContext.distributed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrialcontext-distributed",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchTrialContext.distributed",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchtrialcontext-distributed",
    "content": "class determined.core._distributed.DistributedContext*rank: intsize: intlocal_rank: intlocal_size: intcross_rank: intcross_size: intchief_ip: Optional[str] = Nonepub_port: int = 12360pull_port: int = 12376port_offset: int = 0force_tcp: bool = False DistributedContext provides useful methods for effective distributed training. A DistributedContext has the following required args: rank: the index of this worker in the entire job size: the number of workers in the entire job local_rank: the index of this worker on this machine local_size: the number of workers on this machine cross_rank: the index of this machine in the entire job cross_size: the number of machines in the entire job Additionally, any time that cross_size > 1, you must also provide: chief_ip: the ip address to reach the chief worker (where rank==0) DistributedContext has .allgather(), .gather(), and .broadcast() methods, which are easy to use and which can be useful for coordinating work across workers, but it is not a replacement for the allgather/gather/broadcast operations in your particular distributed training framework. classmethod from_horovodhvd: Anychief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the provided hvd module to determine rank information. Example: import horovod.torch as hvd hvd.init() distributed = DistributedContext.from_horovod(hvd) The IP address for the chief worker is required whenever hvd.cross_size() > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_deepspeedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard deepspeed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided using the chief_ip argument or the DET_CHIEF_IP environment variable. classmethod from_torch_distributedchief_ip: Optional[str] = Nonedetermined.core._distributed.DistributedContext Create a DistributedContext using the standard torch distributed environment variables to determine rank information. The IP address for the chief worker is required whenever CROSS_SIZE > 1. The value may be provided via the chief_ip argument or the DET_CHIEF_IP environment variable. get_rankint Return the rank of the process in the trial. The rank of a process is a unique ID within the trial. That is, no two processes in the same trial are assigned the same rank. get_local_rankint Return the rank of the process on the agent. The local rank of a process is a unique ID within a given agent and trial; that is, no two processes in the same trial that are executing on the same agent are assigned the same rank. get_sizeint Return the number of slots this trial is running on. get_num_agentsint Return the number of agents this trial is running on. gatherstuff: AnyOptional[List] Gather stuff to the chief. The chief returns a list of all stuff, and workers return None. gather() is not a replacement for the gather functionality of your distributed training framework. gather_localstuff: AnyOptional[List] Gather stuff to the local chief. The local chief returns a list of all stuff, and local workers return None. gather_local() is not a replacement for the gather functionality of your distributed training framework. allgatherstuff: AnyList Gather stuff to the chief and broadcast all of it back to the workers. allgather() is not a replacement for the allgather functionality of your distributed training framework. allgather_localstuff: AnyList Gather stuff to the local chief and broadcast all of it back to the local workers. allgather_local() is not a replacement for the allgather functionality of your distributed training framework. broadcaststuff: AnyAny Every worker gets the stuff sent by the chief. broadcast() is not a replacement for the broadcast functionality of your distributed training framework. broadcast_localstuff: Optional[Any] = NoneAny Every worker gets the stuff sent by the local chief. broadcast_local() is not a replacement for the broadcast functionality of your distributed training framework.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchExperimentalContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchexperimentalcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchExperimentalContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchexperimentalcontext",
    "content": "class determined.pytorch.PyTorchExperimentalContextparent: Any disable_auto_to_deviceNone Prevent the PyTorchTrialController from automatically moving batched data to device. Call this if you want to override the default behavior of moving all items of a list, tuple, and/or dict to the GPU. Then, you can control how data is moved to the GPU directly in the train_batch and evaluate_batch methods of your PyTorchTrial definition. You should call context.to_device on primitive data types that you do want to move to GPU as in the example below. # PyTorchTrial methods. def __init__(context): # PyTorchTrial init self.context.experimental.disable_auto_to_device() ... def train_batch(self, context, batch): for k, item in batch.items(): if k == \"img\": batch[\"img\"] = self.context.to_device(batch[\"img\"]) ... disable_dataset_reproducibility_checksNone disable_dataset_reproducibility_checks() allows you to return an arbitrary DataLoader from build_training_data_loader() or build_validation_data_loader(). Normally you would be required to return a det.pytorch.DataLoader instead, which would guarantee that an appropriate Sampler is used that ensures: When shuffle=True, the shuffle is reproducible. The dataset will start at the right location, even after pausing/continuing. Proper sharding is used during distributed training. However, there may be cases where either reproducibility of the dataset is not needed or where the nature of the dataset may cause the det.pytorch.DataLoader to be unsuitable. In those cases, you may call disable_dataset_reproducibility_checks() and you will be free to return any torch.utils.data.DataLoader you like. Dataset reproducibility will still be possible, but it will be your responsibility. If desired, you may find the Sampler classes in determined.pytorch.samplers to be helpful. use_ampNone Handles all operations for the most simple cases automatically with a default gradient scaler. Specifically, wraps forward pass in an autocast context, scales loss before backward pass, unscales before clipping gradients, uses scaler when stepping optimizer(s), and updates scaler afterwards. Do not call wrap_scaler directly when using this method. PyTorch 1.6 or greater is required for this feature.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.DataLoader",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-dataloader",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.DataLoader",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-dataloader",
    "content": "class determined.pytorch.DataLoaderdataset: torch.utils.data.dataset.Datasetbatch_size: Optional[int] = 1shuffle: bool = Falsesampler: Optional[torch.utils.data.sampler.Sampler] = Nonebatch_sampler: Optional[torch.utils.data.sampler.BatchSampler] = Nonenum_workers: int = 0collate_fn: Optional[Callable[[List[determined.pytorch._data.T]], Any]] = Nonepin_memory: bool = Falsedrop_last: bool = Falsetimeout: float = 0worker_init_fn: Optional[Callable[[int], None]] = Nonemultiprocessing_context: Optional[Any] = Nonegenerator: Optional[Any] = None*prefetch_factor: Optional[int] = Nonepersistent_workers: bool = False DataLoader is meant to contain a user\u2019s Dataset, configuration for sampling data in batches, and performance configuration like multiprocessing. The __init__ function determines the defaults in the same way as a torch.utils.data.DataLoader would, so the behavior should be familiar. However, the torch.utils.data.Dataloader that is used for training and validation is not created until get_data_loader(...) is called. This is done so that Determined can ensure that sampling restarts from the right location and distributed sampling is handled correctly. Note that the arguments are from PyTorch. Parameters dataset (Dataset) \u2013 dataset from which to load the data. batch_size (int, optional) \u2013 how many samples per batch to load (default: 1). shuffle (bool, optional) \u2013 set to True to have the data reshuffled at every epoch (default: False). sampler (Sampler, optional) \u2013 defines the strategy to draw samples from the dataset. If specified, shuffle must be False. batch_sampler (Sampler, optional) \u2013 like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last. num_workers (int, optional) \u2013 how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0) collate_fn (callable, optional) \u2013 merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory (bool, optional) \u2013 If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below. drop_last (bool, optional) \u2013 set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False) timeout (numeric, optional) \u2013 if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0) worker_init_fn (callable, optional) \u2013 If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None) generator (torch.Generator, optional) \u2013 If not None, this RNG will be used by RandomSampler to generate random indexes and multiprocessing to generate base_seed for workers. (default: None) prefetch_factor (int, optional, keyword-only arg) \u2013 Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers. (default: 2) persistent_workers (bool, optional) \u2013 If True, the data loader will not shut down the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. (default: False)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.LRScheduler",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-lrscheduler",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.LRScheduler",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-lrscheduler",
    "content": "class determined.pytorch.LRSchedulerscheduler: torch.optim.lr_scheduler._LRSchedulerstep_mode: determined.pytorch._lr_scheduler.LRScheduler.StepModefrequency: int = 1 Wrapper for a PyTorch LRScheduler. This wrapper fulfills two main functions: Save and restore the learning rate when a trial is paused, preempted, etc. Step the learning rate scheduler at the configured frequency (e.g., every batch or every epoch). class StepModevalue Specifies when and how scheduler.step() should be executed. STEP_EVERY_EPOCH STEP_EVERY_BATCH MANUAL_STEP STEP_EVERY_OPTIMIZER_STEP __init__scheduler: torch.optim.lr_scheduler._LRSchedulerstep_mode: determined.pytorch._lr_scheduler.LRScheduler.StepModefrequency: int = 1 LRScheduler constructor. Parameters scheduler (torch.optim.lr_scheduler._LRScheduler) \u2013 Learning rate scheduler to be used by Determined. step_mode (determined.pytorch.LRSchedulerStepMode) \u2013 The strategy Determined will use to call (or not call) scheduler.step().STEP_EVERY_EPOCH: Determined will call scheduler.step() after every frequency training epoch(s). No arguments will be passed to step().STEP_EVERY_BATCH: Determined will call scheduler.step() after every frequency training batch(es). No arguments will be passed to step(). This option does not take into account gradient aggregation; STEP_EVERY_OPTIMIZER_STEP which is recommended.STEP_EVERY_OPTIMIZER_STEP: Determined will call scheduler.step() in sync with optimizer steps. With optimizations.aggregation_frequency unset, this is equivalent to STEP_EVERY_BATCH; when it is set, it ensures the LR scheduler is stepped every _effective_ batch.If the option frequency is set to some value N, Determined will step the LR scheduler every N optimizer steps.MANUAL_STEP: Determined will not call scheduler.step() at all. It is up to the user to decide when to call scheduler.step(), and whether to pass any arguments. frequency \u2013 Sets the frequency at which the batch and epoch step modes get triggered.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.Reducer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-reducer",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.Reducer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-reducer",
    "content": "class determined.pytorch.Reducervalue A Reducer defines a method for reducing (aggregating) evaluation metrics. See evaluation_reducer() for details. AVG SUM MAX MIN",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.MetricReducer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-metricreducer",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.MetricReducer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-metricreducer",
    "content": "class determined.pytorch.MetricReducer Efficiently aggregating validation metrics during a multi-slot distributed trial is done in three steps: Gather all the values to be reduced during the reduction window (either a training or a validation workload). In a multi-slot trial, this is done on each slot in parallel. Calculate the per-slot reduction. This will return some intermediate value that each slot will contribute to the final metric calculation. It can be as simple as a list of all the raw values from step 1, but reducing the intermediate value locally will distribute the final metric calculation more efficiently and will reduce network communication costs. Reduce the per-slot reduction values from Step 2 into a final metric. The MetricReducer API makes it possible for users to define a maximally efficient custom metric by exposing these steps to users: Step 1 is defined by the user; it is not part of the interface. This flexibility gives the user full control when gathering individual values for reduction. Step 2 is the MetricReducer.per_slot_reduce() interface. Step 3 is the MetricReducer.cross_slot_reduce() interface. The MetricReducer.reset() interface allows for MetricReducer reuse across many train and validation workloads. Example implementation and usage: class MyAvgMetricReducer(pytorch.MetricReducer): def __init__(self): self.reset() def reset(self): self.sum = 0 self.counts = 0 # User-defined mechanism for collecting values throughout # training or validation. This update() mechanism demonstrates # a computationally- and memory-efficient way to store the values. def update(self, value): self.sum += sum(value) self.counts += 1 def per_slot_reduce(self): # Because the chosen update() mechanism is so # efficient, this is basically a noop. return self.sum, self.counts def cross_slot_reduce(self, per_slot_metrics): # per_slot_metrics is a list of (sum, counts) tuples # returned by the self.pre_slot_reduce() on each slot sums, counts = zip(*per_slot_metrics) return sum(sums) / sum(counts) class MyPyTorchTrial(pytorch.PyTorchTrial): def __init__(self, context): # Register your custom reducer. self.my_avg = context.wrap_reducer( MyAvgMetricReducer(), name=\"my_avg\" ) ... def train_batch(self, batch, epoch_idx, batch_idx): ... # You decide how/when you call update(). self.my_avg.update(my_val) # The \"my_avg\" metric will be included in the final # metrics after the workload has completed; no need # to return it here. return {\"loss\": loss} See also: determined.pytorch.PyTorchExperimentalContext.wrap_reducer(). abstract resetNone Reset reducer state for another set of values. This will be called before any train or validation workload begins. abstract per_slot_reduceAny This will be called after all workers have finished (even when there is only one worker). It should return some picklable value that is meaningful for cross_slot_reduce. This will be called after any train or validation workload ends. abstract cross_slot_reduceper_slot_metrics: ListAny This will be called after per_slot_reduce has finished (even when there is only one worker). The per_slot_metrics will be a list containing the output of per_slot_reduce() from each worker. The return value should either be: A dict mapping string metric names to metric values, if the call to context.wrap_reducer() omitted the name parameter, or A non-dict metric value if the call to context.wrap_reducer() had name set to a string (an error will be raised if a dict-type metric is returned but name was set). This will be called after per_slot_reduce.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchCallback",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchcallback",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.PyTorchCallback",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-pytorchcallback",
    "content": "class determined.pytorch.PyTorchCallback Abstract base class used to define a callback that should execute during the lifetime of a PyTorchTrial or DeepSpeedTrial. If you are defining a stateful callback (e.g., it mutates a self attribute over its lifetime), you must also override state_dict() and load_state_dict() to ensure this state can be serialized and deserialized over checkpoints. If distributed training is enabled, every GPU will execute a copy of this callback (except for on_checkpoint_write_end() during PyTorchTrial training, which is only called on the chief). To configure a callback implementation to execute on a subset of GPUs, please condition your implementation on trial.context.distributed.get_rank(). load_state_dictstate_dict: Dict[str, Any]None Load the state of this using the deserialized state_dict. on_checkpoint_endcheckpoint_dir: strNone Deprecated. Please use on_checkpoint_write_end() instead. This callback only executes on the chief GPU when doing distributed training with PyTorchTrial. on_checkpoint_load_startcheckpoint: Dict[str, Any]None Run before state_dict is restored. on_checkpoint_save_startcheckpoint: Dict[str, Any]None Run before checkpoint is persisted. on_checkpoint_upload_enduuid: strNone Run after every checkpoint finishes uploading. on_checkpoint_write_endcheckpoint_dir: strNone Run after every checkpoint finishes writing to checkpoint_dir. This callback only executes on the chief GPU when doing distributed training with PyTorchTrial. on_training_epoch_endepoch_idx: intNone Run on end of a training epoch on_training_epoch_startepoch_idx: intNone Run on start of a new training epoch on_training_startNone Run after checkpoint loads and before training begins. on_training_workload_endavg_metrics: Dict[str, Any]batch_metrics: Dict[str, Any]None Run on end of a training workload. Workloads can contain varying numbers of batches. In the current implementation of PyTorchTrial and DeepSpeedTrial, the maximum number of batches in a workload is equal to the scheduling_unit field defined in the experiment config. on_trial_shutdownNone Runs just before shutting down training to get off of the cluster. This does not imply that the trial is complete; it may just be paused or preempted by a higher-priority task. This callback runs each time a Trial shuts down gracefully to come off the cluster. This callback does not mean that the Trial is done training. Additionally, if the trial is killed the container will be destroyed without this callback running. on_trial_startupfirst_batch_idx: intcheckpoint_uuid: Optional[str]None Runs before training, validation, or building dataloaders. Parameters first_batch_idx (int) \u2013 The first batch index to be trained. If the trial has already completed some amount of training in a previous allocation on the cluster, this will be nonzero. checkpoint_uuid (str or None) \u2013 The checkpoint from which weight, optimizer state, etc. will be loaded. When first_batch_idx > 0 this will contain the uuid of the most recent checkpoint saved by this trial. Otherwise, it will contain the uuid of the checkpoint from which this trial was configured to warm start from (via source_trial_id or source_checkpoint_uuid in the searcher config), or None if no warm start was configured. on_validation_endmetrics: Dict[str, Any]None Run after every validation ends. on_validation_epoch_endoutputs: List[Any]None Run after a new validation epoch has finished on_validation_epoch_startNone Run on start of a new validation epoch on_validation_startNone Run before every validation begins. state_dictDict[str, Any] Serialize the state of this callback to a dictionary. Return value must be pickle-able.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.load_trial_from_checkpoint_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-load-trial-from-checkpoint-path",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.load_trial_from_checkpoint_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-load-trial-from-checkpoint-path",
    "content": "determined.pytorch.load_trial_from_checkpoint_pathpath: strtrial_class: Optional[Type[determined.pytorch._pytorch_trial.PyTorchTrial]] = Nonetrial_kwargs: Optional[Dict[str, Any]] = Nonetorch_load_kwargs: Optional[Dict[str, Any]] = None**kwargs: Dict[str, Any]determined.pytorch._pytorch_trial.PyTorchTrial Loads a checkpoint written by a PyTorchTrial. You should have already downloaded the checkpoint files, likely with Checkpoint.download(). The return value will be a restored instance of the subclass PyTorchTrial you used for training. Parameters path (string) \u2013 Top level directory to load the checkpoint from. trial_class (optional) \u2013 Provide your PyTorchTrial class to be loaded. Only necessary if the automatic import logic is insufficient. trial_kwargs (optional) \u2013 Additional keyword arguments to be passed to your PyTorchTrial class, in addition to the context, which will always be the first positional parameter. torch_load_kwargs (optional) \u2013 Keyword arguments for torch.load. See documentation for torch.load. **kwargs (deprecated) \u2013 Use torch_load_kwargs instead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.Trainer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-trainer",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.Trainer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-trainer",
    "content": "class determined.pytorch.Trainertrial: determined.pytorch._pytorch_trial.PyTorchTrialcontext: determined.pytorch._pytorch_context.PyTorchTrialContext pytorch.Trainer is an abstraction on top of a vanilla PyTorch training loop that handles many training details under-the-hood, and exposes APIs for configuring training-related features such as automatic checkpointing, validation, profiling, metrics reporting, etc. Trainer must be initialized and called from within a pytorch.PyTorchTrialContext. configure_profilersync_timings: boolenabled: boolbegin_on_batch: intend_after_batch: intNone Configures the Determined profiler. This method should only be called before .fit(), and only once within the scope of init(). If called multiple times, the last call\u2019s configuration will be used. Parameters sync_timings \u2013 Specifies whether Determined should wait for all GPU kernel streams before considering a timing as ended. Defaults to \u2018true\u2019. Applies only for frameworks that collect timing metrics (currently just PyTorch). enabled \u2013 Defines whether profiles should be collected or not. Defaults to false. begin_on_batch \u2013 Specifies the batch on which profiling should begin. end_after_batch \u2013 Specifies the batch after which profiling should end. fitcheckpoint_period: Optional[determined.pytorch._pytorch_trial.TrainUnit] = Nonevalidation_period: Optional[determined.pytorch._pytorch_trial.TrainUnit] = Nonemax_length: Optional[determined.pytorch._pytorch_trial.TrainUnit] = Nonereporting_period: determined.pytorch._pytorch_trial.TrainUnit = <determined.pytorch._pytorch_trial.Batch object>checkpoint_policy: str = 'best'latest_checkpoint: Optional[str] = Nonestep_zero_validation: bool = Falsetest_mode: bool = FalseNone fit() trains a PyTorchTrial configured from the Trainer and handles checkpointing and validation steps, and metrics reporting. Parameters checkpoint_period \u2013 The number of steps to train for before checkpointing. This is a TrainUnit type (Batch or Epoch) which can take an int or instance of collections.abc.Container (list, tuple, etc.). For example, Batch(100) would checkpoint every 100 batches, while Batch([5, 30, 45]) would checkpoint after every 5th, 30th, and 45th batch. validation_period \u2013 The number of steps to train for before validating. This is a TrainUnit type (Batch or Epoch) which can take an int or instance of collections.abc.Container (list, tuple, etc.). For example, Batch(100) would validate every 100 batches, while Batch([5, 30, 45]) would validate after every 5th, 30th, and 45th batch. max_length \u2013 The maximum number of steps to train for. This value is required and only applicable in local training mode. For on-cluster training, this value will be ignored; the searcher\u2019s max_length must be configured from the experiment configuration. This is a TrainUnit type (Batch or Epoch) which takes an int. For example, Epoch(1) would train for a maximum length of one epoch. reporting_period: checkpoint_policy \u2013 Controls how Determined performs checkpoints after validation operations \u2013 best (default): A checkpoint will be taken after every validation operation that performs better than all previous validations for this experiment. Validation metrics are compared according to the metric and smaller_is_better options in the searcher configuration. This option is only supported for on-cluster training. all: A checkpoint will be taken after every validation, no matter the validation performance. none: A checkpoint will never be taken due to a validation. However, even with this policy selected, checkpoints are still expected to be taken after the trial is finished training, due to cluster scheduling decisions, before search method decisions, or due to min_checkpoint_period. values (if at all. Should be set to one of the following) \u2013 best (default): A checkpoint will be taken after every validation operation that performs better than all previous validations for this experiment. Validation metrics are compared according to the metric and smaller_is_better options in the searcher configuration. This option is only supported for on-cluster training. all: A checkpoint will be taken after every validation, no matter the validation performance. none: A checkpoint will never be taken due to a validation. However, even with this policy selected, checkpoints are still expected to be taken after the trial is finished training, due to cluster scheduling decisions, before search method decisions, or due to min_checkpoint_period. latest_checkpoint \u2013 Configures the checkpoint used to start or continue training. This value should be set to det.get_cluster_info().latest_checkpoint for standard continue training functionality. step_zero_validation \u2013 Configures whether or not to perform an initial validation before training. test_mode \u2013 Runs a minimal loop of training for testing and debugging purposes. Will train and validate one batch. Defaults to false.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.init()",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-init",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch API Reference",
      "lvl1": "det.pytorch API Reference",
      "lvl2": "determined.pytorch.init()",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-reference.html#determined-pytorch-init",
    "content": "determined.pytorch.init*hparams: Optional[Dict] = Noneexp_conf: Optional[Dict[str, Any]] = Nonedistributed: Optional[determined.core._distributed.DistributedContext] = Noneaggregation_frequency: int = 1enable_tensorboard_logging: bool = TrueIterator[determined.pytorch._pytorch_context.PyTorchTrialContext] Creates a PyTorchTrialContext for use with a PyTorchTrial. All trainer.* calls must be within the scope of this context because there are resources started in __enter__ that must be cleaned up in __exit__. Parameters hparams \u2013 (Optional) instance of hyperparameters for the trial exp_conf \u2013 (Optional) for local-training mode. If unset, calling context.get_experiment_config() will fail. distributed \u2013 (Optional) custom distributed training configuration aggregation_frequency \u2013 number of batches before gradients are exchanged in distributed training. This value is configured here because it is used in context.wrap_optimizer. enable_tensorboard_logging \u2013 Configures if upload to tensorboard is enabled",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det API Reference",
      "lvl1": "det API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-det-reference.html#det-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det API Reference",
      "lvl1": "det API Reference",
      "lvl2": "determined.ClusterInfo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-det-reference.html#determined-clusterinfo",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det API Reference",
      "lvl1": "det API Reference",
      "lvl2": "determined.ClusterInfo",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-det-reference.html#determined-clusterinfo",
    "content": "determined.get_cluster_infoOptional[determined._info.ClusterInfo] Returns either the ClusterInfo object for the current task, or None if not running in a task. class determined.ClusterInfomaster_url: strcluster_id: stragent_id: strslot_ids: List[int]task_id: strallocation_id: strsession_token: strtask_type: strmaster_cert_name: Optional[str] = Nonemaster_cert_file: Optional[str] = Nonelatest_checkpoint: Optional[str] = Nonetrial_info: Optional[determined._info.TrialInfo] = Nonerendezvous_info: Optional[determined._info.RendezvousInfo] = Noneresources_info: Optional[determined._info.ResourcesInfo] = None ClusterInfo exposes various properties that are set for tasks while running on the cluster. Examples: info = det.get_cluster_info() assert info is not None, \"this code only runs on-cluster!\" print(\"master_url\", info.master_url) print(\"task_id\", info.task_id) print(\"allocation_id\", info.allocation_id) print(\"session_token\", info.session_token) print(\"container_addrs\", info.container_addrs) print(\"container_rank\", info.container_rank) if info.task_type == \"TRIAL\": print(\"trial.id\", info.trial.trial_id) print(\"trial.hparams\", info.trial.hparams) Be careful with this object! If you depend on a ClusterInfo object during training for anything more than e.g. informational logging, you run the risk of making your training code unable to run outside of Determined. ClusterInfo is meant to be most useful to custom launch layers, which likely are not able to run outside of Determined anyway. agent_id The identifier of the Determined agent this container is running on. allocation_id The unique identifier for the current allocation. cluster_id The unique identifier for this cluster. property container_addrs: List[str] A list of addresses for all containers in the allocation, ordered by rank. property container_rank: int The rank assigned to this container. When using a distributed training framework, the framework may choose a different rank for this container. property container_slot_counts: List[int] A list of slots for all containers in the allocation, ordered by rank. property gpu_uuids: List[str] The UUIDs to the gpus assigned to this container. property latest_checkpoint: Optional[str] The checkpoint ID of the most recent checkpoint that should be loaded. Since non-trial-type tasks cannot currently save checkpoints, .latest_checkpoint is currently always None for non-trial-type tasks. master_cert_file The file location for the master certificate, if present, or \u201cnoverify\u201d if it has been configured not to verify the master cert. master_cert_name The name on the master certificate, when using TLS. master_url The url for reaching the master. session_token The Determined login session token created for the current task. slot_ids The slot ids assigned to this container. task_id The unique identifier for the current task. task_type The type of task. Currently one of the following string literals: \"TRIAL\" \"NOTEBOOK\" \"SHELL\" \"COMMAND\" \"TENSORBOARD\" \"CHECKPOINT_GC\" Additional values may be added in the future. property trial: determined._info.TrialInfo The TrialInfo sub-info object for the current trial task. Attempting to read .trial in a non-trial task type will raise a RuntimeError. property user_data: Dict[str, Any] The content of the data field of the experiment configuration. Since other types of configuration files don\u2019t allow a data field, accessing user_data from non-trial-type tasks will always return an empty dictionary.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det API Reference",
      "lvl1": "det API Reference",
      "lvl2": "determined.import_from_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-det-reference.html#determined-import-from-path",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det API Reference",
      "lvl1": "det API Reference",
      "lvl2": "determined.import_from_path",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-det-reference.html#determined-import-from-path",
    "content": "determined.import_from_pathpath: os.PathLikeIterator import_from_path allows you to import from a specific directory and cleans up afterwards. Even if you are importing identically-named files, you can import them as separate modules. This is intended to help when you have, for example, a current model_def.py, but also import an older model_def.py from a checkpoint into the same interpreter, without conflicts (so long as you import them as different names, of course). Example: import model_def as new_model_def with det.import_from_path(checkpoint_dir): import model_def as old_model_def old_model = old_model_def.my_build_model() old_model.my_load_weights(checkpoint_dir) current_model = new_model_def.my_build_model( base_layers=old_model.base_layers ) Without import_from_path, the above code snippet would hit issues where model_def had already been imported so the second import would have been a noop and both new_model_def and old_model_def would represent the same underlying module.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.samplers API Reference",
      "lvl1": "det.pytorch.samplers API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-samplers-reference.html#module-determined.pytorch.samplers",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.samplers API Reference",
      "lvl1": "det.pytorch.samplers API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-pytorch-samplers-reference.html#module-determined.pytorch.samplers",
    "content": "class determined.pytorch.samplers.DistributedBatchSamplerbatch_sampler: torch.utils.data.sampler.BatchSamplernum_workers: intrank: int DistributedBatchSampler will iterate through an underlying batch sampler and return batches which belong to this shard. DistributedBatchSampler is different from the PyTorch built-in torch.utils.data.distributed.DistributedSampler, because that DistributedSampler expects to bbe called before the BatchSampler, and additionally the DistributedSampler is meant to be a stand-alone sampler. DistributedBatchSampler has the potential gotcha that when wrapping a non-repeating BatchSampler, if the length of the BatchSampler is not divisible by the number of replicas the length of the resulting DistributedBatchSampler will differ based on the rank. In that case, the divergent paths of multiple workers could cause problems during training. PyTorchTrial always uses RepeatBatchSampler during training, PyTorchTrial does not require that the workers stay in step during validation, so this potential gotcha is not a problem in Determined. class determined.pytorch.samplers.DistributedSamplersampler: torch.utils.data.sampler.Samplernum_workers: intrank: int DistributedSampler will iterate through an underlying sampler and return samples which belong to this shard. DistributedSampler is different from the PyTorch built-in torch.utils.data.DistributedSampler because theirs is meant to be a standalone sampler. Theirs does shuffling and assumes a constant size dataset as an input. Ours is meant to be used a building block in a chain of samplers, so it accepts a sampler as input that may or may not be constant-size. class determined.pytorch.samplers.RepeatBatchSamplerbatch_sampler: torch.utils.data.sampler.BatchSampler RepeatBatchSampler yields infinite batches indices by repeatedly iterating through the batches of another BatchSampler. __len__ is just the length of the underlying BatchSampler. class determined.pytorch.samplers.RepeatSamplersampler: torch.utils.data.sampler.Sampler RepeatSampler yields infinite batches indices by repeatedly iterating through the batches of another Sampler. __len__ is just the length of the underlying Sampler. class determined.pytorch.samplers.ReproducibleShuffleBatchSamplerbatch_sampler: torch.utils.data.sampler.BatchSamplerseed: int ReproducibleShuffleBatchSampler will apply a deterministic shuffle based on a seed. Always shuffle before skipping and before repeating. Skip-before-shuffle would break the reproducibility of the shuffle, and repeat-before-shuffle would cause the shuffle to hang as it iterates through an infinite sampler. Always prefer ReproducibleShuffleSampler over this class when possible. The reason is that shuffling at the batch level results in a superior shuffle, where the contents of each batch are varied between epochs, rather than just the order of batches. class determined.pytorch.samplers.ReproducibleShuffleSamplersampler: torch.utils.data.sampler.Samplerseed: int ReproducibleShuffleSampler will apply a deterministic shuffle based on a seed. Always shuffle before skipping and before repeating. Skip-before-shuffle would break the reproducibility of the shuffle, and repeat-before-shuffle would cause the shuffle to hang as it iterates through an infinite sampler. class determined.pytorch.samplers.SkipBatchSamplerbatch_sampler: torch.utils.data.sampler.BatchSamplerskip: int SkipBatchSampler skips some batches from an underlying BatchSampler, and yield the rest. Always skip before you repeat when you are continuing training, or you will apply the skip on every epoch. Because the SkipBatchSampler is only meant to be used on a training dataset (we never checkpoint during evaluation), and because the training dataset should always be repeated before applying the skip (so you only skip once rather than many times), the length reported is always the length of the underlying sampler, regardless of the size of the skip. class determined.pytorch.samplers.SkipSamplersampler: torch.utils.data.sampler.BatchSamplerskip: int SkipSampler skips some records from an underlying Sampler, and yields the rest. Always skip before you repeat when you are continuing training, or you will apply the skip on every epoch. When trying to achieve reproducibility after pausing and restarting, you should never prefer this SkipSampler over the SkipBatchSampler, unless you are sure that your dataset will always yield identically sized batches. This is due to how Determined counts batches trained but does not count records trained. Reproducibility when skipping records is only possible if the records to skip can be reliably calculated based on batch size and batches trained. Because the SkipSampler is only meant to be used on a training dataset (we never checkpoint during evaluation), and because the training dataset should always be repeated before applying the skip (so you only skip once rather than many times), the length reported is always the length of the underlying sampler, regardless of the size of the skip.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#det-pytorch-deepspeed-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#det-pytorch-deepspeed-api-reference",
    "content": "User Guide DeepSpeed API",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.DeepSpeedTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-deepspeedtrial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.DeepSpeedTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-deepspeedtrial",
    "content": "class determined.pytorch.deepspeed.DeepSpeedTrialcontext: determined.pytorch.deepspeed._deepspeed_context.DeepSpeedTrialContext DeepSpeed trials are created by subclassing this abstract class. We can do the following things in this trial class: Define the DeepSpeed model engine which includes the model, optimizer, and lr_scheduler. In the __init__() method, initialize models and, optionally, optimizers and LR schedulers and pass them to deepspeed.initialize to build the model engine. Then pass the created model engine to wrap_model_engine provided by DeepSpeedTrialContext. We support multiple DeepSpeed model engines if they only use data parallelism or if they use the same model parallel unit. Run forward and backward passes. In train_batch(), use the methods provided by the DeepSpeed model engine to perform the backward pass and optimizer step. These methods will differ depending on whether you are using pipeline parallelism or not. trial_controller_class alias of determined.pytorch.deepspeed._deepspeed_trial.DeepSpeedTrialController trial_context_class alias of determined.pytorch.deepspeed._deepspeed_context.DeepSpeedTrialContext abstract __init__context: determined.pytorch.deepspeed._deepspeed_context.DeepSpeedTrialContextNone Initializes a trial using the provided context. The general steps are: Initialize the model(s) and, optionally, the optimizer and lr_scheduler. The latter two can also be configured using the DeepSpeed config. Build the DeepSpeed model engine by calling deepspeed.initialize with the model (optionally optimizer and lr scheduler) and a DeepSpeed config. Wrap it with context.wrap_model_engine. If you want, use a custom model parallel unit by calling context.set_mpu. If you want, disable automatic gradient accumulation by calling context.disable_auto_grad_accumulation. If you want, use a custom data loader by calling context.disable_dataset_reproducibility_checks. Here is a code example. self.context = context self.args = AttrDict(self.context.get_hparams()) # Build deepspeed model engine. model = ... # build model model_engine, optimizer, lr_scheduler, _ = deepspeed.initialize( args=self.args, model=model, ) self.model_engine = self.context.wrap_model_engine(model_engine) abstract train_batchdataloader_iter: Optional[Iterator[Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]]]epoch_idx: intbatch_idx: intUnion[torch.Tensor, Dict[str, Any]] Train one full batch (i.e. train on train_batch_size samples, perhaps consisting of multiple micro-batches). If training without pipeline parallelism, users should implement this function by doing the following things: Get a batch from the dataloader_iter and pass it to the GPU. Compute the loss in the forward pass. Perform the backward pass. Perform an optimizer step. Return training metrics in a dictionary. Here is a code example. # Assume one model_engine wrapped in ``__init__``. batch = self.context.to_device(next(dataloader_iter)) loss = self.model_engine(batch) self.model_engine.backward(loss) self.model_engine.step() return {\"loss\": loss} If using gradient accumulation over multiple micro-batches, Determined will automatically call train_batch multiple times according to gradient_accumulation_steps in the DeepSpeed config. With pipeline parallelism there is no need to manually get a batch from the dataloader_iter and the forward, backward, optimizer steps are combined in the model engine\u2019s train_batch method. # Assume one model_engine wrapped in ``__init__``. loss = self.model_engine.train_batch(dataloader_iter) return {\"loss\": loss} Parameters dataloader_iter (Iterator[torch.utils.data.DataLoader], optional) \u2013 iterator over the train DataLoader. epoch_idx (integer) \u2013 index of the current epoch among all the batches processed per device (slot) since the start of training. batch_idx (integer) \u2013 index of the current batch among all the epochs processed per device (slot) since the start of training. Returns training metrics to return. Return type torch.Tensor or Dict[str, Any] abstract build_training_data_loaderOptional[determined.pytorch._data.DataLoader] Defines the data loader to use during training. Must return an instance of determined.pytorch.DataLoader unless context.disable_dataset_reproducibility_checks is called. If using data parallel training, the batch size should be per GPU batch size. If using gradient aggregation, the data loader should return batches with train_micro_batch_size_per_gpu samples each. abstract build_validation_data_loaderOptional[determined.pytorch._data.DataLoader] Defines the data loader to use during validation. Must return an instance of determined.pytorch.DataLoader unless context.disable_dataset_reproducibility_checks is called. If using data parallel training, the batch size should be per GPU batch size. If using gradient aggregation, the data loader should return batches with a desired micro batch size (most of the time this is the same as train_micro_batch_size_per_gpu). build_callbacksDict[str, determined.pytorch._callback.PyTorchCallback] Defines a dictionary of string names to callbacks to be used during training and/or validation. The string name will be used as the key to save and restore callback state for any callback that defines load_state_dict() and state_dict(). abstract evaluate_batchdataloader_iter: Optional[Iterator[Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]]]batch_idx: intDict[str, Any] Calculate validation metrics for a batch and return them as a dictionary mapping metric names to metric values. Per-batch validation metrics are averaged to produce a single set of validation metrics for the entire validation set by default. The metrics returned from this function must be JSON-serializable. DeepSpeedTrial supports more flexible metrics computation via our custom reducer API, see MetricReducer for more details. Parameters dataloader_iter (Iterator[torch.utils.data.DataLoader], optional) \u2013 iterator over the validation DataLoader. savecontext: determined.pytorch.deepspeed._deepspeed_context.DeepSpeedTrialContextpath: pathlib.PathNone Save is called on every GPU to make sure all checkpoint shards are saved. By default, we loop through the wrapped model engines and call DeepSpeed\u2019s save: for i, m in enumerate(context.models): m.save_checkpoint(path, tag=f\"model{i}\") This method can be overwritten for more custom save behavior. loadcontext: determined.pytorch.deepspeed._deepspeed_context.DeepSpeedTrialContextload_path: pathlib.PathNone By default, we loop through the wrapped model engines and call DeepSpeed\u2019s load. for i, m in enumerate(context.models): m.load_checkpoint(path, tag=f\"model{i}\") This method can be overwritten for more custom load behavior.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.DeepSpeedTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-deepspeedtrialcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.DeepSpeedTrialContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-deepspeedtrialcontext",
    "content": "class determined.pytorch.deepspeed.DeepSpeedTrialContext*args: Any**kwargs: Any Bases: determined._trial_context.TrialContext, determined.pytorch._reducer._PyTorchReducerContext Contains runtime information for any Determined workflow that uses the DeepSpeedTrial API. With this class, users can do the following things: Wrap DeepSpeed model engines that contain the model, optimizer, lr_scheduler, etc. This will make sure Determined can automatically provide gradient aggregation, checkpointing and fault tolerance. In contrast to determined.pytorch.PyTorchTrial, the user does not need to wrap optimizer and lr_scheduler as that should all be instead passed to the DeepSpeed initialize function (see https://www.deepspeed.ai/getting-started/#writing-deepspeed-models) when building the model engine. Overwrite a deepspeed config file or dictionary with values from Determined\u2019s experiment config to ensure consistency in batch size and support hyperparameter tuning. Set a custom model parallel configuration that should instantiate a determined.pytorch.deepspeed.ModelParallelUnit dataclass. We automatically set the mpu for data parallel and standard pipeline parallel training. This should only be needed if there is additional model parallelism outside DeepSpeed\u2019s supported methods. Disable data reproducibility checks to allow custom data loaders. Disable automatic gradient aggregation for non-pipeline-parallel training. current_train_batchint Current global batch index disable_auto_grad_accumulationNone Prevent the DeepSpeedTrialController from automatically calling train_batch multiple times to process enough micro batches to meet the per slot batch size. Thus, the user is responsible for manually training on enough micro batches in train_batch to meet the expected per slot batch size. disable_dataset_reproducibility_checksNone disable_dataset_reproducibility_checks() allows you to return an arbitrary DataLoader from build_training_data_loader() or build_validation_data_loader(). Normally you would be required to return a det.pytorch.DataLoader instead, which would guarantee that an appropriate Sampler is used that ensures: When shuffle=True, the shuffle is reproducible. The dataset will start at the right location, even after pausing/continuing. Proper sharding is used during distributed training. However, there can be cases where either reproducibility of the dataset is not needed or where the nature of the dataset can cause the det.pytorch.DataLoader to be unsuitable. In those cases, you can call disable_dataset_reproducibility_checks() and you will be free to return any torch.utils.data.DataLoader you like. Dataset reproducibility will still be possible, but it will be your responsibility. The Sampler classes in determined.pytorch.samplers can help in this regard. classmethod from_configconfig: Dict[str, Any]determined._trial_context.TrialContext Create a context object suitable for debugging outside of Determined. An example for a subclass of PyTorchTrial: config = { ... } context = det.pytorch.PyTorchTrialContext.from_config(config) my_trial = MyPyTorchTrial(context) train_ds = my_trial.build_training_data_loader() for epoch_idx in range(3): for batch_idx, batch in enumerate(train_ds): metrics = my_trial.train_batch(batch, epoch_idx, batch_idx) ... An example for a subclass of TFKerasTrial: config = { ... } context = det.keras.TFKerasTrialContext.from_config(config) my_trial = tf_keras_one_var_model.OneVarTrial(context) model = my_trial.build_model() model.fit(my_trial.build_training_data_loader()) eval_metrics = model.evaluate(my_trial.build_validation_data_loader()) Parameters config \u2013 An experiment config file, in dictionary form. get_data_configDict[str, Any] Return the data configuration. get_enable_tensorboard_loggingbool Return whether automatic tensorboard logging is enabled get_experiment_configDict[str, Any] Return the experiment configuration. get_experiment_idint Return the experiment ID of the current trial. get_hparamname: strAny Return the current value of the hyperparameter with the given name. get_hparamsDict[str, Any] Return a dictionary of hyperparameter names to values. get_stop_requestedbool Return whether a trial stoppage has been requested. get_tensorboard_pathpathlib.Path Get the path where files for consumption by TensorBoard should be written get_tensorboard_writerAny This function returns an instance of torch.utils.tensorboard.SummaryWriter Trials users who wish to log to TensorBoard can use this writer object. We provide and manage a writer in order to save and upload TensorBoard files automatically on behalf of the user. Usage example: class MyModel(PyTorchTrial): def __init__(self, context): ... self.writer = context.get_tensorboard_writer() def train_batch(self, batch, epoch_idx, batch_idx): self.writer.add_scalar('my_metric', np.random.random(), batch_idx) self.writer.add_image('my_image', torch.ones((3,32,32)), batch_idx) get_trial_idint Return the trial ID of the current trial. is_epoch_endbool Returns true if the current batch is the last batch of the epoch. Not accurate for variable size epochs. is_epoch_startbool Returns true if the current batch is the first batch of the epoch. Not accurate for variable size epochs. set_enable_tensorboard_loggingenable_tensorboard_logging: boolNone Set a flag to indicate whether automatic upload to tensorboard is enabled. set_mpumpu: determined.pytorch.deepspeed._mpu.ModelParallelUnitNone Use a custom model parallel configuration. The argument mpu should implement a determined.pytorch.deepspeed.ModelParallelUnit dataclass to provide information on data parallel topology and whether a rank should compute metrics/build data loaders. This should only be needed if training with custom model parallelism. In the case of multiple model parallel engines, we assume that the MPU and data loaders correspond to the first wrapped model engine. set_stop_requestedstop_requested: boolNone Set a flag to request a trial stoppage. When this flag is set to True, we finish the step, checkpoint, then exit. to_devicedata: Union[Dict[str, Union[numpy.ndarray, torch.Tensor]], Sequence[Union[numpy.ndarray, torch.Tensor]], numpy.ndarray, torch.Tensor]Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor] Map data to the device allocated by the Determined cluster. Since we pass an iterable over the data loader to train_batch and evaluate_batch for DeepSpeedTrial, the user is responsible for moving data to GPU if needed. This is basically a helper function to make that easier. wrap_model_enginemodel: deepspeed.DeepSpeedEnginedeepspeed.DeepSpeedEngine Register a DeepSpeed model engine. In the background, we track the model engine for checkpointing, set batch size information, using the first wrapped model engine, and perform checks to properly handle pipeline parallelism if the model engine is a PipelineEngine. wrap_reducerreducer: Union[Callable, determined.pytorch._reducer.MetricReducer]name: Optional[str] = Nonefor_training: bool = Truefor_validation: bool = Truedetermined.pytorch._reducer.MetricReducer Register a custom reducer that will calculate a metric properly, even with distributed training. During distributed training and evaluation, many types of metrics must be calculated globally, rather than calculating the metric on each shard of the dataset and averaged or summed. For example, an accurate ROC AUC for dataset cannot be derived from the individual ROC AUC metrics calculated on by each worker. Determined solves this problem by offering fully customizable metric reducers which are distributed-aware. These are registered by calling context.wrap_reducer() and are updated by the user during train_batch() or evaluate_batch(). Parameters reducer (Union[Callable, pytorch.MetricReducer]) \u2013 Either a reducer function or a pytorch.MetricReducer. See below for more details. name \u2013 (Optional[str] = None): Either a string name to associate with the metric returned by the reducer, or None to indicate the metric will return a dict mapping string names to metric values. This allows for a single reducer to return many metrics, such as for a per-class mean IOU calculation. Note that if name is a string, the returned metric must NOT be a dict-type metric. for_training \u2013 (bool = True): Indicate that the reducer should be used for training workloads. for_validation \u2013 (bool = True): Indicate that the reducer should be used for validation workloads. Return Value: pytorch.MetricReducer: If reducer was a function, the returned MetricReducer will have a single user-facing method like def update(value: Any) -> None that you should call during train_batch or evaluate_batch. Otherwise, the return value will just be the reducer that was passed in. Reducer functions: the simple API If the reducer parameter is a function, it must have the following properties: It accepts a single parameter, which will be a flat list of all inputs the users pass when they call .update() on the object returned by wrap_reducer(). See the code example below for more details. It returns either a single (non-dict) metric or a dictionary mapping names to metrics, as described above. The primary motivation for passing a function as the reducer is simplicity. Metrics from all batches will be buffered in memory and passed over the network before they are reduced all at once. This introduces some overhead, but it is likely unnoticeable for scalar metrics or on validation datasets of small or medium size. This single function strategy can be useful for quick prototyping or for calculating metrics that are difficult or impossible to calculate incrementally. For example, ROC AUC could be properly calculated by passing a small wrapper function calling sklearn.metrics.roc_auc_score: # Custom reducer function. def roc_auc_reducer(values): # values will be a flat list of all inputs to # .update(), which in this code example are # tuples of (y_true, y_score). We reshape # that list into two separate lists: y_trues, y_scores = zip(*values) # Then we return a metric value: return sklearn.metrics.roc_auc_score( np.array(y_trues), np.array(y_scores) ) class MyPyTorchTrial(PyTorchTrial): def __init__(self, context): self.roc_auc = context.wrap_reducer( roc_auc_reducer, name=\"roc_auc\" ) ... def evaluate_batch(self, batch): ... # Function-based reducers are updated with .update(). # The roc_auc_reducer function will get a list of all # inputs that we pass in here: self.roc_auc.update((y_true, y_score)) # The \"roc_auc\" metric will be included in the final # metrics after the workload has completed; no need # to return it here. If that is your only metric, # just return an empty dict. return {} MetricReducer objects: the advanced API The primary motivation for passing a det.pytorch.MetricReducer as the reducer is performance. det.pytorch.MetricReducer allows the user more control in how values are stored and exposes a per_slot_reduce() call which lets users minimize the cost of the network communication before the final cross_slot_reduce(). An additional reason for using the det.pytorch.MetricReducer is for flexibility of the update mechanism, which is completely user-defined when subclassing MetricReducer. For the full details and a code example, see: MetricReducer.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.overwrite_deepspeed_config",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-overwrite-deepspeed-config",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.overwrite_deepspeed_config",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-overwrite-deepspeed-config",
    "content": "determined.pytorch.deepspeed.overwrite_deepspeed_configbase_ds_config: Union[str, Dict]source_ds_dict: Dict[str, Any]Dict[str, Any] Overwrite a base_ds_config with values from a source_ds_dict. You can use source_ds_dict to overwrite leaf nodes of the base_ds_config. More precisely, we will iterate depth first into source_ds_dict and if a node corresponds to a leaf node of base_ds_config, we copy the node value over to base_ds_config. Parameters base_ds_config (str or Dict) \u2013 either a path to a DeepSpeed config file or a dictionary. source_ds_dict (Dict) \u2013 dictionary with fields that we want to copy to base_ds_config Returns The resulting dictionary when base_ds_config is overwritten with source_ds_dict.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.ModelParallelUnit",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-modelparallelunit",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "det.pytorch.deepspeed API Reference",
      "lvl1": "det.pytorch.deepspeed API Reference",
      "lvl2": "determined.pytorch.deepspeed.ModelParallelUnit",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/training/api-deepspeed-reference.html#determined-pytorch-deepspeed-modelparallelunit",
    "content": "class determined.pytorch.deepspeed.ModelParallelUnitdata_parallel_rank: intdata_parallel_world_size: intshould_report_metrics: boolshould_build_data_loader: bool This class contains the functions we expect in order to accurately carry out parallel training. For custom model parallel training, you need to subclass and override the functions before passing it to the DeepSpeedTrialContext by calling context.wrap_mpu(mpu). The following classes and methods overlap with PyTorchTrial (click to go to respective documentation): determined.pytorch.DataLoader determined.pytorch.samplers determined.pytorch.MetricReducer determined.pytorch.PyTorchCallback",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#pytorch-experimental-torch-batch-process-api-reference",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#pytorch-experimental-torch-batch-process-api-reference",
    "content": "User Guide Torch Batch Processing API This is an experimental API and may change at any time. The main arguments to torch_batch_process are batch_processor_cls, a subclass of TorchBatchProcessor and dataset. torch_batch_process( batch_processor_cls=MyProcessor dataset=dataset )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.torch_batch_process",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torch-batch-process",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.torch_batch_process",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torch-batch-process",
    "content": "determined.pytorch.experimental.torch_batch_processbatch_processor_cls: Type[determined.pytorch.experimental._torch_batch_process.TorchBatchProcessor]dataset: torch.utils.data.dataset.Datasetbatch_size: Optional[int] = Nonemax_batches: Optional[int] = Nonecheckpoint_interval: int = 5dataloader_kwargs: Optional[Dict[str, Any]] = Nonedistributed_context: Optional[determined.core._distributed.DistributedContext] = NoneNone `torch_batch_process` shard and iterate through the provided dataset and process the dataset with user-defined logic in `batch_processor_cls`. Parameters batch_processor_cls \u2013 A user-defined class extending `TorchBatchProcessor` dataset \u2013 A torch dataset class implementing __len__() and __getitem__() batch_size \u2013 The number of items to in each batch max_batches \u2013 The maximum number of batches to iterate over per worker checkpoint_interval \u2013 Interval to checkpoint progress (i.e. record number of batches processed) dataloader_kwargs \u2013 Kwargs to pass to PyTorch dataloader distributed_context \u2013 Distributed context to initialize core context",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.TorchBatchProcessorContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torchbatchprocessorcontext",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.TorchBatchProcessorContext",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torchbatchprocessorcontext",
    "content": "class determined.pytorch.experimental.TorchBatchProcessorContextcore_context: determined.core._context.Contextstorage_path: str to_devicedata: Union[Dict[str, Union[numpy.ndarray, torch.Tensor]], Sequence[Union[numpy.ndarray, torch.Tensor]], numpy.ndarray, torch.Tensor]warned_types: Optional[Set[Type]] = NoneUnion[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor] Accept np.ndarray, torch.Tensor, list, or dictionary. Recursively convert any ndarrays to tensors and call .to() on any tensors or data types that have custom serialization logic defined via a callable to() attribute. If the data cannot be moved to device, log a warning (only once per type) and return the original data. get_tensorboard_pathpathlib.Path Tensorboard files should be written to the path returned to be shown properly in the UI. For example, the path should be passed to PyTorch profiler as shown below: torch.profiler.profile( activities=..., schedule=..., on_trace_ready=torch.profiler.tensorboard_trace_handler(<tensorboard_path>), ) prepare_model_for_inferencemodel: torch.nn.modules.module.Moduletorch.nn.modules.module.Module Set model to eval mode and send model to device :param model: a nn.Module upload_pathAbstractContextManager[pathlib.Path] Returns a context that uploads files to default storage path on exit. report_metricsgroup: strsteps_completed: intmetrics: Dict[str, Any]None Report metrics data to the master. Parameters group (string) \u2013 metrics group name. Can be used to partition metrics into different logical groups or time series. \u201ctraining\u201d and \u201cvalidation\u201d group names map to built-in training and validation time series. Note: Group cannot contain . character. steps_completed (int) \u2013 global step number, e.g. the number of batches processed. metrics (Dict[str, Any]) \u2013 metrics data dictionary. Must be JSON-serializable. When reporting metrics with the same group and steps_completed values, the dictionary keys must not overlap. report_task_using_model_versionmodel_version: model.ModelVersionNone Associate model_version with the current task. This links together the metrics reporting so that any metrics which are reported to the current task will be visible when querying for metrics associated with this model version Parameters model_Version (model.ModelVersion) \u2013 The model version to associate with this task report_task_using_checkpointcheckpoint: checkpoint.CheckpointNone Associate checkpoint with the current task. This links together the metrics reporting so that any metrics which are reported to the current task will be visible when querying for metrics associated with this checkpoint Parameters checkpoint (checkpoint.Checkpoint) \u2013 The checkpoint to associate with this task get_distributed_rankint The rank of this current process in a trial get_distributed_sizeint The number of slots this trial is running on",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.TorchBatchProcessor",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torchbatchprocessor",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "pytorch.experimental.torch_batch_process API Reference",
      "lvl1": "pytorch.experimental.torch_batch_process API Reference",
      "lvl2": "determined.pytorch.TorchBatchProcessor",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "reference/batch-processing/api-torch-batch-process-reference.html#determined-pytorch-torchbatchprocessor",
    "content": "class determined.pytorch.experimental.TorchBatchProcessorcontext: determined.pytorch.experimental._torch_batch_process.TorchBatchProcessorContext abstract process_batchbatch: Anybatch_idx: intNone This function will be called with every batch of data in the dataset Parameters batch \u2013 a batch of data of the dataset passed into torch_batch_process batch_idx \u2013 index of the batch. Note that index is per worker. For example, if there are 8 batches of data to process and 4 workers, each worker would get two batches of data (batch_idx = 0 and batch_idx = 1) on_checkpoint_startNone This function will be called right before each checkpoint on_finishNone This function will be called right before exiting after completing iteration over dataset",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tools",
      "lvl1": "Tools",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/index.html#tools",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tools",
      "lvl1": "Tools",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/index.html#tools",
    "content": "<div class=\"landing\"> <div class=\"tiles-flex\"> <div class=\"tile-container\"> <a class=\"tile\" href=\"cli-ug.html\"> <h2 class=\"tile-title\">CLI User Guide</h2> <p class=\"tile-description\">Instructions for installing and using the Determined CLI.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"commands-and-shells.html\"> <h2 class=\"tile-title\">Commands and Shells</h2> <p class=\"tile-description\">How to use a Determined cluster to run free-form programs.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"webui-if.html\"> <h2 class=\"tile-title\">WebUI</h2> <p class=\"tile-description\">Using the web interface to create and monitor experiments.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"notebooks.html\"> <h2 class=\"tile-title\">Jupyter Notebooks</h2> <p class=\"tile-description\">Launching and managing Jupyter Notebooks.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"tensorboard.html\"> <h2 class=\"tile-title\">Using TensorBoard</h2> <p class=\"tile-description\">Using TensorBoard to examine individual or compare multiple experiments.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"proxy-ports.html\"> <h2 class=\"tile-title\">Exposing Custom Ports</h2> <p class=\"tile-description\">How to expose a custom network port in a task container.</p> </a> </div> </div> </div>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#commands-and-shells",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#commands-and-shells",
    "content": "Determined commands and shells provide support for running code on a Determined cluster without writing a model. This page describes how to manage GPU-powered batch commands and interactive shells. Commands and shells are started through the Determined command-line interface (CLI). To learn more, including installation instructions, visit the Determined CLI user guide or Determined CLI Reference. Commands execute a user-specified program on the cluster. Commands are useful for running existing code in batch mode. Shells start SSH servers that let you use cluster resources interactively. Shells provide access to the cluster in the form of interactive SSH sessions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": "Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#commands",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": "Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#commands",
    "content": "Determined commands are manipulated with CLI commands starting with det command, abbreviated as det cmd. The main subcommand is det cmd run, which runs a command in the cluster and streams its output. For example, the following CLI command uses nvidia-smi to display information about the GPUs available to tasks in the container: det cmd run nvidia-smi You can also run more complex commands including shell constructs provided they are quoted to prevent interpretation by the local shell: det cmd run 'for x in a b c; do echo $x; done' det cmd run streams output from the command until it finishes, but the command continues executing and occupying cluster resources even if the CLI is interrupted or killed, such as due to entering Ctrl-C. To stop the command or view additional output, you need the command UUID, which you can get from the output of the original det cmd run or det cmd list. After you have the UUID, run det cmd logs <UUID> to view a snapshot of logs. det cmd logs -f <UUID> to view the current logs and continue streaming future output. det cmd kill <UUID> to stop the command. <br />",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": "Shells",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#shells",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Commands and Shells",
      "lvl1": "Commands and Shells",
      "lvl2": "Shells",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/commands-and-shells.html#shells",
    "content": "Shell-related CLI commands start with det shell. To start a persistent SSH server container in the Determined cluster and connect an interactive session to it, use det shell start: det shell start After starting a server with det shell start, you can make another independent connection to the same server by running det shell open <UUID>. You can get the UUID from the output of the original det shell start or det shell list command: $ det shell list Id | Owner | Description | State | Exit Status --------------------------------------+------------+------------------------------+---------+--------------- d75c3908-fb11-4fa5-852c-4c32ed30703b | determined | Shell (annually-alert-crane) | RUNNING | N/A $ det shell open d75c3908-fb11-4fa5-852c-4c32ed30703b Optionally, you can provide extra options to pass to the SSH client when using det shell start or det shell open by including them after --. For example, this command starts a new shell and forwards a port from the local machine to the container: det shell start -- -L8080:localhost:8080 To stop the SSH server container and free cluster resources, run det shell kill <UUID>.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#jupyter-notebooks",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#jupyter-notebooks",
    "content": "You can use Jupyter Notebooks to conveniently develop and debug machine learning models, visualize the behavior of trained models, and manage the training lifecycle of a model manually. Determined makes launching and managing notebooks easy. Determined Notebooks provide the following benefits: Jupyter Notebooks run in containerized environments on the cluster. This makes it easy to manage dependencies using images and virtual environments. The HTTP requests are passed through the master proxy from and to the container. Jupyter Notebooks can be automatically terminated if they are idle for a configurable duration to release resources. A notebook instance is considered to be idle if it is not receiving any HTTP traffic and it is not otherwise active (as defined by the notebook_idle_type option in the task configuration). To enable this behavior by default, set notebook_timeout option in your master config. To enable it for a particular notebook, set idle_timeout option in the notebook config. After a Notebook is terminated, it is not possible to restore the files that are not stored in the persistent directories. It is important to configure the cluster to mount persistent directories into the container and save files in the persistent directories in the container. See Save and Restore Notebook State for more information. If you open a Notebook tab in JupyterLab, a kernel is automatically opened. This kernel will not be shut down automatically, so you\u2019ll need to manually terminate it. There are two ways to access notebooks in Determined: the CLI and the WebUI. To install the CLI, see Installation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Command Line",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#command-line",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Command Line",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#command-line",
    "content": "The following command will automatically start a notebook with a single GPU and open it in your browser. $ det notebook start Scheduling notebook unique-oyster (id: 5b2a9ea4-a6bb-4d2b-b42b-25e4064a3220)... [DOCKER BUILD \ud83d\udd28] Step 1/11 : FROM nvidia/cuda:9.0-cudnn7-runtime-ubuntu16.04 [DOCKER BUILD \ud83d\udd28] [DOCKER BUILD \ud83d\udd28] ---> 9918ba890dca [DOCKER BUILD \ud83d\udd28] Step 2/11 : RUN rm /etc/apt/sources.list.d/* ... [DOCKER BUILD \ud83d\udd28] Successfully tagged nvidia/cuda:9.0-cudnn7-runtime-ubuntu16.04-73bf63cc864088137a477ce62f39ffe8 [Determined] 2019-04-04T17:53:22.076591700Z [I 17:53:22.075 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret [Determined] 2019-04-04T17:53:23.067911400Z [W 17:53:23.067 NotebookApp] All authentication is disabled. Anyone who can connect to this server will be able to run code. [Determined] 2019-04-04T17:53:23.073644300Z [I 17:53:23.073 NotebookApp] Serving notebooks from local directory: / disconnecting websocket Jupyter Notebook is running at: http://localhost:8080/proxy/5b2a9ea4-a6bb-4d2b-b42b-25e4064a3220-notebook-0/lab/tree/Notebook.ipynb?reset After the notebook has been scheduled onto the cluster, the Determined CLI will open a web browser window pointed to that notebook\u2019s URL. Back in the terminal, you can use the det notebook list command to see that this notebook is one of those currently RUNNING on the Determined cluster: $ det notebook list Id | Entry Point | Registered Time | State --------------------------------------+--------------------------------------------------------+------------------------------+--------- 0f519413-2411-4b3c-adbc-9b1b60c96156 | ['jupyter', 'notebook', '--config', '/etc/jupyter.py'] | 2019-04-04T17:52:48.1961129Z | RUNNING 5b2a9ea4-a6bb-4d2b-b42b-25e4064a3220 | ['jupyter', 'notebook', '--config', '/etc/jupyter.py'] | 2019-04-04T17:53:20.387903Z | RUNNING 66da599e-62d2-4c2d-91c4-01a04045e4ab | ['jupyter', 'notebook', '--config', '/etc/jupyter.py'] | 2019-04-04T17:52:58.4573214Z | RUNNING The --context option adds a folder or file to the notebook environment, allowing its contents to be accessed from within the notebook. det notebook start --context folder/file The --config-file option can be used to create a notebook with an environment specified by a configuration file. det notebook start --config-file config.yaml For more information on how to write the notebook configuration file, see Notebook Configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Useful CLI Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#useful-cli-commands",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Useful CLI Commands",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#useful-cli-commands",
    "content": "A full list of notebook-related commands can be found by running: det notebook --help To view all running notebooks: det notebook list To kill a notebook, you need its ID, which can be found using the list command. det notebook kill <id>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "WebUI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#webui",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "WebUI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#webui",
    "content": "You can also start a Notebook from the WebUI. To do this, go to the Tasks pane and then select Launch JupyterLab. Depending on your particular setup, you can select the appropriate resource pool when creating a new notebook. The WebUI displays a list of tasks running on the cluster including running notebooks. You can reopen, kill, or view logs for each notebook. You can customize the keyboard shortcut you use to launch a JupyterLab Notebook. To do this, visit the Shorcuts settings by selecting your profile name in the upper left corner and choosing Settings.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Notebook Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#notebook-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Notebook Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#notebook-configuration",
    "content": "Notebooks can be passed a notebook configuration option to control the notebook environment. For example, to launch a notebook that uses two GPUs: $ det notebook start --config resources.slots=2 Alternatively, a YAML file can also be used to configure the notebook, using the --config-file option: $ cat > config.yaml <<EOL description: test-notebook resources: slots: 2 bind_mounts: - host_path: /data/notebook_scratch container_path: /scratch idle_timeout: 30m EOL $ det notebook start --config-file config.yaml See Job Configuration Reference for details on the supported configuration options. Finally, to configure notebooks to run a predefined set of commands at startup, you can include a startup hook in a directory specified with the --context option: $ mkdir my_context_dir $ echo \"pip3 install pandas\" > my_context_dir/startup-hook.sh $ det notebook start --context my_context_dir Example: CPU-Only Notebooks By default, each notebook is assigned a single GPU. This is appropriate for some uses of notebooks (e.g., training a deep learning model) but unnecessary for other tasks (e.g., analyzing the training metrics of a previously trained model). To launch a notebook that does not use any GPUs, set resources.slots to 0: $ det notebook start --config resources.slots=0",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Save and Restore Notebook State",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#save-and-restore-notebook-state",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Save and Restore Notebook State",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#save-and-restore-notebook-state",
    "content": "It is only possible to save and restore notebook state on Determined clusters that are configured with a shared filesystem available to all agents. To ensure that your work is saved even if your notebook gets terminated, it is recommended to launch all notebooks with a shared filesystem directory bind-mounted into the notebook container and work on files inside of the bind mounted directory. For example, a user jimmy with a shared filesystem home directory at /shared/home/jimmy could use the following configuration to launch a notebook: $ cat > config.yaml << EOL bind_mounts: - host_path: /shared/home/jimmy container_path: /shared/home/jimmy EOL $ det notebook start --config-file config.yaml By default, launching a cluster by det deploy gcp up, det deploy aws --deployment-type efs, or det deploy aws --deployment-type fsx creates a Network file system that is shared by all the agents and is automatically mounted into Notebook containers at /run/determined/workdir/shared_fs/. To launch a notebook with det deploy local cluster-up, a user can add the --auto-work-dir flag, which mounts the user\u2019s home directory into the task containers by default: $ det deploy local cluster-up --auto-work-dir=\"/shared/home/jimmy\" $ det notebook start Working on a notebook file within the shared bind mounted directory will ensure that your code and Jupyter checkpoints are saved on the shared filesystem rather than an ephemeral container filesystem. If your notebook gets terminated, launching another notebook and loading the previous notebook file will effectively restore the session of your previous notebook. To restore the full notebook state (in addition to code), you can use Jupyter\u2019s File > Revert to Checkpoint functionality. By default, JupyterLab will take a checkpoint every 120 seconds in an .ipynb_checkpoints folder in the same directory as the notebook file. To modify this setting, click on Settings > Advanced Settings Editor and change the value of \"autosaveInternal\" under Document Manager.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Use the Determined CLI in Notebooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#use-the-determined-cli-in-notebooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Jupyter Notebooks",
      "lvl1": "Jupyter Notebooks",
      "lvl2": "Use the Determined CLI in Notebooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/notebooks.html#use-the-determined-cli-in-notebooks",
    "content": "The Determined CLI is installed into notebook containers by default. This allows you to interact with Determined from inside a notebook\u2014e.g., launch new deep learning workloads or examine the metrics from an active or historical Determined experiment. For example, to list Determined experiments from inside a notebook, run the notebook command !det experiment list.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#web-interface-webui",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#web-interface-webui",
    "content": "You can use the WebUI to create and monitor experiment progress, organize your experiments into projects and workspaces, start a Jupyter Notebook, and more.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#getting-started",
    "content": "To access the WebUI, go to the default URL http://master-addr:8080 in your web browser, where master-addr is the hostname or IP address of the master. If Transport Layer Security (TLS) is enabled, use port 8443 instead. If you have not yet established a valid Determined session, the WebUI will automatically redirect you to the sign-in page. Once you sign in, you will be redirected to the initial URL you entered. To end the Determined session and sign out of the WebUI, select your profile name in the upper left corner and choose Sign Out.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Creating an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#creating-an-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Creating an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#creating-an-experiment",
    "content": "If you have an existing experiment or trial, you can use the WebUI to create an experiment. You\u2019ll need to use the CLI to create a new experiment. To learn how to create a new experiment, visit Submit Experiment.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Organizing Your Experiments into Projects and Workspaces",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#organizing-your-experiments-into-projects-and-workspaces",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Organizing Your Experiments into Projects and Workspaces",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#organizing-your-experiments-into-projects-and-workspaces",
    "content": "The WebUI lets you organize your experiments into projects and workspaces. To learn more about Projects and Workspaces, visit Workspaces and Projects.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Configuring the Behavior of an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#configuring-the-behavior-of-an-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Configuring the Behavior of an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#configuring-the-behavior-of-an-experiment",
    "content": "Many experiment configuration settings can be performed via the WebUI. To learn more about configuring an experiment via a YAML file, visit Experiment Configuration Reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Evaluating the Performance of a Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#evaluating-the-performance-of-a-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Evaluating the Performance of a Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#evaluating-the-performance-of-a-model",
    "content": "You can access training and validation performance information via the WebUI. To see model evaluation in action, follow the steps described in the PyTorch MNIST Tutorial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Adding Models to the Model Registry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#adding-models-to-the-model-registry",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Adding Models to the Model Registry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#adding-models-to-the-model-registry",
    "content": "You can use the WebUI to create and edit models and add models to the model registry. You can also use the WebUI to edit model metadata. To find out more, visit Organize Models in the Model Registry.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Viewing Historical Cluster Usage Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#viewing-historical-cluster-usage-data",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Viewing Historical Cluster Usage Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#viewing-historical-cluster-usage-data",
    "content": "You can use the WebUI to view Historical Cluster Usage Data.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Managing User Accounts and Groups",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#managing-user-accounts-and-groups",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Managing User Accounts and Groups",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#managing-user-accounts-and-groups",
    "content": "The admin user manages user authentication including creating and managing users. To learn more, visit User Accounts. With the Determined Enterprise Edition, you can also create and manage user groups. To learn more, visit RBAC.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Managing User Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#managing-user-settings",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Managing User Settings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#managing-user-settings",
    "content": "User settings allow you to manage profile settings, preferences, and shortcuts. You can also toggle experimental features on or off and access advanced features. To view user settings: Select your profile name in the upper left corner and choose Settings. To change user settings: Select the edit icon. Make changes to the setting. Confirm the changes by selecting the checkmark. To revert to default settings: Navigate to the Advanced section of the user settings. Select I know what I\u2019m doing. Select Reset to Default. Confirm you want to reset all user settings to their default values.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Selecting a Table Density (Row Height)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#selecting-a-table-density-row-height",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Selecting a Table Density (Row Height)",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#selecting-a-table-density-row-height",
    "content": "In the Preferences section of your user settings, you can set the table density so that the rows are shorter or taller.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Toggling Experimental (Pre-Release) Features On or Off",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#toggling-experimental-pre-release-features-on-or-off",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Toggling Experimental (Pre-Release) Features On or Off",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#toggling-experimental-pre-release-features-on-or-off",
    "content": "In the Experimental section of your user settings, you can turn experimental features on or off. However, if you don\u2019t know what the feature is referring to or the possible impact, you likely should not turn it on. Experimental features are pre-release features. They can be changed or removed at any time.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Configuring Telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#configuring-telemetry",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Configuring Telemetry",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#configuring-telemetry",
    "content": "To find what kind of anonymous information the WebUI collects, visit Common Configuration Options.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Viewing and Managing the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#viewing-and-managing-the-job-queue",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Viewing and Managing the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#viewing-and-managing-the-job-queue",
    "content": "To find out how to view and modify the Job Queue in the WebUI, start with View the Job Queue.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Starting a Jupyter Notebook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#starting-a-jupyter-notebook",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Starting a Jupyter Notebook",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#starting-a-jupyter-notebook",
    "content": "You can start Jupyter Notebooks from the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Launching TensorBoard",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#launching-tensorboard",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Web Interface (WebUI)",
      "lvl1": "Web Interface (WebUI)",
      "lvl2": "Launching TensorBoard",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/webui-if.html#launching-tensorboard",
    "content": "You can launch TensorBoard from the WebUI. To learn how, visit Using TensorBoard.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#using-tensorboard",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#using-tensorboard",
    "content": "TensorBoard is a popular tool for visualizing and inspecting deep learning models. In Determined, you can use TensorBoard to examine individual experiments or compare multiple experiments.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#getting-started",
    "content": "Launch TensorBoard instances via the WebUI or the Determined CLI. Before launching TensorBoard instances from the CLI, install the CLI on your development machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Experiments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#analyzing-experiments",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Experiments",
      "lvl3": "Single Experiment Analysis",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#single-experiment-analysis",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Experiments",
      "lvl3": "Single Experiment Analysis",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#single-experiment-analysis",
    "content": "To analyze a single Determined experiment using TensorBoard, use det tensorboard start <experiment-id>: $ det tensorboard start 7 Scheduling TensorBoard (rarely-cute-man) (id: aab49ba5-3357-4145-861c-7e6ff2d702c5)... TensorBoard (rarely-cute-man) was assigned to an agent... Scheduling tensorboard tensorboard (id: c68c9fc9-7eed-475b-a50f-fd78406d7c83)... TensorBoard is running at: http://localhost:8080/proxy/c68c9fc9-7eed-475b-a50f-fd78406d7c83/ disconnecting websocket The Determined master schedules a TensorBoard instance within the cluster. Once the TensorBoard instance is running, The Determined CLI opens the TensorBoard web interface in your local browser. To view information about scheduled and running TensorBoard instances, use: $ det tensorboard list Id | Owner | Description | State | Experiment Id | Trial Ids | Exit Status --------------------------------------+------------+-------------------------------------+------------+-----------------+-------------+-------------- aab49ba5-3357-4145-861c-7e6ff2d702c5 | determined | TensorBoard (rarely-cute-man) | RUNNING | 7 | N/A | N/A",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Experiments",
      "lvl3": "Multiple Experiment Analysis",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#multiple-experiment-analysis",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Experiments",
      "lvl3": "Multiple Experiment Analysis",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#multiple-experiment-analysis",
    "content": "To analyze multiple experiments, use det tensorboard start <experiment-id> <experiment-id> .... Metrics might not be immediately available in TensorBoard upon opening the browser window. It usually takes up to five minutes for TensorBoard to receive data and display visualizations.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Customizing TensorBoard Instances",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#customizing-tensorboard-instances",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Customizing TensorBoard Instances",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#customizing-tensorboard-instances",
    "content": "Determined allows you to initialize TensorBoard with a job configuration (YAML) file. This can be useful for running TensorBoard with a specific container image or for enabling access to additional data through a bind-mount. Example job configuration file: environment: image: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.8-gpu-0.20.1 bind_mounts: - host_path: /my/agent/path container_path: /my/container/path read_only: true tensorboard_args: ['--samples_per_plugin=images=100'] The tensorboard_args field allows you to provide optional TensorBoard arguments. In the example above, we set the maximum number of image to display to 100, overriding TensorBoard\u2019s default value. For detailed configuration settings, refer to the Job Configuration Reference. To launch TensorBoard with an experiment configuration file, use det tensorboard start <experiment-id> --config-file=my_config.yaml. To view the configuration of a running TensorBoard instance, use det tensorboard config <tensorboard_id>.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Specific Trials",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#analyzing-specific-trials",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Analyzing Specific Trials",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#analyzing-specific-trials",
    "content": "Determined also supports analyzing specific trials from one or more experiments. This can be useful for comparing a small number of trials from an experiment with many trials, or for comparing trials from different experiments. To analyze specific trials, use det tensorboard start --trial-ids <trial_id 1> <trial_id 2> ....",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Data in TensorBoard",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#data-in-tensorboard",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Data in TensorBoard",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#data-in-tensorboard",
    "content": "This section provides a brief overview of how Determined captures data from TensorFlow models. For a more in depth discussion on how TensorBoard visualizes data, consult the TensorBoard documentation. TensorBoard visualizes data captured during model training and validation, which is stored in tfevent files. These files are generated by writing TensorFlow summary operations to disk using a tf.summary.FileWriter. Each deep learning framework has support for writing and upload metrics as tfevent files. FileWriters are configured to write log files, called tfevent files, to a directory known as the logdir. TensorBoard monitors this directory for changes and updates accordingly. The logdir supported by Determined is /tmp/tensorboard. All tfevent files written to /tmp/tensorboard in a trial are uploaded to persistent storage when a trial is configured with Determined TensorBoard support.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Determined Batch Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#determined-batch-metrics",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Determined Batch Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#determined-batch-metrics",
    "content": "At the end of every training workload, batch metrics are collected and stored in the database, providing a granular view of model metrics over time. Batch metrics will appear in TensorBoard under the Determined group. The x-axis of each plot corresponds to the batch number. For example, a point at step 5 of the plot is the metric associated with the fifth batch seen.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#framework-specific-configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#framework-specific-configuration",
    "content": "To configure TensorBoard for a specific framework, follow the examples below:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": "TensorFlow Keras",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#tensorflow-keras",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": "TensorFlow Keras",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#tensorflow-keras",
    "content": "For models using TFKerasTrial, add a determined.keras.callabacks.TensorBoard callback to your trial class: from determined.keras import TFKerasTrial from determined.keras.callbacks import TensorBoard class MyModel(TFKerasTrial): ... def keras_callbacks(self): return [TensorBoard()]",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": "PyTorch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#pytorch",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Framework-Specific Configuration",
      "lvl3": "PyTorch",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#pytorch",
    "content": "See PyTorchTrialContext.get_tensorboard_writer() For a full-length example of using TensorBoard with PyTorch, check out the mnist-GAN model.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "TensorBoard Lifecycle Management",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#tensorboard-lifecycle-management",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "TensorBoard Lifecycle Management",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#tensorboard-lifecycle-management",
    "content": "Determined automatically terminates idle TensorBoard instances. A TensorBoard instance is considered idle if it does not receive HTTP traffic (a TensorBoard that is still being viewed by a web browser is not considered idle). TensorBoards are terminated after 5 minutes by default; however, you can change the timeout duration by editing tensorboard_timeout in the master config file. You can also terminate TensorBoard instances manually by using det tensorboard kill <tensorboard-id>: $ det tensorboard kill aab49ba5-3357-4145-861c-7e6ff2d702c5 To open a web browser window connected to a previously launched TensorBoard instance, use det tensorboard open. To view the logs of an existing TensorBoard instance, use det tensorboard logs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Implementation Details",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#implementation-details",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Implementation Details",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#implementation-details",
    "content": "Determined schedules TensorBoard instances in containers that run on agent machines. The Determined master will proxy HTTP requests to and from the TensorBoard container. TensorBoard instances are hosted on agent machines but they do not occupy GPUs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Logging Additional TensorBoard Events",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#logging-additional-tensorboard-events",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Using TensorBoard",
      "lvl1": "Using TensorBoard",
      "lvl2": "Logging Additional TensorBoard Events",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/tensorboard.html#logging-additional-tensorboard-events",
    "content": "Any additional TFEvent files that are written to the appropriate path during training are accessible to TensorBoard. The appropriate path varies by worker rank and can be obtained by one of the following functions: For CoreAPI users: get_tensorboard_path() For PyTorchTrial users: get_tensorboard_path() For DeepSpeedTrial users: get_tensorboard_path() For TFKerasTrial users: get_tensorboard_path() For more details and examples, refer to the TensorBoard How-To Guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#determined-cli",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#determined-cli",
    "content": "Reference Determined CLI Reference To use Determined, you\u2019ll need, at minimum, the Determined command-line interface (Determined CLI) and a Determined cluster. The Determined CLI includes the det command-line tools for interacting with a Determined cluster. This page contains instructions for using the CLI, including installion and upgrade. Although Determined supports password-based authentication, communication between the Determined CLI, Determined WebUI, and Determined master does not take place over an encrypted channel by default. All users should install the Determined CLI on their local development machine. You can also interact with Determined using the web interface (WebUI).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#installation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#installation",
    "content": "The CLI is distributed as a Python wheel package and requires Python >= 3.7. We recommend setting up a virtualenv and using the pip utility to install determined into the environment: pip install determined The command, pip install determined, installs the determined library which includes the Determined command-line interface (CLI). After installing the CLI, configure it to connect to the Determined master at the appropriate IP address. To do this, set the DET_MASTER environment variable: export DET_MASTER=<master IP> Place this into the appropriate configuration file for your login shell, such as .bashrc.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Environment Variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#environment-variables",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Environment Variables",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#environment-variables",
    "content": "DET_MASTER: The network address of the master of the Determined installation. The value can be overridden using the -m flag. DET_USER and DET_PASS: Specifies the current Determined user and password for use when non-interactive behaviour is required such as scripts. det user login is preferred for normal usage. Both DET_USER and DET_PASS must be set together to take effect. These variables can be overridden by using the -u flag.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Verifying Installation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#verifying-installation",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Verifying Installation",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#verifying-installation",
    "content": "To verify that the Determined CLI has been installed correctly, use the following command: det --version This command displays the installed version of the Determined CLI. If the installation was successful, you should see the version number in the output.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Uninstalling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#uninstalling",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Uninstalling",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#uninstalling",
    "content": "If you need to uninstall the Determined CLI, use the following command: pip uninstall determined This command uninstalls the determined library, including the Determined CLI, from your system.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Upgrading",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#upgrading",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Installation",
      "lvl3": "Upgrading",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#upgrading",
    "content": "To upgrade the Determined CLI to the latest version, use the following command: pip install --upgrade determined This command upgrades determined (along with the Determined CLI) to the latest available version.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Getting Help",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#getting-help",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Getting Help",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#getting-help",
    "content": "Using the -h or --help argument on objects or actions prints a help message and exits the CLI. For example, to print usage for the deploy command, run the following: det deploy -h Similarly, you can get help for a subcommand. For example, to get help for deploy aws: det deploy aws -h",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#getting-started",
    "content": "After installing the Determined CLI, you can start using it to interact with your Determined cluster. The CLI is invoked with the det command. CLI subcommands usually follow a <noun> <verb> form, similar to the paradigm of ip. Certain abbreviations are supported, and a missing verb is the same as list, when possible. The following examples show different ways to achieve the same outcome using the full <noun> <verb> form, then with an abbreviation, and finally with an implicit list: # List all experiments. $ det experiment list $ det e list $ det e # List all agents. $ det agent list $ det a list $ det a # List all slots. $ det slot list $ det slot $ det s",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Usage Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#usage-examples",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Determined CLI",
      "lvl1": "Determined CLI",
      "lvl2": "Usage Examples",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/cli-ug.html#usage-examples",
    "content": "Task Example Command Options List all experiments. Display a list of all experiments in the cluster. det experiment list List all experiments for a specific network address. Display a list of all experiments in the cluster at network address 1.2.3.4. det -m 1.2.3.4 e View a snapshot of logs. Display the most recent logs for a specific command. det command logs <command_id> -f, \u2013tail View logs for a trial. Show the logs for trial 289 and continue streaming logs in real-time. det t logs -f 289 -f Add a label. Add the label foobar to experiment 17. det e label add 17 foobar Create an experiment. Create an experiment in a paused state with the configuration file const.yaml and the code contained in the current directory. The paused experiment is not scheduled on the cluster until activated. det e create -f --paused const.yaml . Describe an experiment. Display information about experiment 493, including full metrics, in CSV format. det e describe 493 --metrics --csv Set max slots. Ensure that experiment 85 does not use more than 4 slots in the cluster. det e set max-slots 85 4 Display details about the CLI and master. Show detailed information about the CLI and master. This command does not take both an object and an action. det version Stop (kill) a command. Terminate a running command. det command kill <command_id> Set a password for the admin user. Set the password for the admin user during cluster setup. det user change-password admin Create a user. Create a new user named hoid who has admin privileges. det u create --admin hoid",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#exposing-custom-ports",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#exposing-custom-ports",
    "content": "Determined allows you to expose a custom network port in a task container, and access it using a local tunnel. For multi-container tasks, such as distributed training experiments, only the ports on the chief container (rank=0) will be exposed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": "Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": "Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#configuration",
    "content": "First, specify the ports in the environments -> proxy_ports section of the experiment or task config, for example: environment: proxy_ports: - proxy_port: 8265 proxy_tcp: true Launch your task or experiment normally. Then, use the det CLI to start a tunnel. Running the following command will setup a tunnel proxying localhost:8265 to port 8265 in the task container. python -m determined.cli.tunnel --listener 8265 --auth $DET_MASTER $TASK_ID:8265 where $DET_MASTER is your Determined master address, and $TASK_ID is the task id of the launched task or experiment. You can look up the task id using CLI command det task list. Alternatively, you can use a shortcut which allows to launch the experiment, follow its logs, and run the tunnel all at once: det e create config_file.yaml model_def -f -p 8265",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": "Configuration",
      "lvl3": "Unauthenticated Mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#unauthenticated-mode",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Exposing Custom Ports",
      "lvl1": "Exposing Custom Ports",
      "lvl2": "Configuration",
      "lvl3": "Unauthenticated Mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/proxy-ports.html#unauthenticated-mode",
    "content": "Optionally, you can run a tunnel with determined authentication turned off. This mode may be useful when the proxied app is handling security by itself, such as a web app protected by username and password. To use it, Add unauthenticated: true option in the task config. Omit --auth option from the tunnel CLI. environment: proxy_ports: - proxy_port: 8265 proxy_tcp: true unauthenticated: true python -m determined.cli.tunnel --listener 8265 $DET_MASTER $TASK_ID:8265",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#ide-integration",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#ide-integration",
    "content": "Determined shells can be used in the popular IDEs similarly to a common remote SSH host.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": "Visual Studio Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#visual-studio-code",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": "Visual Studio Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#visual-studio-code",
    "content": "Make sure Visual Studio Code Remote - SSH extension is installed. Start a new shell and get its SSH command by running: det shell start --show-ssh-command You can also get the SSH command for an existing shell using: det shell show_ssh_command <SHELL UUID> Copy the SSH command, then select Remote-SSH: Add new SSH Host... from the Command Palette in VS Code, and paste the copied SSH command when prompted. Finally, you\u2019ll be asked to pick a config file to use. The default option should work for most users. The remote host will now be available in the VS Code Remote Explorer. For further detail, please refer to the official documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": "PyCharm",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#pycharm",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "IDE Integration",
      "lvl1": "IDE Integration",
      "lvl2": "PyCharm",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "interfaces/ide-integration.html#pycharm",
    "content": "PyCharm Professional is required for remote Python interpreters via SSH. Start a new shell and get its SSH command by running: det shell start --show-ssh-command You can also get the SSH command for an existing shell using: det shell show_ssh_command <SHELL UUID> As of this writing, PyCharm doesn\u2019t support providing custom options in the SSH commands via the UI, so you\u2019ll need to supply them via an entry in your ssh_config file, commonly located at ~/.ssh/config on Linux and macOS systems. Determined SSH command line will have the following pattern: ssh -o \"ProxyCommand=<YOUR PROXY COMMAND>\" -o StrictHostKeyChecking=no -tt -o IdentitiesOnly=yes -i <YOUR KEY PATH> -p <YOUR PORT NUMBER> <YOUR USERNAME>@<YOUR SHELL HOSTNAME> You\u2019ll need to add the following to your SSH config: Host <YOUR SHELL HOSTNAME> HostName <YOUR SHELL HOSTNAME> ProxyCommand <YOUR PROXY COMMAND> StrictHostKeyChecking no IdentitiesOnly yes IdentityFile <YOUR KEY PATH> Port <YOUR PORT NUMBER> User <YOUR USERNAME> In PyCharm, open Settings/Preferences > Tools > SSH Configurations. Click the plus icon to add a new configuration. Enter YOUR HOST NAME, YOUR PORT NUMBER, and YOUR USERNAME in the corresponding fields. Then switch Authentication type dropdown to OpenSSH config and authentication agent. Save the new configuration by clicking \u201cOK\u201d. Use the new SSH configuration to setup a remote interpreter by following the official documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Hub Library",
      "lvl1": "Model Hub Library",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/index.html#model-hub-library",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Hub Library",
      "lvl1": "Model Hub Library",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/index.html#model-hub-library",
    "content": "Title Description Transformers The Determined library serves as an alternative to the HuggingFace Trainer Class and provides access to the benefits of using Determined. MMDetection The MMDetection library serves as an alternative to the trainer used by MMDetection and provides access to all of the Determined benefits.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#transformers",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#transformers",
    "content": "The Huggingface transformers library is the de facto library for natural language processing (NLP) models. It provides pretrained weights for leading NLP models and lets you easily use these pretrained models for the most common NLP tasks, such as language modeling, text classification, and question answering. model-hub makes it easy to train transformer models in Determined while keeping the developer experience as close as possible to working directly with transformers. The Determined library serves as an alternative to the HuggingFace Trainer Class and provides access to the benefits of using Determined, including: Easy multi-node distributed training with no code modifications. Determined automatically sets up the distributed backend for you. Experiment monitoring and tracking, artifact tracking, and state-of-the-art hyperparameter search without requiring third-party integrations. Automated cluster management, fault tolerance, and job rescheduling to free you from provisioning resources closely monitoring experiments. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. Model Hub Transformers is similar to the no_trainer version of transformers examples in that you have more control over the training and evaluation routines if you want. Given the above benefits, this library can be particularly useful if any of the following apply: You are an Determined user that wants to get started quickly with transformers. You are a transformers user that wants to easily run more advanced workflows like multi-node distributed training and advanced hyperparameter search. You are a transformers user looking for a single platform to manage experiments, handle checkpoints with automated fault tolerance, and perform hyperparameter search/visualization.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#getting-started",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": "Getting Started",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#getting-started",
    "content": "The easiest way to use Model Hub Transformers is to start with an existing example Trial. Model Hub Transformers includes thoroughly tested implementations of all core transformers tasks. Model Hub Transformers Trials are infinitely customizable. See the Model Hub Transformers Tutorial to learn how to customize or build a Trial.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": "Limitations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#limitations",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Transformers",
      "lvl1": "Transformers",
      "lvl2": "Limitations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/overview.html#limitations",
    "content": "The following HuggingFace transformers features are currently not supported: TensorFlow version of transformers Support for fairscale Running on TPUs",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/examples.html#examples",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Examples",
      "lvl1": "Examples",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/examples.html#examples",
    "content": "Transformers examples are the starting point for many users of the transformers library. Hence, they are the core feature of model-hub\u2019s support for transformers library. In fact, each transformer example corresponding to a core transformer task has an associated task in model-hub that is guaranteed to work with Determined and verified for correctness. See the table below for a summary of the model-hub transformers examples: Task Dataset Filename language-modeling WikiText-2 language-modeling.tgz multiple-choice SWAG multiple-choice.tgz question-answering SQuAD and SQuAD version 2 question-answering.tgz text-classification GLUE and XNLI text-classification.tgz token-classification CoNLL-2003 token-classification.tgz summarization CNN/DailyMail and XSum Coming Soon translation WMT-16 Coming Soon Each of the Determined trials above subclasses the BaseTransformerTrial and makes use of helper functions in model_hub.huggingface to drastically reduce the code needed to run the example. See the api for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#tutorial",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#tutorial",
    "content": "The easiest way to get started with transformers in Determined is to use one of the provided examples. In this tutorial, we will walk through the question answering example to get a better understanding of how to use model-hub for transformers. The question answering example includes two implementations of PyTorch API: qa_trial.py uses the model_hub.huggingface.BaseTransformerTrial parent __init__ function to build transformers config, tokenizer, and model objects; and optimizer and learning rate scheduler. qa_beam_search_trial.py overrides the model_hub.huggingface.BaseTransformerTrial parent __init__ function to customize how the transformers config, tokenizer, and model objects are constructed. To learn the basics, we\u2019ll walk through qa_trial.py. We won\u2019t cover the model definition line-by-line but will highlight the parts that make use of model-hub. If you are new to Determined, we recommend going through the Quickstart for ML Developers document to get a better understanding of how to use PyTorch in Determined using determined.harness.pytorch.PyTorchTrial. After this tutorial, if you want to further customize a trial for your own use, you can look at qa_beam_search_trial.py for an example.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#initialize-the-qatrial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#initialize-the-qatrial",
    "content": "The __init__ for QATrial is responsible for creating and processing the dataset; building the transformers config, tokenizer, and model; and tokenizing the dataset. The specifications for how we should perform these steps is passed from PyTorchContext via the hyperparameters and data configuration fields. These fields are set to hparams and data_config class attributes in model_hub.huggingface.BaseTransformerTrial.__init__(). You can also get them by calling context.get_hparams() and context.get_data_config() respectively. Note that context.get_hparams() and context.get_data_config() returns the hyperparameters and data section respectively of the experiment configuration file squad.yaml.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Build transformers config, tokenizer, and model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-transformers-config-tokenizer-and-model",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Build transformers config, tokenizer, and model",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-transformers-config-tokenizer-and-model",
    "content": "First, we\u2019ll build the transformer config, tokenizer, and model objects by calling model_Hub.huggingface.BaseTransformerTrial.__init__(): super(QATrial, self).__init__(context) This will parse the hyperparameters and fill the fields of model_hub.huggingface.ConfigKwargs, model_hub.huggingface.TokenizerKwargs, and model_hub.huggingface.ModelKwargs if present in hyperparameters and then pass them to model_hub.huggingface.build_using_auto() to build the config, tokenizer, and model using transformers autoclasses. You can look at the associated class definitions for the Kwargs objects to see the fields you can pass. This step needs to be done before we can use the tokenizer to tokenize the dataset. In some cases, you may need to first load the raw dataset and get certain metadata like the number of classes before creating the transformers objects (see ner_trial.py for example). You are not tied to using model.huggingface.build_using_auto() to build the config, tokenizer, and model objects. See qa_beam_search_trial.py for an example of a trial directly calling transformers methods.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Build the optimizer and LR scheduler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-the-optimizer-and-lr-scheduler",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Build the optimizer and LR scheduler",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-the-optimizer-and-lr-scheduler",
    "content": "The model_Hub.huggingface.BaseTransformerTrial.__init__() also parses the hyperparameters into model_hub.huggingface.OptimizerKwargs() and model_hub.huggingface.LRSchedulerKwargs() before passing them to model_hub.huggingface.build_default_optimizer() and model_hub.huggingface.build_default_lr_scheduler() respectively. These two build methods have the same behavior and configuration options as the transformers Trainer. Again, you can look at the associated class definitions for the Kwargs objects to see the fields you can pass. You are not tied to using these functions to build the optimizer and LR scheduler. You can very easily override the parent __init__ methods to use whatever optimizer and LR scheduler you want.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Load the Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#load-the-dataset",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Load the Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#load-the-dataset",
    "content": "self.raw_datasets = hf.default_load_dataset(self.data_config) This example uses the helper function model_hub.huggingface.default_load_dataset() to load the SQuAD dataset. The function takes the data_config as input and parses the fields into those expected by the model_hub.huggingface.DatasetKwargs dataclass before passing it to the load_dataset function from Huggingface datasets. Not all the fields of model_hub.huggingface.DatasetKwargs are always applicable to an example. For this example, we specify the following fields in squad.yaml for loading the dataset: data: dataset_name: squad train_file: null validation_file: null If the dataset you want to use is registered in Huggingface datasets then you can simply specify the dataset_name. Otherwise, you can set dataset_name: null and pass your own dataset in using train_file and validation_file. There is more guidance on how to use this example with custom data files in qa_trial.py. You can also bypass model_hub.huggingface.default_load_dataset() and call load_dataset directly for more options.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Data processing",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#data-processing",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Data processing",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#data-processing",
    "content": "Our text data needs to be converted to vectors before we can apply our models to them. This usually involves some preprocessing before passing the result to the tokenizer for vectorization. This part usually has task-specific preprocessing required as well to process the targets. model-hub has no prescription for how you should process your data but all the provided examples implement a build_datasets function to create the tokenized dataset. The Huggingface transformers and datasets library have optimized routiens for tokenization that caches results for reuse if possible. We have taken special care to make sure all our examples make use of this functionality. As you start implementing your own Trials, one pitfall to watch out for that prevents efficient caching is passing a function to Dataset.map that contains unserializable objects.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Define metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-metrics",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Initialize the QATrial",
      "lvl3": "Define metrics",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-metrics",
    "content": "Next, we\u2019ll define the metrics that we wish to compute over the predictions generated for the validation dataset. # Create metric reducer metric = datasets.load_metric( \"squad_v2\" if self.data_config.version_2_with_negative else \"squad\" ) self.reducer = context.wrap_reducer( functools.partial( qa_utils.compute_metrics, self.data_config, self.column_names, self.data_processors.post_processing_function, self.raw_datasets, self.tokenized_datasets, self.model, metric, ), for_training=False, ) We use the metric function associated with the SQuAD dataset from huggingface datasets and apply it after post-processing the predictions in the qa_utils.compute_metrics function. Determined supports parallel evaluation via custom reducers. The reducer we created above will aggregate predictions across all GPUs then apply the qa_utils.compute_metrics function to the result.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#fill-in-the-rest-of-pytorchtrial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#fill-in-the-rest-of-pytorchtrial",
    "content": "The remaining class methods we must implement are determined.harness.pytorch.PyTorchTrial.build_training_data_loader(), determined.harness.pytorch.PyTorchTrial.build_validation_data_loader(), and determined.harness.pytorch.PyTorchTrial.evaluate_batch().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Build the Dataloaders",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-the-dataloaders",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Build the Dataloaders",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#build-the-dataloaders",
    "content": "The two functions below are responsible for building the dataloaders used for training and validation. def build_training_data_loader(self) -> det_torch.DataLoader: return det_torch.DataLoader( self.tokenized_datasets[\"train\"], batch_size=self.context.get_per_slot_batch_size(), collate_fn=self.collator, ) def build_validation_data_loader(self) -> det_torch.DataLoader: # Determined's distributed batch sampler interleaves shards on each GPU slot so # sample i goes to worker with rank i % world_size. Therefore, we need to re-sort # all the samples once we gather the predictions before computing the validation metric. return det_torch.DataLoader( qa_utils.DatasetWithIndex(self.tokenized_datasets[\"validation\"]), batch_size=self.context.get_per_slot_batch_size(), collate_fn=self.collator, ) There are two things to note: Batch size passed to the dataloader is context.get_per_slot_batch_size which is the effective per GPU batch size when performing distributed training. The dataloader returned is a determined.harness.pytorch.DataLoader which has the same signature as PyTorch dataloaders but automatically handles data sharding and resuming dataloader state when recovering from a fault.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Define the Training Routine",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-the-training-routine",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Define the Training Routine",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-the-training-routine",
    "content": "The train_batch method below for model_hub.huggingface.BaseTransformerTrial is sufficient for this example. def train_batch(self, batch: Any, epoch_idx: int, batch_idx: int) -> Any: # By default, all HF models return the loss in the first element. # We do not automatically apply a label smoother for the user. # If this is something you want to use, please see how it's # applied by transformers.Trainer: # https://github.com/huggingface/transformers/blob/v4.3.3/src/transformers/trainer.py#L1324 outputs = self.model(**batch) loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0] self.context.backward(loss) self.context.step_optimizer(self.optimizer, self.grad_clip_fn) return loss",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Define the Evaluation Routine",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-the-evaluation-routine",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Fill in the Rest of PyTorchTrial",
      "lvl3": "Define the Evaluation Routine",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#define-the-evaluation-routine",
    "content": "Finally, we can define the evaluation routine for this example. def evaluate_batch(self, batch: det_torch.TorchData, batch_idx: int) -> Dict: ind = batch.pop(\"ind\") outputs = self.model(**batch) if isinstance(outputs, dict): predictions = tuple( v.detach().cpu().numpy() for k, v in outputs.items() if k not in (\"loss\", \"mems\") ) else: predictions = outputs[1:].detach().cpu().numpy() self.reducer.update((ind.detach().cpu().numpy(), predictions)) # Although we are returning the empty dictionary below, we will still get the metrics from # custom reducer that we passed to the context during initialization. return {} After passing the batch through the model and doing some processing to get the predictions, we pass the predictions to reducer.update to aggregate the predictions in each GPU. Once each GPU has exhausted the batches in its dataloader, Determined automatically performs an all gather operation to collect the predictions in the rank 0 GPU before passing them to the compute_metrics function.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "HF Library Versions",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#hf-library-versions",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "HF Library Versions",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#hf-library-versions",
    "content": "model-hub support for transformers is tied to specific versions of the source library to ensure compatibility. Be sure to use the latest Docker image with all the necessary dependencies for transformers with model-hub. All provided examples already have this Docker image specified: environment: image: We periodically bump these libraries up to more recent versions of transformers and datasets so you can access the latest upstream features. That said, once you create a trial definition using a particular Docker image, you will not need to upgrade to a new Docker image for your code to continue working with model-hub. Additionally, your code will continue to work with that image even if you use it with a more recent version of the Determined cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Tutorial",
      "lvl1": "Tutorial",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/transformers/tutorial.html#next-steps",
    "content": "Take a look at qa_beam_search_trial.py for an example of how you can further customize your trial. Dive into the api.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection",
      "lvl1": "MMDetection",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/mmdetection/overview.html#mmdetection",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "MMDetection",
      "lvl1": "MMDetection",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-hub-library/mmdetection/overview.html#mmdetection",
    "content": "The MMDetection library is a popular library for object detection. It provides implementations for many popular object detection approaches like Faster-RCNN and Mask-RCNN in addition to cutting edge methods from the research community. model-hub makes it easy to use MMDetection with Determined while keeping the developer experience as close as possible to what it\u2019s like working directly with MMDetection. Our library serves as an alternative to the trainer used by MMDetection (see mmcv\u2019s runner) and provides access to all of Determined\u2019s benefits including: Easy multi-node distributed training with no code modifications. Determined automatically sets up the distributed backend for you. Experiment monitoring and tracking, artifact tracking, and state-of-the-art hyperparameter search without requiring third-party integrations. Automated cluster management, fault tolerance, and job rescheduling so you don\u2019t have to worry about provisioning resources or babysitting your experiments. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. Given the benefits above, we think this library will be particularly useful to you if any of the following apply: You want to perform object detection using a powerful integrated platform that will scale easily with your needs. You are an Determined user that wants to get started quickly with MMDetection. You are a MMDetection user that wants to easily run more advanced workflows like multi-node distributed training and advanced hyperparameter search. You are a MMDetection user looking for a single platform to manage experiments, handle checkpoints with automated fault tolerance, and perform hyperparameter search/visualization. The easiest way to use MMDetection is to start with the provided experiment configuration for Faster-RCNN. The associated README is a tutorial on how to use MMDetection with Determined and covers how to modify the configuration for custom behavior.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Developer Guide",
      "lvl1": "Model Developer Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/index.html#model-developer-guide",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Developer Guide",
      "lvl1": "Model Developer Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/index.html#model-developer-guide",
    "content": "<div class=\"landing\"> <div class=\"tiles-flex\"> <div class=\"tile-container\"> <a class=\"tile\" href=\"../tutorials/quickstart-mdldev.html\"> <h2 class=\"tile-title\">Model Developer Quickstart</h2> <p class=\"tile-description\">This quickstart helps first-time users get started.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/dtrain/index.html\"> <h2 class=\"tile-title\">Distributed Training</h2> <p class=\"tile-description\">Learn how to perform optimized distributed training with Determined to speed up the training of a single trial.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/prepare-container/index.html\"> <h2 class=\"tile-title\">Preparing Container Environment</h2> <p class=\"tile-description\">Resources for preparing your container environment.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/load-model-data.html\"> <h2 class=\"tile-title\">Preparing Data</h2> <p class=\"tile-description\">What is the best way to load data into your ML models? This depends on several factors...</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/api-guides/apis-howto/index.html\"> <h2 class=\"tile-title\">Using a Training API</h2> <p class=\"tile-description\">Learn how to work with Training APIs and configure your distributed training experiments.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/apis-howto/api-core-ug.html\"> <h2 class=\"tile-title\">Core API</h2> <p class=\"tile-description\">Learn how to use the flexible Core API to train any deep learning model.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/hyperparameter/index.html\"> <h2 class=\"tile-title\">Hyperparameter Tuning</h2> <p class=\"tile-description\">Conceptual information about why hyperparameter tuning can be challenging and why it's important.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/submit-experiment.html\"> <h2 class=\"tile-title\">Submitting Experiment</h2> <p class=\"tile-description\">Find out how to run an experiment by providing a launcher.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/debug-models.html\"> <h2 class=\"tile-title\">Debugging Models</h2> <p class=\"tile-description\">Step-by-step instructions for debugging your models.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/model-management/index.html\"> <h2 class=\"tile-title\">Managing Models</h2> <p class=\"tile-description\">Model management involves using and deleting checkpoints, archiving experiments, and managing trained models.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/best-practices/index.html\"> <h2 class=\"tile-title\">Best Practices</h2> <p class=\"tile-description\">General tips for the trial definition, and best practices for separating configuration from code.</p> </a> </div> <div class=\"tile-container\"> <a class=\"tile\" href=\"../model-dev-guide/batch-processing/batch-process-api-ug.html\"> <h2 class=\"tile-title\">Batch Inference</h2> <p class=\"tile-description\">Try the experimental Batch Processing API for batch inference.</p> </a> </div> </div> </div>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#how-to-debug-models",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#how-to-debug-models",
    "content": "Using Determined to debug models depends on your environment. Your code on a Determined cluster differs from typical training scripts in the following ways: The code conforms to the Trial APIs as a subclass of the Determined Trial class, indirectly, by using one of the concrete subclasses, such as PyTorchTrial. The code runs in a Docker container on another machine. Your model can run many times in a hyperparameter search. Your model can be distributed across multiple GPUs or machines. These debugging steps introduce code changes incrementally, working toward a fully functioning Determined model. Follow the nine steps as applicable to your environment: Model-related Issues Step 1 - Verify that your code runs locally Step 2 - Verify that each Trial subclass method works locally Step 3 - Verify local test mode Docker- or Cluster-related Issues Step 4 - Verify that the original code runs in a notebook or shell Step 5 - Verify that each Trial subclass method works in a notebook or shell Step 6 - Verify that local test mode works in a notebook or shell Higher-level Issues Step 7 - Verify that cluster test mode works with slots_per_trial set to 1 Step 8 - Verify that a single-GPU experiment works Step 9 - Verify that a multi-GPU experiment works",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Prerequisite",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#prerequisite",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Prerequisite",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#prerequisite",
    "content": "Ensure you have successfully installed a Determined cluster. The cluster can be installed on a local development machine, on-prem, or on cloud. For installation guides, visit Install and Set Up Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 1 - Verify that your code runs locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-1-verify-that-your-code-runs-locally",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 1 - Verify that your code runs locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-1-verify-that-your-code-runs-locally",
    "content": "This step assumes you have ported (converted) your model from code outside of Determined. Otherwise, skip to Step 2. Confirm that your code works as expected before continuing.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 2 - Verify that each Trial subclass method works locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-2-verify-that-each-trial-subclass-method-works-locally",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 2 - Verify that each Trial subclass method works locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-2-verify-that-each-trial-subclass-method-works-locally",
    "content": "This step assumes you have a working local environment for training. If you typically run your code in a Docker environment, skip to Step 4. This step also ensures that your class performs as expected by calling its methods and verifying the output. Create simple tests to verify each Trial subclass method. Examples of what these tests might look like for PyTorchTrial and TFKerasTrial can be found in the determined.TrialContext.from_config() documentation, but only you can verify what is reasonable for your test. Diagnose failures: If you experience issues running the Trial subclass methods locally, it is likely there are errors are in your trial class or the hyperparameters section of your configuration file. Ideally, method-by-method evaluation makes it easier to find and solve issues.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 3 - Verify local test mode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-3-verify-local-test-mode",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 3 - Verify local test mode",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-3-verify-local-test-mode",
    "content": "Step 2 validated that your Trial API calls work as expected. This step uses your code to run an actual Determined training loop with abbreviated workloads to make sure that it meets Determined requirements. This step assumes you have a working local environment for training. If you do not, skip to Step 4. Create an experiment using the following command: det experiment create myconfig.yaml my_model_dir --local --test The --local argument specifies that training occurs where you launched the experiment instead of occurring on a cluster. The --test argument runs abbreviated workloads to try to detect bugs sooner and exits immediately. The test is considered to have passed if the command completes successfully. Diagnose failures: Local test mode performs the following actions: Builds a model. Runs a single batch of training data. Evaluates the model. Saves a checkpoint to a dummy location. If your per-method checks in Step 2 passed but local test mode fails, your Trial subclass might not be implemented correctly. Double-check the documentation. It is also possible that you have found a bug or an invalid assumption in the Determined software and should file a GitHub issue or contact Determined on Slack.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 4 - Verify that the original code runs in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-4-verify-that-the-original-code-runs-in-a-notebook-or-shell",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 4 - Verify that the original code runs in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-4-verify-that-the-original-code-runs-in-a-notebook-or-shell",
    "content": "This step is the same as Step 1, except the original code runs on the Determined cluster instead of locally. Launch a notebook or shell on the cluster: Pass the root directory containing your model and training scripts in the --context argument: If you prefer a Jupyter notebook, enter: det notebook start --context my_model_dir # Your browser should automatically open the notebook. If you prefer to use SSH to interact with your model, enter: det shell start --context my_model_dir # Your terminal should automatically connect to the shell. Note that changes made to the --context directory while inside the notebook or shell do not affect the original files outside of the notebook or shell. See Save and Restore Notebook State for more information. Verify code execution: After you are on the cluster, testing is the same as Step 1. Diagnose failures: If you are unable to start the container and receive a message about the context directory exceeding the maximum allowed size, it is because the --context directory cannot be larger than 95MB. If you need larger model definition files, consider setting up a bind mount using the bind_mounts field of the task configuration. The Prepare Data document lists additional strategies for accessing files inside a containerized environment. You might be referencing files that exist locally but are outside of the --context directory. If the files are small, you may be able to copy them into the --context directory. Otherwise, bind mounting the files can be an option. If you get dependency errors, dependencies might be installed locally that are not installed in the Docker environment used on the cluster. See Customizing Your Environment and Custom Images for available options. If you need environment variables to be set for your model to work, see Job Configuration Reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 5 - Verify that each Trial subclass method works in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-5-verify-that-each-trial-subclass-method-works-in-a-notebook-or-shell",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 5 - Verify that each Trial subclass method works in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-5-verify-that-each-trial-subclass-method-works-in-a-notebook-or-shell",
    "content": "This step is the same as Step 2, except the original code runs on the Determined cluster instead of locally. Launch a notebook or shell: If you prefer to use Jupyter notebook, enter: det notebook start --context my_model_dir # Your browser should automatically open the notebook. If you prefer to use SSH to interact with your model, enter: det shell start --context my_model_dir # Your terminal should automatically connect to the shell. When interacting with the shell or notebook, testing is the same as Step 2. Diagnose failures: Combine the failure diagnosis steps used in Step 2 and Step 4.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 6 - Verify that local test mode works in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-6-verify-that-local-test-mode-works-in-a-notebook-or-shell",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 6 - Verify that local test mode works in a notebook or shell",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-6-verify-that-local-test-mode-works-in-a-notebook-or-shell",
    "content": "This step is the same as Step 3, except the original code runs on the Determined cluster instead of locally. Launch a notebook or shell as described in Step 4. On the cluster, testing is the same as Step 3, except that the second model definition argument of the det experiment create command should be /run/determined/workdir or . if you have not changed the working directory after connecting to the cluster. This is because the --context specified when creating the shell or notebook is copied to the /run/determined/workdir directory inside the container, the same as the model definition argument is copied to det experiment create. Diagnose failures following the same steps described in Step 3 and Step 4.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 7 - Verify that cluster test mode works with slots_per_trial set to 1",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-7-verify-that-cluster-test-mode-works-with-slots-per-trial-set-to-1",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 7 - Verify that cluster test mode works with slots_per_trial set to 1",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-7-verify-that-cluster-test-mode-works-with-slots-per-trial-set-to-1",
    "content": "This step is similar to Step 6, except instead of launching the command from an interactive environment, it is submitted to the cluster and managed by Determined. Apply customizations: If you customized your command environment in testing Step 3, Step 4, or Step 5, make sure to apply the same customizations in your experiment configuration file. Set resources.slots_per_trial: Confirm that your experiment config does not specify resources.slots_per_trial or that it is set to 1. For example: resources: slots_per_trial: 1 Create an experiment with the --test argument, omitting the --local argument: det experiment create myconfig.yaml my_model_dir --test Diagnose failures: If you can run local test mode inside a notebook or shell but are unable to successfully submit an experiment, make sure that notebook or shell customizations you might have made are replicated in your experiment configuration, such as: If required, a custom Docker image is set in the experiment configuration. pip install or apt install commands needed in the interactive environment are built into a custom Docker image or included in the startup-hook.sh file in the model definition directory root. See Startup Hooks for more information. Custom bind mounts required in the interactive environment are specified in the experiment configuration. Environment variables are correctly set in the experiment configuration. If no customizations are missing, the following new layers introduced with a cluster-managed experiment could be the cause of the problem: The checkpoint_storage settings are used for cluster-managed training. If checkpoint_storage is not configured in the experiment configuration or the master configuration, an error message can occur during experiment configuration validation before the experiment or trials are created. Correct this by providing a checkpoint_storage configuration in one of the following locations: Master Configuration Reference Experiment Configuration Reference For a cluster-based experiment, configured checkpoint_storage settings are validated before training starts. The message Checkpoint storage validation failed, indicates that you should review the checkpoint_storage setting values. The experiment configuration is more strictly validated for cluster-managed experiments than for --local --test mode. Errors related to invalid experiment configuration when attempting to submit the experiment to the cluster indicate that the experiment configuration has errors. Review the experiment configuration. If you are unable to identify the cause of the problem, contact Determined community support!",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 8 - Verify that a single-GPU experiment works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-8-verify-that-a-single-gpu-experiment-works",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 8 - Verify that a single-GPU experiment works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-8-verify-that-a-single-gpu-experiment-works",
    "content": "This step is similar to Step 7, except that it introduces hyperparameter search and executes full training for each trial. Configure your system the same as Step 7: Confirm that your experiment configuration does not specify resources.slots_per_trial or that it is set to 1. For example: resources: slots_per_trial: 1 Create an experiment without the --test or --local arguments: You might find the --follow, or -f, argument helpful: det experiment create myconfig.yaml my_model_dir -f Diagnose failures: If Step 7 worked but this step does not, check: Check if the error happens when the experiment configuration has searcher.source_trial_id set. One possibility in an actual experiment that does not occur in a --test experiment is the loading of a previous checkpoint. Errors when loading from a checkpoint can be caused by architectural changes, where the new model code is not architecturally compatible with the old model code. Generally, issues in this step are caused by doing training and evaluation continuously. Focus on how that change can cause issues with your code.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 9 - Verify that a multi-GPU experiment works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-9-verify-that-a-multi-gpu-experiment-works",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "How to Debug Models",
      "lvl1": "How to Debug Models",
      "lvl2": "Step 9 - Verify that a multi-GPU experiment works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/debug-models.html#step-9-verify-that-a-multi-gpu-experiment-works",
    "content": "This step is similar to Step 8, except that it introduces distributed training. This step only applies if you have multiple GPUs and want to use distributed training. Configure your system the same as Step 7: Set resources.slots_per_trial to a number greater than 1. For example: resources: slots_per_trial: 2 Create your experiment: det experiment create myconfig.yaml my_model_dir -f Diagnose failures: If you are using the determined library APIs correctly, distributed training should work without error. Otherwise, common problems might be: If your experiment is not being scheduled on the cluster, ensure that the slots_per_trial setting is valid for your cluster. For example: If you have four Determined agents running with four GPUs each, your slots_per_trial could be 1, 2, 3, or 4, which fits on a single machine. A slots_per_trial value of 8, 12, or 16 completely utilizes a number of agent machines. A slots_per_trial value of 5 implies more than one agent but it is not a multiple of agent size so this is an invalid case. A slots_per_trial value of 32 is too large for the cluster and is also an invalid case. Ensure that there are no other notebooks, shells, or experiments on the cluster that might consume too many resources and prevent the experiment from starting. Determined is designed to control the details of distributed training for you. If you also try to control those details, such as by calling tf.config.set_visible_devices() in a TFKerasTrial, it is likely to cause issues. Some classes of metrics must be specially calculated during distributed training. Most metrics, such as loss or accuracy, can be calculated piecemeal on each worker in a distributed training job and averaged afterward. Those metrics are handled automatically by Determined and do not need special handling. Other metrics, such as F1 score, cannot be averaged from individual worker F1 scores. Determined has tooling for handling these metrics. See the documentation for using custom metric reducers with PyTorch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#submit-experiment",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#submit-experiment",
    "content": "You run training code by submitting your code to a cluster and running it as an experiment. To run an experiment, you provide a launcher and specify the launcher in the experiment configuration endpoint field. Launcher options are: legacy bare-Trial-class Determined predefined launchers: Horovod Launcher PyTorch Distributed Launcher DeepSpeed Launcher custom launcher or use one of the Determined predefined launchers a command with arguments, which is run in the container For distributed training, it is good practice to separate the launcher that starts a number of distributed workers from your training script, which typically runs each worker. The distributed training launcher must implement the following logic: Launch all of the workers you want, passing any required peer info, such as rank or chief ip address, to each worker. Monitor workers. If a worker exits with non-zero, the launcher should terminate the remaining workers and exit with non-zero. Exit zero after all workers exit zero. These requirements ensure that distributed training jobs do not hang after a single worker failure.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#configure-a-launcher",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#configure-a-launcher",
    "content": "The entry point of a model is configured in the Experiment Configuration file and specifies the path of the model and how it should be launched. Predefined launchers are provided in the determined.launch module and custom scripts are also supported. The launcher is configurable in the experiment configuration entrypoint field. The entrypoint trial object or script launches the training code. entrypoint: python3 -m (LAUNCHER) (TRIAL_DEFINITION) or a custom script: entrypoint: python3 script.py arg1 arg2 Preconfigured launcher entrypoint arguments can differ but have the same format: python3 -m (LAUNCH_MODULE) (--trial TRIAL)|(SCRIPT...) where (LAUNCH_MODULE) is a Determined launcher and (--trial TRIAL)|(SCRIPT...) refers to the training script, which can be in a simplified format that the Determined launcher recognizes or a custom script. You can write a custom launcher, in which case the launcher should wrap each rank worker in the python3 -m determined.launch.wrap_rank $RANK CMD [ARGS...] script, so the final logs can be separated according to rank in the WebUI.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#training-code-definition",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#training-code-definition",
    "content": "To launch a model or training script, either pass a trial class path to \u2013trial or run a custom script that runs the training code. Only one of these can be used at the same time.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": "Trial Class",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#trial-class",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": "Trial Class",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#trial-class",
    "content": "--trial TRIAL To specify a trial class to be trained, the launcher accepts a TRIAL argument in the following format: filepath:ClassName where filepath is the location of your training class file, and ClassName is the name of the Python training class",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": "Custom Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#custom-script",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Training Code Definition",
      "lvl4": "Custom Script",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#custom-script",
    "content": "A custom script can be launched under a supported launcher instead of a trial class definition, with arguments passed as expected. Example Python script command: script.py [args...]",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Horovod Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#horovod-launcher",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Horovod Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#horovod-launcher",
    "content": "Format: determined.launch.horovod [[HVD_OVERRIDES...] --] (--trial TRIAL)|(SCRIPT...) The horovod launcher is a wrapper around horovodrun which automatically configures the workers for the trial. You can pass arguments directly to horovodrun, overriding Determined values, as HVD_OVERRIDES, which must end with a -- to separate the overrides from the normal arguments. Example: python3 -m determined.launch.horovod --fusion-threshold-mb 1 --cycle-time-ms 2 -- --trial model_def:MyTrial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "PyTorch Distributed Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pytorch-distributed-launcher",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "PyTorch Distributed Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pytorch-distributed-launcher",
    "content": "Format: determined.launch.torch_distributed [[TORCH_OVERRIDES...] --] (--trial TRIAL)|(SCRIPT...) This launcher is a Determined wrapper around PyTorch\u2019s native distributed training launcher, torch.distributed.run. Any arbitrary override arguments to torch.distributed.run are accepted, which overrides default values set by Determined. See the official PyTorch documentation for information about how to use torch.distributed.run. The optional override arguments must end with a -- separator before the trial specification. Example: python3 -m determined.launch.torch_distributed --rdzv_endpoint=$CUSTOM_RDZV_ADDR -- --trial model_def:MyTrial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "DeepSpeed Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#deepspeed-launcher",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "DeepSpeed Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#deepspeed-launcher",
    "content": "Format: determined.launch.deepspeed [[DEEPSPEED_ARGS...] --] (--trial TRIAL)|(SCRIPT...) The DeepSpeed launcher launches a training script under deepspeed with automatic handling of: IP addresses sshd containers shutdown See the DeepSpeed Launching DeepSpeed Training documentation for information about how to use the DeepSpeed launcher. Example: python3 -m determined.launch.deepspeed --trial model_def:MyTrial Use the help option to get the latest usage: python3 -m determined.launch.deepspeed -h",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Legacy Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#legacy-launcher",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Legacy Launcher",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#legacy-launcher",
    "content": "Format: entrypoint: model_def:TrialClass The entry point field expects a predefined or custom script, but also supports legacy file and trial class definitions. When you specify a trial class as the entry point, it must be a subclass of a Determined trial class. Each trial class is designed to support one deep learning application framework. When training or validating models, the trial might need to load data from an external source so the training code needs to define data loaders. A TrialClass is located in the model_def filepath and launched automatically. This is considered legacy behavior. By default, this configuration automatically detects distributed training, based on slot size and the number of machines, and launches with Horovod for distributed training. If used in a distributed training context, the entry point is: python3 -m determined.launch.horovod --trial model_def:TrialClass",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Nested Launchers",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#nested-launchers",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Configure a Launcher",
      "lvl3": "Nested Launchers",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#nested-launchers",
    "content": "The entry point supports nesting multiple launchers in a single script. This can be useful for tasks that need to be run before the training code starts, such as profiling tools (dlprof), custom memory management tools (numactl), or data preprocessing. Example: dlprof --mode=simple python3 -m determined.launch.autohorovod --trial model_def:MnistTrial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Create an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#create-an-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Create an Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#create-an-experiment",
    "content": "The CLI is the recommended way to create an experiment, although you can also use the WebUI to create from an existing experiment or trial. To create an experiment: $ det experiment create <configuration file> <context directory> The Experiment Configuration file is a YAML file that controls your experiment. The context directory contains relevant training code, which is uploaded to the master. The total size of the files in the context cannot exceed 95 MB. As a result, only very small datasets should be included. Instead, set up data loaders to read data from an external source. Refer to the Prepare Data section for more data loading options. Because project directories can include large artifacts that should not be packaged as part of the model definition, including data sets or compiled binaries, users can specify a .detignore file at the top level, which lists the file paths to be omitted from the model definition. The .detignore file uses the same syntax as .gitignore. Byte-compiled Python files, including .pyc files and __pycache__ directories, are always ignored.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Pre-training Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pre-training-setup",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Pre-training Setup",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pre-training-setup",
    "content": "Trials are created to train the model. The Hyperparameter Tuning searcher specified in the experiment configuration file defines a set of hyperparameter configurations. Each hyperparameter configuration corresponds to a single trial. After the context and experiment configuration reach the master, the experiment waits for the scheduler to assign slots. The master handles allocating necessary resources as defined in the cluster configuration. When a trial is ready to run, the master communicates with the agent, or distributed training agents, which create(s) containers that have the configured environment and training code. A set of default container images applicable to many deep learning tasks is provided, but you can also specify a custom image. If the specified container images do not exist locally, the trial container fetches the images from the registry. See Organize Models in the Model Registry. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. After starting the containers, each trial runs the startup-hook.sh script in the context directory. The pre-training activity can incur a delay before each trial begins training but typically only takes a few seconds.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Pause and Activate",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pause-and-activate",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Pause and Activate",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#pause-and-activate",
    "content": "A trial can be paused and reactivated without losing training progress. Pausing a trial preserves its progress by saving a checkpoint before exiting the cluster. The scheduler can pause a trial to free its resources for another task. Also, you can manually pause an experiment, which pauses all trials in the experiment. This frees the slots used by the trial. When the trial resumes, because more slots become available or because you activate an experiment, the saved checkpoint is loaded and training continues from the saved state.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "View the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#view-the-job-queue",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "View the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#view-the-job-queue",
    "content": "The Determined Queue Management system extends scheduler functionality to offer better visibility and control over scheduling decisions. It does this using the Job Queue, which provides better information about job ordering, such as which jobs are queued, and permits dynamic job modification. Queue Management is a new feature that is available to the fair share scheduler and the priority scheduler. Queue Management, described in detail in the following sections, shows all submitted jobs and their states, and lets you modify some configuration options, such as priority, position in the queue, and resource pool. To begin managing job queues, go to the WebUI Job Queue section or use the det job set of CLI commands. Queued jobs can be in the Queued or Scheduled state: Queued: Job received but resources not allocated Scheduled: Scheduled to run or running, and resources may have been allocated. Completed or errored jobs are not counted as active and are omitted from this list. You can view the job queue using the CLI or WebUI. In the WebUI, click the Job Queue tab. In the CLI, use one of the following commands: $ det job list $ det job ls These commands show the default resource pool queue. To view other resource pool queues, use the --resource-pool option, specifying the pool: $ det job list --resource-pool compute-pool For more information about the CLI options, see the CLI documentation or use the det job list -h command. The WebUI and the CLI display a table of results, ordered by scheduling order. The scheduling order does not represent the job priority. In addition to job order, the table includes the job states and number of slots allocated to each job.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue",
    "content": "The job queue can be changed in the WebUI Job Queue section or by using the CLI det job update command. You can make changes on a per-job basis by selecting a job and a job operation. Available operations include: changing priorities for resource pools using the priority scheduler changing weights for resource pools using the fair share scheduler changing the order of queued jobs changing resource pools There are a number of constraints associated with using the job queue to modify jobs: The priority and fair share fields are mutually exclusive. The priority field is only active for the priority scheduler and the fair share field is only active for the fair share scheduler. It is not possible for both to be active simultaneously. The ahead-of, behind-of, and WebUI Move to Top operations are only available for the priority scheduler and are not possible with the fair share scheduler. These operations are not yet fully supported for the Kubernetes priority scheduler. The change resource pool operation can only be performed on experiments. To change the resource pool of other tasks, cancel the task and resubmit it.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": "Modify the Job Queue using the WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue-using-the-webui",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": "Modify the Job Queue using the WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue-using-the-webui",
    "content": "To modify the job queue in the Webui, Go to the Job Queue section. Find the job to modify. Click the three dots in the right-most column of the job. Find and click the Manage Job option. Make the change you want on the pop-up page, and click OK.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": "Modify the Job Queue using the CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue-using-the-cli",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Submit Experiment",
      "lvl1": "Submit Experiment",
      "lvl2": "Modify the Job Queue",
      "lvl3": "Modify the Job Queue using the CLI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/submit-experiment.html#modify-the-job-queue-using-the-cli",
    "content": "To modify the job queue in the CLI, use the det job update command. Run det job update --help for more information. Example operations: $ det job update jobID --priority 10 $ det job update jobID --resource-pool a100 $ det job update jobID --ahead-of jobID-2 To update a job in batch, provide updates as shown: $ det job update-batch job1.priority=1 job2.resource-pool=\"compute\" job3.ahead-of=job1 Example workflow: $ det job list # | ID | Type | Job Name | Priority | Submitted | Slots (acquired/needed) | Status | User -----+--------------------------------------+-----------------+--------------------------+------------+---------------------------+--------- 0 | 0d714127 | TYPE_EXPERIMENT | first_job | 42 | 2022-01-01 00:01:00 | 1/1 | STATE_SCHEDULED | user1 1 | 73853c5c | TYPE_EXPERIMENT | second_job | 42 | 2022-01-01 00:01:01 | 0/1 | STATE_QUEUED | user1 $ det job update 73853c5c --ahead-of 0d714127 $ det job list # | ID | Type | Job Name | Priority | Submitted | Slots (acquired/needed) | Status | User -----+--------------------------------------+-----------------+--------------------------+------------+---------------------------+--------- 0 | 73853c5c | TYPE_EXPERIMENT | second_job | 42 | 2022-01-01 00:01:01 | 1/1 | STATE_SCHEDULED | user1 1 | 0d714127 | TYPE_EXPERIMENT | first_job | 42 | 2022-01-01 00:01:00 | 0/1 | STATE_QUEUED | user1 $ det job update-batch 73853c5c.priority=1 0d714127.priority=1 $ det job list # | ID | Type | Job Name | Priority | Submitted | Slots (acquired/needed) | Status | User -----+--------------------------------------+-----------------+--------------------------+------------+---------------------------+--------- 0 | 73853c5c | TYPE_EXPERIMENT | second_job | 1 | 2022-01-01 00:01:01 | 1/1 | STATE_SCHEDULED | user1 1 | 0d714127 | TYPE_EXPERIMENT | first_job | 1 | 2022-01-01 00:01:00 | 0/1 | STATE_QUEUED | user1",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#prepare-data",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#prepare-data",
    "content": "Data plays a fundamental role in machine learning model development. The best way to load data into your ML models depends on several factors, including whether you are running on-premise or in the cloud, the size of your data sets, and your security requirements. Accordingly, Determined supports a variety of methods for accessing data. The easiest way to include data in your experiment is to add the data to the same directory as your model code. When you create a new experiment, all files in your model code directory will be packaged and uploaded to the Determined cluster, assuming the package is smaller than 96MB. If your dataset is larger than 96MB, you can use a Startup Hook shell script to download the dataset prior to training. This document also introduces production data source options, such as Object Store ( Amazon S3, Google Cloud Storage) or Distributed File Systems (NFS, Ceph) if the above approaches do not apply to you.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Including Data With Your Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#including-data-with-your-code",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Including Data With Your Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#including-data-with-your-code",
    "content": "The data set can be uploaded as part of the experiment directory, which usually include your training API implementation. The size of this directory must not exceed 96MB, so this method is only appropriate when the size of the data set is small. For example, the experiment directory below contains the model definition, an experiment configuration file, and a CSV data file. All three files are small and hence the total size of the directory is much smaller than the 96MB limit: . \u251c\u2500\u2500 const.yaml (0.3 KB) \u251c\u2500\u2500 data.csv (5 KB) \u2514\u2500\u2500 model_def.py (4.1 KB) The data can be submitted along with the model definition using the command: det create experiment const.yaml . Determined injects the contents of the experiment directory into each trial container that is launched for the experiment. Any file in that directory can then be accessed by your model code, e.g., by relative path (the model definition directory is the initial working directory for each trial container). For example, the code below uses Pandas to load data.csv into a DataFrame: df = pandas.read_csv(\"data.csv\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Distributed File System",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#distributed-file-system",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Distributed File System",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#distributed-file-system",
    "content": "Another way to store data is to use a distributed file system, which enables a cluster of machines to access a shared data set via the familiar POSIX file system interface. Amazon\u2019s Elastic File System and Google\u2019s Cloud Filestore are examples of distributed file systems that are available in cloud environments. For on-premise deployments, popular distributed file systems include Ceph, GlusterFS, and NFS. To access data on a distributed file system, you should first ensure that the file system is mounted at the same mount point on every Determined agent. For cloud deployments, this can be done by configuring provisioner.startup_script in master.yaml to point to a script that mounts the distributed file system. An example of how to do this on GCP can be found here. Next, you will need to ensure the file system is accessible to each trial container. This can be done by configuring a bind mount in the experiment configuration file. Each bind mount consists of a host_path and a container_path; the host path specifies the absolute path where the distributed file system has been mounted on the agent, while the container path specifies the path within the container\u2019s file system where the distributed file system will be accessible. To avoid confusion, you may wish to set the container_path to be equal to the host_path. You may also want to set read_only to true for each bind mount, to ensure that data sets are not modified by training code. The following example assumes a Determined cluster is configured with a distributed file system mounted at /mnt/data on each agent. To access data on this file system, we use an experiment configuration file as follows: bind_mounts: - host_path: /mnt/data container_path: /mnt/data read_only: true Our model definition code can then access data in the /mnt/data directory as follows: def build_training_data_loader(self): return make_data_loader(data_path=\"/mnt/data/training\", ...) def build_validation_data_loader(self): return make_data_loader(data_path=\"/mnt/data/validation\", ...)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#object-storage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#object-storage",
    "content": "Object stores manage data as a collection of key-value pairs. Object storage is particularly popular in cloud environments \u2013 for example, Amazon\u2019s Simple Storage Service (S3) and Google Cloud Storage (GCS) are both object stores. When running Determined in the cloud, it is highly recommended that you store your data using the same cloud provider being used for the Determined cluster itself. Unless you are accessing a publicly available data set, you will need to ensure that Determined trial containers can access data in the object storage service you are using. This can be done by configuring a custom environment with the appropriate credentials. When using Dynamic Agents on GCP, a system administrator will need to configure a valid service account with read credentials. When using Dynamic Agents on AWS, the system administrator will need to configure an iam_instance_profile_arn with read credentials. Once security access has been configured, we can use open-source libraries such as boto3 or gcsfs to access data from object storage. The simplest way to do this is for your model definition code to download the entire data set whenever a trial container starts up.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": "Downloading from Object Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#downloading-from-object-storage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": "Downloading from Object Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#downloading-from-object-storage",
    "content": "The example below demonstrates how to download data from S3 using boto. The S3 bucket name is specified in the experiment config file (using a field named data.bucket). The download_directory variable defines where data that is downloaded from S3 will be stored. Note that we include self.context.distributed.get_rank() in the name of this directory: when doing distributed training, multiple processes might be downloading data concurrently (one process per GPU), so embedding the rank in the directory name ensures that these processes do not conflict with one another. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. Once the download directory has been created, s3.download_file(s3_bucket, data_file, filepath) fetches the file from S3 and stores it at the specified location. The data can then be accessed in the download_directory. import boto3 import os def download_data_from_s3(self): s3_bucket = self.context.get_data_config()[\"bucket\"] download_directory = f\"/tmp/data-rank{self.context.distributed.get_rank()}\" data_file = \"data.csv\" s3 = boto3.client(\"s3\") os.makedirs(download_directory, exist_ok=True) filepath = os.path.join(download_directory, data_file) if not os.path.exists(filepath): s3.download_file(s3_bucket, data_file, filepath) return download_directory To use this in your trial class, start by calling download_data_from_s3 in the trial\u2019s __init__ function. Next, implement the build_training_data_loader and build_validation_data_loader functions to load the training and validation data sets, respectively, from the downloaded data.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": "Streaming from Object Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#streaming-from-object-storage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Data",
      "lvl1": "Prepare Data",
      "lvl2": "Object Storage",
      "lvl3": "Streaming from Object Storage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/load-model-data.html#streaming-from-object-storage",
    "content": "Rather than downloading the entire training data set from object storage during trial startup, another way to load data is to stream batches of data from the training and validation sets as needed. This has several advantages: It avoids downloading the entire data set during trial startup, allowing training tasks to start more quickly. If a container doesn\u2019t need to access the entire data set, streaming can result in downloading less data. For example, when doing hyperparameter searches, many trials can often be terminated after having been trained for less than a full epoch. If the data set is extremely large, streaming can avoid the need to store the entire data set on disk. Streaming can allow model training and data downloading to happen in parallel, improving performance. To perform streaming data loading, the data must be stored in a format that allows efficient random access, so that the model code can fetch a specific batch of training or validation data. One way to do this is to store each batch of data as a separate object in the object store. Alternatively, if the data set consists of fixed-size records, you can use a single object and then read the appropriate byte range from it. To stream data, a custom torch.utils.data.Dataset or tf.keras.utils.Sequence object is required, depending on whether you are using PyTorch or TensorFlow Keras, respectively. These classes require a __getitem__ method that is passed an index and returns the associated batch or record of data. When streaming data, the implementation of __getitem__ should fetch the required data from the object store. The code below demonstrates a custom tf.keras.utils.Sequence class that streams data from Amazon S3. In the __getitem__ method, boto3 is used to fetch the data based on the provided bucket and key. import boto3 class ObjectStorageSequence(tf.keras.utils.Sequence): ... def __init__(self): self.s3_client = boto3.client(\"s3\") def __getitem__(self, idx): bucket, key = get_s3_loc_for_batch(idx) blob_data = self.s3_client.get_object(Bucket=bucket, Key=key)[\"Body\"].read() return data_to_batch(blob_data)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Your Container Environment",
      "lvl1": "Prepare Your Container Environment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/index.html#prepare-your-container-environment",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Prepare Your Container Environment",
      "lvl1": "Prepare Your Container Environment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/index.html#prepare-your-container-environment",
    "content": "Find resources and operations for preparing your container environment. Title Description Set Environment Images How to use Determined-provided containers that include common deep learning libraries and frameworks for GPU and CPU training. Customizing Your Environment How to set environment variables, use a startup hook, and use custom and default Docker images.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#customizing-your-environment",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#customizing-your-environment",
    "content": "Determined launches workloads using Docker containers. By default, workloads execute inside a Determined-provided container that includes common deep learning libraries and frameworks. If your model code has additional dependencies, the easiest way to install them is to specify a startup hook. For more complex dependencies, use a custom Docker image. If you are using Determined on Kubernetes, review the Custom Pod Specs guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Environment Variables",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#environment-variables",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Environment Variables",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#environment-variables",
    "content": "For both trial runners and commands, you can configure the environment variables inside the container using the experiment or task environment.environment_variables configuration field. The format is a list of NAME=VALUE strings. For example: environment: environment_variables: - A=hello world - B=$A - C=${B} Variables are set sequentially, which affect variables that depend on the expansion of other variables. In the example, names A, B, and C each have the value hello_world in the container. Proxy variables set in this way take precedent over variables set in the agent configuration. You can also set variables for each accelerator type, separately: environment: environment_variables: cpu: - A=hello x86 gpu: - A=hello nvidia rocm: - A=hello amd",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Startup Hooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#startup-hooks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Startup Hooks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#startup-hooks",
    "content": "If a startup-hook.sh file exists in the top level of your model definition directory, this file is automatically run with every Docker container startup. This occurs before any Python interpreters are launched or deep learning operations are performed. The startup hook can be used to customize the container environment, install additional dependencies, and download data sets among other shell script commands. Startup hooks are not cached and run before the start of every workload, so expensive or long-running operations in a startup hook can result in poor performance. This example startup hook installs the wget utility and the pandas Python package: apt-get update && apt-get install -y wget python3 -m pip install pandas This Iris example contains a TensorFlow Keras model that uses a startup hook to install an additional Python dependency.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#container-images",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#container-images",
    "content": "Officially supported, default Docker images are provided to launch containers for experiments, commands, and other workflows. All trial runner containers are launched with additional Determined-specific harness code, which orchestrates model training and evaluation in the container. Trial runner containers are also loaded with the experiment\u2019s model definition and hyperparameter values for the current trial. GPU-specific versions of each library are automatically selected when running on agents with GPUs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": "Default Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#default-images",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": "Default Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#default-images",
    "content": "Environment File Name CPUs determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 NVIDIA GPUs determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 AMD GPUs determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-0.24.0",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": "Custom Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#custom-images",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Container Images",
      "lvl3": "Custom Images",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#custom-images",
    "content": "While the official images contain all the dependencies needed for basic deep learning workloads, many workloads have additional dependencies. If the extra dependencies are quick to install, you might consider using a startup hook. Where installing dependencies using startup-hook.sh takes too long, it is recommended that you build your own Docker image and publish to a Docker registry, such as Docker Hub. Do NOT install TensorFlow, PyTorch, Horovod, or Apex packages, which conflict with Determined-installed packages. It is recommended that custom images use one of the official Determined images as a base image, using the FROM instruction. Example Dockerfile that installs custom conda-, pip-, and apt-based dependencies: # Determined Image FROM determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 # Custom Configuration RUN apt-get update && \\ DEBIAN_FRONTEND=\"noninteractive\" apt-get -y install tzdata && \\ apt-get install -y unzip python-opencv graphviz COPY environment.yml /tmp/environment.yml COPY pip_requirements.txt /tmp/pip_requirements.txt RUN conda env update --name base --file /tmp/environment.yml RUN conda clean --all --force-pkgs-dirs --yes RUN eval \"$(conda shell.bash hook)\" && \\ conda activate base && \\ pip install --requirement /tmp/pip_requirements.txt Assuming that this image is published to a public repository on Docker Hub, use the following declaration format to configure an experiment, command, or notebook: environment: image: \"my-user-name/my-repo-name:my-tag\" where my-user-name is your Docker Hub user, my-repo-name is the name of the Docker Hub repository, and my-tag is the image tag to use, such as latest. If you publish your image to a private Docker Hub repository, you can specify the credentials needed to access the repository: environment: image: \"my-user-name/my-repo-name:my-tag\" registry_auth: username: my-user-name password: my-password If you publish the image to a private Docker Registry, specify the registry path as part of the image field: environment: image: \"myregistry.local:5000/my-user-name/my-repo-name:my-tag\" Images are fetched using HTTPS by default. An HTTPS proxy can be configured using the https_proxy field in the agent configuration. The custom image and credentials can be set as the defaults for all tasks launched in Determined, using the image and registry_auth fields in the master configuration. Make sure to restart the master for this to take effect.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Virtual Environments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#virtual-environments",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Customizing Your Environment",
      "lvl1": "Customizing Your Environment",
      "lvl2": "Virtual Environments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/custom-env.html#virtual-environments",
    "content": "Model developers commonly use virtual environments. The following example configures virtual environments using custom images: # Determined Image FROM determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 # Create a virtual environment RUN conda create -n myenv python=3.8 RUN eval \"$(conda shell.bash hook)\" && \\ conda activate myenv && \\ pip install scikit-learn # Set the default virtual environment RUN echo 'eval \"$(conda shell.bash hook)\" && conda activate myenv' >> ~/.bashrc To ensure that a virtual environment is activated every time a new interactive terminal session is created, in JupyterLab or using Determined Shell, update ~/.bashrc with the scripts to activate the virtual environment you want. This example switches to a virtual environment using a startup hook: # Switch to the desired virtual environment eval \"$(conda shell.bash hook)\" conda activate myenv # Do that for every new interactive terminal session echo 'eval \"$(conda shell.bash hook)\" && conda activate myenv' >> ~/.bashrc",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set Environment Images",
      "lvl1": "Set Environment Images",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/set-environment-images.html#set-environment-images",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Set Environment Images",
      "lvl1": "Set Environment Images",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/prepare-container/set-environment-images.html#set-environment-images",
    "content": "Determined launches workloads using Docker containers. By default, workloads execute inside a Determined-provided container that includes common deep learning libraries and frameworks. The default containers can be found on the Determined Docker Hub with tags for each Determined version: Default containers for CPU training Default containers for GPU training By default, Determined will use the tag corresponding to your cluster\u2019s version. To specify a different image from this default, update your job configuration to include: environment: image: cpu: # full CPU image path, e.g., determined/environments/<tag> gpu: # full GPU image path, e.g., determined/environments/<tag> If one of the images above contain your required libraries, there is no additional environment preparation needed. If you need to add additional customization to the training environment, review the Customizing Your Environment page.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "API Guides",
      "lvl1": "API Guides",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/index.html#api-guides",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "API Guides",
      "lvl1": "API Guides",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/index.html#api-guides",
    "content": "Training API Guides: Learn how to use the training APIs including the Core API and the High-Level APIs. Inference API Guides: Learn how to use the batch processing API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#training-apis",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#training-apis",
    "content": "You can train almost any deep learning model using the Determined Training APIs. The Training API guides describe how to take your existing model code and train your model in Determined. Each API guide contains a link to its corresponding API reference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "Core API",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#core-api",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "Core API",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#core-api",
    "content": "The Core API is a low-level, flexible API that lets you train models in any deep learning framework. With the Core API, you can plug in your existing training code. You\u2019ll then use an experiment configuration to tell Determined how to train the model - e.g., multi-GPU, hyperparameter search, etc. Core API User Guide",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#high-level-apis",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#high-level-apis",
    "content": "The Trial APIs offer higher-level integrations with popular deep learning frameworks. With the Trial APIs, you first convert your existing training code by subclassing a Trial class and implementing methods that define each component of training - e.g., model architecture, data loader, optimizer, learning rate scheduler, callbacks, etc. This is called the Trial definition. With the code structured in this way, Determined is able to run the training loop and provide advanced training and model management capabilities. Once you have converted your code, you can use an experiment configuration to tell Determined how to train the model - e.g., multi-GPU, hyperparameter search, etc. PyTorch API Keras API DeepSpeed API",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": "Looking for a Basic Tutorial?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#looking-for-a-basic-tutorial",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": "Looking for a Basic Tutorial?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#looking-for-a-basic-tutorial",
    "content": "If you\u2019d like to review how to implement the Determined APIs on simple models, visit our Tutorials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": "Prefer to use an Example Model?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#prefer-to-use-an-example-model",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "High-Level APIs",
      "lvl3": "Prefer to use an Example Model?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#prefer-to-use-an-example-model",
    "content": "If you\u2019d like to build off of an existing model that already runs on Determined, visit our Examples to see if the model you\u2019d like to train is already available.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "TensorFlow Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#tensorflow-support",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "TensorFlow Support",
      "lvl3": "TensorFlow Core Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#tensorflow-core-models",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "TensorFlow Support",
      "lvl3": "TensorFlow Core Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#tensorflow-core-models",
    "content": "Determined has support for TensorFlow models that use the Keras API. For models that use the low-level TensorFlow Core APIs, we recommend wrapping your model in Keras, as recommended by the official TensorFlow documentation.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "TensorFlow Support",
      "lvl3": "TensorFlow 1 vs 2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#tensorflow-1-vs-2",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "TensorFlow Support",
      "lvl3": "TensorFlow 1 vs 2",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#tensorflow-1-vs-2",
    "content": "Determined supports both TensorFlow 1 and 2. The version of TensorFlow that is used for a particular experiment is controlled by the container image that has been configured for that experiment. Determined provides prebuilt Docker images that include TensorFlow 2.11, 1.15, and 2.8, respectively: determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-0.24.0 (default) determinedai/environments:cuda-10.2-pytorch-1.7-tf-1.15-gpu-0.21.2 determinedai/environments:cuda-11.2-tf-2.8-gpu-0.24.0 We also provide lightweight CPU-only counterparts: determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-0.24.0 determinedai/environments:py-3.7-pytorch-1.7-tf-1.15-cpu-0.21.2 determinedai/environments:py-3.8-tf-2.8-cpu-0.24.0 To change the container image used for an experiment, specify environment.image in the experiment configuration file. Please see Container Images for more details about configuring training environments and a more complete list of prebuilt Docker images.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "AMD ROCm Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#amd-rocm-support",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Training APIs",
      "lvl1": "Training APIs",
      "lvl2": "AMD ROCm Support",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/index.html#amd-rocm-support",
    "content": "Determined has experimental support for ROCm. Determined provides a prebuilt Docker image that includes ROCm 5.0, PyTorch 1.10 and TensorFlow 2.7: determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-0.24.0 Known limitations: Only agent-based deployments are available; Kubernetes is not yet supported. GPU profiling is not yet supported.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#keras-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#keras-api",
    "content": "In this guide, you\u2019ll learn how to use the Keras API. Visit the API reference det.keras API Reference This document guides you through training a Keras model in Determined. You need to implement a trial class that inherits TFKerasTrial and specify it as the entrypoint in the experiment configuration. To learn about this API, you can start by reading the trial definitions from the following examples: Fashion MNIST example CIFAR-10 example",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Load Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#load-data",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Load Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#load-data",
    "content": "Before loading data, visit Prepare Data to understand how to work with different sources of data. Loading data is done by defining build_training_data_loader() and build_validation_data_loader() methods. Each should return one of the following data types: A tuple (x, y) of NumPy arrays. x must be a NumPy array (or array-like), a list of arrays (in case the model has multiple inputs), or a dict mapping input names to the corresponding array, if the model has named inputs. y should be a numpy array. A tuple (x, y, sample_weights) of NumPy arrays. A tf.data.dataset returning a tuple of either (inputs, targets) or (inputs, targets, sample_weights). A keras.utils.Sequence returning a tuple of either (inputs, targets) or (inputs, targets, sample weights). If using tf.data.Dataset, users are required to wrap both their training and validation dataset using self.context.wrap_dataset. This wrapper is used to shard the dataset for distributed training. For optimal performance, users should wrap a dataset immediately after creating it. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Define the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#define-the-model",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Define the Model",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#define-the-model",
    "content": "Users are required wrap their model prior to compiling it using self.context.wrap_model. This is typically done inside build_model().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Customize Calling Model Fitting Function",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#customize-calling-model-fitting-function",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Customize Calling Model Fitting Function",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#customize-calling-model-fitting-function",
    "content": "The TFKerasTrial interface allows the user to configure how model.fit is called by calling self.context.configure_fit().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Checkpointing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#checkpointing",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Checkpointing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#checkpointing",
    "content": "A checkpoint includes the model definition (Python source code), experiment configuration file, network architecture, and the values of the model\u2019s parameters (i.e., weights) and hyperparameters. When using a stateful optimizer during training, checkpoints will also include the state of the optimizer (i.e., learning rate). You can also embed arbitrary metadata in checkpoints via a Python SDK. TensorFlow Keras trials are checkpointed to a file named determined-keras-model.h5 using tf.keras.models.save_model. You can learn more from the TF Keras docs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Callbacks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#callbacks",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Keras API",
      "lvl1": "Keras API",
      "lvl2": "Callbacks",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-keras-ug.html#callbacks",
    "content": "To execute arbitrary Python code during the lifecycle of a TFKerasTrial, implement the determined.keras.callbacks.Callback interface (an extension of the tf.keras.callbacks.Callbacks interface) and supply them to the TFKerasTrial by implementing keras_callbacks().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-api",
    "content": "In this guide, you\u2019ll learn how to use PyTorch Trial and PyTorch Trainer. Visit the API reference determined.pytorch.PyTorchTrial",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-trial",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-trial",
    "content": "To train a PyTorch model in Determined, you need to implement a trial class that inherits from PyTorchTrial and specify it as the entrypoint in the experiment configuration. To implement a PyTorchTrial, you need to override specific functions that represent the components that are used in the training procedure. It is helpful to work off of a skeleton to keep track of what is still required. A good starting template can be found below: from typing import Any, Dict, Union, Sequence from determined.pytorch import DataLoader, PyTorchTrial, PyTorchTrialContext TorchData = Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor] class MyTrial(PyTorchTrial): def __init__(self, context: PyTorchTrialContext) -> None: self.context = context def build_training_data_loader(self) -> DataLoader: return DataLoader() def build_validation_data_loader(self) -> DataLoader: return DataLoader() def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int) -> Dict[str, Any]: return {} def evaluate_batch(self, batch: TorchData) -> Dict[str, Any]: return {} To learn more about the PyTorch API, you can start by reading the trial definitions from the following examples: cifar10_pytorch.tgz mnist_pytorch.tgz fasterrcnn_coco_pytorch.tgz For tips on debugging, see How to Debug Models.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Distributed Backend",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#distributed-backend",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Distributed Backend",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#distributed-backend",
    "content": "By default, PyTorch Trial uses Horovod as the backend. You can choose to use torch.distributed and DistributedDataParallel as your distributed backend, by following PyTorch Distributed Launcher.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Download Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#download-data",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Download Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#download-data",
    "content": "Before continuing, read how to Prepare Data to understand how to work with different sources of data. There are two ways to download your dataset in the PyTorch API: Download the data in the startup-hook.sh. Download the data in the constructor function __init__() of PyTorchTrial. If you are running a distributed training experiment, we suggest you to use the second approach. During distributed training, a trial needs running multiple processes on different containers. In order for all the processes to have access to the data and to prevent multiple download download processes (one process per GPU) from conflicting with one another, the data should be downloaded to unique directories for different ranks. See the following code as an example: def __init__(self, context) -> None: self.context = context # Create a unique download directory for each rank so they don't overwrite each # other when doing distributed training. self.download_directory = f\"/tmp/data-rank{self.context.distributed.get_rank()}\" self.download_directory = download_data( download_directory=self.download_directory, url=self.context.get_data_config()[\"url\"], )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#load-data",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Load Data",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#load-data",
    "content": "Loading data into PyTorchTrial models is done by defining two functions, build_training_data_loader() and build_validation_data_loader(). Each function should return an instance of determined.pytorch.DataLoader. The determined.pytorch.DataLoader class behaves the same as torch.utils.data.DataLoader and is a drop-in replacement in most cases. It handles distributed training with PyTorchTrial. Each determined.pytorch.DataLoader will return batches of data, which will be fed directly to the train_batch() and evaluate_batch() functions. The batch size of the data loader will be set to the per-slot batch size, which is calculated based on global_batch_size and slots_per_trial as defined in the experiment configuration. See the following code as an example: def build_training_data_loader(self): traindir = os.path.join(self.download_directory, 'train') self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) train_dataset = datasets.ImageFolder( traindir, transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), self.normalize, ])) train_loader = determined.pytorch.DataLoader( train_dataset, batch_size=self.context.get_per_slot_batch_size(), shuffle=True, num_workers=self.context.get_hparam(\"workers\", pin_memory=True), ) return train_loader The output train_batch() returns a batch of data in one of the following formats: # A numpy array batch: np.ndarray = np.array([0, 0], [0, 0]]) # A PyTorch tensor batch: torch.Tensor = torch.Tensor([[0, 0], [0, 0]]) # A tuple of arrays or tensors batch: Tuple[np.ndarray] = (np.array([0, 0]), np.array([0, 0])) batch: Tuple[torch.Tensor] = (torch.Tensor([0, 0]), torch.Tensor([0, 0])) # A list of arrays or tensors batch: List[np.ndarray] = [np.array([0, 0]), np.array([0, 0])] batch: List[torch.Tensor] = [torch.Tensor([0, 0]), torch.Tensor([0, 0])] # A dictionary mapping strings to arrays or tensors batch: Dict[str, np.ndarray] = {\"data\": np.array([0, 0]), \"label\": np.array([0, 0])} batch: Dict[str, torch.Tensor] = {\"data\": torch.Tensor([0, 0]), \"label\": torch.Tensor([0, 0])} # A combination of the above batch = { \"data\": [ {\"sub_data1\": torch.Tensor([[0, 0], [0, 0]])}, {\"sub_data2\": torch.Tensor([0, 0])}, ], \"label\": (torch.Tensor([0, 0]), torch.Tensor([[0, 0], [0, 0]])), }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#initialize-objects",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#initialize-objects",
    "content": "You need to initialize the objects that will be used in training in the constructor __init__() of determined.pytorch.PyTorchTrial using the provided context: these objects include the model(s), optimizer(s), learning rate scheduler(s), and custom loss and metric functions. See __init__() for details. Be sure to wrap your objects! You may see metrics for trials that are paused and later continued that are significantly different from trials that are not paused if some of your models, optimizers, and learning rate schedulers are not wrapped. The reason is that the model\u2019s state may not be restored accurately or completely from the checkpoint, which is saved to a checkpoint and then later loaded into the trial during resumed training. When using PyTorch, this can sometimes happen if the PyTorch API is not used correctly.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": "Optimizers",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#optimizers",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": "Optimizers",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#optimizers",
    "content": "You need to call the wrap_optimizer() method of the PyTorchTrialContext to wrap your instantiated optimizers in the __init__() constructor. For example, def __init__(self, context: PyTorchTrialContext): self.context = context ... optimizer = torch.optim.SGD( self.model.parameters(), self.context.get_hparam(\"lr\"), momentum=self.context.get_hparam(\"momentum\"), weight_decay=self.context.get_hparam(\"weight_decay\"), ) self.optimizer = self.context.wrap_optimizer(optimizer) Then you need to step your optimizer in the train_batch() (see Optimization Step below).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": "Learning Rate Schedulers",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#learning-rate-schedulers",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Initialize Objects",
      "lvl4": "Learning Rate Schedulers",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#learning-rate-schedulers",
    "content": "Determined has a few ways of managing the learning rate. Determined can automatically update every batch or epoch, or you can manage it yourself. You need to call the wrap_lr_scheduler() method of the PyTorchTrialContext to wrap your instantiated learning rate schedulers in the __init__() constructor. For example, def __init__(self, context: PyTorchTrialContext): self.context = context ... lr_sch = torch.optim.lr_scheduler.StepLR(self.optimizer, gamma=.1, step_size=2) self.lr_sch = self.context.wrap_lr_scheduler( lr_sch, step_mode=LRScheduler.StepMode.STEP_EVERY_EPOCH, ) If your learning rate scheduler uses the manual step mode, you will need to step your learning rate scheduler in the train_batch() method of PyTorchTrial by calling: def train_batch(self, batch: pytorch.TorchData, epoch_idx: int, batch_idx: int) ... self.lr_sch.step() ...",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Training Loop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#define-the-training-loop",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Training Loop",
      "lvl4": "Optimization Step",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#optimization-step",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Training Loop",
      "lvl4": "Optimization Step",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#optimization-step",
    "content": "You need to implement the train_batch() method of your PyTorchTrial subclass. Typically when training with native PyTorch, you write a training loop, which iterates through the dataloader to access and train your model one batch at a time. You can usually identify this code by finding the common code snippet: for batch in dataloader. In Determined, train_batch() also works with one batch at a time. Take this script implemented with the native PyTorch as an example. It has the following code for the training loop. for i, (images, target) in enumerate(train_loader): # measure data loading time data_time.update(time.time() - end) # move data to the same device as model images = images.to(device, non_blocking=True) target = target.to(device, non_blocking=True) # compute output output = model(images) loss = criterion(output, target) # measure accuracy and record loss acc1, acc5 = accuracy(output, target, topk=(1, 5)) losses.update(loss.item(), images.size(0)) top1.update(acc1[0], images.size(0)) top5.update(acc5[0], images.size(0)) # compute gradient and do SGD step optimizer.zero_grad() loss.backward() optimizer.step() # measure elapsed time batch_time.update(time.time() - end) end = time.time() if i % args.print_freq == 0: progress.display(i + 1) Notice that this pure-PyTorch loop manages the per-batch metrics. With Determined, metrics returned by train_batch() are automatically averaged and displayed, so we do not need to do this ourselves. Next, we will convert some PyTorch functions to use Determined\u2019s equivalents. We need to change optimizer.zero_grad(), loss.backward(), and optimizer.step(). The self.context object will be used to call loss.backwards and handle zeroing and stepping the optimizer. The final train_batch() will look like: def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int): images, target = batch output = self.model(images) loss = self.criterion(output, target) acc1, acc5 = self.accuracy(output, target, topk=(1, 5)) self.context.backward(loss) self.context.step_optimizer(self.optimizer) return {\"loss\": loss.item(), \"top1\": acc1[0], \"top5\": acc5[0]}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Training Loop",
      "lvl4": "Checkpointing",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#checkpointing",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Training Loop",
      "lvl4": "Checkpointing",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#checkpointing",
    "content": "A checkpoint includes the model definition (Python source code), experiment configuration file, network architecture, and the values of the model\u2019s parameters (i.e., weights) and hyperparameters. When using a stateful optimizer during training, checkpoints will also include the state of the optimizer (i.e., learning rate). You can also embed arbitrary metadata in checkpoints via a Python SDK. PyTorch trials are checkpointed as a state-dict.pth file. This file is created in a similar manner to the procedure described in the PyTorch documentation, but instead of the fields in that documentation, the dictionary will have four keys: models_state_dict, optimizers_state_dict, lr_schedulers_state_dict, and callbacks, which are the state_dict of the models, optimizers, LR schedulers, and callbacks respectively.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Validation Loop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#define-the-validation-loop",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Define the Validation Loop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#define-the-validation-loop",
    "content": "You need to implement either the evaluate_batch() or evaluate_full_dataset() method. To load data into the validation loop, define build_validation_data_loader(). To define reducing metrics, define evaluation_reducer(). For example, def evaluate_batch(self, batch: TorchData): images, target = batch output = self.model(images) validation_loss = self.criterion(output, target) return {\"validation_loss\": loss.item()}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Callbacks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#callbacks",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Callbacks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#callbacks",
    "content": "To execute arbitrary Python code during the lifecycle of a PyTorchTrial, implement the PyTorchCallback and supply them to the PyTorchTrial by implementing build_callbacks().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#advanced-usage",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Gradient Clipping",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#gradient-clipping",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Gradient Clipping",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#gradient-clipping",
    "content": "Users need to pass a gradient clipping function to step_optimizer().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Reducing Metrics",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#reducing-metrics",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Reducing Metrics",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#reducing-metrics",
    "content": "Determined supports proper reduction of arbitrary training and validation metrics, even during distributed training, by allowing users to define custom reducers. Custom reducers can be either a function or an implementation of the determined.pytorch.MetricReducer interface. See determined.pytorch.PyTorchTrialContext.wrap_reducer() for more details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Customize a Reproducible Dataset",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#customize-a-reproducible-dataset",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Customize a Reproducible Dataset",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#customize-a-reproducible-dataset",
    "content": "Normally, using determined.pytorch.DataLoader is required and handles all of the below details without any special effort on your part (see Load Data). When determined.pytorch.DataLoader is not suitable (especially in the case of IterableDatasets), you may disable this requirement by calling context.experimental.disable_dataset_reproducibility_checks() in your Trial\u2019s __init__() method. Then you may choose to follow the below guidelines for ensuring dataset reproducibility on your own. Achieving a reproducible dataset that is able to pause and continue (sometimes called \u201cincremental training\u201d) is easy if you follow a few rules. Even if you are going to ultimately return an IterableDataset, it is best to use PyTorch\u2019s Sampler class as the basis for choosing the order of records. Operations on Samplers are quick and cheap, while operations on data afterwards are expensive. For more details, see the discussion of random vs sequential access here. If you don\u2019t have a custom sampler, start with a simple one: code::python sampler = torch.utils.data.SequentialSampler(my_dataset) Shuffle first: Always use a reproducible shuffle when you shuffle. Determined provides two shuffling samplers for this purpose; the ReproducibleShuffleSampler for operating on records and the ReproducibleShuffleBatchSampler for operating on batches. You should prefer to shuffle on records (use the ReproducibleShuffleSampler) whenever possible, to achieve the highest-quality shuffle. Repeat when training: In Determined, you always repeat your training dataset and you never repeat your validation datasets. Determined provides a RepeatSampler and a RepeatBatchSampler to wrap your sampler or batch_sampler. For your training dataset, make sure that you always repeat AFTER you shuffle, otherwise your shuffle will hang. Always shard, and not before a repeat: Use Determined\u2019s DistributedSampler or DistributedBatchSampler to provide a unique shard of data to each worker based on your sampler or batch_sampler. It is best to always shard your data, and even when you are not doing distributed training, because in non-distributed-training settings, the sharding is nearly zero-cost, and it makes distributed training seamless if you ever want to use it in the future. It is generally important to shard after you repeat, unless you can guarantee that each shard of the dataset will have the same length. Otherwise, differences between the epoch boundaries for each worker can grow over time, especially on small datasets. If you shard after you repeat, you can change the number of workers arbitrarily without issue. Skip when training, and always last: In Determined, training datasets should always be able to start from an arbitrary point in the dataset. This allows for advanced hyperparameter searches and responsive preemption for training on spot instances in the cloud. The easiest way to do this, which is also very efficient, is to apply a skip to the sampler. Determined provides a SkipBatchSampler that you can apply to your batch_sampler for this purpose. There is also a SkipSampler that you can apply to your sampler, but you should prefer to skip on batches unless you are confident that your dataset always yields identical size batches, where the number of records to skip can be reliably calculated from the number of batches already trained. Always skip AFTER your repeat, so that the skip only happens once, and not on every epoch. Always skip AFTER your shuffle, to preserve the reproducibility of the shuffle. Here is some example code that follows each of these rules that you can use as a starting point if you find that the built-in context.DataLoader() does not support your use case. def make_batch_sampler( sampler_or_dataset, mode, # mode=\"training\" or mode=\"validation\" shuffle_seed, num_workers, rank, batch_size, skip, ): if isinstance(sampler_or_dataset, torch.utils.data.Sampler): sampler = sampler_or_dataset else: # Create a SequentialSampler if we started with a Dataset. sampler = torch.utils.data.SequentialSampler(sampler_or_dataset) if mode == \"training\": # Shuffle first. sampler = samplers.ReproducibleShuffleSampler(sampler, shuffle_seed) # Repeat when training. sampler = samplers.RepeatSampler(sampler) # Always shard, and not before a repeat. sampler = samplers.DistributedSampler(sampler, num_workers=num_workers, rank=rank) # Batch before skip, because Determined counts batches, not records. batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last=False) if mode == \"training\": # Skip when training, and always last. batch_sampler = samplers.SkipBatchSampler(batch_sampler, skip) return batch_sampler class MyPyTorchTrial(det.pytorch.PyTorchTrial): def __init__(self, context): context.experimental.disable_dataset_reproducibility_checks() def build_training_data_loader(self): my_dataset = ... batch_sampler = make_batch_sampler( dataset=my_dataset, mode=\"training\", seed=self.context.get_trial_seed(), num_workers=self.context.distributed.get_size(), rank=self.distributed.get_rank(), batch_size=self.context.get_per_slot_batch_size(), skip=self.context.get_initial_batch(), ) return torch.utils.data.DataLoader(my_dataset, batch_sampler=batch_sampler) See the determined.pytorch.samplers for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Profiling",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#profiling",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Advanced Usage",
      "lvl4": "Profiling",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#profiling",
    "content": "Determined provides support for the native PyTorch profiler, torch-tb-profiler. You can configure this by calling set_profiler() from within your Trial\u2019s __init__. set_profiler accepts the same arguments as the PyTorch plugin\u2019s torch.profiler.profile method. However, Determined sets on_trace_ready to the appropriate TensorBoard path, and the stepping of the profiler during training is automatically handled. The following example profiles CPU and GPU activities on batches 3 and 4 (skipping batch 1, warming up on batch 2), and repeats for 2 cycles: class MyPyTorchTrial(det.pytorch.PyTorchTrial): def __init__(self, context): context.set_profiler( activities=[ torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA, ], schedule=torch.profiler.schedule( wait=1, warmup=1, active=2, repeat=2, ), ) See the PyTorch tensorboard profiler tutorial for a complete list of accepted configurations parameters.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#porting-checklist",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#porting-checklist",
    "content": "If you port your code to Determined, you should walk through this checklist to ensure your code does not conflict with the Determined library.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Remove Pinned GPUs",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#remove-pinned-gpus",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Remove Pinned GPUs",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#remove-pinned-gpus",
    "content": "Determined handles scheduling jobs on available slots. However, you need to let the Determined library handles choosing the GPUs. Take this script as an example. It has the following code to configure the GPU: if args.gpu is not None: print(\"Use GPU: {} for training\".format(args.gpu)) Any use of args.gpu should be removed.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Remove Distributed Training Code",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#remove-distributed-training-code",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Remove Distributed Training Code",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#remove-distributed-training-code",
    "content": "To run distributed training outside Determined, you need to have code that handles the logic of launching processes, moving models to pined GPUs, sharding data, and reducing metrics. You need to remove this code to be not conflict with the Determined library. Take this script as an example. It has the following code to initialize the process group: if args.distributed: if args.dist_url == \"env://\" and args.rank == -1: args.rank = int(os.environ[\"RANK\"]) if args.multiprocessing_distributed: # For multiprocessing distributed training, rank needs to be the # global rank among all the processes args.rank = args.rank * ngpus_per_node + gpu dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank) This example also has the following code to set up CUDA and converts the model to a distributed one. if not torch.cuda.is_available(): print('using CPU, this will be slow') elif args.distributed: # For multiprocessing distributed, DistributedDataParallel constructor # should always set the single device scope, otherwise, # DistributedDataParallel will use all available devices. if args.gpu is not None: torch.cuda.set_device(args.gpu) model.cuda(args.gpu) # When using a single GPU per process and per # DistributedDataParallel, we need to divide the batch size # ourselves based on the total number of GPUs we have args.batch_size = int(args.batch_size / ngpus_per_node) args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node) model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu]) else: model.cuda() # DistributedDataParallel will divide and allocate batch_size to all # available GPUs if device_ids are not set model = torch.nn.parallel.DistributedDataParallel(model) elif args.gpu is not None: torch.cuda.set_device(args.gpu) model = model.cuda(args.gpu) else: # DataParallel will divide and allocate batch_size to all available GPUs if args.arch.startswith('alexnet') or args.arch.startswith('vgg'): model.features = torch.nn.DataParallel(model.features) model.cuda() else: model = torch.nn.DataParallel(model).cuda() This code is unnecessary in the trial definition. When we create the model, we will wrap it with self.context.wrap_model(model), which will convert the model to distributed if needed. We will also automatically set up horovod for you. If you would like to access the rank (typically used to view per GPU training), you can get it by calling self.context.distributed.rank. To handle data loading in distributed training, this example has the code below: traindir = os.path.join(args.data, 'train') valdir = os.path.join(args.data, 'val') normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) train_dataset = datasets.ImageFolder( traindir, transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize, ])) # Handle distributed sampler for distributed training. if args.distributed: train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) else: train_sampler = None This should be removed since we will use distributed data loader if you following the instructions of build_training_data_loader() and build_validation_data_loader().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Get Hyperparameters from PyTorchTrialContext",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#get-hyperparameters-from-pytorchtrialcontext",
    "content": null,
    "type": "lvl4",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 60,
      "position": 41
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trial",
      "lvl3": "Porting Checklist",
      "lvl4": "Get Hyperparameters from PyTorchTrialContext",
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#get-hyperparameters-from-pytorchtrialcontext",
    "content": "Take the following code for example. def __init__(self, context: PyTorchTrialContext): self.context = context if args.pretrained: print(\"=> using pre-trained model '{}'\".format(args.arch)) model = models.__dict__[args.arch](pretrained=True) else: print(\"=> creating model '{}'\".format(args.arch)) model = models.__dict__[args.arch]() args.arch is a hyperparameter. You should define the hyperparameter space in the experiment config. By doing so, you get better tracking in the WebUI, especially for experiments that use a searcher. Depending on how your trial is run, you can access all the current hyperparameters from inside the trial by either calling self.context.get_hparams() if you submitted your trial with entrypoint: model_def:Trial or passing in hyperparameters directly into the Trial __init__ if using PyTorch Trainer API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 42
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-trainer",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 43
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#pytorch-trainer",
    "content": "With the PyTorch Trainer API, you can implement and iterate on model training code locally before running on cluster. When you are satisfied with your model code, you configure and submit the code on cluster. The PyTorch Trainer API lets you do the following: Work locally, iterating on your model code. Debug models in your favorite debug environment (e.g., directly on your machine, IDE, or Jupyter notebook). Run training scripts without needing to use an experiment configuration file. Load previously saved checkpoints directly into your model.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 44
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Initializing the Trainer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#initializing-the-trainer",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 45
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Initializing the Trainer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#initializing-the-trainer",
    "content": "After defining the PyTorch Trial, initialize the trial and the trainer. init() returns a PyTorchTrialContext for instantiating PyTorchTrial. Initialize Trainer with the trial and context. from determined import pytorch def main(): with det.pytorch.init() as train_context: trial = MyTrial(train_context) trainer = det.pytorch.Trainer(trial, train_context) if __name__ == \"__main__\": # Configure logging logging.basicConfig(level=logging.INFO, format=det.LOG_FORMAT) main() Training is configured with a call to fit() with training loop arguments, such as checkpointing periods, validation periods, and checkpointing policy. from determined import pytorch def main(): with det.pytorch.init() as train_context: trial = MyTrial(train_context) trainer = det.pytorch.Trainer(trial, train_context) + trainer.fit( + checkpoint_period=pytorch.Batch(100), + validation_period=pytorch.Batch(100), + checkpoint_policy=\"all\" + ) if __name__ == \"__main__\": # Configure logging logging.basicConfig(level=logging.INFO, format=det.LOG_FORMAT) main()",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 46
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Run Your Training Script Locally",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#run-your-training-script-locally",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 47
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Run Your Training Script Locally",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#run-your-training-script-locally",
    "content": "Run training scripts locally without submitting to a cluster or defining an experiment configuration file. Be sure to specify max_length in the .fit() call, which is used in local training mode to determine the maximum number of steps to train for. from determined import pytorch def main(): with det.pytorch.init() as train_context: trial = MyTrial(train_context) trainer = det.pytorch.Trainer(trial, train_context) trainer.fit( max_length=pytorch.Epoch(1), checkpoint_period=pytorch.Batch(100), validation_period=pytorch.Batch(100), checkpoint_policy=\"all\", ) if __name__ == \"__main__\": # Configure logging logging.basicConfig(level=logging.INFO, format=det.LOG_FORMAT) main() You can run this Python script directly (python3 train.py), or in a Jupyter notebook. This code will train for one epoch, and checkpoint and validate every 100 batches.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 48
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Local Distributed Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#local-distributed-training",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 49
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Local Distributed Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#local-distributed-training",
    "content": "Local training can utilize multiple GPUs on a single node with a few modifications to the above code. Both Horovod and PyTorch Distributed backends are supported. def main(): + # Initialize distributed backend before pytorch.init() + dist.init_process_group(backend=\"gloo|nccl\") + # Set flag used by internal PyTorch training loop + os.environ[\"USE_TORCH_DISTRIBUTED\"] = \"true\" + # Initialize DistributedContext with det.pytorch.init( + distributed=core.DistributedContext.from_torch_distributed() ) as train_context: trial = MyTrial(train_context) trainer = det.pytorch.Trainer(trial, train_context) trainer.fit( max_length=pytorch.Epoch(1), checkpoint_period=pytorch.Batch(100), validation_period=pytorch.Batch(100), checkpoint_policy=\"all\" ) This code can be directly invoked with your distributed backend\u2019s launcher: torchrun --nproc_per_node=4 train.py",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 50
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Test Mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#test-mode",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 51
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Test Mode",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#test-mode",
    "content": "Trainer accepts a test_mode parameter which, if true, trains and validates your training code for only one batch, checkpoints, then exits. This is helpful for debugging code or writing automated tests around your model code. trainer.fit( max_length=pytorch.Epoch(1), checkpoint_period=pytorch.Batch(100), validation_period=pytorch.Batch(100), + test_mode=True )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 52
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Prepare Your Training Code for Deploying to a Determined Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#prepare-your-training-code-for-deploying-to-a-determined-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 53
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Prepare Your Training Code for Deploying to a Determined Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#prepare-your-training-code-for-deploying-to-a-determined-cluster",
    "content": "Once you are satisfied with the results of training the model locally, you submit the code to a cluster. This example allows for distributed training locally and on cluster without having to make code changes. Example workflow of frequent iterations between local debugging and cluster deployment: def main(): + local = det.get_cluster_info() is None + if local: + # Local: configure local distributed training. + dist.init_process_group(backend=\"gloo|nccl\") + os.environ[\"USE_TORCH_DISTRIBUTED\"] = \"true\" + distributed_context = core.DistributedContext.from_torch_distributed() + latest_checkpoint = None + else: + # On-cluster: Determined will automatically detect distributed context. + distributed_context = None + # On-cluster: configure the latest checkpoint for pause/resume training functionality. + latest_checkpoint = det.get_cluster_info().latest_checkpoint + with det.pytorch.init( + distributed=distributed_context ) as train_context: trial = MNistTrial(train_context) trainer = det.pytorch.Trainer(trial, train_context) trainer.fit( max_length=pytorch.Epoch(1), checkpoint_period=pytorch.Batch(100), validation_period=pytorch.Batch(100), + latest_checkpoint=latest_checkpoint, ) To run Trainer API solely on-cluster, the code is much simpler: def main(): with det.pytorch.init() as train_context: trial_inst = model.MNistTrial(train_context) trainer = det.pytorch.Trainer(trial_inst, train_context) trainer.fit( checkpoint_period=pytorch.Batch(100), validation_period=pytorch.Batch(100), latest_checkpoint=det.get_cluster_info().latest_checkpoint, )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 54
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Submit Your Trial for Training on Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#submit-your-trial-for-training-on-cluster",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 55
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Submit Your Trial for Training on Cluster",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#submit-your-trial-for-training-on-cluster",
    "content": "To run your experiment on cluster, you\u2019ll need to create an experiment configuration (YAML) file. Your experiment configuration file must contain searcher configuration and entrypoint. name: pytorch_trainer_trial searcher: name: single metric: validation_loss max_length: epochs: 1 resources: slots_per_trial: 8 entrypoint: python3 -m determined.launch.torch_distributed python3 train.py Submit the trial to the cluster: det e create det.yaml . If your training code needs to read some values from the experiment configuration, pytorch.init() accepts an exp_conf argument which allows calling context.get_experiment_config() from PyTorchTrialContext.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 56
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Loading Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#loading-checkpoints",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 57
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorch API",
      "lvl1": "PyTorch API",
      "lvl2": "PyTorch Trainer",
      "lvl3": "Loading Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-pytorch-ug.html#loading-checkpoints",
    "content": "To load a checkpoint from a checkpoint saved using Trainer, you\u2019ll need to download the checkpoint to a file directory and use determined.pytorch.load_trial_from_checkpoint_path(). If your Trial was instantiated with arguments, you can pass them via the trial_kwargs parameter of load_trial_from_checkpoint_path.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 58
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#core-api-user-guide",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#core-api-user-guide",
    "content": "This guide will help you get up and running with the Core API. Visit the API reference det.core API Reference In this user guide, we\u2019ll show you how to adapt model training code to use the Core API. As an example, we\u2019ll be working with the PyTorch MNIST model.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Objectives",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#objectives",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Objectives",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#objectives",
    "content": "These step-by-step instructions walk you through modifying a script for the purpose of performing the following functions: Report metrics Report checkpoints Perform a hyperparameter search Perform distributed training After completing the steps in this user guide, you will be able to: Understand the minimum requirements for running an experiment Modify a script and an experiment configuration file Understand how to convert model code Use the Core API to train a model",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#prerequisites",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Prerequisites",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#prerequisites",
    "content": "Required A Determined cluster Recommended Quickstart for Model Developers",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 1: Get the Tutorial Files & Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-1-get-the-tutorial-files-run-the-experiment",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 1: Get the Tutorial Files & Run the Experiment",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-1-get-the-tutorial-files-run-the-experiment",
    "content": "To run an experiment, you need, at minimum, a script and an experiment configuration (YAML) file. Create a new directory. Access the tutorial files via the core_api_pytorch_mnist.tgz download link or directly from the Github repository. These scripts have already been modified to fit the steps outlined in this tutorial. In this initial step, we\u2019ll run our experiment using the model_def.py script and its accompanying const.yaml experiment configuration file. CD into the directory and run this command: det e create const.yaml . -f det e create const.yaml . -f instructs Determined to follow the logs of the first trial that is created as part of the experiment. The command will stay active and display the live output from the logs of the first trial as it progresses. Open the Determined WebUI by navigating to the master URL. One way to do this is to navigate to http://localhost:8080/, accept the default username of determined, and click Sign In. A password is not required. This tutorial provides instructions for running a local distributed training job. Your setup may be different. For example, for instructions on how to run a remote distributed training job, visit the Quickstart for Model Developers. In the WebUI, select your experiment. You\u2019ll notice the tabs do not yet contain any information. In the next section, we\u2019ll report training and validation metrics.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-report-metrics",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-report-metrics",
    "content": "To report training and validation metrics to the Determined master, we\u2019ll add a few lines of code to our script. More specifically, we\u2019ll create a Context object to allow interaction with the master. Then, we\u2019ll pass the core_context as an argument into main(), train(), and test() and modify the function headers accordingly. To run our experiment, we\u2019ll use the model_def_metrics.py script and its accompanying metrics.yaml experiment configuration file. For this tutorial, we\u2019ve already created the script for you. Take a moment to review the changes we\u2019ve made to the provided script so that you\u2019ll know how to modify your own script. To run the experiment, you can either use the provided scripts, which have already been modified, or you can build your own file by making changes to \u201cmodel_def.py\u201d. Begin by importing Determined: import determined as det",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.1: Modify the Main Loop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-1-modify-the-main-loop",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.1: Modify the Main Loop",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-1-modify-the-main-loop",
    "content": "We\u2019ll need a Context object for interacting with the master. To accomplish this, we\u2019ll modify the __main__ loop to include core_context: Refer to the if __name__ == \"__main__\": block in model_def_metrics.py if __name__ == \"__main__\": # NEW: Establish new determined.core.Context and pass to main # function. with det.core.init() as core_context: main(core_context=core_context)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.2: Modify the Train Method",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-2-modify-the-train-method",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.2: Modify the Train Method",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-2-modify-the-train-method",
    "content": "Use core_context.train to report training and validation metrics. Begin by importing the determined module: # NEW: Report training metrics to Determined # master via core_context. # Index by (batch_idx + 1) * (epoch-1) * len(train_loader) # to continuously plot loss on one graph for consecutive # epochs. core_context.train.report_training_metrics( steps_completed=batches_completed + epoch_idx * len(train_loader), metrics={\"train_loss\": loss.item()}, ) and core_context.train.report_validation_metrics(): # NEW: Report validation metrics to Determined master # via core_context. core_context.train.report_validation_metrics( steps_completed=steps_completed, metrics={\"test_loss\": test_loss}, )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.3: Modify the Test Method",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-3-modify-the-test-method",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.3: Modify the Test Method",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-3-modify-the-test-method",
    "content": "Modify the test() function header to include args and other elements you\u2019ll need during the evaluation loop. The args variable lets you pass configuration settings such as batch size and learning rate. In addition, pass the newly created core_context into both train() and test(). Passing core_context enables reporting of metrics to the Determined master. # NEW: Pass core_context into train() and test(). train(args, model, device, train_loader, optimizer, epoch_idx, core_context) # NEW: Pass args, test_loader, epoch, and steps_completed into # test(). test( args, model, device, test_loader, epoch_idx, core_context, steps_completed=steps_completed, ) scheduler.step() Create a steps_completed variable to plot metrics on a graph in the WebUI: # NEW: Calculate steps_completed for plotting test metrics. steps_completed = epoch_idx * len(train_loader)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.4: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-4-run-the-experiment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 2: Report Metrics",
      "lvl3": "Step 2.4: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-2-4-run-the-experiment",
    "content": "Run the following command to run the experiment: det e create metrics.yaml . Open the Determined WebUI again and go to the Overview tab. The WebUI now displays metrics. In this step, you learned how to add a few new lines of code in order to report training and validation metrics to the Determined master. Next, we\u2019ll modify our script to report checkpoints.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-checkpointing",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-checkpointing",
    "content": "Checkpointing periodically during training and reporting the checkpoints to the master gives us the ability to stop and restart training. In this section, we\u2019ll modify our script for the purpose of checkpointing. In this step, we\u2019ll run our experiment using the model_def_checkpoints.py script and its accompanying checkpoints.yaml experiment configuration file. For this tutorial, we\u2019ve already created the script for you. Take a moment to review the changes we\u2019ve made to the provided script so that you\u2019ll know how to modify your own script. To run the experiment, you can either use the provided scripts, which have already been modified, or you can build your own file by making changes to \u201cmodel_def.py\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.1: Save Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-1-save-checkpoints",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.1: Save Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-1-save-checkpoints",
    "content": "To save checkpoints, add the store_path function to your script: # NEW: Save checkpoint. checkpoint_metadata_dict = {\"steps_completed\": steps_completed} # NEW: Here we are saving multiple files to our checkpoint # directory. 1) a model state file and 2) a file includes # information about the training loop state. with core_context.checkpoint.store_path(checkpoint_metadata_dict) as (path, storage_id): torch.save(model.state_dict(), path / \"checkpoint.pt\") with path.joinpath(\"state\").open(\"w\") as f: f.write(f\"{epochs_completed},{info.trial.trial_id}\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.2: Continuations",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-2-continuations",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 23
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.2: Continuations",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-2-continuations",
    "content": "There are two types of continuations: pausing and reactivating training using the WebUI or clicking Continue Trial after the experiment completes. These two types of continuations have different behaviors. While you always want to preserve the model\u2019s state, you do not always want to preserve the batch index. When you pause and reactivate you want training to continue from the same batch index, but when starting a fresh experiment you want training to start with a fresh batch index. You can save the trial ID in the checkpoint and use it to distinguish the two types of continuations. To distinguish between the two types of continuations, you can save the trial ID in the checkpoint. Enable Pausing and Resuming an Experiment To enable pausing an experiment, enable preemption: # NEW: Detect when the experiment is paused by the WebUI. if core_context.preempt.should_preempt(): return Define a load_state function for restarting model training from existing checkpoint: # NEW: Define load_state function for restarting model training from # existing checkpoint. Returns (.pt, int). # Also update load_state header to take trial info object as an argument. def load_state(checkpoint_directory, trial_id): checkpoint_directory = pathlib.Path(checkpoint_directory) with checkpoint_directory.joinpath(\"checkpoint.pt\").open(\"rb\") as f: model = torch.load(f) with checkpoint_directory.joinpath(\"state\").open(\"r\") as f: epochs_completed, ckpt_trial_id = [int(field) for field in f.read().split(\",\")] # Docs snippet start: compare checkpoint and current trial IDs # If trial ID does not match our current trial ID, we'll ignore # epochs completed and start training from epoch_idx = 0 if ckpt_trial_id != trial_id: epochs_completed = 0 # Docs snippet end: compare checkpoint and current trial IDs return model, epochs_completed If checkpoint exists, load it and assign it to model state prior to resuming training: # NEW: If checkpoint exists, load it and assign it to model state # prior to resuming training. info = det.get_cluster_info() assert info is not None, \"this example only runs on-cluster\" latest_checkpoint = info.latest_checkpoint if latest_checkpoint is None: epochs_completed = 0 else: with core_context.checkpoint.restore_path(latest_checkpoint) as path: model, epochs_completed = load_state(path, info.trial.trial_id) Enable Continuing the Trial To enable continuing the trial after the experiment completes, save the trial ID. One way to do this is to load the checkpoint and save the checkpoint in a file in the checkpoint directory. Open the checkpoint.pt file in binary mode and compare ckpt_trial_id with the current trial_id: # If trial ID does not match our current trial ID, we'll ignore # epochs completed and start training from epoch_idx = 0 if ckpt_trial_id != trial_id: epochs_completed = 0 Save the checkpoint in the checkpoint.pt file: # NEW: Save checkpoint. checkpoint_metadata_dict = {\"steps_completed\": steps_completed} # NEW: Here we are saving multiple files to our checkpoint # directory. 1) a model state file and 2) a file includes # information about the training loop state. with core_context.checkpoint.store_path(checkpoint_metadata_dict) as (path, storage_id): torch.save(model.state_dict(), path / \"checkpoint.pt\") with path.joinpath(\"state\").open(\"w\") as f: f.write(f\"{epochs_completed},{info.trial.trial_id}\") Detect when the experiment is paused by the WebUI: # NEW: Detect when the experiment is paused by the WebUI. if core_context.preempt.should_preempt(): return",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 24
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.3: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-3-run-the-experiment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 25
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 3: Checkpointing",
      "lvl3": "Step 3.3: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-3-3-run-the-experiment",
    "content": "Run the following command to run the experiment: det e create checkpoints.yaml . -f In the Determined WebUI, nagivate to the Checkpoints tab. Checkpoints are saved and deleted according to the default Checkpoint Policy. You can modify the checkpoint policy in the experiment configuration file.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 26
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 4: Hyperparameter Search",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-4-hyperparameter-search",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 27
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 4: Hyperparameter Search",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-4-hyperparameter-search",
    "content": "With the Core API you can run advanced hyperparameter searches with arbitrary training code. The hyperparameter search logic is in the master, which coordinates many different Trials. Each trial runs a train-validate-report loop: Train Train until a point chosen by the hyperparameter search algorithm and obtained via the Core API. The length of training is absolute, so you have to keep track of how much you have already trained to know how much more to train. Validate Validate your model to obtain the metric you configured in the searcher.metric field of your experiment config. Report Use the Core API to report results to the master. To perform a hyperparameter search, we\u2019ll update our script to define the hyperparameter search settings we want to use for our experiment. More specifically, we\u2019ll need to define the following settings in our experiment configuration file: name: adaptive_asha (name of our searcher. For all options, visit Search Methods. metric: test_loss smaller_is_better: True (This is equivalent to minimization vs. maximization of objective.) max_trials: 500 (This is the maximum number of trials the searcher should run.) max_length: 20 epochs (The max length of a trial. For more information, visit Adaptive ASHA in the Experiment Configuration Reference. In addition, we also need to define the hyperparameters themselves. Adaptive ASHA will pick values between the minval and maxval for each hyperparameter for each trial. To see early stopping in action, try setting max_trials to over 500 and playing around with the hyperparameter search values. In this step, we\u2019ll run our experiment using the model_def_adaptive.py script and its accompanying adaptive.yaml experiment configuration file. For this tutorial, we\u2019ve already created the script for you. Take a moment to review the changes we\u2019ve made to the provided script so that you\u2019ll know how to modify your own script. To run the experiment, you can either use the provided scripts, which have already been modified, or you can build your own file by making changes to \u201cmodel_def.py\u201d. Begin by accessing the hyperparameters in your code: # NEW: Get hparams chosen for this trial from cluster info object. hparams = info.trial.hparams Then, pass the hyperparameters into your model and optimizer: # NEW: Pass relevant hparams to model and optimizer. model = Net(hparams).to(device) optimizer = optim.Adadelta(model.parameters(), lr=hparams[\"learning_rate\"]) Ensure your model is set to use the selected values on a per-trial basis rather than your previously hardcoded values: # NEW: Add hparams to __init__. def __init__(self, hparams): # NEW: Read hyperparameters provided for this trial. super(Net, self).__init__() self.conv1 = nn.Conv2d(1, hparams[\"n_filters1\"], 3, 1) self.conv2 = nn.Conv2d(hparams[\"n_filters1\"], hparams[\"n_filters2\"], 3, 1) self.dropout1 = nn.Dropout(hparams[\"dropout1\"]) self.dropout2 = nn.Dropout(hparams[\"dropout2\"]) self.fc1 = nn.Linear(144 * hparams[\"n_filters2\"], 128) self.fc2 = nn.Linear(128, 10)",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 28
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 4: Hyperparameter Search",
      "lvl3": "Step 4.1: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-4-1-run-the-experiment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 29
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 4: Hyperparameter Search",
      "lvl3": "Step 4.1: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-4-1-run-the-experiment",
    "content": "Run the following command to run the experiment: det e create adaptive.yaml . In the Determined WebUI, navigate to the Hyperparameters tab. You should see a graph in the WebUI that displays the various trials initiated by the Adaptive ASHA hyperparameter search algorithm.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 30
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-distributed-training",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 31
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-distributed-training",
    "content": "The Core API has special features for running distributed training. Some of the more important features are: Access to all IP addresses of every node in the Trial (through the ClusterInfo API). Communication primitives such as allgather(), gather(), and broadcast() to give you out-of-the-box coordination between workers. Since many distributed training frameworks expect all workers in training to operate in-step, the should_preempt() call is automatically synchronized across workers so that all workers decide to preempt or continue as a unit. Launchers Typically, you do not have to write your own launcher. Determined provides launchers for Horovod, torch.distributed, and DeepSpeed. For more information about launcher options, visit Submit Experiment. In this example, we\u2019ll be using PyTorch\u2019s DistributedDataParallel. We\u2019ll also need to make specific changes to our configuration experiment file. In this step, we\u2019ll run our experiment using the model_def_distributed.py script and its accompanying distributed.yaml experiment configuration file. For this tutorial, we\u2019ve already created the script for you. Take a moment to review the changes we\u2019ve made to the provided script so that you\u2019ll know how to modify your own script. To run the experiment, you can either use the provided scripts, which have already been modified, or you can build your own file by making changes to \u201cmodel_def.py\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 32
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.1: Edit Your Experiment Configuration File",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-1-edit-your-experiment-configuration-file",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 33
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.1: Edit Your Experiment Configuration File",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-1-edit-your-experiment-configuration-file",
    "content": "Edit your experiment configuration file to point to a launch script: entrypoint: >- python3 -m determined.launch.torch_distributed python3 model_def_distributed.py and, set slots_per_trial (under resources) to the number of GPUs you want to distribute the training across: resources: slots_per_trial: 4",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 34
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.2: Modify Your Training Script",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-2-modify-your-training-script",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 35
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.2: Modify Your Training Script",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-2-modify-your-training-script",
    "content": "Add a few more imports to your training script: # NEW: Import torch distributed libraries. import torch import torch.distributed as dist import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torch.nn.parallel import DistributedDataParallel as DDP from torch.optim.lr_scheduler import StepLR from torch.utils.data.distributed import DistributedSampler from torchvision import datasets, transforms import determined as det Initialize a process group using torch. After initializing a process group, initialize a Determined distributed context using from_torch_distributed: if __name__ == \"__main__\": # NEW: Initialize process group using torch. dist.init_process_group(\"nccl\") # NEW: Initialize distributed context using from_torch_distributed # (obtains info such as rank, size, etc. from default torch # environment variables). distributed = det.core.DistributedContext.from_torch_distributed() with det.core.init(distributed=distributed) as core_context: main(core_context) In main, set your selected device to the device with index of local_rank. This is a best practice even if you only have a single GPU-per-node setup: Refer to the if use_cuda: block in model_def_distributed.py # NEW: Change selected device to the one with index of local_rank. device = torch.device(core_context.distributed.local_rank) elif use_mps: device = torch.device(\"mps\") else: device = torch.device(\"cpu\") Shard the data into num_replicas non-overlapping parts. num_replicas is equal to core_context.distributed.size, or the number of slots: # NEW: Create DistributedSampler object for sharding data into # core_context.distributed.size parts. train_sampler = DistributedSampler( train_dataset, num_replicas=core_context.distributed.size, rank=core_context.distributed.rank, shuffle=True, ) test_sampler = DistributedSampler( test_dataset, num_replicas=core_context.distributed.size, rank=core_context.distributed.rank, shuffle=True, ) # NEW: Shard data. train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, **train_kwargs) test_loader = torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, **test_kwargs) Wrap your model with torch\u2019s DistributedDataParallel: model = Net(hparams).to(device) # NEW: Wrap model with DDP. Aggregates gradients and synchronizes # model training across slots. model = DDP(model, device_ids=[device], output_device=device) Finally, at each place in the code where you upload checkpoints, report training metrics, or report progress to the master, make sure this is done only on rank 0, e.g.,: # NEW: Report metrics only on rank 0: only the chief worker # may report training metrics and progress, or upload checkpoints. if core_context.distributed.rank == 0: core_context.train.report_training_metrics( steps_completed=(batch_idx + 1) + epoch_idx * len(train_loader), metrics={\"train_loss\": loss.item()}, )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 36
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.3: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-3-run-the-experiment",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 37
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Step 5: Distributed Training",
      "lvl3": "Step 5.3: Run the Experiment",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#step-5-3-run-the-experiment",
    "content": "Run the following command to run the experiment: det e create distributed.yaml . In the Determined WebUI, go to the Cluster pane. You should be able to see multiple slots active corresponding to the value you set for slots_per_trial you set in distributed.yaml, as well as logs appearing from multiple ranks.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 38
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 39
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Core API User Guide",
      "lvl1": "Core API User Guide",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/api-core-ug.html#next-steps",
    "content": "In this user guide, you learned how to use the Core API to integrate a model into Determined. You also saw how to modify a training script and use the appropriate configuration file to report metrics and checkpointing, perform a hyperparameter search, and run distributed training. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 40
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorchTrial to DeepSpeedTrial",
      "lvl1": "PyTorchTrial to DeepSpeedTrial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/pytorch2deepspeed.html#pytorchtrial-to-deepspeedtrial",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "PyTorchTrial to DeepSpeedTrial",
      "lvl1": "PyTorchTrial to DeepSpeedTrial",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/pytorch2deepspeed.html#pytorchtrial-to-deepspeedtrial",
    "content": "Adapting an existing PyTorchTrial to use DeepSpeed mirrors the process for adapting existing code to use DeepSpeed outside of Determined. The first step is to switch to the DeepSpeed trial and context objects. Next, you need to initialize the model engine and replace the context calls with appropriate replacements. Remember to modify the experiment configuration, specifying an appropriate DeepSpeed configuration. Reference conversion example: -class MyTrial(PyTorchTrial): +class MyTrial(DeepSpeedTrial): def __init__(self, context): self.context = context self.args = AttrDict(self.context.get_hparams()) net = ... optimizer = ... - self.model = self.context.wrap_model(net) - self.optimizer = self.context.wrap_optimizer(optimizer) + model_engine = deepspeed.initialize( + args=self.args, + model=net, + optimizer=optimizer, + ... + ) + self.model = self.context.wrap_model_engine(model_engine) def build_training_data_loader(self) -> Any: trainset = ... return DataLoader( trainset, - batch_size=self.context.get_per_slot_batch_size(), + batch_size=self.model.train_micro_batch_size_per_gpu(), shuffle=True ) def build_validation_data_loader(self) -> Any: valset = ... return DataLoader( valset, - batch_size=self.context.get_per_slot_batch_size(), + batch_size=self.model.train_micro_batch_size_per_gpu(), shuffle=True ) - def train_batch(self, batch, epoch_idx, batch_idx): + def train_batch(self, iter_dataloader, epoch_idx, batch_idx): - inputs, targets = batch + inputs, targets = self.context.to_device( + next(iter_dataloader) + ) # Get a batch from the iterator outputs = self.model(inputs) loss = self.criterion(outputs, targets) - self.context.backward(loss) - self.context.step_optimizer(self.optimizer) + self.model.backward(loss) + self.model.step() return {\"loss\": loss} - def evaluate_batch(self, batch, batch_idx): + def evaluate_batch(self, iter_dataloader, batch_idx): - inputs, targets = batch + inputs, targets = self.context.to_device( + next(iter_dataloader) + ) # Get a batch from the iterator outputs = self.model(inputs) metric = ... return {\"metric\": metric}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed API",
      "lvl1": "DeepSpeed API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/index.html#deepspeed-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed API",
      "lvl1": "DeepSpeed API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/index.html#deepspeed-api",
    "content": "In this guide, you\u2019ll learn how to use the DeepSpeed API. Visit the API reference det.pytorch.deepspeed API Reference DeepSpeed is a Microsoft library that supports large-scale, distributed learning with sharded optimizer state training and pipeline parallelism. Determined supports DeepSpeed with the DeepSpeedTrial API. DeepSpeedTrial provides a way to use an automated training loop with DeepSpeed. Determined DeepSpeed documentation: Usage Guide guides you through how to subclass DeepSpeedTrial for your own training experiments. Advanced Usage discusses advanced topics like using multiple model engines, manual gradient aggregation, custom data loaders, and custom model parallelism. PyTorchTrial to DeepSpeedTrial covers how to convert an existing PyTorchTrial to DeepSpeedTrial. DeepSpeed Autotune: User Guide demonstrates how to use DeepSpeed Autotune to take full advantage of your hardware and model. API Reference lays out the classes and methods related to DeepSpeed support including the full API specification for DeepSpeedTrial and DeepSpeedTrialContext.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#deepspeed-autotune-user-guide",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#deepspeed-autotune-user-guide",
    "content": "Getting the most out of DeepSpeed (DS) requires aligning the many DS parameters with the specific properties of your hardware and model. Determined AI\u2019s DeepSpeed Autotune (dsat) helps to optimize these settings through an easy-to-use API with very few changes required in user-code, as we describe in the remainder of this user guide. dsat can be used with DeepSpeedTrial, Core API, and HuggingFace Trainer.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "How it Works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#how-it-works",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "How it Works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#how-it-works",
    "content": "You do not need to create a special configuration file to use dsat. Assuming you have DeepSpeed code which already functions, autotuning is as easy as inserting one or two helper functions into your code and modifying the launch command. For instance, let\u2019s say your directory contains DeepSpeed code and a corresponding single trial experiment configuration file deepspeed.yaml. Then, after inserting a line or two of dsat-specific code per the instructions in the following sections, launching the dsat experiments is as easy as replacing the usual experiment-launching command: det experiment create deepspeed.yaml . with: python3 -m determined.pytorch.dsat asha deepspeed.yaml . The above uses Determined AI\u2019s DeepSpeed Autotune with the asha algorithm, one of three available search methods: asha: Adaptively searches over randomly selected DeepSpeed configurations, allocating more compute resources to well-performing configurations. See this introduction to ASHA for more details. binary: Performs a simple binary search over the batch size for randomly-generated DS configurations. random: Conducts a search over random DeepSpeed configurations with an aggressive early-stopping criteria based on domain-knowledge of DeepSpeed and the search history. DeepSpeed Autotune is built on top of Custom Searcher (see Custom Search Methods) which starts up two separate experiments: single Search Runner Experiment: This experiment coordinates and schedules the trials that run the model code. custom Experiment: This experiment contains the trials referenced above whose results are reported back to the search runner. Initially, a profiling trial is created to gather information regarding the model and computational resources. The search runner experiment takes this initial profiling information and creates a series of trials to search for the DS settings which optimize FLOPS_per_gpu, throughput (samples/second), or latency timing information. The results of all such trials can be viewed in the custom experiment above. The search is informed both by the initial profiling trial and the results of each subsequent trial, all of whose results are fed back to the search runner. Determined\u2019s DeepSpeed Autotune is not compatible with pipeline or model parallelism. The to-be-trained model must be a DeepSpeedEngine instance (not a PipelineEngine instance).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#user-code-changes",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#user-code-changes",
    "content": "To use dsat with DeepSpeedTrial, Core API, and HuggingFace Trainer, specific changes must be made to your user code. In the following sections, we will describe specific use cases and the changes needed for each.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "DeepSpeedTrial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#deepspeedtrial",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "DeepSpeedTrial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#deepspeedtrial",
    "content": "To use Determined\u2019s DeepSpeed Autotune with DeepSpeedTrial, you must meet the following requirements. First, it is assumed that a base DeepSpeed configuration exists in a file (written following the DeepSpeed documentation here). We then require that your Determined yaml configuration points to the location of that file through a deepspeed_config key in its hyperparameters section. For example, if your default DeepSpeed configuration is stored in ds_config.json at the top-level of your model directory, your hyperparameters section should include: hyperparameters: deepspeed_config: ds_config.json Second, your DeepSpeedTrial code must use our get_ds_config_from_hparams() helper function to get the DeepSpeed configuration dictionary which is generated by DeepSpeed Autotune for each trial. These dictionaries are generated by overwriting certain fields in the base DeepSpeed configuration referenced in the step above. The returned dictionary can then be passed to deepspeed.initialize as usual: from determined.pytorch.deepspeed import DeepSpeedTrial, DeepSpeedTrialContext from determined.pytorch import dsat class MyDeepSpeedTrial(DeepSpeedTrial): def __init__(self, context: DeepSpeedTrialContext) -> None: self.hparams = self.context.get_hparams() config = dsat.get_ds_config_from_hparams(self.hparams) model = ... model_parameters= ... model_engine, optimizer, train_loader, lr_scheduler = deepspeed.initialize( model=model, model_parameters=model_parameters, config=config ) Using Determined\u2019s DeepSpeed Autotune with a DeepSpeedTrial instance requires no further changes to your code. For a complete example of how to use DeepSpeed Autotune with DeepSpeedTrial, visit the Determined GitHub Repo and navigate to examples/deepspeed_autotune/torchvision/deepspeed_trial . To find out more about DeepSpeedTrial, visit Usage Guide.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "Core API",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#core-api",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "Core API",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#core-api",
    "content": "When using DeepSpeed Autotune with a Core API experiment, there is one additional change to be made following the steps in the DeepSpeedTrial section above. The forward, backward, and step methods of the DeepSpeedEngine class need to be wrapped in the dsat_reporting_context() context manager. This addition ensures that the autotuning metrics from each trial are captured and reported back to the Determined master. Here is an example sketch of dsat code with Core API: for op in core_context.searcher.operations(): for (inputs, labels) in trainloader: with dsat.dsat_reporting_context(core_context, op): # <-- The new code outputs = model_engine(inputs) loss = criterion(outputs, labels) model_engine.backward(loss) model_engine.step() In this code snippet, core_context is the Context instance which was initialized with determined.core.init(). The context manager requires access to both core_context and the current SearcherOperation instance (op) to appropriately report results. Outside of a dsat context, dsat_reporting_context is a no-op, so there is no need to remove the context manager after the dsat trials have completed. For a complete example of how to use DeepSpeed Autotune with Core API, visit the Determined GitHub Repo and navigate to examples/deepspeed_autotune/torchvision/core_api .",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "HuggingFace Trainer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#huggingface-trainer",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "User Code Changes",
      "lvl3": "HuggingFace Trainer",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#huggingface-trainer",
    "content": "You can also use Determined\u2019s DeepSpeed Autotune with the HuggingFace (HF) Trainer and Determined\u2019s DetCallback callback object to optimize your DeepSpeed parameters. Similar to the previous case (Core API), you need to add a deepspeed_config field to the hyperparameters section of your experiment configuration file, specifying the relative path to the DS json config file. Reporting results back to the Determined master requires both the dsat.dsat_reporting_context context manager and DetCallback. Furthermore, since dsat performs a search over different batch sizes and HuggingFace expects parameters to be specified as command-line arguments, an additional helper function, get_hf_args_with_overwrites(), is needed to create consistent HuggingFace arguments. Here is an example code snippet from a HuggingFace Trainer script that contains key pieces of relevant code: from determined.transformers import DetCallback from determined.pytorch import dsat from transformers import HfArgumentParser,Trainer, TrainingArguments, hparams = self.context.get_hparams() parser = HfArgumentParser(TrainingArguments) args = sys.argv[1:] args = dsat.get_hf_args_with_overwrites(args, hparams) training_args = parser.parse_args_into_dataclasses(args, look_for_args_file=False) det_callback = DetCallback(core_context, ...) trainer = Trainer(args=training_args, ...) with dsat.dsat_reporting_context(core_context, op=det_callback.current_op): train_result = trainer.train(resume_from_checkpoint=checkpoint) The dsat_reporting_context context manager shares the same initial SearcherOperation as the DetCallback instance through its op=det_callback.current_op argument. The entire train method of the HuggingFace trainer is wrapped in the dsat_reporting_context context manager. To find examples that use DeepSpeed Autotune with HuggingFace Trainer, visit the Determined GitHub Repo and navigate to examples/hf_trainer_api.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#advanced-options",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#advanced-options",
    "content": "The command-line entrypoint to dsat has various available options, some of them search-algorithm-specific. All available options for any given search method can be found through the command: python3 -m determined.pytorch.dsat asha --help and similar for the binary and random search methods. Flags that are particularly important are detailed below.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "General Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#general-options",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "General Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#general-options",
    "content": "The following options are available for every search method. --max-trials: The maximum number of trials to run. Default: 64. --max-concurrent-trials: The maximum number of trials that can run concurrently. Default: 16. --max-slots: The maximum number of slots that can be used concurrently. Defaults to None, i.e., there is no limit by default. --metric: The metric to be optimized. Defaults to FLOPS-per-gpu. Other available options are throughput, forward, backward, and latency. --run-full-experiment: If specified, after the dsat experiment has completed, a single experiment will be launched using the specifications in the deepspeed.yaml overwritten with the best-found DS configuration parameters. --zero-stages: This flag allows the user to limit the search to a subset of the stages by providing a space-separated list, as in --zero-stages 2 3. Default: 1 2 3.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "asha Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#asha-options",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "asha Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#asha-options",
    "content": "The asha search algorithm randomly generates various DeepSpeed configurations and attempts to tune the batch size for each configuration through a binary search. asha adaptively allocates resources to explore each configuration (providing more resources to promising lineages) where the resource is the number of steps taken in each binary search (i.e., the number of trials). asha can be configured with the following flags: --max-rungs: The maximum total number of rungs to use in the ASHA algorithm. Larger values allow for longer binary searches. Default: 5. --min-binary-search-trials: The minimum number of trials to use for each binary search. The r parameter in the ASHA paper. Default: 3. --divisor: Factor controlling the increased computational allotment across rungs, and the decrease in their population size. The eta parameter in the ASHA paper. Default: 2. --search-range-factor: The inclusive, initial hi bound on the binary search is set by an approximate computation (the lo bound is always initialized to 1). This parameter adjusts the hi bound by a factor of search-range-factor. Default: 1.0.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "binary Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#binary-options",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "binary Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#binary-options",
    "content": "The binary search algorithm performs a straightforward search over the batch size for a collection of randomly-drawn DS configurations. A single option is available for this search: --search-range-factor, which plays precisely the same role as in the asha Options section above.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "random Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#random-options",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "DeepSpeed Autotune: User Guide",
      "lvl1": "DeepSpeed Autotune: User Guide",
      "lvl2": "Advanced Options",
      "lvl3": "random Options",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/autotuning.html#random-options",
    "content": "The random search algorithm performs a search over randomly drawn DS configurations and uses a semi-random search over the batch size. random can be configured with the following flags: --trials-per-random-config: The maximum batch size configuration which will tested for a given DS configuration. Default: 5. --early-stopping: If provided, the experiment will terminate if a new best-configuration has not been found in the last early-stopping trials. Default: None, corresponding to no such early stopping.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#advanced-usage",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Training Multiple Model Engines",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#training-multiple-model-engines",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Training Multiple Model Engines",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#training-multiple-model-engines",
    "content": "If the model engines use the same ModelParallelUnit, you can train multiple model engines in a single DeepSpeedTrial by calling wrap_model_engine() on additional model engines you want to use, and by modifying train_batch() and evaluate_batch() accordingly. The accounting for number of samples is with respect to the train_batch_size for the first model engine passed to wrap_model_engine(). For more advanced cases where model engines have different model parallel topologies, contact support on the Determined community Slack.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Reducers",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-reducers",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Reducers",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-reducers",
    "content": "Determined supports arbitrary training and validation metrics reduction, including during distributed training, by letting you define custom reducers. Custom reducers can be a function or an implementation of the determined.pytorch.MetricReducer interface. See determined.pytorch.PyTorchTrialContext.wrap_reducer() for more information.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Manual Distributed Backend Initialization",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#manual-distributed-backend-initialization",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Manual Distributed Backend Initialization",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#manual-distributed-backend-initialization",
    "content": "By default, DeepSpeedTrial initializes the distributed backend by calling deepspeed.init_distributed before a trial is created. This initializes the torch.distributed backend to use the NVIDIA Collective Communications Library (NCCL). If you want to customize the distributed backend initialization, set the DET_MANUAL_INIT_DISTRIBUTED environment variable in your experiment configuration: environment: environment_variables: - DET_MANUAL_INIT_DISTRIBUTED=1",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Manual Gradient Aggregation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#manual-gradient-aggregation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Manual Gradient Aggregation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#manual-gradient-aggregation",
    "content": "DeepSpeedTrial automatically ensures a total of train_batch_size samples are processed in each training iteration. With the assumption that train_batch() calls the model engine\u2019s forward, backward, and optimizer step methods once, DeepSpeedTrial calls train_batch(): gradient_accumulation_steps times when not using pipeline parallelism once when using pipeline parallelism to reach model_engine.train_batch_size() for the first wrapped model engine. To disable this behavior, call disable_auto_grad_accumulation() in the __init__() method of DeepSpeedTrial. In this case, make sure the first model engine processes train_batch_size samples in each call to train_batch().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Data Loaders",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-data-loaders",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Data Loaders",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-data-loaders",
    "content": "By default, build_training_data_loader() and build_validation_data_loader() are expected to return a determined.pytorch.DataLoader, which is a thin wrapper around torch.utils.data.DataLoader that supports reproducibility and data sharding for distributed training. Override this requirement and return a torch.utils.data.DataLoader by setting disable_dataset_reproducibility_checks(). Review customizing a reproducible dataset for recommended best practices when using a custom data loader. A common use case for a custom data loader is if you created the data loader when building the model engine as show in this example: class MyTrial(DeepSpeedTrial): def __init__(self, context: DeepSpeedTrialContext) -> None: self.context = context self.args = AttrDict(self.context.get_hparams()) training_data = ... model = Net(self.args) parameters = filter(lambda p: p.requires_grad, model.parameters()) model_engine, __, __, self.train_dataloader = deepspeed.initialize( args=self.args, model=model, model_parameters=parameters, training_data=training_data, ) self.model_engine = self.context.wrap_model_engine(model_engine) def build_training_data_loader(self) -> torch.utils.data.DataLoader: return self.train_dataloader",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Model Parallelism",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-model-parallelism",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Advanced Usage",
      "lvl1": "Advanced Usage",
      "lvl2": "Custom Model Parallelism",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/advanced.html#custom-model-parallelism",
    "content": "DeepSpeedTrial relies on a ModelParallelUnit to provide data parallel world size and to determine whether a GPU slot should build the data loaders and report metrics. For data parallel training with DeepSpeed, the data parallel world size is equal to the number of GPU slots and all GPU slots build the data loaders and report metrics. If the model engine passed to wrap_model_engine() is a PipelineEngine, the ModelParallelUnit is built using the MPU associated with the model engine. To change this behavior to support custom model parallelism, pass a custom set_mpu as shown in the following example: context.set_mpu( ModelParallelUnit( data_parallel_rank=[fill in], data_parallel_world_size=[fill in], should_report_metrics=[fill in], should_build_dataloader=[fill in] ) )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#usage-guide",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#usage-guide",
    "content": "This usage guide introduces DeepSpeed and guides you through how to train a PyTorch model with the DeepSpeed engine. To implement DeepSpeedTrial, you need to overwrite specific functions corresponding to common training aspects. It is helpful to work from a skeleton trial to keep track of what is required, as the following example template shows: from typing import Any, Dict, Iterator, Optional, Union from attrdict import AttrDict import torch import deepspeed import determined.pytorch import DataLoader, TorchData from determined.pytorch.deepspeed import DeepSpeedTrial, DeepSpeedTrialContext class MyTrial(DeepSpeedTrial): def __init__(self, context: DeepSpeedTrialContext) -> None: self.context = context self.args = AttrDict(self.context.get_hparams()) def build_training_data_loader(self) -> DataLoader: return DataLoader() def build_validation_data_loader(self) -> DataLoader: return DataLoader() def train_batch( self, dataloader_iter: Optional[Iterator[TorchData]], epoch_idx: int, batch_idx: int, ) -> Union[torch.Tensor, Dict[str, Any]]: return {} def evaluate_batch( self, dataloader_iter: Optional[Iterator[TorchData]], batch_idx: int ) -> Dict[str, Any]: return {} The DeepSpeed API organizes training routines into common steps like creating the data loaders and training and evaluating the model. The provided template shows the function signatures, including the expected return types, for these methods. Because DeepSpeed is built on top of PyTorch, there are many similarities between the API for PyTorchTrial and DeepSpeedTrial. The following steps show you how to implement each of the DeepSpeedTrial methods beginning with training objects initialization.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-1-configure-and-initialize-training-objects",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-1-configure-and-initialize-training-objects",
    "content": "DeepSpeed training initialization consists of two steps: Initialize the distributed backend. Create the DeepSpeed model engine. Refer to the DeepSpeed Getting Started guide for more information. Outside of Determined, this is typically done in the following way: deepspeed.init_distributed(dist_backend=args.backend) net = ... model_engine, optimizer, lr_scheduler, _ = deepspeed.initialize(args=args, net=net, ...) DeepSpeedTrial automatically initializes the distributed training backend so all you need to do is initialize the model engine and other training objects in the DeepSpeedTrial __init__() method.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": "Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#configuration",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": "Configuration",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#configuration",
    "content": "DeepSpeed behavior during training is configured by passing arguments when initializing the model engine. This can be done in two ways: Using a configuration file specified as an argument with a field named deepspeed_config. Using a dictionary, which is passed in directly when initializing a model engine. Both approaches can be used in combination with the Determined experiment configuration. See the DeepSpeed documentation for more information on what can be specified in the configuration. If you want to use a DeepSpeed configuration file, the hyperparameters section can be used as arguments to pass to deepspeed.initialize. For example, if the DeepSpeed configuration file is named ds_config.json, the hyperparameter section of the Determined experiment configuration is: hyperparameters: deepspeed_config: ds_config.json ... If you want to overwrite some values in an existing DeepSpeed configuration file, use overwrite_deepspeed_config() and an experiment configuration similar to: hyperparameters: deepspeed_config: ds_config.json overwrite_deepspeed_args: train_batch_size: 16 optimizer: params: lr: 0.005 ... If you want to use a dictionary directly, specify a DeepSpeed configuration dictionary in the hyperparameters section: hyperparameters: optimizer: type: Adam params: betas: - 0.8 - 0.999 eps: 1.0e-08 lr: 0.001 weight_decay: 3.0e-07 train_batch_size: 16 zero_optimization: stage: 0 allgather_bucket_size: 50000000 allgather_partitions: true contiguous_gradients: true cpu_offload: false overlap_comm: true reduce_bucket_size: 50000000 reduce_scatter: true",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#initialization",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 1- Configure and Initialize Training Objects",
      "lvl3": "Initialization",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#initialization",
    "content": "After configuration, you can initialize the model engine in the DeepSpeedTrial. The following example corresponds to the experiment configuration above, with a field in the hyperparameters section named overwrite_deepspeed_args. class MyTrial(DeepSpeedTrial): def __init__(self, context: DeepSpeedTrialContext) -> None: self.context = context self.args = AttrDict(self.context.get_hparams()) model = Net(self.args) ds_config = overwrite_deepspeed_config( self.args.deepspeed_config, self.args.get(\"overwrite_deepspeed_args\", {}) ) parameters = filter(lambda p: p.requires_grad, model.parameters()) model_engine, __, __, __ = deepspeed.initialize( model=model, model_parameters=parameters, config=ds_config ) self.model_engine = self.context.wrap_model_engine(model_engine) After the model engine is initialized, you need to register it with Determined by calling wrap_model_engine(). Differing from PyTorchTrial, you do not need to register the optimizer or learning rate scheduler with Determined because both are attributes of the model engine. If you want to use pipeline parallelism with a given model, pass layers of the model for partitioning to the DeepSpeed PipelineModule before creating the pipeline model engine: net = ... net = deepspeed.PipelineModule( layers=get_layers(net), loss_fn=torch.nn.CrossEntropyLoss(), num_stages=args.pipeline_parallel_size, ..., )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 2 - Load Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-2-load-data",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 2 - Load Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-2-load-data",
    "content": "The next step is to build the data loader used for training and validation. The same process is used to download the data for PyTorchTrial. Building the data loaders is also similar, except for the batch size specification for the returned data loaders, which differs because the DeepSpeed model engines automatically handle gradient aggregation. Automatic gradient aggregation in DeepSpeed is specified in configuration fields: train_batch_size train_micro_batch_size gradient_accumulation_steps which are related as follows: train_batch_size = train_micro_batch_size * gradient_accumulation_steps * data_parallel_size, where data_parallel_size is the number of model replicas across all GPUs used during training. Therefore, a single train batch consists of multiple micro batches, specified by the gradient_accumulation_steps argument. Given a model parallelization scheme, you can specify two fields and the third can be inferred. The DeepSpeed model engines assume the model is processing micro batches and automatically handle stepping the optimizer and learning rate scheduler every gradient_accumulation_steps micro batches. This means that the build_training_data_loader should return batches of size train_micro_batch_size_per_gpu. In most cases, build_validation_data_loader also returns batches of size train_micro_batch_size_per_gpu. If you want exact epoch boundaries to be respected, the number of micro batches in the training data loader should be divisible by gradient_accumulation_steps. If you are using pipeline parallelism, the validation data loader needs to have at least gradient_accumulation_steps worth of batches.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-3-training-and-evaluation",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#step-3-training-and-evaluation",
    "content": "This step covers the training and evaluation routine for the standard data parallel model engine and the pipeline parallel engine available in DeepSpeed. After you create the DeepSpeed model engine and data loaders, define the training and evaluation routines for the DeepSpeedTrial. Differing from PyTorchTrial, train_batch() and evaluate_batch() take an iterator over the corresponding data loader built from build_training_data_loader() and build_validation_dataloader() instead of a batch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": "Data Parallel Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#data-parallel-training",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": "Data Parallel Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#data-parallel-training",
    "content": "For data parallel training, only, the training and evaluation routines are: def train_batch( self, dataloader_iter: Optional[Iterator[TorchData]], epoch_idx: int, batch_idx: int, ) -> Union[torch.Tensor, Dict[str, Any]]: inputs = self.context.to_device(next(dataloader_iter)) loss = self.model_engine(inputs) self.model_engine.backward(loss) self.model_engine.step() return {\"loss\": loss} def evaluate_batch( self, dataloader_iter: Optional[Iterator[TorchData]], batch_idx: int ) -> Dict[str, Any]: inputs = self.context.to_device(next(dataloader_iter)) loss = self.model_engine(inputs) return {\"loss\": loss} You need to manually get a batch from the iterator and move it to the GPU using the provided to_device() helper function, which knows the GPU assigned to a given distributed training process.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": "Pipeline Parallel Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#pipeline-parallel-training",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Step 3 - Training and Evaluation",
      "lvl3": "Pipeline Parallel Training",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#pipeline-parallel-training",
    "content": "When using pipeline parallelism, the forward and backward steps during training are combined into a single function call because DeepSpeed automatically interleaves multiple micro batches for processing in a single training step. In this case, there is no need to manually get a batch from the dataloader_iter iterator because the pipeline model engine requests it as needed while interleaving micro batches: def train_batch( self, dataloader_iter: Optional[Iterator[TorchData]], epoch_idx: int, batch_idx: int, ) -> Union[torch.Tensor, Dict[str, Any]]: loss = self.model_engine.train_batch() return {\"loss\": loss} def evaluate_batch( self, dataloader_iter: Optional[Iterator[TorchData]], batch_idx: int ) -> Dict[str, Any]: loss = self.model_engine.eval_batch() return {\"loss\": loss}",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Known DeepSpeed Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#known-deepspeed-constraints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Usage Guide",
      "lvl1": "Usage Guide",
      "lvl2": "Known DeepSpeed Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/apis-howto/deepspeed/deepspeed.html#known-deepspeed-constraints",
    "content": "Some DeepSpeed constraints are inherited concerning supported feature compatibility: Pipeline parallelism can only be combined with Zero Redundancy Optimizer (ZeRO) stage 1. Parameter offloading is only supported with ZeRO stage 3. Optimizer offloading is only supported with ZeRO stage 2 and 3.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torch-batch-processing-api",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torch-batch-processing-api",
    "content": "In this guide, you\u2019ll learn about the Torch Batch Process API and how to perform batch inference (also known as offline inference). Visit the API reference pytorch.experimental.torch_batch_process API Reference This is an experimental API and may change at any time.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Overview",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#overview",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Overview",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#overview",
    "content": "The Torch Batch Processing API takes in (1) a dataset and (2) a user-defined processor class and runs distributed data processing. This API automatically handles the following for you: shards a dataset by number of workers available applies user-defined logic to each batch of data handles synchronization between workers tracks job progress to enable preemption and resumption of trial This is a flexible API that can be used for many different tasks, including batch (offline) inference. If you have some trained models in a :class:~determined.experimental.checkpoint.Checkpoint or a :class:~determined.experimental.model.Model with more than one :class:~determined.experimental.model.ModelVersion inside, you can associate the trial with the :class:~determined.experimental.checkpoint.Checkpoint or :class:~determined.experimental.model.ModelVersion used in a given inference run to aggregate custom inference metrics. You can then query those :class:~determined.experimental.checkpoint.Checkpoint or :class:~determined.experimental.model.ModelVersion objects using the :ref:Python SDK <python-sdk> to see all metrics associated with them.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#usage",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#usage",
    "content": "The main arguments to torch_batch_process() are processor class and dataset. torch_batch_process( batch_processor_cls=MyProcessor dataset=dataset ) In the experiment config file, use a distributed launcher as the API requires information such as rank set by the launcher. Below is an example. entrypoint: >- python3 -m determined.launch.torch_distributed python3 batch_processing.py resources: slots_per_trial: 4",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": "TorchBatchProcessor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torchbatchprocessor",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": "TorchBatchProcessor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torchbatchprocessor",
    "content": "During __init__() of TorchBatchProcessor, we pass in a TorchBatchProcessorContext object, which contains useful methods that can be used within the TorchBatchProcessor class. TorchBatchProcessor is compatible with Determined\u2019s MetricReducer. You can pass MetricReducer to TorchBatchProcessor as follow:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": "TorchBatchProcessorContext",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torchbatchprocessorcontext",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "Usage",
      "lvl3": "TorchBatchProcessorContext",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#torchbatchprocessorcontext",
    "content": "TorchBatchProcessorContext should be a subclass of TorchBatchProcessor. The two functions you must implement are the __init__() and process_batch(). The other lifecycle functions are optional. class MyProcessor(TorchBatchProcessor): def __init__(self, context): self.reducer = context.wrap_reducer(reducer=AccuracyMetricReducer(), name=\"accuracy\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#how-to-perform-batch-offline-inference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#how-to-perform-batch-offline-inference",
    "content": "In this section, we\u2019ll learn how to perform batch inference using the Torch Batch Processing API.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 1: Define an InferenceProcessor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-1-define-an-inferenceprocessor",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 1: Define an InferenceProcessor",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-1-define-an-inferenceprocessor",
    "content": "The first step is to define an InferenceProcessor. You should initialize your model in the __init__() function of the InferenceProcessor. You should implement process_batch() function with inference logic. You can optionally implement on_checkpoint_start() and on_finish() to be run before every checkpoint and after all the data has been processed, respectively. For an example of how to accomplish this, visit our Torch Batch Process Embeddings example. \"\"\" Define custom processor class \"\"\" class InferenceProcessor(TorchBatchProcessor): def __init__(self, context): self.context = context self.model = context.prepare_model_for_inference(get_model()) self.output = [] self.last_index = 0 def process_batch(self, batch, batch_idx) -> None: model_input = batch[0] model_input = self.context.to_device(model_input) with torch.no_grad(): with self.profiler as p: pred = self.model(model_input) p.step() output = {\"predictions\": pred, \"input\": batch} self.output.append(output) self.last_index = batch_idx def on_checkpoint_start(self): \"\"\" During checkpoint, we persist prediction result \"\"\" if len(self.output) == 0: return file_name = f\"prediction_output_{self.last_index}\" with self.context.upload_path() as path: file_path = pathlib.Path(path, file_name) torch.save(self.output, file_path) self.output = []",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 2: Link the Run to a Checkpoint or Model Version (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-2-link-the-run-to-a-checkpoint-or-model-version-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 2: Link the Run to a Checkpoint or Model Version (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-2-link-the-run-to-a-checkpoint-or-model-version-optional",
    "content": "You have the option to associate your batch inference run with the :class:~determined.experimental.checkpoint.Checkpoint or :class:~determined.experimental.model.ModelVersion employed during the run. This allows you to compile custom metrics for that specific object, which can then be analyzed at a later stage. The inference_example.py file in the CIFAR10 Pytorch Example is an example. Connect the Checkpoint or ModelVersion to the inference run. def __init__(self, context): self.context = context hparams = self.context.get_hparams() # Model Version model = client.get_model(hparams.get(\"model_name\")) model_version = model.get_version(hparams.get(\"model_version\")) self.context.report_task_using_model_version(model_version) # Or Checkpoint ckpt = client.get_checkpoint(hparams.get(\"checkpoint_uuid\")) self.context.report_task_using_checkpoint(ckpt) The Checkpoint and ModelVersion used are now available to any query via .get_metrics().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 3: Initialize the Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-3-initialize-the-dataset",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 3: Initialize the Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-3-initialize-the-dataset",
    "content": "Initialize the dataset you want to process. \"\"\" Initialize dataset \"\"\" transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] ) with filelock.FileLock(os.path.join(\"/tmp\", \"inference.lock\")): inference_data = tv.datasets.CIFAR10( root=\"/data\", train=False, download=True, transform=transform )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 4: Pass the InferenceProcessor Class and Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-4-pass-the-inferenceprocessor-class-and-dataset",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 4: Pass the InferenceProcessor Class and Dataset",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-4-pass-the-inferenceprocessor-class-and-dataset",
    "content": "Pass the InferenceProcessor class and the dataset to torch_batch_process. \"\"\" Pass processor class and dataset to torch_batch_process \"\"\" torch_batch_process( InferenceProcessor, dataset, batch_size=64, checkpoint_interval=10 )",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 5: Send and Query Custom Inference Metrics (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-5-send-and-query-custom-inference-metrics-optional",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 21
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Torch Batch Processing API",
      "lvl1": "Torch Batch Processing API",
      "lvl2": "How To Perform Batch (Offline) Inference",
      "lvl3": "Step 5: Send and Query Custom Inference Metrics (Optional)",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/api-guides/batch-processing/batch-process-api-ug.html#step-5-send-and-query-custom-inference-metrics-optional",
    "content": "Report metrics anywhere in the trial to have them aggregated for the Checkpoint or ModelVersion in question. For example, you could send metrics in on_finish(). def on_finish(self): self.context.report_metrics( group=\"inference\", steps_completed=self.rank, metrics={ \"my_metric\": 1.0, }, ) And check the metric afterwards from the SDK: from determined.experimental import client # Checkpoint ckpt = client.get_checkpoint(\"<CHECKPOINT_UUID>\") metrics = ckpt.get_metrics(\"inference\") # Or Model Version model = client.get_model(\"<MODEL_NAME>\") model_version = model.get_version(MODEL_VERSION_NUM) metrics = model_version.get_metrics(\"inference\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 22
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#topic-guides-hp-tuning-basics",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#topic-guides-hp-tuning-basics",
    "content": "Hyperparameter tuning is the common machine learning process of selecting the data, features, model architecture, and learning algorithm to yield an effective model. Hyperparameter tuning is a challenging problem given the potentially large number of hyperparameters to consider.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": "Why Do Hyperparameters Matter?",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#why-do-hyperparameters-matter",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": "Why Do Hyperparameters Matter?",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#why-do-hyperparameters-matter",
    "content": "During the model development lifecycle, a machine learning engineer makes a wide range of decisions impacting model performance. For example, a computer vision model requires decisions on sample features, model architecture, and training algorithm parameters, e.g.: Should we consider features aside from the raw images in the training set? Would synthetic data augmentation techniques like image rotation or horizontal flipping yield a better model? Should we populate additional features via advanced image processing techniques such as shape edge extraction? What model architecture works best? How many layers? What kind of layers (e.g., dense, dropout, pooling)? How should we parameterize each layer (e.g., size, activation function)? What learning algorithm hyperparameters should we use? What gradient descent batch size should we use? What optimizer should we use, and how should we parameterize it (e.g., learning rate)? A machine learning engineer can manually guess and test hyperparameters, or they might narrow the search space by using a pretrained model. However, even if the engineer achieves seemingly good model performance, they\u2019re left wondering how much better they might do with additional tuning.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": "Hyperparameter Tuning",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#id2",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Tuning",
      "lvl1": "Hyperparameter Tuning",
      "lvl2": "Hyperparameter Tuning",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/index.html#id2",
    "content": "Hyperparameter tuning is a crucial phase in the model development lifecycle. However, tuning deep learning models is difficult because: A deep learning model\u2019s objective (e.g., validation loss) as a function of the hyperparameters is non-continuous and noisy, so we can\u2019t apply analytical or continuous optimization techniques to calculate the validation objective given a set of hyperparameters. Thus, hyperparameter tuning is a black box optimization problem in that we must train a model under a set of hyperparameters in order to evaluate the objective. Hyperparameter tuning suffers from the curse of dimensionality, as the number of possible hyperparameter configurations is exponential in the number of hyperparameters. For instance, even if a model has just ten categorical hyperparameters with five values per hyperparameter, and each hyperparameter configuration takes one minute to train on average, it would take 5^10 minutes, or nearly 20 years, to evaluate all possible hyperparameter configurations. Deep learning model training is computationally expensive. It\u2019s not uncommon for a model to require hours or days to train, even on expensive hardware. Fortunately, there are automatic hyperparameter tuning techniques that the machine learning engineer can leverage to find an effective model. Determined provides support for hyperparameter search as a first-class workflow that is tightly integrated with Determined\u2019s job scheduler, which allows for efficient execution of state-of-the-art early-stopping based approaches as well as seamless parallelization of these methods. An intuitive interface is provided to use hyperparameter searching, and is described in the following sections.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Hyperparameter Ranges",
      "lvl1": "Configure Hyperparameter Ranges",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/configure-hp-ranges.html#configure-hyperparameter-ranges",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configure Hyperparameter Ranges",
      "lvl1": "Configure Hyperparameter Ranges",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/configure-hp-ranges.html#configure-hyperparameter-ranges",
    "content": "The first step toward automatic hyperparameter tuning is to define the hyperparameter space, e.g., by listing the decisions that may impact model performance. For each hyperparameter in the search space, the machine learning engineer specifies a range of possible values in the experiment configuration: hyperparameters: ... dropout_probability: type: double minval: 0.2 maxval: 0.5 ... Determined supports the following searchable hyperparameter data types: int: an integer within a range double: a floating point number within a range log: a logarithmically scaled floating point number. Users specify a base, and Determined searches the space of exponents within a range. categorical: a variable that can take on a value within a specified set of discrete values. The values themselves can be of any type. The experiment configuration reference details these data types and their associated options.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Handle Trial Errors and Early Stopping Requests",
      "lvl1": "Handle Trial Errors and Early Stopping Requests",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/handle-trial-errors.html#handle-trial-errors-and-early-stopping-requests",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Handle Trial Errors and Early Stopping Requests",
      "lvl1": "Handle Trial Errors and Early Stopping Requests",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/handle-trial-errors.html#handle-trial-errors-and-early-stopping-requests",
    "content": "When a trial encounters an error or fails unexpectedly, Determined will restart it from the latest checkpoint up to some maximum number of times, which is configured by max_restarts in the experiment configuration. After Determined reaches max_restarts, any further trials that fail will be marked as errored and will not be restarted. For the adaptive (ASHA) search method, which adapts to validation metric values, we do not continue training errored trials, even if the search method would typically call for us to continue training. This behavior is useful when some parts of the hyperparameter space result in models that cannot be trained successfully (e.g., the search explores a range of batch sizes and some of those batch sizes cause GPU OOM errors). An experiment can complete successfully as long as at least one of the trials within it completes successfully. Trial code can also request that training be stopped early, e.g., via a framework callback such as tf.keras.callbacks.EarlyStopping or manually by calling determined.TrialContext.set_stop_requested(). When early stopping is requested, Determined will finish the current training or validation workload and checkpoint the trial. Trials that are stopped early are considered to be \u201ccompleted\u201d, whereas trials that fail are marked as \u201cerrored\u201d.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Instrument Model Code",
      "lvl1": "Instrument Model Code",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/instrument-model-code.html#instrument-model-code",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Instrument Model Code",
      "lvl1": "Instrument Model Code",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/instrument-model-code.html#instrument-model-code",
    "content": "Determined injects hyperparameters from the experiment configuration into model code via a context object in the Trial base class. This TrialContext object exposes a get_hparam() method that takes the hyperparameter name. For example, to inject the value of the dropout_probability hyperparameter defined in the experiment configuration into the constructor of a PyTorch Dropout layer: nn.Dropout(p=self.context.get_hparam(\"dropout_probability\")) To see hyperparameter injection throughout a complete trial implementation, refer to the Training APIs.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#hyperparameter-search-constraints",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#hyperparameter-search-constraints",
    "content": "Determined\u2019s Hyperparameter (HP) Search Constraints API enables finer-grained control over the hyperparameter search space through the specification of additional constraints. This functionality is particularly useful for incorporating prior knowledge/domain expertise into a hyperparameter search and constraining the search to models that fit a particular deployment environment. Using Determined\u2019s HP Search Constraints requires no changes to the configuration files. Rather, users can simply raise a determined.InvalidHP exception in their model code when the trial is first created in its constructor or at any subsequent point during training. This user-raised exception is then handled by Determined\u2019s system internally \u2013 resulting in the graceful stop of the current trial being trained, logging the InvalidHP exception in the trial logs, and propagating that information to the search method. It is important to note that each search method has different behavior when a determined.InvalidHP is raised by the user in accordance with the internal dynamics of each searcher, as detailed below.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "HP Search Constraints in PyTorch vs. TF Keras",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#hp-search-constraints-in-pytorch-vs-tf-keras",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "HP Search Constraints in PyTorch vs. TF Keras",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#hp-search-constraints-in-pytorch-vs-tf-keras",
    "content": "Since the PyTorch and TF Keras APIs have different behavior, the timing/placement of user-raised InvalidHP exceptions are somewhat different. In the case of PyTorch, this exception can be raised in the trial\u2019s __init__, train_batch, or evaluate_batch methods. In the case of TF Keras, this exception can be raised in the __init__ method or in an on_checkpoint_end callback. See the hp_constraints_mnist_pytorch example for a demonstration of HP Search Constraints with PyTorch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "Searcher-Specific Behavior for HP Search Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#searcher-specific-behavior-for-hp-search-constraints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "Searcher-Specific Behavior for HP Search Constraints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#searcher-specific-behavior-for-hp-search-constraints",
    "content": "Search Algorithm HP Search Constraints Behavior Single Not applicable to HP Search Constraints as only a single hyperparameter configuration will be trained. Grid Does nothing since grid does not take actions based on search status or progress. Random Gracefully terminates current trial, creates a new trial with a randomly sampled set of hyperparameters and adds it to the trial queue. Adaptive (ASHA) Gracefully terminates and removes metrics associated with the current trial and creates a new trial with a randomly sampled set of hyperparameters.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Hyperparameter Search Constraints",
      "lvl1": "Hyperparameter Search Constraints",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/hp-constraints-det.html#next-steps",
    "content": "Experiment Configuration",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#search-methods",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#search-methods",
    "content": "Determined supports a variety of hyperparameter search algorithms. Aside from the single searcher, a searcher runs multiple trials and decides the hyperparameter values to use in each trial. Every searcher is configured with the name of the validation metric to optimize (via the metric field), in addition to other searcher-specific options. For example, the adaptive_asha searcher (arXiv:1810.0593), suitable for larger experiments with many trials, is configured with the maximum number of trials to run, the maximum training length allowed per trial, and the maximum number of trials that can be worked on simultaneously: searcher: name: \"adaptive_asha\" metric: \"validation_loss\" max_trials: 16 max_length: epochs: 1 max_concurrent_trials: 8 For details on the supported searchers and their respective configuration options, refer to Hyperparameter Tuning. That\u2019s it! After submitting an experiment, you can easily see the best validation metric observed across all trials over time in the WebUI. After the experiment has completed, you can view the hyperparameter values for the best-performing trials and then export the associated model checkpoints for downstream serving.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": "Adaptive Search",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#adaptive-search",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": "Adaptive Search",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#adaptive-search",
    "content": "Our default recommended search method is Adaptive (ASHA), a state-of-the-art early-stopping based technique that speeds up traditional techniques like random search by periodically abandoning low-performing hyperparameter configurations in a principled fashion. Adaptive (ASHA) offers asynchronous search functionality more suitable for large-scale HP search experiments in the distributed setting.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": "Other Supported Search Methods",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#other-supported-search-methods",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Search Methods",
      "lvl1": "Search Methods",
      "lvl2": "Other Supported Search Methods",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/index.html#other-supported-search-methods",
    "content": "Determined also supports other common hyperparameter search algorithms: Single is appropriate for manual hyperparameter tuning, as it trains a single hyperparameter configuration. Grid evaluates all possible hyperparameter configurations by brute force and returns the best. Random evaluates a set of hyperparameter configurations chosen at random and returns the best. You can also implement your own custom search methods.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#custom-search-methods",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#custom-search-methods",
    "content": "API reference Custom Searcher Reference Determined supports defining your own hyperparameter search algorithms and provides search runner utilities for executing them. Remember that a Determined experiment is a set of trials, each corresponding to a point in the hyperparameter space. To implement a custom hyperparameter tuning algorithm, subclass SearchMethod, overriding its event handler methods. If you want to achieve fault tolerance and your search method carries any state in addition to the SearcherState passed into the event handlers, also override save_method_state() and load_method_state(). To run the custom hyperparameter tuning algorithm, you can use: LocalSearchRunner to run on your machine, RemoteSearchRunner to run on a Determined cluster. Using RemoteSearchRunner will create two experiments, with one orchestrating the hyperparameter search of the other. Both search runners execute the custom hyperparameter tuning algorithm and start a multi-trial experiment on a Determined cluster. The following sections explain the steps to take in order to implement and use a custom hyperparameter search algorithm. A detailed example can be found in asha_search_method.tgz.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Experiment Configuration for Custom Searcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#experiment-configuration-for-custom-searcher",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Experiment Configuration for Custom Searcher",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#experiment-configuration-for-custom-searcher",
    "content": "Specify the custom searcher type in the experiment configuration: searcher: name: custom metric: validation_loss smaller_is_better: true unit: batches",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Run Hyperparameter Search Locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#run-hyperparameter-search-locally",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Run Hyperparameter Search Locally",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#run-hyperparameter-search-locally",
    "content": "A script performing hyperparameter tuning using LocalSearchRunner may look like the following run_local_searcher.py: import logging from pathlib import Path from determined import searcher if __name__ == \"__main__\": # The content of the following directory is uploaded to Determined cluster. # It should include all files necessary to run the experiment (as usual). model_context_dir = \"experiment_files\" # Path to the .yaml file with the multi-trial experiment configuration. model_config = \"experiment_files/config.yaml\" # While LocalSearchRunner saves its own state and ensures invoking save() and # load() methods when necessary, a user is responsible for implementing # SearchMethod.save_method_state() and SearchMethod.load_method_state() to ensure # correct resumption of the SearchMethod. searcher_dir = Path(\"local_search_runner/searcher_dir\") # Instantiate your search method, passing the necessary parameters. search_method = MySearchMethod(...) search_runner = searcher.LocalSearchRunner(search_method, searcher_dir=searcher_dir) experiment_id = search_runner.run(model_config, model_dir=model_context_dir) logging.info(f\"Experiment {experiment_id} has been completed.\") To start the custom search method locally, you can use the following CLI command: $ python run_local_searcher.py",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Run Hyperparameter Search on a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#run-hyperparameter-search-on-a-cluster",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Custom Search Methods",
      "lvl1": "Custom Search Methods",
      "lvl2": "Run Hyperparameter Search on a Cluster",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-custom.html#run-hyperparameter-search-on-a-cluster",
    "content": "A script to run your custom search method on a Determined cluster may look like the following run_remote_searcher.py: import determined as det from pathlib import Path from determined import searcher if __name__ == \"__main__\": model_context_dir = \"experiment_files\" model_config = \"experiment_files/config.yaml\" with det.core.init() as core_context: info = det.get_cluster_info() assert info is not None search_method = MySearchMethod(...) search_runner = searcher.RemoteSearchRunner(search_method, context=core_context) search_runner.run(model_config, model_dir=model_context_dir) To start the custom search method on a cluster, you need to submit it to the master as a single-trial experiment. To this end, you can use the following CLI command: $ det e create searcher_config.yaml context_dir The custom search method runs on a Determined cluster as a single trial experiment. Configuration for the search method experiment is specified in the searcher_config.yaml and may look like this: name: remote-searcher entrypoint: python3 run_remote_searcher.py searcher: metric: validation_error smaller_is_better: true name: single max_length: batches: 1000 max_restarts: 0",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#adaptive-asynchronous-method",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#adaptive-asynchronous-method",
    "content": "The adaptive_asha search method employs an Asynchronous version of the Successive Halving Algorithm (ASHA), which is suitable for large-scale experiments with hundreds or thousands of trials.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Quick start",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#quick-start",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Quick start",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#quick-start",
    "content": "Here are some suggested initial settings for adaptive_asha that typically work well. Search mode: mode: Set to standard. Resource budget: max_length: The maximum training length (see Training Units) of any trial that survives to the end of the experiment. This quantity is domain-specific and should roughly reflect the number of minibatches the model must be trained on for it to converge on the data set. For users who would like to determine this number experimentally, train a model with reasonable hyperparameters using the single search method. max_trials: This indicates the total number of hyperparameter settings that will be evaluated in the experiment. Set max_trials to at least 500 to take advantage of speedups from early-stopping. You can also set a large max_trials and stop the experiment once the desired performance is achieved. max_concurrent_trials: This field controls the degree of parallelism of the experiment. The experiment will have a maximum of this many trials training simultaneously at any one time. The adaptive_asha searcher scales nearly perfectly with additional compute, so you should set this field based on compute environment constraints. If this value is less than the number of brackets produced by the adaptive algorithm, it will be rounded up.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#details",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#details",
    "content": "Conceptually, the adaptive_asha searcher is a carefully tuned strategy for spawning multiple ASHA (asynchronous successive halving algorithm) searchers, themselves hyperparameter search algorithms. ASHA can be configured to make different tradeoffs between exploration and exploitation, i.e., how many trials are explored versus how long a single trial is trained for. Because the right tradeoff between exploration and exploitation is hard to know in advance, the adaptive_asha algorithm tries several ASHA searches with different tradeoffs. The configuration settings available to Determined experiments running in adaptive_asha mode mostly affect the ASHA subroutines directly. The mode configuration is the only one affecting the decisions of the adaptive_asha searcher, by changing the number and types of ASHA subroutines spawned. The first section here gives a description of the synchronous version of ASHA called successive halving. The second section discusses the motivation for the asynchronous promotions used by ASHA. The third section describes why you would choose adaptive_asha over plain asynchronous_halving. The final section and conclusion is a set of FAQs regarding adaptive_asha.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#id1",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#id1",
    "content": "At a high level, SHA prunes (\u201chalves\u201d) a set of trials in successive rounds we call rungs. SHA starts with an initial set of trials. (A trial means one model, with a fixed set of hyperparameter values.) SHA trains all the trials for some length and the trials with the worst validation performance are discarded. In the next rung, the remaining trials are trained for a longer period of time, and then trials with the worst validation performance are pruned once again. This is repeated until the maximum training length is reached. First, an example of SHA. Rung 1: SHA creates N initial trials; the hyperparameter values for each trial are randomly sampled from the hyperparameters defined in the experiment configuration file. Each trial is trained for 1 epoch, and then validation metrics are computed. Rung 2: SHA picks the N/4 top-performing trials according to validation metrics. These are trained for 4 epochs. Rung 3: SHA picks the N/16 top-performing trials according to validation metrics. These are trained for 16 epochs. At the end, the trial with best performance has the hyperparameter setting the SHA searcher returns. In the example above, we generalize \u201chalving\u201d with a field called divisor, which determines what fraction of trials are kept in successive rungs, as well as the training length in successive rungs. max_length is 16 epochs, which is the maximum length a trial is trained for. In general, SHA has a fixed divisor d. In the first rung, it generates an initial set of randomly chosen trials and runs until each trial has trained for the same length. In the next rung, it keeps 1/d of those trials and closes the rest. Then it runs each remaining trial until it has trained for d times as long as the previous rung. ASHA iterates this process until some stopping criterion is reached, such as completing a specified number of rungs or having only one trial remaining. The total training length, rungs, and trials within rungs are fixed within each SHA searcher, but vary across different calls to SHA by the adaptive algorithm. Note that although the name \u201cSHA\u201d includes the phrase \u201chalving\u201d, the fraction of trials pruned after every rung is controlled by divisor.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "Why Asynchronous Halving?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#why-asynchronous-halving",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "Why Asynchronous Halving?",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#why-asynchronous-halving",
    "content": "Successive halving (SHA) promotes hyperparameter configurations synchronously, waiting for each rung to complete before performing any promotions. This allows the algorithm to have complete information about all trials at the time of promotion, but it results in underutilized nodes waiting on completion of validation steps for other configurations. ASHA, asynchronous successive halving, asynchronously promotes trials when it has the minimum information required to make a decision in order to maximize compute efficiency of the searcher. In contrast to SHA which initializes all trials in the bottom rung at the outset, ASHA will continuously add trials to the bottom rung until the desired number of trials is reached. See the difference in asynchronous vs. synchronous promotions in the two animated GIFs below:",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "Adaptive over ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#adaptive-over-asha",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "Details",
      "lvl3": "Adaptive over ASHA",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#adaptive-over-asha",
    "content": "The adaptive algorithm calls ASHA subroutines with varying parameters. The exact calls are configured through the choice of mode, which specifies how aggressively to perform early stopping. One way to think about this behavior is as a spectrum that ranges from \u201cone ASHA run\u201d (aggressive early stopping; eliminate most trials every rung) to \u201csearcher: random\u201d \u201cmultiple ASHA runs, some of which will not early stop and others will early stop later\u201d (try some without early stopping; initialized trials may be allowed to run to completion). On one end, aggressive applies early stopping in a very eager manner; this mode essentially corresponds to only making a single call to ASHA. With the default divisor of 4, 75% of the remaining trials will be eliminated in each rung after only being trained for 25% the length of the next rung. This implies that relatively few trials will be allowed to finish even a small fraction of the length needed train to convergence (max_length). This aggressive early stopping behavior allows the searcher to start more trials for a wider exploration of hyperparameter configurations, at the risk of discarding a configuration too soon. On the other end, conservative mode is more similar to a random search, in that it performs significantly less pruning. Extra ASHA subroutines are spawned with fewer rungs and longer training lengths to account for the high percentage of trials eliminated after only a short time. However, a conservative adaptive search will only explore a small fraction of the configurations explored by an aggressive search, given the same budget. Once the number and types of calls to ASHA are determined (via mode), the adaptive algorithm will allocate training length budgets to the ASHA subroutines, from the overall budget for the adaptive algorithm (user-specified through budget). This determines the number of trials at each rung (N in the above ASHA example).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "FAQ",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#faq",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Adaptive (Asynchronous) Method",
      "lvl1": "Adaptive (Asynchronous) Method",
      "lvl2": "FAQ",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.html#faq",
    "content": "Q: How do I control how long a trial is trained for before it is potentially discarded? The training length is guaranteed to be at least max_length / 256 by default, or max_length / divisor ^ max_rungs-1 in general. It is recommended to configure this in records or epochs if the global_batch_size hyperparameter is not constant, to ensure each trial trains on the same amount of data. Q: How do I make sure ``x`` trials are run the full training length (``max_length``)? The number of initial trials is determined by a combination of mode, max_trials, divisor, max_rungs, max_length and bracket_rungs. Here is a rule of thumb for the default configuration of max_rungs: 5 and divisor: 4, with mode: standard and a large enough max_trials: The initial number of trials is max_trials. To ensure that x trials are run max_length, set max_trials high enough for the brackets with their halving rate (the divisor) to allow x trials to make it to the final rungs. This can be viewed by the command describe below. A configuration setting that meets set goals can be found by trial and error. The command det preview-search <file_name.yaml> will display information on the number of trials versus training length for the configuration specified in file_name.yaml. Q: The adaptive algorithm sounds great so far. What are its weaknesses? In our experience, early-stopping works well across a variety of deep learning models. However, there may be some search spaces in which early-stopping underperforms simple random search. This can happen if model complexity varies drastically in a search space leading to different converge rates or if the search space contains hyperparameters that are strongly correlated with training length.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Single Search Method",
      "lvl1": "Single Search Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-single.html#single-search-method",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Single Search Method",
      "lvl1": "Single Search Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-single.html#single-search-method",
    "content": "The single search method does a very minimal \u201csearch\u201d: it trains a single hyperparameter configuration for the number of units specified by max_length (see Training Units) and then performs validation. This method is useful for testing or for training a single model configuration until convergence. See Experiment Configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Grid Method",
      "lvl1": "Grid Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-grid.html#grid-method",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Grid Method",
      "lvl1": "Grid Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-grid.html#grid-method",
    "content": "The grid search method generates trials on a \u201cgrid\u201d of hyperparameter configurations and trains each trial for the number of training units specified by max_length. The user specifies a set of values for each hyperparameter via the hyperparameters field in the experiment configuration. The \u201cgrid\u201d of hyperparameter configurations is generated by taking the product of these sets. For example, if the set of values for three separate hyperparameters aparam, bparam, and cparam are specified as {0, 1, 2}, {10, 20}, and {\"c\"} respectively, then the grid of tuples (aparam, bparam, cparam) generated is: (0, 10, \"c\") (0, 20, \"c\") (1, 10, \"c\") (1, 20, \"c\") (2, 10, \"c\") (2, 20, \"c\") The way the set of hyperparameter values is specified depends on the type of hyperparameter: const: The set of values contains just the single value. For example, cparam above could be specified as a const hyperparameter with val: c. categorical: The set of values is exactly the set of categorical values. For example, bparam above could be specified as a categorical hyperparameter with vals: [10, 20]. int: The set of count values is taken evenly from the range [minval, maxval], inclusive of endpoints. If count is larger than the number of integer values in the range, that is interpreted as the entire range of integers in [minval, maxval]. For example, aparam above could be specified as an int hyperparameter with minval: 0, maxval: 2, and count: 3 or count: 100. double: The set of count values is taken evenly from the range [minval, maxval], inclusive of endpoints. The set {0.1, 0.3, 0.5} could be specified as a double hyperparameter with minval: 0.1, maxval: 0.5, count: 3. log: The set of count values is taken logarithmically evenly from the range [base^minval, base^maxval], inclusive of endpoints. For example, the set {0.00001, 0.0001, 0.001} could be specified as a log hyperparameter with base: 10, minval: -5, maxval: -3, and count: 3. In the special case of count: 1 for int, double, or log, the midpoint (with rounding for int and with base midpoint for log) is returned.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Random Method",
      "lvl1": "Random Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-random.html#random-method",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Random Method",
      "lvl1": "Random Method",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/hyperparameter/search-methods/hp-random.html#random-method",
    "content": "The random search method generates max_trials trials with hyperparameters chosen uniformly at random from the configured hyperparameter space. Each trial is trained for the number of units specified by max_length (see Training Units) and then then the trial\u2019s validation metrics are computed. See Experiment Configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#optimizing-training",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#optimizing-training",
    "content": "When optimizing the training speed of a model, the first step is to understand where and why training is slow. Once the bottlenecks have been identified, the next step is to do further investigation and experimentation to alleviate those bottlenecks. To understand the performance profile of a training job, the training code and infrastructure need to be instrumented. Many different layers can be instrumented, from raw throughput all the way down to GPU kernels. Determined provides two tools out-of-the-box for instrumenting training: System Metrics: measurements of hardware usage Timings: durations of actions taken during training, such as data loading System Metrics are useful to see if the software is taking full advantage of the available hardware, particularly around GPU usage, data loading, and network communication during distributed training. Timings are useful for identifying the section of code to focus on for optimizations. Most commonly, Timings help answer the question of whether the dataloader is the main bottleneck in training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": "System Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#system-metrics",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": "System Metrics",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#system-metrics",
    "content": "System Metrics are statistics around hardware usage, such as GPU utilization and network throughput. These metrics are useful for seeing whether training is using the hardware effectively. When the System Metrics reported for an experiment are below what is expected from the hardware, that is a sign that the software may be able to be optimized to make better use of the hardware resources. Specifically, Determined tracks: GPU utilization GPU free memory Network throughput (sent) Network throughput (received) Disk IOPS Disk throughput (read) Disk throughput (write) Host available memory CPU utilization averaged across cores For distributed training, these metrics are collected for every agent. The data are broken down by agent, and GPU metrics can be further broken down by GPU. System Metrics record agent-level metrics, so when there are multiple experiments on the same agent, it is difficult to analyze. We suggest that profiling is done with only a single experiment per agent.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": "Timings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#timings",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Optimizing Training",
      "lvl1": "Optimizing Training",
      "lvl2": "Timings",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/optimize-training.html#timings",
    "content": "The other type of profiling metric that Determined tracks is Timings. Timings are measurements of how long specific training events take. Examples of training events include retrieving data from the dataloader, moving data between host and device, running the forward/backward pass, and executing callbacks. Timings are currently only supported for PyTorchTrial. These measurements provide a high-level picture of where to focus optimization efforts. Specifically, Determined tracks the following Timings: dataloader_next: time to retrieve the next item from the dataloader to_device: time to transfer input from host to device train_batch: how long the user-defined train_batch function takes to execute* step_lr_schedulers: amount of time to update the LR schedules from_device: time to transfer output from device to host reduce_metrics: time taken to calculate global metrics in distributed training * train_batch is typically the forward pass and the backward pass, but it is a user-defined function so it could include other steps.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#distributed-training-concepts",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "How Determined Distributed Training Works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#how-determined-distributed-training-works",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "How Determined Distributed Training Works",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#how-determined-distributed-training-works",
    "content": "Determined employs data parallelism in its approach to distributed training. Data parallelism for deep learning consists of a set of workers, where each worker is assigned to a unique compute accelerator such as a GPU or a TPU. Each worker maintains a copy of the model parameters (weights that are being trained), which is synchronized across all the workers at the start of training. Determined AI Distributed Training Loop After initialization is completed, distributed training in Determined follows a loop where: Every worker performs a forward and backward pass on a unique mini-batch of data. As a result of the backward pass, every worker generates a set of updates to the model parameters based on the data it processed. The workers communicate their updates to each other so that all the workers see all the updates made during that batch. Every worker averages the updates by the number of workers. Every worker applies the updates to its copy of the model parameters, resulting in all the workers having identical solution states. Return to the first step.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Performance Optimization",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#performance-optimization",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Performance Optimization",
      "lvl3": "Reducing Computation and Communication Overhead",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#reducing-computation-and-communication-overhead",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Performance Optimization",
      "lvl3": "Reducing Computation and Communication Overhead",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#reducing-computation-and-communication-overhead",
    "content": "The first two steps of the training loop (forward and backward pass + generate updates) incur the most computational overhead. To reduce this computational overhead, we recommend using the GPU to its maximimum capacity. This can be accomplished by using the largest possible batch size that fits into memory. To achieve this, set the global_batch_size to the largest batch size that fits into a single GPU multiplied by the number of slots. This approach is commonly known as weak scaling. The third step of Determined\u2019s distributed training loop incurs the majority of the communication overhead. Since deep learning models typically perform dense updates, where every model parameter is updated for every training sample, batch_size does not affect how long it takes workers to communicate updates. However, increasing global_batch_size does reduce the required number of passes through the training loop, thus reducing the total communication overhead. Determined optimizes the communication in the third step by using an efficient form of ring all-reduce, which minimizes the amount of communication necessary for all the workers to communicate their updates. Furthermore, Determined reduces the communication overhead by overlapping computation (steps 1 & 2) and communication (step 3) by communicating updates for deeper layers concurrently with computing updates for the shallower layers. Visit Advanced Optimizations for additional optimizations for reducing the communication overhead.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Performance Optimization",
      "lvl3": "Debugging Performance Bottlenecks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#debugging-performance-bottlenecks",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Performance Optimization",
      "lvl3": "Debugging Performance Bottlenecks",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#debugging-performance-bottlenecks",
    "content": "Scaling up distributed training from one machine to two machines may result in non-linear speedup because intra-machine communication (e.g., NVLink) is often significantly faster than inter-machine communication. Scaling up beyond two machines often provides close to linear speed-up, but it does vary depending on the model characteristics. If observing unexpected scaling performance, assuming you have scaled your global_batch_size proportionally with slots_per_trial, it\u2019s possible that training performance is being bottlenecked by network communication or disk I/O. To check if your training is bottlenecked by communication, we suggest setting optimizations.aggregation_frequency in the experiment configuration to a very large number (e.g., 1000). This setting results in communicating updates once every 1000 batches. Comparing throughput with an aggregation_frequency of 1 vs. an aggregation_frequency of 1000 will demonstrate the communication overhead. For more guidance on optimizing communication, see Advanced Optimizations. To check if your training is bottlenecked by I/O, we encourage users to experiment with using synthetic datasets. If you observe that I/O is a significant bottleneck, we suggest optimizing the data input pipeline to the model (e.g., copy training data to local SSDs).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Training Effectively with Large Batch Sizes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#training-effectively-with-large-batch-sizes",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training Concepts",
      "lvl1": "Distributed Training Concepts",
      "lvl2": "Training Effectively with Large Batch Sizes",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-introduction.html#training-effectively-with-large-batch-sizes",
    "content": "To improve the performance of distributed training, we recommend using the largest possible global_batch_size, setting it to be largest batch size that fits into a single GPU multiplied by the number of slots. However, training with a large global_batch_size can have adverse effects on the convergence (accuracy) of the model. The following techniques can be used for training with large batch sizes: Start with the original learning rate used for a single GPU and gradually increase it to number of slots * original learning rate throughout the first several epochs. For more details, see Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. Use custom optimizers designed for large batch training, such as RAdam, LARS, or LAMB. In our experience, RAdam has been particularly effective. Applying these techniques often requires hyperparameter modifications. To help automate this process, use the Hyperparameter Tuning capabilities in Determined.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#reproducibility",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#reproducibility",
    "content": "Determined aims to support reproducible machine learning experiments: that is, the result of running a Determined experiment should be deterministic, so that rerunning a previous experiment should produce an identical model. For example, if the model produced from an experiment is ever lost, it can be recovered by rerunning the experiment that produced it.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Status",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#status",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Status",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#status",
    "content": "The current version of Determined provides limited support for reproducibility; unfortunately, the hardware and software stack typically used for deep learning makes perfect reproducibility very challenging. Determined can control and reproduce the following sources of randomness: Hyperparameter sampling decisions. The initial weights for a given hyperparameter configuration. Shuffling of training data in a trial. Dropout or other random layers. Determined currently does not offer support for controlling non-determinism in floating-point operations. Modern deep learning frameworks typically implement training using floating point operations that result in non-deterministic results, particularly on GPUs. If only CPUs are used for training, reproducible results can be achieved, as described in the following sections.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Random Seeds",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#random-seeds",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Random Seeds",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#random-seeds",
    "content": "Each Determined experiment is associated with an experiment seed: an integer ranging from 0 to 231\u20131. The experiment seed can be set using the reproducibility.experiment_seed field of the experiment configuration. If an experiment seed is not explicitly specified, the master will assign one automatically. The experiment seed is used as a source of randomness for any hyperparameter sampling procedures. The experiment seed is also used to generate a trial seed for every trial associated with the experiment. In the Trial interface, the trial seed is accessible within the trial class using self.ctx.get_trial_seed().",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Coding Guidelines",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#coding-guidelines",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Coding Guidelines",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#coding-guidelines",
    "content": "To achieve reproducible initial conditions in an experiment, please follow these guidelines: Use the np.random or random APIs for random procedures, such as shuffling of data. Both PRNGs will be initialized with the trial seed by Determined automatically. Use the trial seed to seed any randomized operations (e.g., initializers, dropout) in your framework of choice. For example, Keras initializers accept an optional seed parameter. Again, it is not necessary to set any graph-level PRNGs (e.g., TensorFlow\u2019s tf.set_random_seed), as Determined manages this for you.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Deterministic Floating Point on CPUs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#deterministic-floating-point-on-cpus",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Deterministic Floating Point on CPUs",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#deterministic-floating-point-on-cpus",
    "content": "When doing CPU-only training with TensorFlow, it is possible to achieve floating-point reproducibility throughout optimization. If using the TFKerasTrial API, implement the optional session_config() method to override the default session configuration: def session_config(self) -> tf.ConfigProto: return tf.ConfigProto( intra_op_parallelism_threads=1, inter_op_parallelism_threads=1 ) Disabling thread parallelism may negatively affect performance. Only enable this feature if you understand and accept this trade-off.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Pausing Experiments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#pausing-experiments",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Reproducibility",
      "lvl1": "Reproducibility",
      "lvl2": "Pausing Experiments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/reproducibility.html#pausing-experiments",
    "content": "TensorFlow does not fully support the extraction or restoration of a single, global RNG state. Consequently, pausing experiments that use a TensorFlow-based framework may introduce an additional source of entropy.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training with Determined",
      "lvl1": "Distributed Training with Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/index.html#distributed-training-with-determined",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Distributed Training with Determined",
      "lvl1": "Distributed Training with Determined",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/index.html#distributed-training-with-determined",
    "content": "Learn how to perform optimized distributed training with Determined to speed up the training of a single trial. In Concepts of Distributed Training, you\u2019ll learn about the following topics: How Determined distributed training works Reducing computation and communication overhead Training effectively with large batch sizes Model characteristics that affect performance Debugging performance bottlenecks Optimizing training Visit Implementing Distributed Training to discover how to implement distributed training, including the following: Connectivity considerations for multi-machine training Configuration including slots per trial and global batch size Considerations for concurrent data downloads Details to be aware regarding scheduler behavior Accelerating inference workloads Additional Resources: Learn how Configuration Templates can help reduce redundancy. Discover how Determined aims to support reproducible machine learning experiments in Reproducibility. In Optimizing Training, you\u2019ll learn about out-of-the box tools you can use for instrumenting training.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#implementing-distributed-training",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Connectivity",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#connectivity",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Connectivity",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#connectivity",
    "content": "Multi-machine training necessitates that all machines are capable of establishing a direct connection. Firewall rules or network configurations might exist that prevent machines in your cluster from communicating with each other. You can verify that agent machines can connect with each other outside of Determined by using tools such as ping or netcat. More rarely, if agents have multiple network interfaces and some of them are not routable, Determined may pick one of those interfaces rather than one that allows one agent to contact another. In this case, it is possible to explicitly set the network interface used for distributed training, as described in dtrain_network_interface.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#configuration",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Slots Per Trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#slots-per-trial",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Slots Per Trial",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#slots-per-trial",
    "content": "The resources.slots_per_trial field in the experiment configuration controls the number of GPUs used to train a single trial. By default, this field is set to a value of 1, which disables distributed training. If you increase the slots_per_trial value, this will automatically enable multi-GPU training. Bear in mind that these GPUs can either be located on a single machine or distributed across multiple machines. The experiment configuration merely dictates the number of GPUs to be used in the training process, while the Determined job scheduler decides whether to schedule the task on a single agent or multiple agents. Whether the job scheduler schedules the task on a single agent or multiple agents depends on the machines in the cluster and other active workloads. Multi-machine parallelism allows you to further parallelize training across more GPUs. To use this feature, set slots_per_trial to a multiple of the total number of GPUs on an agent machine. For example, if your resource pool consists of multiple 8-GPU agent machines, valid slots_per_trial values would be 16, 24, 32, and so on. In the following configuration, trials will use the combined resources of multiple machines to train a model: resources: slots_per_trial: 16 # Two 8-GPU agent machines will be used in a trial For distributed multi-machine training, Determined will automatically detect a common network interface that is shared by the agent machines. If your cluster has multiple common network interfaces, specify the fastest one. To do this, configure the dtrain_network_interface in the master configuration file. When the slots_per_trial field is set, the per-slot (i.e., per-GPU) batch size is set to global_batch_size // slots_per_trial. The per-slot and global batch sizes can be accessed through the context using context.get_per_slot_batch_size() and context.get_global_batch_size(), respectively. If global_batch_size is not evenly divisible by slots_per_trial, the remainder is dropped. When scheduling a multi-machine distributed training job, Determined prefers that the job use all of the slots (GPUs) on an agent. The section on Scheduling Behavior describes this preference in more detail. You might have existing tasks that are running on a single machine that are preventing your multi-GPU trials from acquiring sufficient GPUs. To alleviate this, you may want to consider adjusting slots_per_trial or terminating existing tasks to free up slots in your cluster.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Global Batch Size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#global-batch-size",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Global Batch Size",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#global-batch-size",
    "content": "You can reduce computational overhead by setting the global_batch_size to the largest batch size that fits into a single GPU multiplied times the number of slots. The global_batch_size field will be automatically respected by the Trial APIs. To use this hyperparameter with the Core API, you\u2019ll need to reference global_batch_size explicitly and organize your code to respect its value. During distributed training, the global_batch_size specified in the experiment configuration file is partitioned across slots_per_trial GPUs. The per-GPU batch size is set to: global_batch_size // slots_per_trial. Recall that if global_batch_size is not evenly divisible by slots_per_trial, the remainder is dropped. For convenience, the per-GPU batch size can be accessed via the Trial API, using context.get_per_slot_batch_size. For improved performance, weak-scaling is recommended. Weak-scaling means proportionally increasing your global_batch_size with slots_per_trial. For example, you might change global_batch_size and slots_per_trial from 32 and 1 to 128 and 4, respectively. You can visit the blog post, Scaling deep learning workloads, to learn more about weak scaling. Note that adjusting global_batch_size can impact your model convergence, which in turn can affect your training and/or testing accuracy. You might need to adjust model hyperparameters, such as the learning rate, or consider using a different optimizer when training with larger batch sizes.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Advanced Optimizations",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#advanced-optimizations",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Configuration",
      "lvl3": "Advanced Optimizations",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#advanced-optimizations",
    "content": "The following optimizations can further reduce training time. optimizations.aggregation_frequency controls how many batches are evaluated before exchanging gradients. This optimization increases your effective batch size to aggregation_frequency * global_batch_size. optimizations.aggregation_frequency is useful in scenarios where directly increasing the batch size is not possible (for example, due to GPU memory limitations). optimizations.gradient_compression reduces the time it takes to transfer gradients between GPUs. optimizations.auto_tune_tensor_fusion automatically identifies the optimal message size during gradient transfers, thereby reducing communication overhead. optimizations.average_training_metrics averages the training metrics across GPUs at the end of every training workload, a process that requires communication. average_training_metrics is set to true by default and typically does not have a significant impact on training performance. However, if you have a very small scheduling_unit, disabling this option could improve performance. When disabled, only the training metrics from the chief GPU are reported. This impacts results shown in the WebUI and TensorBoard but does not influence model behavior or hyperparameter search. To learn more about these optimizations, visit the optimizations section in the Experiment Configuration Reference. If you\u2019re not seeing improved performance with distributed training, your model might have a performance bottleneck that can\u2019t be directly alleviated by using multiple GPUs, such as with data loading. You\u2019re encouraged to experiment with a synthetic dataset in order to verify the performance of multi-GPU training. Multi-machine distributed training is designed to maximize performance by training with all the resources of a machine. This can lead to situations where an experiment is created but never becomes active, such as when the number of GPUs requested does not factor into (divide evenly) the machines available, or when another experiment is already using some GPUs on a machine. If an experiment does not become active after a minute or so, please ensure that slots_per_trial is a multiple of the number of GPUs available on a machine. You can also use the CLI command det task list to check if any other tasks are using GPUs and preventing your experiment from using all the GPUs on a machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Downloading Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#downloading-data",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Downloading Data",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#downloading-data",
    "content": "When performing distributed training, Determined automatically creates one process for each GPU that is being used for training. Each of these processes attempts to download training and/or validation data, so it is important to ensure that concurrent data downloads do not conflict with one another. One way to achieve this is to include a unique identifier in the local file system path where the downloaded data is stored. A convenient identifier is the rank of the current process. The process rank is automatically assigned by Determined and is unique among all trial processes. You can accomplish this by leveraging the self.context.distributed.get_rank() function. The following example demonstrates how to accomplish this when downloading data from S3. In this example, the S3 bucket name is configured via a data.bucket field in the experiment configuration file. import boto3 import os def download_data_from_s3(self): s3_bucket = self.context.get_data_config()[\"bucket\"] download_directory = f\"/tmp/data-rank{self.context.distributed.get_rank()}\" data_file = \"data.csv\" s3 = boto3.client(\"s3\") os.makedirs(download_directory, exist_ok=True) filepath = os.path.join(download_directory, data_file) if not os.path.exists(filepath): s3.download_file(s3_bucket, data_file, filepath) return download_directory",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Scheduling Behavior",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#scheduling-behavior",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Scheduling Behavior",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#scheduling-behavior",
    "content": "The Determined master schedules distributed training jobs automatically, ensuring that all of the compute resources required for a job are available before the job is launched. Here are some important details regarding slots_per_trial and the scheduler\u2019s behavior: If slots_per_trial is less than or equal to the number of slots on a single agent, Determined considers scheduling multiple distributed training jobs on a single agent. This approach is designed to improve utilization and to allow multiple small training jobs to run on a single agent. For example, an agent with eight GPUs could be assigned two 4-GPU jobs or four 2-GPU jobs. If slots_per_trial is greater than the number of slots on a single agent, Determined schedules the distributed training job onto multiple agents. To ensure good performance and utilize the full network bandwidth of each machine and to minimize inter-machine networking, Determined prefers utilizing all of the agent GPUs on a machine. For example, if all the agents in your cluster have eight GPUs each, you should submit jobs with slots_per_trial set to a multiple of eight, such as 8, 16, or 24. The scheduler can find fits for distributed jobs against agents of different sizes. This is configured via the allowing_heterogeneous_fits parameter. This parameter defaults to false. By default Determined requires that the job use all of the slots (GPUs) on an agent. If these scheduling constraints for multi-machine distributed training are not satisfied, and you have not configured the allowing_heterogeneous_fits parameter, distributed training jobs are not scheduled and wait indefinitely. For example, if every agent in the cluster has eight GPUs, a job with slots_per_trial set to 12 is never scheduled. If a multi-GPU experiment does not become active after a minute or so, please ensure that slots_per_trial is set so that it can be scheduled within these constraints. You can also use the CLI command det task list to check if any other tasks are using GPUs and preventing your experiment from using all the GPUs on a machine.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Distributed Inference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#distributed-inference",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Implementing Distributed Training",
      "lvl1": "Implementing Distributed Training",
      "lvl2": "Distributed Inference",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/dtrain-implement.html#distributed-inference",
    "content": "PyTorch users have the option to use the existing distributed training workflow with PyTorchTrial to accelerate their inference workloads. This workflow is not yet officially supported, therefore, users must specify certain training-specific artifacts that are not used for inference. To run a distributed batch inference job, create a new PyTorchTrial and follow these steps: Load the trained model and build the inference dataset using build_validation_data_loader(). Specify the inference step using evaluate_batch() or evaluate_full_dataset(). Register a dummy optimizer. Specify a build_training_data_loader() that returns a dummy dataloader. Specify a no-op train_batch() that returns an empty map of metrics. Once the new PyTorchTrial object is created, use the experiment configuration to distribute inference in the same way as training. cifar10_pytorch_inference serves as an example of distributed batch inference.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#configuration-templates",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#configuration-templates",
    "content": "In a typical organization, many Determined configuration files will share similar settings. This can cause redundancy. For example, all training workloads run at a given organization might use the same checkpoint storage configuration. One way to reduce this redundancy is to use configuration templates. This feature allows users to consolidate settings shared across many experiments into a single YAML file that can be referenced by configurations needings those settings. Each configuration template has a unique name and is stored by the Determined master. If a configuration employs a template, the effective configuration of the task will be the outcome of merging the two YAML files (the configuration file and the template). The semantics of this merge operation are described below. Determined stores this effective configuration to ensure future changes to a template do not affect the reproducibility of experiments that used a previous version of the configuration template. A single configuration file can use at most one configuration template. A configuration template cannot itself use another configuration template.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Leveraging Templates to Simplify Experiment Configurations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#leveraging-templates-to-simplify-experiment-configurations",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Leveraging Templates to Simplify Experiment Configurations",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#leveraging-templates-to-simplify-experiment-configurations",
    "content": "An experiment can adopt a configuration template by using the --template command-line option to denote the name of the desired template. The following example demonstrates splitting an experiment configuration into a reusable template and a simplified configuration. name: mnist_tf_const checkpoint_storage: type: s3 access_key: my-access-key secret_key: my-secret-key bucket: my-bucket-name data: base_url: https://s3-us-west-2.amazonaws.com/determined-ai-datasets/mnist/ training_data: train-images-idx3-ubyte.gz training_labels: train-labels-idx1-ubyte.gz validation_set_size: 10000 hyperparameters: base_learning_rate: 0.001 weight_cost: 0.0001 global_batch_size: 64 n_filters1: 40 n_filters2: 40 searcher: name: single metric: error max_length: batches: 500 smaller_is_better: true You may find that many experiments share the same values for the checkpoint_storage field, leading to redundancy. To reduce the redundancy you could use a configuration template. For example, consider the following template: description: template-tf-gpu checkpoint_storage: type: s3 access_key: my-access-key secret_key: my-secret-key bucket: my-bucket-name The experiment configuration for this experiment can then be written using the following code: description: mnist_tf_const data: base_url: https://s3-us-west-2.amazonaws.com/determined-ai-datasets/mnist/ training_data: train-images-idx3-ubyte.gz training_labels: train-labels-idx1-ubyte.gz validation_set_size: 10000 hyperparameters: base_learning_rate: 0.001 weight_cost: 0.0001 global_batch_size: 64 n_filters1: 40 n_filters2: 40 searcher: name: single metric: error max_length: batches: 500 smaller_is_better: true To launch the experiment with the template: $ det experiment create --template template-tf-gpu mnist_tf_const.yaml <model_code>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Managing Templates through the CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#managing-templates-through-the-cli",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Managing Templates through the CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#managing-templates-through-the-cli",
    "content": "The Determined command-line interface provides tools for managing configuration templates including listing, creating, updating, and deleting templates. This functionality can be accessed through the det template sub-command. This command can be abbreviated as det tpl. To list all the templates stored in Determined, use det template list. To show additional details, use the -d or --detail option. $ det tpl list Name ------------------------- template-s3-tf-gpu template-s3-pytorch-gpu template-s3-keras-gpu To create or update a template, use det tpl set template_name template_file. $ cat > template-s3-keras-gpu.yaml << EOL description: template-s3-keras-gpu checkpoint_storage: type: s3 access_key: my-access-key secret_key: my-secret-key bucket: my-bucket-name EOL $ det tpl set template-s3-keras-gpu template-s3-keras-gpu.yaml Set template template-s3-keras-gpu",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Merge Behavior",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#merge-behavior",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Configuration Templates",
      "lvl1": "Configuration Templates",
      "lvl2": "Merge Behavior",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/dtrain/config-templates.html#merge-behavior",
    "content": "To demonstrate merge behavior when merging a template and a configuration, let\u2019s say we have a template that specifies top-level fields a and b, and a configuration that specifies fields b and c. The resulting merged configuration will have fields a, b, and c. The value for field a will simply be the value set in the template. Likewise, the value for field c will be whatever was specified in the configuration. The final value for field b, however, depends on the value\u2019s type: If the field specifies a scalar value, the configuration\u2019s value will take precedence in the merged configuration (overriding the template\u2019s value). If the field specifies a list value, the merged value will be the concatenation of the list specified in the template and the one specified in the configuration. There are certain exceptions for bind_mounts and resources.devices. There could be situations where both the original config and the template will attempt to mount to the same container_path, resulting in an unstable configuration. In such scenarios, the original configuration is preferred, and the conflicting bind mount or device from the template is omitted in the merged result. If the field specifies an object value, the resulting value will be the object generated by recursively applying this merging algorithm to both objects.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#best-practices",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "General Tips for the Trial Definition",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#general-tips-for-the-trial-definition",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "General Tips for the Trial Definition",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#general-tips-for-the-trial-definition",
    "content": "Do: Use framework abstractions to implement learning rate scheduling instead of directly changing the learning rate. See tf.keras.optimizers.schedules.LearningRateSchedule and determined.pytorch.LRScheduler as examples. For code that needs to download artifacts (e.g., data, configurations, pretrained weights), download to a tempfile.TemporaryDirectory unique to the Python process. This will avoid race conditions when using distributed training, in which Determined executes multiple Python processes in the same task container. To learn more about distributed training with Determined, visit the conceptual overview or the intro to implementing distributed training. Do not use instance attributes on a trial class to save any state over time (e.g., storing metric history in a self attribute). The Trial instance will only save and restore model weights and optimizer state over time; self attributes may be reset to their initial state at any time if the Determined cluster reschedules the trial to another task container.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "Separate Configuration from Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#separate-configuration-from-code",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "Separate Configuration from Code",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#separate-configuration-from-code",
    "content": "We encourage a clean separation of code from configuration via the experiment configuration. Specifically, you are encouraged to use the pre-defined fields in the experiment configuration, such as the searcher, hyperparameters, optimizations, and resources. This not only allows you to reuse the trial definition when you tune different configuration fields but also improve the visualibility because those fields can be browsed in our WebUI. Do: Move any hardcoded scalar values to the hyperparameters or data fields in the experiment configuration. Use context.get_hparam() or context.get_data_config() to reference them in code. Move any hardcoded filesystem paths (e.g., /data/train.csv) to the data field of the experiment configuration. Use context.get_data_config() to reference them in code. Do not use global variables in your model definition; consider moving them to the experiment configuration.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "Understand Dependencies",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#understand-dependencies",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Best Practices",
      "lvl1": "Best Practices",
      "lvl2": "Understand Dependencies",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/best-practices/index.html#understand-dependencies",
    "content": "We encourage tracking the dependencies associated with every workflow via the environment field. Understanding and standardizing the environment you use to execute Python in your development environment will pay off dividends in portability, allowing you to flexibly move between local, cloud, and on-premise cluster environments. Do: Ramp up quickly by using our default environment Docker image, optionally specifying additional PyPI dependencies by using pip install in startup-hook.sh. As your dependencies increase in complexity, invest in building and using a custom Docker image that meets your needs. Pin Python package dependencies to specific versions (e.g., <package>==<version>) in build tools. Do not modify the PYTHONPATH or PATH environment variables to import libraries by circumventing the Python packaging system.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#model-management",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Use Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#use-checkpoints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Use Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#use-checkpoints",
    "content": "When a model is trained with Determined, checkpoints are automatically saved to external storage. These checkpoints can then be exported for use outside Determined. See Checkpoints for details.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Archive Experiments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#archive-experiments",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Archive Experiments",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#archive-experiments",
    "content": "After training, you can archive experiments to clean up your list of experiments. Archiving is designed to make it easier to organize experiments by omitting information about experiment runs that are no longer relevant (e.g., training jobs that failed with an error or jobs submitted as part of the model development process). When an experiment is archived, it is hidden from the default view in both the WebUI and the Determined CLI, but all of the metadata associated with the experiment (including checkpoints) is preserved. An experiment can subsequently be unarchived if desired, without losing any of the experiment\u2019s metadata.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Delete Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#delete-checkpoints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Delete Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#delete-checkpoints",
    "content": "The best way to delete a checkpoint is to modify the garbage collection policy of the experiment that created the checkpoint. For example, to delete all of the experiments associated with an experiment, run: det experiment set gc-policy --save-experiment-best 0 --save-trial-best 0 --save-trial-latest 0 <experiment-id>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Manage Trained Models",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#manage-trained-models",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Model Management",
      "lvl1": "Model Management",
      "lvl2": "Manage Trained Models",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/index.html#manage-trained-models",
    "content": "Determined includes a built-in model registry to manage trained models and their respective versions.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#checkpoints",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#checkpoints",
    "content": "Determined provides APIs for downloading checkpoints and loading them into memory in a Python process. This guide discusses: Querying model checkpoints from trials and experiments. Loading model checkpoints in Python. Storing additional user-defined metadata in a checkpoint. Using the Determined CLI to download checkpoints to disk. The Checkpoint Export API is a subset of the features found in the client module.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Querying Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#querying-checkpoints",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Querying Checkpoints",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#querying-checkpoints",
    "content": "The ExperimentReference class is a reference to an experiment. The reference contains the top_checkpoint() method. Without arguments, the method will check the experiment configuration searcher field for the metric and smaller_is_better values. These values are used to sort the experiment\u2019s checkpoints by validation performance. The searcher settings in the following snippet from an experiment configuration file will result in checkpoints being sorted by the loss metric in ascending order. searcher: metric: \"loss\" smaller_is_better: true The following snippet of Python code can be run after the specified experiment has generated a checkpoint. It returns an instance of Checkpoint representing the checkpoint that has the best validation metric. from determined.experimental import client checkpoint = client.get_experiment(id).top_checkpoint() Checkpoints can be sorted by any metric using the sort_by keyword argument, which defines which metric to use, and smaller_is_better, which defines whether to sort the checkpoints in ascending or descending order with respect to the specified metric. from determined.experimental import client checkpoint = ( client.get_experiment(id).top_checkpoint(sort_by=\"accuracy\", smaller_is_better=False) ) You may also query multiple checkpoints at the same time using the top_n_checkpoints() method. Only the single best checkpoint from each trial is considered; out of those, the checkpoints with the best validation metric values are returned in sorted order, with the best one first. For example, the following snippet returns the top five checkpoints from distinct trials of a specified experiment. from determined.experimental import client checkpoints = client.get_experiment(id).top_n_checkpoints(5) This method also accepts sort_by and smaller_is_better arguments. TrialReference is used for fine-grained control over checkpoint selection within a trial. It contains a top_checkpoint() method, which mirrors top_checkpoint() for an experiment. It also contains select_checkpoint(), which offers three ways to query checkpoints: best: Returns the best checkpoint based on validation metrics as discussed above. When using best, smaller_is_better and sort_by are also accepted. latest: Returns the most recent checkpoint for the trial. uuid: Returns the checkpoint with the specified UUID. The following snippet showcases how to use the different modes for selecting checkpoints. from determined.experimental import client trial = client.get_trial(id) best_checkpoint = trial.top_checkpoint() most_accurate_checkpoint = trial.select_checkpoint( best=True, sort_by=\"accuracy\", smaller_is_better=False ) most_recent_checkpoint = trial.select_checkpoint(latest=True) specific_checkpoint = client.get_checkpoint(uuid=\"uuid-for-checkpoint\")",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#using-the-checkpoint-class",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#using-the-checkpoint-class",
    "content": "The Checkpoint class can both download the checkpoint from persistent storage and load it into memory in a Python process. The download() method downloads a checkpoint from persistent storage to a directory on the local file system. By default, checkpoints are downloaded to checkpoints/<checkpoint-uuid>/ (relative to the current working directory). The download() method accepts path as an optional parameter, which changes the checkpoint download location. from determined.experimental import client checkpoint = client.get_experiment(id).top_checkpoint() checkpoint_path = checkpoint.download() specific_path = checkpoint.download(path=\"specific-checkpoint-path\") The load() method downloads the checkpoint, if it does not already exist locally, and loads it into memory. The return type and behavior is different depending on whether you are using TensorFlow or PyTorch.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": "PyTorch Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#pytorch-checkpoints",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": "PyTorch Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#pytorch-checkpoints",
    "content": "When using PyTorch models, the load() method returns a parameterized instance of your trial class as defined in the experiment config under the entrypoint field. The trained model can then be accessed from the model attribute of the Trial object, as shown in the following snippet. from determined.experimental import client from determined import pytorch checkpoint = client.get_experiment(id).top_checkpoint() path = checkpoint.download() trial = pytorch.load_trial_from_checkpoint_path(path) model = trial.model predictions = model(samples) PyTorch checkpoints are saved using pickle and loaded as PyTorch API objects (see the PyTorch documentation for details).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": "TensorFlow Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#tensorflow-checkpoints",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Using the Checkpoint Class",
      "lvl3": "TensorFlow Checkpoints",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#tensorflow-checkpoints",
    "content": "When using TensorFlow models, the load() method returns a compiled model with weights loaded. This will be the same TensorFlow model returned by your build_model() method defined in your trial class specified by the experiment config entrypoint field. The trained model can then be used to make predictions as shown in the following snippet. from determined.experimental import client from determined import keras checkpoint = client.get_experiment(id).top_checkpoint() path = checkpoint.download() model = keras.load_model_from_checkpoint_path(path) predictions = model(samples) TensorFlow checkpoints are saved in either the saved_model or h5 formats and are loaded as trackable objects (see documentation for tf.compat.v1.saved_model.load_v2 for details).",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Adding User-Defined Checkpoint Metadata",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#adding-user-defined-checkpoint-metadata",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Adding User-Defined Checkpoint Metadata",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#adding-user-defined-checkpoint-metadata",
    "content": "You can add arbitrary user-defined metadata to a checkpoint via the Python SDK. This feature is useful for storing post-training metrics, labels, information related to deployment, etc. from determined.experimental import client checkpoint = client.get_experiment(id).top_checkpoint() checkpoint.add_metadata({\"environment\": \"production\"}) # Metadata will be stored in Determined and accessible on the checkpoint object. print(checkpoint.metadata) You may store an arbitrarily nested dictionary using the add_metadata() method. If the top level key already exists the entire tree beneath it will be overwritten. from determined.experimental import client checkpoint = client.get_experiment(id).top_checkpoint() checkpoint.add_metadata({\"metrics\": {\"loss\": 0.12}}) checkpoint.add_metadata({\"metrics\": {\"acc\": 0.92}}) print(checkpoint.metadata) # Output: {\"metrics\": {\"acc\": 0.92}} You may remove metadata via the remove_metadata() method. The method accepts a list of top level keys. The entire tree beneath the keys passed will be deleted. from determined.experimental import client checkpoint = client.get_experiment(id).top_checkpoint() checkpoint.remove_metadata([\"metrics\"])",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Downloading Checkpoints using the CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#downloading-checkpoints-using-the-cli",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Downloading Checkpoints using the CLI",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#downloading-checkpoints-using-the-cli",
    "content": "The Determined CLI can be used to view all the checkpoints associated with an experiment: $ det experiment list-checkpoints <experiment-id> Checkpoints are saved to external storage, according to the checkpoint_storage section in the experiment configuration. Each checkpoint has a UUID, which is used as the name of the checkpoint directory on the external storage system. For example, if the experiment is configured to save checkpoints to a shared file system: checkpoint_storage: type: shared_fs host_path: /mnt/nfs-volume-1 A checkpoint with UUID b3ed462c-a6c9-41e9-9202-5cb8ff00e109 can be found in the directory /mnt/nfs-volume-1/b3ed462c-a6c9-41e9-9202-5cb8ff00e109. Determined offers the following CLI commands for downloading checkpoints locally: det checkpoint download det trial download det experiment download When downloading checkpoints in a shared file system, we assume the same shared file system is mounted locally. The det checkpoint download command downloads a checkpoint for the given UUID as shown below: # Download a specific checkpoint. det checkpoint download 46985143-af68-4d48-ab91-a6447052ca49 The command should display output resembling the following upon successfully downloading the checkpoint. Local checkpoint path: checkpoints/46985143-af68-4d48-ab91-a6447052ca49 Batch | Checkpoint UUID | Validation Metrics -----------+--------------------------------------+--------------------------------------------- 1000 | 46985143-af68-4d48-ab91-a6447052ca49 | { | | \"num_inputs\": 0, | | \"validation_metrics\": { | | \"loss\": 7.906739711761475, | | \"accuracy\": 0.9646000266075134, | | \"global_step\": 1000, | | \"average_loss\": 0.12492649257183075 | | } | | } The det trial download command downloads checkpoints for a specified trial. Similar to the TrialReference API, the det trial download command accepts --best, --latest, and --uuid options. # Download best checkpoint. det trial download <trial_id> --best # Download best checkpoint to a particular directory. det trial download <trial_id> --best --output-dir local_checkpoint The command should display output resembling the following upon successfully downloading the checkpoint. Local checkpoint path: checkpoints/46985143-af68-4d48-ab91-a6447052ca49 Batch | Checkpoint UUID | Validation Metrics -----------+--------------------------------------+--------------------------------------------- 1000 | 46985143-af68-4d48-ab91-a6447052ca49 | { | | \"num_inputs\": 0, | | \"validation_metrics\": { | | \"loss\": 7.906739711761475, | | \"accuracy\": 0.9646000266075134, | | \"global_step\": 1000, | | \"average_loss\": 0.12492649257183075 | | } | | } The --latest and --uuid options are used as follows: # Download the most recent checkpoint. det trial download <trial_id> --latest # Download a specific checkpoint. det trial download <trial_id> --uuid <uuid-for-checkpoint> Finally, the det experiment download command provides a similar experience to using the Python SDK. # Download the best checkpoint for a given experiment. det experiment download <experiment_id> # Download the best 3 checkpoints for a given experiment. det experiment download <experiment_id> --top-n 3 The command should display output resembling the following upon successfully downloading the checkpoints. Local checkpoint path: checkpoints/8d45f621-8652-4268-8445-6ae9a735e453 Batch | Checkpoint UUID | Validation Metrics -----------+--------------------------------------+------------------------------------------ 400 | 8d45f621-8652-4268-8445-6ae9a735e453 | { | | \"num_inputs\": 56, | | \"validation_metrics\": { | | \"val_loss\": 0.26509127765893936, | | \"val_categorical_accuracy\": 1 | | } | | } Local checkpoint path: checkpoints/62131ba1-983c-49a8-98ef-36207611d71f Batch | Checkpoint UUID | Validation Metrics -----------+--------------------------------------+------------------------------------------ 1600 | 62131ba1-983c-49a8-98ef-36207611d71f | { | | \"num_inputs\": 50, | | \"validation_metrics\": { | | \"val_loss\": 0.04411194706335664, | | \"val_categorical_accuracy\": 1 | | } | | } Local checkpoint path: checkpoints/a36d2a61-a384-44f7-a84b-8b30b09cb618 Batch | Checkpoint UUID | Validation Metrics -----------+--------------------------------------+------------------------------------------ 400 | a36d2a61-a384-44f7-a84b-8b30b09cb618 | { | | \"num_inputs\": 46, | | \"validation_metrics\": { | | \"val_loss\": 0.07265569269657135, | | \"val_categorical_accuracy\": 1 | | } | | }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Checkpoints",
      "lvl1": "Checkpoints",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/checkpoints.html#next-steps",
    "content": "Python SDK Reference: The reference documentation for this API. Organize Models in the Model Registry",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#organize-models-in-the-model-registry",
    "content": null,
    "type": "lvl1",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 90,
      "position": 1
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": null,
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#organize-models-in-the-model-registry",
    "content": "Determined includes built-in support for a model registry, which makes it easy to organize trained models and their respective versions. Common use-cases for the model registry include: Grouping related checkpoints together, including checkpoints across experiments. Storing metadata about a model that is specific to your problem or organization. Examples include references to production systems, dataset links, Git links, and metrics calculated outside of Determined. Retrieving the latest version of a model for downstream tasks like serving or batch inference. The model registry contains a set of models. Each model has a unique name and zero or more model versions. A model version consists of a version number and a checkpoint, which represents the state of a trained model. The model registry is designed to be flexible, and the best way to use it depends on your organization\u2019s requirements and workflow. For example, one approach is to define a model for each high-level task you want to use machine learning for (e.g., \u201cobject-detection\u201d, \u201csentiment-analysis\u201d, etc.). Then each version of this model would correspond to a new approach to solving that task. Note that different versions of a model might come from different experiments, use different network architectures, or even use different deep learning frameworks. Another approach would be to register a model named \u201cFasterRCNN\u201d, and ensure that each version of the model uses that network architecture.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 2
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#manage-models",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 3
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#manage-models",
    "content": "A model has a unique name, an optional description, user-defined metadata, and zero or more model versions. A model\u2019s metadata can contain arbitrary information about the model. The following is an example JSON representation of a model for illustration. { \"mnist_cnn\": { \"description\": \"a character recognition model\", \"metadata\": { \"dataset_url\": \"http://yann.lecun.com/exdb/mnist/\", \"git_url\": \"http://github.com/user/repo\" }, \"versions\": [] } }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 4
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Use the WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#use-the-webui",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 5
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Use the WebUI",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#use-the-webui",
    "content": "Models can be created and edited through the WebUI. Some features can only be accessed through the WebUI, such as writing longform notes in Markdown. A new model can be created on the Model Registry page, which can be found in the navigation bar. This launches a modal where basic information can be specified before creation. A new version can be added to a model from the Checkpoint modal. This launches a model where basic information can be specified before registering the model version. A new model can also be created from here. Once a model and/or version is created, notes, metadata, and other information can be added and edited through the Model Registry page after selecting the model or model version in question.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 6
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Register Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#register-models",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 7
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Register Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#register-models",
    "content": "A model can be added to the registry via the WebUI, Python SDK, REST API, or CLI. This guide will cover the Python and CLI methods. For information on the REST API, see the REST API documentation. The following example demonstrates how to add a new model to the registry; create_model() returns an instance of the Model class. The new model will not have any versions (model checkpoints) associated with it; adding versions to a model is described below. from determined.experimental import Determined model = Determined().create_model( \"model_name\", description=\"optional description\", metadata={\"optional\": \"JSON serializable dictionary\"}, ) Similarly, you can create a model from the CLI using the following command. det model create <model_name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 8
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Query Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#query-models",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 9
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Query Models",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#query-models",
    "content": "The following example returns models registered in Determined as a list of Model objects. Models can be sorted by name, description, creation time, and last updated time. Additionally, models can be filtered by name or description via the Python SDK. For sorting and ordering options, see ModelSortBy and ModelOrderBy respectively. from determined.experimental import Determined, ModelOrderBy d = Determined() all_models = d.get_models() chronological_sort = d.get_models(sort_by=ModelSortBy.CREATION_TIME) # Find all models with \"mnist\" in their name. Some possible model names # are \"mnist_pytorch\", \"mnist_cnn\", \"mnist\", etc. mnist_models = d.get_models(name=\"mnist\") # Find all models whose description contains \"ocr\". ocr_models = d.get_models(description=\"ocr\") Similarly, you can list models from the CLI using the following command. det model list --sort-by={name,description,creation_time,last_updated_time} --order-by={asc,desc} The following snippet queries for a single model by name. from determined.experimental import Determined model = Determined().get_model(\"model_name\") The CLI equivalent is below. The describe command will print information about the latest version of the model by default as well. det model describe <model_name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 10
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Modify Model Metadata",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#modify-model-metadata",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 11
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Models",
      "lvl3": "Modify Model Metadata",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#modify-model-metadata",
    "content": "Currently, model metadata can only be edited via the WebUI and Python SDK. The following example demonstrates how to use this API. from determined.experimental import Determined model = Determined().get_model(\"model_name\") # Metadata is merged with existing metadata. model.add_metadata({\"key\", \"value\"}) model.add_metadata({\"metrics\": {\"test_set_loss\": 0.091}}) # Result: {\"key\": \"value\", \"metrics\": {\"test_set_loss\": 0.091}}. # Only top-level keys are merged. The following statement will replace the # previous value of the \"metrics\" key. model.add_metadata({\"metrics\": {\"test_set_acc\": 0.97}}) # Result: {\"key\": \"value\", \"metrics\": {\"test_set_acc\": 0.97}}. model.remove_metadata([\"key\"]) # Result: {\"metrics\": {\"test_set_acc\": 0.97}}.",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 12
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#manage-model-versions",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 13
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#manage-model-versions",
    "content": "Once a model has been added to the registry, you can add one or more checkpoints to it. These registered checkpoints are known as model versions. Version numbers are assigned by the registry; version numbers start at 1 and increment each time a new model version is registered. For illustration, this JSON document illustrates an example model with a single registered version. { \"mnist_cnn\": { \"description\": \"a character recognition model\", \"metadata\": { \"dataset_url\": \"http://yann.lecun.com/exdb/mnist/\", \"git_url\": \"http://github.com/user/repo\" }, \"versions\": [ { \"version_number\": 1, \"checkpoint\": { \"uuid\": \"6a24d772-f1f7-4655-9061-22d582afd96c\", \"experiment_config\": { \"...\": \"...\" }, \"experimentId\": 1, \"trialId\": 1, \"hparams\": { \"...\": \"...\" }, \"batchNumber\": 100, \"resources\": { \"...\": \"...\" }, \"metadata\": {}, \"framework\": \"tensorflow-1.14.0\", \"format\": \"h5\", \"metrics\": { \"...\": \"...\" } } } ] } }",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 14
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": "Create Versions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#create-versions",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 15
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": "Create Versions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#create-versions",
    "content": "The following snippet registers a new version of a model. register_version() returns an updated Checkpoint object representing the new model version. from determined.experimental import Determined d = Determined() checkpoint = d.get_experiment(exp_id).top_checkpoint() model = d.get_model(\"model_name\") model_version = model.register_version(checkpoint.uuid) Similarly, a new model version can be registered using the CLI as follows: det model register-version <model_name> <checkpoint_uuid>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 16
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": "Access Versions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#access-versions",
    "content": null,
    "type": "lvl3",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 70,
      "position": 17
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Manage Model Versions",
      "lvl3": "Access Versions",
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#access-versions",
    "content": "The example below demonstrates how to retrieve versions of a model from the registry. If no version number is specified, the most recent version of the model is returned. get_version() returns an instance of Checkpoint; as shown in the example, this makes it easy to perform common operations like downloading the checkpoint to local storage or loading the trained model into memory. from determined.experimental import Determined model = Determined().get_model(\"model_name\") specific_version = model.get_version(3) latest_version = model.get_version() # Depending on the framework used to create the checkpoint, loading from # the checkpoint may return either a PyTorchTrial instance or a TensorFlow # object representing the trained model. path = latest_version.checkpoint.download() from determined import pytorch my_pytorch_trial = pytorch.load_trial_from_checkpoint_path(path) from determined import keras my_keras_model = keras.load_model_from_checkpoint_path(path) The following example lists all the versions of a model. By default, model versions are returned in descending order such that the most recent versions are returned first. from determined.experimental import Determined model = Determined().get_model(\"model_name\") model_versions = model.get_versions() The CLI equivalent is as follows: det model list-versions <model_name>",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 18
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#next-steps",
    "content": null,
    "type": "lvl2",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 80,
      "position": 19
    }
  },
  {
    "recordVersion": "v3",
    "hierarchy": {
      "lvl0": "Organize Models in the Model Registry",
      "lvl1": "Organize Models in the Model Registry",
      "lvl2": "Next Steps",
      "lvl3": null,
      "lvl4": null,
      "lvl5": null,
      "lvl6": null
    },
    "url": "model-dev-guide/model-management/model-registry-org.html#next-steps",
    "content": "Python SDK Reference: The reference documentation for this API. Checkpoints",
    "type": "content",
    "lang": "en",
    "language": "en",
    "weight": {
      "pageRank": 0,
      "level": 0,
      "position": 20
    }
  }
]