{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f891729d-9030-4d9e-a7be-e81386ae820f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SQLCoder\n",
    "\n",
    "Welcome to the third part of the tutorial series on building a chatbot over a corpus of private\n",
    "documents using Large Language Models (LLMs).\n",
    "\n",
    "In this Notebook, you set up an SQLCoder, an Large Language Model (LLM) that can take a user's\n",
    "question and turn it into a SQL query that can be run against a database. This is a powerful tool\n",
    "that can be used to query a database using natural language.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Creating the SQLCoder Deployment](#creating-the-sqlcoder-deployment)\n",
    "1. [Conclusion and Next Steps](#conclusion-and-next-steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22867e3-a69c-488a-819e-cced462be9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b51ccb-f1d3-4132-a88b-62b84d90b11a",
   "metadata": {},
   "source": [
    "# Creating the SQLCoder Deployment\n",
    "\n",
    "Apply the deployment spec below to create the SQLCoder deployment. This will create a new deployment\n",
    "with the SQLCoder model and expose it within the cluster using a Kubernetes service. Make sure to\n",
    "provide the PVC name that houses the SQLCode name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pvc = \"...\"  # PVC name here\n",
    "\n",
    "sql_llm_deploy = \"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    io.kompose.service: sql-llm\n",
    "  name: sql-llm\n",
    "spec:\n",
    "  progressDeadlineSeconds: 600\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      io.kompose.service: sql-llm\n",
    "  strategy:\n",
    "    type: Recreate\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        hpe-ezua/app: ezaf-other\n",
    "        hpe-ezua/type: infra-service\n",
    "        io.kompose.network/nvidia-llm: \"true\"\n",
    "        io.kompose.service: sql-llm\n",
    "    spec:\n",
    "      containers:\n",
    "      - args:\n",
    "        - --model\n",
    "        - defog/sqlcoder-7b-2\n",
    "        - --tensor-parallel-size\n",
    "        - \"2\"\n",
    "        env:\n",
    "        - name: HF_HOME\n",
    "          value: /cache\n",
    "        - name: NUMBA_CACHE_DIR\n",
    "          value: /tmp/numba_cache\n",
    "        image: vllm/vllm-openai:v0.4.1\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        name: sqlcoder-server\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "          hostPort: 8000\n",
    "          name: 8000-tcp\n",
    "          protocol: TCP\n",
    "        resources:\n",
    "          limits:\n",
    "            nvidia.com/gpu: \"2\"\n",
    "          requests:\n",
    "            nvidia.com/gpu: \"2\"\n",
    "        volumeMounts:\n",
    "        - mountPath: /cache\n",
    "          name: sql-llm-claim\n",
    "      priorityClassName: sql-bot\n",
    "      restartPolicy: Always\n",
    "      volumes:\n",
    "      - name: sql-llm-claim\n",
    "        persistentVolumeClaim:\n",
    "          claimName: {0}\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  labels:\n",
    "    io.kompose.service: sql-llm\n",
    "  name: sql-llm\n",
    "spec:\n",
    "  ports:\n",
    "  - name: 8000-tcp\n",
    "    port: 8000\n",
    "    protocol: TCP\n",
    "    targetPort: 8000\n",
    "  selector:\n",
    "    io.kompose.service: sql-llm\n",
    "  type: ClusterIP\n",
    "\"\"\".format(model_pvc)\n",
    "\n",
    "with open(\"sql-llm.yaml\", \"w\") as f:\n",
    "    f.write(sql_llm_deploy)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"sql-llm.yaml\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20235af7-7b47-4b68-8f6d-f0b01b0c23e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusion and Next Steps\n",
    "\n",
    "Congratulations on completing this crucial step in this tutorial series! You've successfully\n",
    "deployed an SQLCoder LLM that can take a user's question and turn it into a SQL query that can be\n",
    "run against a database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
