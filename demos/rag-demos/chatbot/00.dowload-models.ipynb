{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Models\n",
    "\n",
    "The first step in this demo is to download the models you will use. You will\n",
    "download two models:\n",
    "\n",
    "- An Large Language Model (LLM) model to support the agent's decisions as well\n",
    "  as the chatbot's responses.\n",
    "- An Embeddings model to embed the users queries so the agent can retrieve the\n",
    "  most relevant information from the vector store.\n",
    "\n",
    "To this end, you will need the following:\n",
    "\n",
    "- An NGC API Key, to download the Embeddings model.\n",
    "- A Hugging Face API Key, to download the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import getpass\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGC_API_KEY = getpass.getpass(\"Enter your NGC API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_API_KEY = getpass.getpass(\"Enter your Hugging Face API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to create:\n",
    "\n",
    "- An NGC CLI secret to store the NGC API Key. You will use this secret to\n",
    "  download the Embeddings model.\n",
    "- A Hugging Face CLI secret to store the Hugging Face API Key. You will use\n",
    "  this secret to download the LLM.\n",
    "- An image pull secret to download the NVIDIA-specific containers you will use\n",
    "  throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_cli_secret = \"\"\"\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: ngc-cli-secret\n",
    "type: Opaque\n",
    "data:\n",
    "  NGC_CLI_API_KEY: {0}\n",
    "\"\"\".format(base64.b64encode(NGC_API_KEY.encode()).decode())\n",
    "\n",
    "with open(\"ngc-cli-secret.yaml\", \"w\") as f:\n",
    "    f.write(ngc_cli_secret)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"ngc-cli-secret.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_cli_secret = \"\"\"apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: hf-cli-secret\n",
    "type: Opaque\n",
    "data:\n",
    "  HF_CLI_API_KEY: {0}\n",
    "\"\"\".format(base64.b64encode(HF_API_KEY.encode()).decode())\n",
    "\n",
    "with open(\"hf-cli-secret.yaml\", \"w\") as f:\n",
    "    f.write(hf_cli_secret)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"hf-cli-secret.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVCR_SECRET = \"\"\"\n",
    "{{\"auths\":{{\"nvcr.io\":{{\"username\":\"$oauthtoken\",\"password\":\"{0}\"}}}}}}\n",
    "\"\"\"\n",
    "\n",
    "ngc_secret = \"\"\"apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: ngc-secret\n",
    "type: kubernetes.io/dockerconfigjson\n",
    "data:\n",
    "  .dockerconfigjson: {0}\n",
    "\"\"\".format(base64.b64encode(NVCR_SECRET.format(NGC_API_KEY).encode()).decode())\n",
    "\n",
    "with open(\"ngc-secret.yaml\", \"w\") as f:\n",
    "    f.write(ngc_secret)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"ngc-secret.yaml\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will create a PVC that will store the models you download. This PVC\n",
    "will be mounted to the containers you will use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repository = \"\"\"\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: model-repository\n",
    "spec:\n",
    "  accessModes:\n",
    "  - ReadWriteMany\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 500Gi\n",
    "  storageClassName: dataplatform\n",
    "\"\"\"\n",
    "\n",
    "with open(\"model-repository.yaml\", \"w\") as f:\n",
    "    f.write(model_repository)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"model-repository.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_downloader_job = \"\"\"apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: ngc-downloader\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: ngc-downloader\n",
    "        image: nvcr.io/ohlfw0olaadg/ea-participants/ngc-cli:v3.41.2\n",
    "        command:\n",
    "        - \"/bin/sh\"\n",
    "        - \"-c\"\n",
    "        - |\n",
    "          echo \"Creating directory /mnt/model-repo/model-store\"\n",
    "          mkdir -p /mnt/model-repo/model-store\n",
    "          echo \"Downloading embeddings model...\"\n",
    "          ngc registry model download-version --dest /mnt/model-repo/model-store ohlfw0olaadg/ea-participants/nv-embed-qa:4\n",
    "          echo \"Model downloaded successfully.\"\n",
    "        volumeMounts:\n",
    "        - name: model-volume\n",
    "          mountPath: /mnt/model-repo\n",
    "        env:\n",
    "        - name: NGC_CLI_API_KEY\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: ngc-cli-secret\n",
    "              key: NGC_CLI_API_KEY\n",
    "        - name: NGC_CLI_ORG\n",
    "          value: \"nemo-microservice (ohlfw0olaadg)\"\n",
    "        securityContext:\n",
    "          runAsUser: 0\n",
    "      restartPolicy: Never\n",
    "      imagePullSecrets:\n",
    "      - name: ngc-secret\n",
    "      volumes:\n",
    "      - name: model-volume\n",
    "        persistentVolumeClaim:\n",
    "          claimName: model-repository\n",
    "\"\"\"\n",
    "\n",
    "with open(\"ngc-downloader-job.yaml\", \"w\") as f:\n",
    "    f.write(ngc_downloader_job)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"ngc-downloader-job.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_downloader_job = \"\"\"apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: hf-downloader\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: hf-downloader\n",
    "        image: python:3.12.3\n",
    "        command:\n",
    "        - \"/bin/sh\"\n",
    "        - \"-c\"\n",
    "        - |\n",
    "          echo \"Installing the HuggingFace CLI...\"\n",
    "          pip install -U huggingface_hub[cli]\n",
    "          echo \"Creating directory /mnt/model-repo/Llama-2-7b-chat-hf\"\n",
    "          mkdir -p /mnt/model-repo/Llama-2-7b-chat-hf\n",
    "          echo \"Downloading Llama 2 7B Chat from HuggingFace HUB...\"\n",
    "          huggingface-cli download meta-llama/Llama-2-7b-chat-hf --local-dir /mnt/model-repo/Llama-2-7b-chat-hf\n",
    "          echo \"Model downloaded successfully.\"\n",
    "        volumeMounts:\n",
    "        - name: model-volume\n",
    "          mountPath: /mnt/model-repo\n",
    "        env:\n",
    "        - name: HF_TOKEN\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: hf-cli-secret\n",
    "              key: HF_CLI_API_KEY\n",
    "        securityContext:\n",
    "          runAsUser: 0\n",
    "      restartPolicy: Never\n",
    "      volumes:\n",
    "      - name: model-volume\n",
    "        persistentVolumeClaim:\n",
    "          claimName: model-repository\n",
    "\"\"\"\n",
    "\n",
    "with open(\"hf-downloader-job.yaml\", \"w\") as f:\n",
    "    f.write(hf_downloader_job)\n",
    "\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", \"hf-downloader-job.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
