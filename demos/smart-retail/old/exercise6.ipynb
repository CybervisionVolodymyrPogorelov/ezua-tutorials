{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c186f6-e95f-463b-980c-1b8c83503285",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 6: Serve a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d070da-f40b-4756-bad3-9a2a66190dc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What we will cover:\n",
    "- Create a Kserve container\n",
    "- Register the model and move it to Production\n",
    "- Prediction test to validate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9f249-d5ad-4cda-b875-199647ed87ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set up the group parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbc2bf-0ac0-4125-97d5-a1c77d5710d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set your group name (in quotes)\n",
    "group_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbbe00-5d21-482f-a4fc-d9a0737806be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if GROUP is empty\n",
    "if not group_name:\n",
    "    print(\"Please set your group name before proceeding to the next cell.\")\n",
    "    # You can also raise an exception to stop execution if needed\n",
    "    # raise ValueError(\"Group name is empty. Please set a valid group name.\")\n",
    "else:\n",
    "    print(\"Group name is set. Proceed to the next cell.\")\n",
    "    # Your code for the next cell can go here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ee564-9e1a-46c2-9b7c-093df4839c33",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Double Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61908eb-2fca-487a-b791-f1a35841b903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if GROUP is empty\n",
    "if not group_name:\n",
    "    print(\"Please set your group name before proceeding to the next cell.\")\n",
    "    # You can also raise an exception to stop execution if needed\n",
    "    # raise ValueError(\"Group name is empty. Please set a valid group name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490016b4-5cb1-4699-9c00-ecfc8a19cd23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prerequisites \n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important</b> Make sure it's valid\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129f625-a3e9-4b4b-a95e-ee05fbe6ba0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parametes\n",
    "\n",
    "# adapt to your EZUA Domain name\n",
    "EZAF_ENV = \"pe1.ezmeral.de\"\n",
    "# type of demo (DemoContent - in this case fruit and vegetables) \n",
    "DC = \"fruit\"\n",
    "# path to end2end demo (not data)\n",
    "end2end_path = '/mnt/datasources/datafabric/ezua/end2end/' \n",
    "# path to data for model training, etc.\n",
    "path = '/mnt/datasources/datafabric/ezua/end2end-data/fruits/' \n",
    "# path to GROUP INDIVIDUAL data for model training, etc.\n",
    "group_data_path = '/mnt/datasources/datafabric/ezua/end2end-group-data/' \n",
    "# experiment name prefix for mlflow\n",
    "experiment_name = \"end2end-retail-demo\"\n",
    "exp_name = group_name + \"-\" + experiment_name\n",
    "model_name = \"end2end-retail-demo\"\n",
    "g_model_name = group_name + \"-\" + model_name\n",
    "# artifact_path = \"end2end-retail-demo\"\n",
    "artifact_path = \"model\"\n",
    "# password for UA user login (needed to get keycloak token)\n",
    "UA_password = \"Hpepoc@123\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9589dae-75c1-49fd-8ea8-72dc42c2c429",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import required libraries & refresh the token\n",
    "- Ignore the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f8bf7-ed2c-4c87-934c-9c79e6a63a93",
   "metadata": {
    "papermill": {
     "duration": 7.613981,
     "end_time": "2023-03-13T20:40:28.950010",
     "exception": false,
     "start_time": "2023-03-13T20:40:21.336029",
     "status": "completed"
    },
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "from kubernetes import client \n",
    "from kubernetes.client import V1EnvVar\n",
    "from kubernetes.client.models import V1ObjectMeta\n",
    "from kserve import KServeClient\n",
    "from kserve import constants\n",
    "from kserve import utils\n",
    "from kserve import V1beta1InferenceService\n",
    "from kserve import V1beta1InferenceServiceSpec\n",
    "from kserve import V1beta1PredictorSpec\n",
    "from kserve import V1beta1TFServingSpec\n",
    "import urllib3\n",
    "import mlflow\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fc0fa-91f8-4f05-abb3-e43c55a2e9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%update_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f91cdf-3363-4e18-8a00-4b47067899ca",
   "metadata": {
    "papermill": {
     "duration": 0.074875,
     "end_time": "2023-03-13T21:22:22.585971",
     "exception": false,
     "start_time": "2023-03-13T21:22:22.511096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Model Serving with KServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f9206-fe7f-4eca-8e10-c362a5555039",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get details from MLflow\n",
    "- Connect to MLflow\n",
    "- Get the last version like it the last exercise please `Fill in` the missing parts\n",
    "- Get the model URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad2cc0-5394-47cb-9f66-a748090a2049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an instance of the MlflowClient\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Get the latest model version in Production\n",
    "latest_versions = client.get_latest_versions(name=g_model_name, stages=[\"Production\"])\n",
    "latest_version = latest_versions[0]\n",
    "\n",
    "# Get the model uri\n",
    "model_uri = latest_version.source.replace(\"model\", \"tf_serving_model\")\n",
    "\n",
    "print(\"Model Storage Path in S3 (as shown in MLflow): \" + str(model_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86510ed0-768f-42ec-95f4-4fec04238247",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the Inference Service using YAML config file\n",
    "- Set paramenters\n",
    "- Create a yaml file with the name set in parameter 'yaml_name' (see below)\n",
    "- The yaml cointains Kubernetes (k8s) objects \"Secret\", \"ServiceAccount\" and \"InferenceService\"\n",
    "- Execute a kubctl command on the 'shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c184d0-e715-4266-9e0d-974aa86d66ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set paramentes\n",
    "isvc_name = group_name + \"-\" + experiment_name + \"-isvc\"\n",
    "secret_name = 's3-proxy-kserve-secret'\n",
    "sa_name = 's3-proxy-kserve-sa'\n",
    "yaml_name = './s3-proxy-kserve.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffa909-99c2-461f-99d7-ce26bbe4ed58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create YAML configuration file\n",
    "with open(yaml_name, 'w') as file:\n",
    "    text = f\"\"\"---\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: \"{secret_name}\"\n",
    "  annotations:\n",
    "    serving.kserve.io/s3-cabundle: \"\"\n",
    "    serving.kserve.io/s3-endpoint: \"local-s3-service.ezdata-system.svc.cluster.local:30000/\"\n",
    "    serving.kserve.io/s3-useanoncredential: \"false\"\n",
    "    serving.kserve.io/s3-usehttps: \"0\"\n",
    "    serving.kserve.io/s3-verifyssl: \"0\"\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: \"{os.environ['AUTH_TOKEN']}\"\n",
    "  AWS_SECRET_ACCESS_KEY: \"s3\"\n",
    "type: Opaque\n",
    "\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: \"{sa_name}\"\n",
    "secrets:\n",
    "  - name: \"access-token\"\n",
    "\n",
    "---\n",
    "apiVersion: serving.kserve.io/v1beta1\n",
    "kind: InferenceService\n",
    "metadata:\n",
    "  name: \"{isvc_name}\"\n",
    "  annotations:\n",
    "    \"sidecar.istio.io/inject\": \"false\"\n",
    "spec:\n",
    "  predictor:\n",
    "    tensorflow:\n",
    "      storageUri: \"{model_uri}\"\n",
    "    serviceAccountName: \"{sa_name}\"\n",
    "\"\"\"\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57361cd2-819f-4901-a800-ea72c8a30ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the container\n",
    "!kubectl apply -f {yaml_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17d8fd-2f82-43ee-825e-2c33cfcdee9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait until the ISvc is ready\n",
    "kserve_client = KServeClient()\n",
    "kserve_client.wait_isvc_ready(isvc_name, watch=True, timeout_seconds=120)\n",
    "print(f\"\\nInferenceService {isvc_name} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a530e1d-1ad4-4a9e-b899-f658a3746323",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb00d4-dc0a-4787-849e-71e4dab53751",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Head back to the menu and select `Model Serving`\n",
    "![image.png](./images/exercise6/menu3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5095b51-0f7f-4591-b3d6-82b04a165272",
   "metadata": {
    "tags": []
   },
   "source": [
    "### It will open Kubeflow\n",
    "- You can see here a list of the model served\n",
    "\n",
    "![image.png](./images/exercise6/Kserve1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb024006-4c79-4b20-af12-11ce92f320fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Look into your model\n",
    "- Clic on your model\n",
    "- Now you can see the model details including the serving endpoint, model URI and predictor used\n",
    "\n",
    "![image.png](./images/exercise6/Kserve2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a8fec-becf-4bda-a5db-b4076333da45",
   "metadata": {
    "papermill": {
     "duration": 0.074875,
     "end_time": "2023-03-13T21:22:22.585971",
     "exception": false,
     "start_time": "2023-03-13T21:22:22.511096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37d6bb-deec-4cac-907d-8942c107524b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%update_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0ef51-c563-4060-a8be-14952d5ad8f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Paramenters\n",
    "- `Fill in` the URL using the `URL internal` from Kubeflow\n",
    "- We're using the URL internal because we're making the prediction within the Kubernetes cluster otherwise we would use the External one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298806c-5d0f-4746-8267-67e7791c3e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"Fill in\"\n",
    "\n",
    "# Build the Serving URL\n",
    "serving_url = url + \"/v1/models/\" + isvc_name + \":predict\"\n",
    "\n",
    "print(\"Serving URL: \" + serving_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a306316-8590-4167-b3d9-228a91ad63c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the prediction functions\n",
    "- The prediction is different when you are serving the model as you don't directly use an image but a json file\n",
    "- Therefore, the first step is to convert the image to json so that it can be sent to the Inference Service\n",
    "- We use the same approach to preprocess the image\n",
    "- Then format it to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dccaa-6807-420b-a661-5cb19418255a",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_image(url):\n",
    "    # Load the image\n",
    "    response = requests.get(url, stream=True)\n",
    "    img = Image.open(response.raw)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Display the image\n",
    "    display(img)\n",
    "\n",
    "    return img_array\n",
    "\n",
    "def format_data(data):\n",
    "    # Convert the NumPy array to a list\n",
    "    data_list = data.tolist()\n",
    "    \n",
    "    # Format the list as a JSON string\n",
    "    data_formatted = json.dumps(data_list)\n",
    "    \n",
    "    # Create a JSON request string with the formatted data\n",
    "    json_request = '{{ \"instances\" : {} }}'.format(data_formatted)\n",
    "    \n",
    "    return json_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeac32f-c210-4df2-9d61-9c2171529b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the image and tranform it to JSON\n",
    "- `Fill in` the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240cfb5f-485f-4512-81a7-5039f5e8c45c",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Define your labels\n",
    "labels = \"Fill in\"\n",
    "\n",
    "# Specify the image URL here.\n",
    "image_url = \"Fill in\"\n",
    "\n",
    "preprocessed_image = preprocess_image(image_url)\n",
    "\n",
    "json_request = format_data(preprocessed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7361c8-8ac5-45af-8339-0a08cfd818ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the prediction request\n",
    "- Use the Serving URL & JSON data generated above\n",
    "- Create a header that includes the token to authentorize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f837d-ab95-4b9a-bdd6-ead2c9684f15",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Make the POST request\n",
    "response = requests.post(serving_url, data=json_request, verify=False)\n",
    "\n",
    "# Print the raw response content\n",
    "print(\"Raw Response Content:\")\n",
    "print(response.content.decode('utf-8'))\n",
    "\n",
    "# If the response is in JSON format, you can decode it\n",
    "if response.headers.get(\"Content-Type\") == \"application/json\":\n",
    "    response_data = response.json()\n",
    "    predictions = response_data['predictions']\n",
    "\n",
    "    formatted_predictions = [[round(pred * 100, 2) for pred in prediction] for prediction in predictions]\n",
    "\n",
    "    print(\"\\nTranslated Predictions:\")\n",
    "    for label, prob in zip(labels, formatted_predictions[0]):\n",
    "        print(f\"- {label}: \\t{prob}%\")\n",
    "\n",
    "    # Get the predicted label\n",
    "    predicted_label_index = np.argmax(formatted_predictions)\n",
    "    predicted_label = labels[predicted_label_index]\n",
    "\n",
    "    print(\"\\nPredicted class label:\", predicted_label, \"with\", formatted_predictions[0][predicted_label_index], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33620aa3-f065-4c09-9362-749c1274fcee",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3349fb7-473a-4d4f-a583-ef4ddeb68743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-cuda-full:ezaf-fy23-q2",
   "experiment": {
    "id": "new",
    "name": "jk-fruit-demo"
   },
   "experiment_name": "jk-fruit-demo",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "random",
     "algorithmSettings": [
      {
       "name": "random_state",
       "value": "10"
      },
      {
       "name": "acq_optimizer",
       "value": "auto"
      },
      {
       "name": "acq_func",
       "value": "gp_hedge"
      },
      {
       "name": "base_estimator",
       "value": "GP"
      }
     ]
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "additionalMetricNames": [],
     "goal": 1,
     "objectiveMetricName": "stage",
     "type": "maximize"
    },
    "parallelTrialCount": 3,
    "parameters": [
     {
      "feasibleSpace": {
       "max": "50",
       "min": "1",
       "step": "1"
      },
      "name": "param_epoch",
      "parameterType": "int"
     },
     {
      "feasibleSpace": {
       "list": [
        "32",
        "64"
       ]
      },
      "name": "param_batch_size",
      "parameterType": "categorical"
     },
     {
      "feasibleSpace": {
       "max": "10",
       "min": "1",
       "step": "1"
      },
      "name": "param_patience",
      "parameterType": "int"
     }
    ]
   },
   "katib_run": false,
   "pipeline_description": "fruit-veg",
   "pipeline_name": "fruit-veg",
   "snapshot_volumes": false,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:add-ldapcert-secret:true",
    "label:add-sssd-secret:true",
    "label:add-user-s3-secret:true"
   ],
   "storage_class_name": "dataplatform",
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/mnt/shared/",
     "name": "kubeflow-pipeline",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2679.282234,
   "end_time": "2023-03-13T21:24:51.692744",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-13T20:40:12.410510",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
